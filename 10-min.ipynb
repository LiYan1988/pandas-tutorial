{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20180401', periods=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-04-01', '2018-04-02', '2018-04-03', '2018-04-04',\n",
       "               '2018-04-05', '2018-04-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B    float64\n",
       "C    float64\n",
       "D    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-04-01', '2018-04-02', '2018-04-03', '2018-04-04',\n",
       "               '2018-04-05', '2018-04-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28118161,  0.00806849,  2.0310983 ,  0.09889041],\n",
       "       [ 0.3686297 , -0.60939058, -0.57836243, -0.26097705],\n",
       "       [ 2.0485164 , -0.73284824,  1.19096515,  0.22067664],\n",
       "       [ 0.59364869, -0.37573496, -1.48948893, -0.40495425],\n",
       "       [ 0.1826977 , -0.68186598,  0.54877672,  0.01620098],\n",
       "       [-0.55248415,  2.0229308 , -0.47526228,  1.4194038 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.393304</td>\n",
       "      <td>-0.061473</td>\n",
       "      <td>0.204621</td>\n",
       "      <td>0.181540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.913704</td>\n",
       "      <td>1.056805</td>\n",
       "      <td>1.294036</td>\n",
       "      <td>0.649277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.165212</td>\n",
       "      <td>-0.663747</td>\n",
       "      <td>-0.552587</td>\n",
       "      <td>-0.191683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.275664</td>\n",
       "      <td>-0.492563</td>\n",
       "      <td>0.036757</td>\n",
       "      <td>0.057546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.537394</td>\n",
       "      <td>-0.087882</td>\n",
       "      <td>1.030418</td>\n",
       "      <td>0.190230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean   0.393304 -0.061473  0.204621  0.181540\n",
       "std    0.913704  1.056805  1.294036  0.649277\n",
       "min   -0.552484 -0.732848 -1.489489 -0.404954\n",
       "25%   -0.165212 -0.663747 -0.552587 -0.191683\n",
       "50%    0.275664 -0.492563  0.036757  0.057546\n",
       "75%    0.537394 -0.087882  1.030418  0.190230\n",
       "max    2.048516  2.022931  2.031098  1.419404"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    6\n",
       "B    6\n",
       "C    6\n",
       "D    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <th>2018-04-02 00:00:00</th>\n",
       "      <th>2018-04-03 00:00:00</th>\n",
       "      <th>2018-04-04 00:00:00</th>\n",
       "      <th>2018-04-05 00:00:00</th>\n",
       "      <th>2018-04-06 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.368630</td>\n",
       "      <td>2.048516</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.552484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.008068</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>2.022931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2.031098</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>-0.475262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.098890</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2018-04-01  2018-04-02  2018-04-03  2018-04-04  2018-04-05  2018-04-06\n",
       "A   -0.281182    0.368630    2.048516    0.593649    0.182698   -0.552484\n",
       "B    0.008068   -0.609391   -0.732848   -0.375735   -0.681866    2.022931\n",
       "C    2.031098   -0.578362    1.190965   -1.489489    0.548777   -0.475262\n",
       "D    0.098890   -0.260977    0.220677   -0.404954    0.016201    1.419404"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.098890</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>-0.281182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>-0.260977</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>0.368630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>0.220677</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>2.048516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>-0.404954</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>0.593649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.016201</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.182698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>1.419404</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.552484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   D         C         B         A\n",
       "2018-04-01  0.098890  2.031098  0.008068 -0.281182\n",
       "2018-04-02 -0.260977 -0.578362 -0.609391  0.368630\n",
       "2018-04-03  0.220677  1.190965 -0.732848  2.048516\n",
       "2018-04-04 -0.404954 -1.489489 -0.375735  0.593649\n",
       "2018-04-05  0.016201  0.548777 -0.681866  0.182698\n",
       "2018-04-06  1.419404 -0.475262  2.022931 -0.552484"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_index(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='D', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01   -0.281182\n",
       "2018-04-02    0.368630\n",
       "2018-04-03    2.048516\n",
       "2018-04-04    0.593649\n",
       "2018-04-05    0.182698\n",
       "2018-04-06   -0.552484\n",
       "Freq: D, Name: A, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    0.098890\n",
       "2018-04-02   -0.260977\n",
       "2018-04-03    0.220677\n",
       "2018-04-04   -0.404954\n",
       "2018-04-05    0.016201\n",
       "2018-04-06    1.419404\n",
       "Freq: D, Name: D, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    0.098890\n",
       "2018-04-02   -0.260977\n",
       "2018-04-03    0.220677\n",
       "2018-04-04   -0.404954\n",
       "2018-04-05    0.016201\n",
       "2018-04-06    1.419404\n",
       "Freq: D, Name: D, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['20180401':'20180403']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.368630\n",
       "B   -0.609391\n",
       "C   -0.578362\n",
       "D   -0.260977\n",
       "Name: 2018-04-02 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[dates[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2018-04-01 -0.281182  0.008068\n",
       "2018-04-02  0.368630 -0.609391\n",
       "2018-04-03  2.048516 -0.732848\n",
       "2018-04-04  0.593649 -0.375735\n",
       "2018-04-05  0.182698 -0.681866\n",
       "2018-04-06 -0.552484  2.022931"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['A', 'B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01   -0.281182\n",
       "2018-04-02    0.368630\n",
       "2018-04-03    2.048516\n",
       "2018-04-04    0.593649\n",
       "2018-04-05    0.182698\n",
       "2018-04-06   -0.552484\n",
       "Freq: D, Name: A, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.A>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-02    0.368630\n",
       "2018-04-03    2.048516\n",
       "2018-04-04    0.593649\n",
       "2018-04-05    0.182698\n",
       "Freq: D, Name: A, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A[df.A>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28118161284571147"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01       NaN  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630       NaN       NaN       NaN\n",
       "2018-04-03  2.048516       NaN  1.190965  0.220677\n",
       "2018-04-04  0.593649       NaN       NaN       NaN\n",
       "2018-04-05  0.182698       NaN  0.548777  0.016201\n",
       "2018-04-06       NaN  2.022931       NaN  1.419404"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D      E\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890    one\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977    one\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677    two\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954  three\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201   four\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404  three"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2['E'] = ['one', 'one','two','three','four','three']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df2['E'].isin(['one', 'three'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    1\n",
       "2018-04-02    2\n",
       "2018-04-03    3\n",
       "2018-04-04    4\n",
       "2018-04-05    5\n",
       "2018-04-06    6\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=dates)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.281182</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D  F\n",
       "2018-04-01 -0.281182  0.008068  2.031098  0.098890  1\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977  2\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677  3\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954  4\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201  5\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404  6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['F'] = s1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D  F\n",
       "2018-04-01  0.000000  0.000000  2.031098  0.098890  1\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977  2\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677  3\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954  4\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201  5\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404  6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[dates[0], 'A'] = 0\n",
    "df.iat[0, 1] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>0.609391</td>\n",
       "      <td>0.578362</td>\n",
       "      <td>0.260977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.375735</td>\n",
       "      <td>1.489489</td>\n",
       "      <td>0.404954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D  F\n",
       "2018-04-01  0.000000  0.000000  2.031098  0.098890  1\n",
       "2018-04-02  0.368630  0.609391  0.578362  0.260977  2\n",
       "2018-04-03  2.048516  0.732848  1.190965  0.220677  3\n",
       "2018-04-04  0.593649  0.375735  1.489489  0.404954  4\n",
       "2018-04-05  0.182698  0.681866  0.548777  0.016201  5\n",
       "2018-04-06  0.552484  2.022931  0.475262  1.419404  6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[df<0] = -df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C   E\n",
       "2018-04-01  0.000000  2.031098 NaN\n",
       "2018-04-02  0.368630 -0.578362 NaN\n",
       "2018-04-03  2.048516  1.190965 NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.reindex(index=dates[0:3], columns=list('AC')+['E'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C    E\n",
       "2018-04-01  0.000000  2.031098  1.0\n",
       "2018-04-02  0.368630 -0.578362  1.0\n",
       "2018-04-03  2.048516  1.190965  NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[dates[0:2], 'E'] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.36863</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         C    E\n",
       "2018-04-01  0.00000  2.031098  1.0\n",
       "2018-04-02  0.36863 -0.578362  1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>3.141593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C         E\n",
       "2018-04-01  0.000000  2.031098  1.000000\n",
       "2018-04-02  0.368630 -0.578362  1.000000\n",
       "2018-04-03  2.048516  1.190965  3.141593"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.fillna(value=np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A      C      E\n",
       "2018-04-01  False  False  False\n",
       "2018-04-02  False  False  False\n",
       "2018-04-03  False  False   True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C    E\n",
       "2018-04-01  0.000000  2.031098  1.0\n",
       "2018-04-02  0.368630 -0.578362  1.0\n",
       "2018-04-03  2.048516  1.190965  5.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A      C      E\n",
       "2018-04-01  False  False  False\n",
       "2018-04-02  False  False  False\n",
       "2018-04-03  False  False   True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.440168\n",
       "B   -0.062818\n",
       "C    0.204621\n",
       "D    0.181540\n",
       "F    3.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.440168\n",
       "B   -0.062818\n",
       "C    0.204621\n",
       "D    0.181540\n",
       "F    3.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    0.625998\n",
       "2018-04-02    0.183980\n",
       "2018-04-03    1.145462\n",
       "2018-04-04    0.464694\n",
       "2018-04-05    1.013162\n",
       "2018-04-06    1.682918\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    0.625998\n",
       "2018-04-02    0.183980\n",
       "2018-04-03    1.145462\n",
       "2018-04-04    0.464694\n",
       "2018-04-05    1.013162\n",
       "2018-04-06    1.682918\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    1.0\n",
       "2018-04-02    3.0\n",
       "2018-04-03    5.0\n",
       "2018-04-04    NaN\n",
       "2018-04-05    6.0\n",
       "2018-04-06    8.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    NaN\n",
       "2018-04-02    NaN\n",
       "2018-04-03    1.0\n",
       "2018-04-04    3.0\n",
       "2018-04-05    5.0\n",
       "2018-04-06    NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    1.0\n",
       "2018-04-02    3.0\n",
       "2018-04-03    5.0\n",
       "2018-04-04    NaN\n",
       "2018-04-05    6.0\n",
       "2018-04-06    8.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    5.0\n",
       "2018-04-02    NaN\n",
       "2018-04-03    6.0\n",
       "2018-04-04    8.0\n",
       "2018-04-05    NaN\n",
       "2018-04-06    NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shift(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = s.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    NaN\n",
       "2018-04-02    NaN\n",
       "2018-04-03    1.0\n",
       "2018-04-04    3.0\n",
       "2018-04-05    5.0\n",
       "2018-04-06    NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D  F\n",
       "2018-04-01  0.000000  0.000000  2.031098  0.098890  1\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977  2\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677  3\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954  4\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201  5\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404  6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>1.048516</td>\n",
       "      <td>-1.732848</td>\n",
       "      <td>0.190965</td>\n",
       "      <td>-0.779323</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>-2.406351</td>\n",
       "      <td>-3.375735</td>\n",
       "      <td>-4.489489</td>\n",
       "      <td>-3.404954</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>-4.817302</td>\n",
       "      <td>-5.681866</td>\n",
       "      <td>-4.451223</td>\n",
       "      <td>-4.983799</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D    F\n",
       "2018-04-01       NaN       NaN       NaN       NaN  NaN\n",
       "2018-04-02       NaN       NaN       NaN       NaN  NaN\n",
       "2018-04-03  1.048516 -1.732848  0.190965 -0.779323  2.0\n",
       "2018-04-04 -2.406351 -3.375735 -4.489489 -3.404954  1.0\n",
       "2018-04-05 -4.817302 -5.681866 -4.451223 -4.983799  0.0\n",
       "2018-04-06       NaN       NaN       NaN       NaN  NaN"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sub(s, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D  F\n",
       "2018-04-01  0.000000  0.000000  2.031098  0.098890  1\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977  2\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677  3\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954  4\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201  5\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404  6"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>1.452736</td>\n",
       "      <td>-0.162087</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.417146</td>\n",
       "      <td>-1.342239</td>\n",
       "      <td>2.643701</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>3.010795</td>\n",
       "      <td>-1.717974</td>\n",
       "      <td>1.154212</td>\n",
       "      <td>-0.346364</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>3.193492</td>\n",
       "      <td>-2.399840</td>\n",
       "      <td>1.702989</td>\n",
       "      <td>-0.330163</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>2.641008</td>\n",
       "      <td>-0.376909</td>\n",
       "      <td>1.227727</td>\n",
       "      <td>1.089241</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D   F\n",
       "2018-04-01  0.000000  0.000000  2.031098  0.098890   1\n",
       "2018-04-02  0.368630 -0.609391  1.452736 -0.162087   3\n",
       "2018-04-03  2.417146 -1.342239  2.643701  0.058590   6\n",
       "2018-04-04  3.010795 -1.717974  1.154212 -0.346364  10\n",
       "2018-04-05  3.193492 -2.399840  1.702989 -0.330163  15\n",
       "2018-04-06  2.641008 -0.376909  1.227727  1.089241  21"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>2.129989</td>\n",
       "      <td>3.129989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.240761</td>\n",
       "      <td>-0.819123</td>\n",
       "      <td>-1.080100</td>\n",
       "      <td>0.919900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>1.315668</td>\n",
       "      <td>2.506633</td>\n",
       "      <td>2.727310</td>\n",
       "      <td>5.727310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>-1.271575</td>\n",
       "      <td>-1.676529</td>\n",
       "      <td>2.323471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.499168</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>5.065809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>1.470447</td>\n",
       "      <td>0.995184</td>\n",
       "      <td>2.414588</td>\n",
       "      <td>8.414588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D         F\n",
       "2018-04-01  0.000000  0.000000  2.031098  2.129989  3.129989\n",
       "2018-04-02  0.368630 -0.240761 -0.819123 -1.080100  0.919900\n",
       "2018-04-03  2.048516  1.315668  2.506633  2.727310  5.727310\n",
       "2018-04-04  0.593649  0.217914 -1.271575 -1.676529  2.323471\n",
       "2018-04-05  0.182698 -0.499168  0.049608  0.065809  5.065809\n",
       "2018-04-06 -0.552484  1.470447  0.995184  2.414588  8.414588"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(np.cumsum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2.601001\n",
       "B    2.755779\n",
       "C    3.520587\n",
       "D    1.824358\n",
       "F    5.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-04-01    2.031098\n",
       "2018-04-02    2.609391\n",
       "2018-04-03    3.732848\n",
       "2018-04-04    5.489489\n",
       "2018-04-05    5.681866\n",
       "2018-04-06    6.552484\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: x.max() - x.min(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    0\n",
       "3    6\n",
       "4    4\n",
       "5    3\n",
       "6    6\n",
       "7    5\n",
       "8    4\n",
       "9    4\n",
       "dtype: int32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3\n",
       "6    2\n",
       "3    2\n",
       "5    1\n",
       "1    1\n",
       "0    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    0\n",
       "3    6\n",
       "4    4\n",
       "5    3\n",
       "6    6\n",
       "7    5\n",
       "8    4\n",
       "9    4\n",
       "dtype: int32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031098</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.368630</td>\n",
       "      <td>-0.609391</td>\n",
       "      <td>-0.578362</td>\n",
       "      <td>-0.260977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>2.048516</td>\n",
       "      <td>-0.732848</td>\n",
       "      <td>1.190965</td>\n",
       "      <td>0.220677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.593649</td>\n",
       "      <td>-0.375735</td>\n",
       "      <td>-1.489489</td>\n",
       "      <td>-0.404954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.182698</td>\n",
       "      <td>-0.681866</td>\n",
       "      <td>0.548777</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>-0.552484</td>\n",
       "      <td>2.022931</td>\n",
       "      <td>-0.475262</td>\n",
       "      <td>1.419404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D  F\n",
       "2018-04-01  0.000000  0.000000  2.031098  0.098890  1\n",
       "2018-04-02  0.368630 -0.609391 -0.578362 -0.260977  2\n",
       "2018-04-03  2.048516 -0.732848  1.190965  0.220677  3\n",
       "2018-04-04  0.593649 -0.375735 -1.489489 -0.404954  4\n",
       "2018-04-05  0.182698 -0.681866  0.548777  0.016201  5\n",
       "2018-04-06 -0.552484  2.022931 -0.475262  1.419404  6"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       A\n",
       "1       B\n",
       "2       C\n",
       "3    Aaba\n",
       "4    Baca\n",
       "5     NaN\n",
       "6    CABA\n",
       "7     dog\n",
       "8     cat\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a\n",
       "1       b\n",
       "2       c\n",
       "3    aaba\n",
       "4    baca\n",
       "5     NaN\n",
       "6    caba\n",
       "7     dog\n",
       "8     cat\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.193317</td>\n",
       "      <td>1.207970</td>\n",
       "      <td>1.622549</td>\n",
       "      <td>-1.130942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250589</td>\n",
       "      <td>-0.903680</td>\n",
       "      <td>-0.559647</td>\n",
       "      <td>-1.552191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.120327</td>\n",
       "      <td>-0.351508</td>\n",
       "      <td>-2.132311</td>\n",
       "      <td>0.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393667</td>\n",
       "      <td>-1.368149</td>\n",
       "      <td>-1.374397</td>\n",
       "      <td>0.503296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.508219</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>1.676595</td>\n",
       "      <td>0.930217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763941</td>\n",
       "      <td>-0.588807</td>\n",
       "      <td>0.097569</td>\n",
       "      <td>1.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.400289</td>\n",
       "      <td>-1.344519</td>\n",
       "      <td>0.736718</td>\n",
       "      <td>1.067279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.036242</td>\n",
       "      <td>-2.171609</td>\n",
       "      <td>0.695080</td>\n",
       "      <td>-0.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011286</td>\n",
       "      <td>-0.791814</td>\n",
       "      <td>1.688854</td>\n",
       "      <td>0.498582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.934343</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>-1.654384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.193317  1.207970  1.622549 -1.130942\n",
       "1  0.250589 -0.903680 -0.559647 -1.552191\n",
       "2 -1.120327 -0.351508 -2.132311  0.635300\n",
       "3 -0.393667 -1.368149 -1.374397  0.503296\n",
       "4 -0.508219  0.903993  1.676595  0.930217\n",
       "5  0.763941 -0.588807  0.097569  1.001529\n",
       "6  2.400289 -1.344519  0.736718  1.067279\n",
       "7 -1.036242 -2.171609  0.695080 -0.770596\n",
       "8  1.011286 -0.791814  1.688854  0.498582\n",
       "9 -0.934343  0.348974  0.657420 -1.654384"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          0         1         2         3\n",
       " 0  1.193317  1.207970  1.622549 -1.130942\n",
       " 1  0.250589 -0.903680 -0.559647 -1.552191\n",
       " 2 -1.120327 -0.351508 -2.132311  0.635300,\n",
       "           0         1         2         3\n",
       " 3 -0.393667 -1.368149 -1.374397  0.503296\n",
       " 4 -0.508219  0.903993  1.676595  0.930217\n",
       " 5  0.763941 -0.588807  0.097569  1.001529\n",
       " 6  2.400289 -1.344519  0.736718  1.067279,\n",
       "           0         1         2         3\n",
       " 7 -1.036242 -2.171609  0.695080 -0.770596\n",
       " 8  1.011286 -0.791814  1.688854  0.498582\n",
       " 9 -0.934343  0.348974  0.657420 -1.654384]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.036242</td>\n",
       "      <td>-2.171609</td>\n",
       "      <td>0.695080</td>\n",
       "      <td>-0.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011286</td>\n",
       "      <td>-0.791814</td>\n",
       "      <td>1.688854</td>\n",
       "      <td>0.498582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.934343</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>-1.654384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393667</td>\n",
       "      <td>-1.368149</td>\n",
       "      <td>-1.374397</td>\n",
       "      <td>0.503296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.508219</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>1.676595</td>\n",
       "      <td>0.930217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763941</td>\n",
       "      <td>-0.588807</td>\n",
       "      <td>0.097569</td>\n",
       "      <td>1.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.400289</td>\n",
       "      <td>-1.344519</td>\n",
       "      <td>0.736718</td>\n",
       "      <td>1.067279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.193317</td>\n",
       "      <td>1.207970</td>\n",
       "      <td>1.622549</td>\n",
       "      <td>-1.130942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250589</td>\n",
       "      <td>-0.903680</td>\n",
       "      <td>-0.559647</td>\n",
       "      <td>-1.552191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.120327</td>\n",
       "      <td>-0.351508</td>\n",
       "      <td>-2.132311</td>\n",
       "      <td>0.635300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "7 -1.036242 -2.171609  0.695080 -0.770596\n",
       "8  1.011286 -0.791814  1.688854  0.498582\n",
       "9 -0.934343  0.348974  0.657420 -1.654384\n",
       "3 -0.393667 -1.368149 -1.374397  0.503296\n",
       "4 -0.508219  0.903993  1.676595  0.930217\n",
       "5  0.763941 -0.588807  0.097569  1.001529\n",
       "6  2.400289 -1.344519  0.736718  1.067279\n",
       "0  1.193317  1.207970  1.622549 -1.130942\n",
       "1  0.250589 -0.903680 -0.559647 -1.552191\n",
       "2 -1.120327 -0.351508 -2.132311  0.635300"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(pieces[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.193317</td>\n",
       "      <td>1.207970</td>\n",
       "      <td>1.622549</td>\n",
       "      <td>-1.130942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250589</td>\n",
       "      <td>-0.903680</td>\n",
       "      <td>-0.559647</td>\n",
       "      <td>-1.552191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.120327</td>\n",
       "      <td>-0.351508</td>\n",
       "      <td>-2.132311</td>\n",
       "      <td>0.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393667</td>\n",
       "      <td>-1.368149</td>\n",
       "      <td>-1.374397</td>\n",
       "      <td>0.503296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.508219</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>1.676595</td>\n",
       "      <td>0.930217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763941</td>\n",
       "      <td>-0.588807</td>\n",
       "      <td>0.097569</td>\n",
       "      <td>1.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.400289</td>\n",
       "      <td>-1.344519</td>\n",
       "      <td>0.736718</td>\n",
       "      <td>1.067279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.036242</td>\n",
       "      <td>-2.171609</td>\n",
       "      <td>0.695080</td>\n",
       "      <td>-0.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011286</td>\n",
       "      <td>-0.791814</td>\n",
       "      <td>1.688854</td>\n",
       "      <td>0.498582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.934343</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>-1.654384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.193317  1.207970  1.622549 -1.130942\n",
       "1  0.250589 -0.903680 -0.559647 -1.552191\n",
       "2 -1.120327 -0.351508 -2.132311  0.635300\n",
       "3 -0.393667 -1.368149 -1.374397  0.503296\n",
       "4 -0.508219  0.903993  1.676595  0.930217\n",
       "5  0.763941 -0.588807  0.097569  1.001529\n",
       "6  2.400289 -1.344519  0.736718  1.067279\n",
       "7 -1.036242 -2.171609  0.695080 -0.770596\n",
       "8  1.011286 -0.791814  1.688854  0.498582\n",
       "9 -0.934343  0.348974  0.657420 -1.654384"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.036242</td>\n",
       "      <td>-2.171609</td>\n",
       "      <td>0.695080</td>\n",
       "      <td>-0.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011286</td>\n",
       "      <td>-0.791814</td>\n",
       "      <td>1.688854</td>\n",
       "      <td>0.498582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.934343</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>-1.654384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393667</td>\n",
       "      <td>-1.368149</td>\n",
       "      <td>-1.374397</td>\n",
       "      <td>0.503296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.508219</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>1.676595</td>\n",
       "      <td>0.930217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763941</td>\n",
       "      <td>-0.588807</td>\n",
       "      <td>0.097569</td>\n",
       "      <td>1.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.400289</td>\n",
       "      <td>-1.344519</td>\n",
       "      <td>0.736718</td>\n",
       "      <td>1.067279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.193317</td>\n",
       "      <td>1.207970</td>\n",
       "      <td>1.622549</td>\n",
       "      <td>-1.130942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250589</td>\n",
       "      <td>-0.903680</td>\n",
       "      <td>-0.559647</td>\n",
       "      <td>-1.552191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.120327</td>\n",
       "      <td>-0.351508</td>\n",
       "      <td>-2.132311</td>\n",
       "      <td>0.635300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "7 -1.036242 -2.171609  0.695080 -0.770596\n",
       "8  1.011286 -0.791814  1.688854  0.498582\n",
       "9 -0.934343  0.348974  0.657420 -1.654384\n",
       "3 -0.393667 -1.368149 -1.374397  0.503296\n",
       "4 -0.508219  0.903993  1.676595  0.930217\n",
       "5  0.763941 -0.588807  0.097569  1.001529\n",
       "6  2.400289 -1.344519  0.736718  1.067279\n",
       "0  1.193317  1.207970  1.622549 -1.130942\n",
       "1  0.250589 -0.903680 -0.559647 -1.552191\n",
       "2 -1.120327 -0.351508 -2.132311  0.635300"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat(pieces[::-1])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.193317</td>\n",
       "      <td>1.207970</td>\n",
       "      <td>1.622549</td>\n",
       "      <td>-1.130942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250589</td>\n",
       "      <td>-0.903680</td>\n",
       "      <td>-0.559647</td>\n",
       "      <td>-1.552191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.120327</td>\n",
       "      <td>-0.351508</td>\n",
       "      <td>-2.132311</td>\n",
       "      <td>0.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393667</td>\n",
       "      <td>-1.368149</td>\n",
       "      <td>-1.374397</td>\n",
       "      <td>0.503296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.508219</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>1.676595</td>\n",
       "      <td>0.930217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763941</td>\n",
       "      <td>-0.588807</td>\n",
       "      <td>0.097569</td>\n",
       "      <td>1.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.400289</td>\n",
       "      <td>-1.344519</td>\n",
       "      <td>0.736718</td>\n",
       "      <td>1.067279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.036242</td>\n",
       "      <td>-2.171609</td>\n",
       "      <td>0.695080</td>\n",
       "      <td>-0.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011286</td>\n",
       "      <td>-0.791814</td>\n",
       "      <td>1.688854</td>\n",
       "      <td>0.498582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.934343</td>\n",
       "      <td>0.348974</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>-1.654384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.193317  1.207970  1.622549 -1.130942\n",
       "1  0.250589 -0.903680 -0.559647 -1.552191\n",
       "2 -1.120327 -0.351508 -2.132311  0.635300\n",
       "3 -0.393667 -1.368149 -1.374397  0.503296\n",
       "4 -0.508219  0.903993  1.676595  0.930217\n",
       "5  0.763941 -0.588807  0.097569  1.001529\n",
       "6  2.400289 -1.344519  0.736718  1.067279\n",
       "7 -1.036242 -2.171609  0.695080 -0.770596\n",
       "8  1.011286 -0.791814  1.688854  0.498582\n",
       "9 -0.934343  0.348974  0.657420 -1.654384"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.reindex(index=range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval\n",
       "0  foo     1\n",
       "1  foo     2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  rval\n",
       "0  foo     4\n",
       "1  foo     5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval  rval\n",
       "0  foo     1     4\n",
       "1  foo     1     5\n",
       "2  foo     2     4\n",
       "3  foo     2     5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval  rval\n",
       "0  foo     1     4\n",
       "1  bar     2     5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574740</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>-0.593001</td>\n",
       "      <td>0.402163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287423</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>-1.939178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044803</td>\n",
       "      <td>-1.457178</td>\n",
       "      <td>2.111622</td>\n",
       "      <td>-0.557102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520771</td>\n",
       "      <td>-1.265202</td>\n",
       "      <td>1.188084</td>\n",
       "      <td>0.080956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.536831</td>\n",
       "      <td>-2.418096</td>\n",
       "      <td>-0.955397</td>\n",
       "      <td>-1.469708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275441</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.510896</td>\n",
       "      <td>0.099812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.221963</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-2.083170</td>\n",
       "      <td>0.759453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.574740  0.801150 -0.593001  0.402163\n",
       "1 -0.287423  0.798242  0.797095 -1.939178\n",
       "2  1.044803 -1.457178  2.111622 -0.557102\n",
       "3 -0.830459 -1.159893  1.011344  2.211089\n",
       "4  0.520771 -1.265202  1.188084  0.080956\n",
       "5 -0.536831 -2.418096 -0.955397 -1.469708\n",
       "6  0.275441  0.395056  0.510896  0.099812\n",
       "7  1.221963  0.180815 -2.083170  0.759453"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A   -0.830459\n",
       "B   -1.159893\n",
       "C    1.011344\n",
       "D    2.211089\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.iloc[3]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574740</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>-0.593001</td>\n",
       "      <td>0.402163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287423</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>-1.939178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044803</td>\n",
       "      <td>-1.457178</td>\n",
       "      <td>2.111622</td>\n",
       "      <td>-0.557102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520771</td>\n",
       "      <td>-1.265202</td>\n",
       "      <td>1.188084</td>\n",
       "      <td>0.080956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.536831</td>\n",
       "      <td>-2.418096</td>\n",
       "      <td>-0.955397</td>\n",
       "      <td>-1.469708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275441</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.510896</td>\n",
       "      <td>0.099812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.221963</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-2.083170</td>\n",
       "      <td>0.759453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.574740  0.801150 -0.593001  0.402163\n",
       "1 -0.287423  0.798242  0.797095 -1.939178\n",
       "2  1.044803 -1.457178  2.111622 -0.557102\n",
       "3 -0.830459 -1.159893  1.011344  2.211089\n",
       "4  0.520771 -1.265202  1.188084  0.080956\n",
       "5 -0.536831 -2.418096 -0.955397 -1.469708\n",
       "6  0.275441  0.395056  0.510896  0.099812\n",
       "7  1.221963  0.180815 -2.083170  0.759453\n",
       "8 -0.830459 -1.159893  1.011344  2.211089"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574740</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>-0.593001</td>\n",
       "      <td>0.402163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287423</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>-1.939178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044803</td>\n",
       "      <td>-1.457178</td>\n",
       "      <td>2.111622</td>\n",
       "      <td>-0.557102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520771</td>\n",
       "      <td>-1.265202</td>\n",
       "      <td>1.188084</td>\n",
       "      <td>0.080956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.536831</td>\n",
       "      <td>-2.418096</td>\n",
       "      <td>-0.955397</td>\n",
       "      <td>-1.469708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275441</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.510896</td>\n",
       "      <td>0.099812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.221963</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-2.083170</td>\n",
       "      <td>0.759453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.574740  0.801150 -0.593001  0.402163\n",
       "1 -0.287423  0.798242  0.797095 -1.939178\n",
       "2  1.044803 -1.457178  2.111622 -0.557102\n",
       "3 -0.830459 -1.159893  1.011344  2.211089\n",
       "4  0.520771 -1.265202  1.188084  0.080956\n",
       "5 -0.536831 -2.418096 -0.955397 -1.469708\n",
       "6  0.275441  0.395056  0.510896  0.099812\n",
       "7  1.221963  0.180815 -2.083170  0.759453"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574740</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>-0.593001</td>\n",
       "      <td>0.402163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287423</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>-1.939178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044803</td>\n",
       "      <td>-1.457178</td>\n",
       "      <td>2.111622</td>\n",
       "      <td>-0.557102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520771</td>\n",
       "      <td>-1.265202</td>\n",
       "      <td>1.188084</td>\n",
       "      <td>0.080956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.536831</td>\n",
       "      <td>-2.418096</td>\n",
       "      <td>-0.955397</td>\n",
       "      <td>-1.469708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275441</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.510896</td>\n",
       "      <td>0.099812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.221963</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-2.083170</td>\n",
       "      <td>0.759453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.574740  0.801150 -0.593001  0.402163\n",
       "1 -0.287423  0.798242  0.797095 -1.939178\n",
       "2  1.044803 -1.457178  2.111622 -0.557102\n",
       "3 -0.830459 -1.159893  1.011344  2.211089\n",
       "4  0.520771 -1.265202  1.188084  0.080956\n",
       "5 -0.536831 -2.418096 -0.955397 -1.469708\n",
       "6  0.275441  0.395056  0.510896  0.099812\n",
       "7  1.221963  0.180815 -2.083170  0.759453\n",
       "3 -0.830459 -1.159893  1.011344  2.211089"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.append(s, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574740</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>-0.593001</td>\n",
       "      <td>0.402163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287423</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>-1.939178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044803</td>\n",
       "      <td>-1.457178</td>\n",
       "      <td>2.111622</td>\n",
       "      <td>-0.557102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520771</td>\n",
       "      <td>-1.265202</td>\n",
       "      <td>1.188084</td>\n",
       "      <td>0.080956</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.536831</td>\n",
       "      <td>-2.418096</td>\n",
       "      <td>-0.955397</td>\n",
       "      <td>-1.469708</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275441</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.510896</td>\n",
       "      <td>0.099812</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.221963</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-2.083170</td>\n",
       "      <td>0.759453</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.830459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.159893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.011344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.211089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         3\n",
       "0 -0.574740  0.801150 -0.593001  0.402163       NaN\n",
       "1 -0.287423  0.798242  0.797095 -1.939178       NaN\n",
       "2  1.044803 -1.457178  2.111622 -0.557102       NaN\n",
       "3 -0.830459 -1.159893  1.011344  2.211089       NaN\n",
       "4  0.520771 -1.265202  1.188084  0.080956       NaN\n",
       "5 -0.536831 -2.418096 -0.955397 -1.469708       NaN\n",
       "6  0.275441  0.395056  0.510896  0.099812       NaN\n",
       "7  1.221963  0.180815 -2.083170  0.759453       NaN\n",
       "A       NaN       NaN       NaN       NaN -0.830459\n",
       "B       NaN       NaN       NaN       NaN -1.159893\n",
       "C       NaN       NaN       NaN       NaN  1.011344\n",
       "D       NaN       NaN       NaN       NaN  2.211089"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574740</td>\n",
       "      <td>0.801150</td>\n",
       "      <td>-0.593001</td>\n",
       "      <td>0.402163</td>\n",
       "      <td>-0.593001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287423</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.797095</td>\n",
       "      <td>-1.939178</td>\n",
       "      <td>0.797095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044803</td>\n",
       "      <td>-1.457178</td>\n",
       "      <td>2.111622</td>\n",
       "      <td>-0.557102</td>\n",
       "      <td>2.111622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.159893</td>\n",
       "      <td>1.011344</td>\n",
       "      <td>2.211089</td>\n",
       "      <td>1.011344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520771</td>\n",
       "      <td>-1.265202</td>\n",
       "      <td>1.188084</td>\n",
       "      <td>0.080956</td>\n",
       "      <td>1.188084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.536831</td>\n",
       "      <td>-2.418096</td>\n",
       "      <td>-0.955397</td>\n",
       "      <td>-1.469708</td>\n",
       "      <td>-0.955397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275441</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.510896</td>\n",
       "      <td>0.099812</td>\n",
       "      <td>0.510896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.221963</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-2.083170</td>\n",
       "      <td>0.759453</td>\n",
       "      <td>-2.083170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         C\n",
       "0 -0.574740  0.801150 -0.593001  0.402163 -0.593001\n",
       "1 -0.287423  0.798242  0.797095 -1.939178  0.797095\n",
       "2  1.044803 -1.457178  2.111622 -0.557102  2.111622\n",
       "3 -0.830459 -1.159893  1.011344  2.211089  1.011344\n",
       "4  0.520771 -1.265202  1.188084  0.080956  1.188084\n",
       "5 -0.536831 -2.418096 -0.955397 -1.469708 -0.955397\n",
       "6  0.275441  0.395056  0.510896  0.099812  0.510896\n",
       "7  1.221963  0.180815 -2.083170  0.759453 -2.083170"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df['C']\n",
    "pd.concat([df, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "   ....:                           'foo', 'bar', 'foo', 'foo'],\n",
    "   ....:                    'B' : ['one', 'one', 'two', 'three',\n",
    "   ....:                           'two', 'two', 'one', 'three'],\n",
    "   ....:                    'C' : np.random.randn(8),\n",
    "   ....:                    'D' : np.random.randn(8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>0.818465</td>\n",
       "      <td>-0.177589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.750453</td>\n",
       "      <td>0.008061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>-0.051004</td>\n",
       "      <td>-0.929798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>three</td>\n",
       "      <td>-1.382434</td>\n",
       "      <td>-0.919710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>0.797656</td>\n",
       "      <td>0.938389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>0.257448</td>\n",
       "      <td>0.005717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.193536</td>\n",
       "      <td>0.302404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foo</td>\n",
       "      <td>three</td>\n",
       "      <td>0.831086</td>\n",
       "      <td>-0.662253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B         C         D\n",
       "0  foo    one  0.818465 -0.177589\n",
       "1  bar    one -0.750453  0.008061\n",
       "2  foo    two -0.051004 -0.929798\n",
       "3  bar  three -1.382434 -0.919710\n",
       "4  foo    two  0.797656  0.938389\n",
       "5  bar    two  0.257448  0.005717\n",
       "6  foo    one -0.193536  0.302404\n",
       "7  foo  three  0.831086 -0.662253"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           C  D\n",
       "A   B          \n",
       "bar one    1  1\n",
       "    three  1  1\n",
       "    two    1  1\n",
       "foo one    2  2\n",
       "    three  1  1\n",
       "    two    2  2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['A', 'B']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>0.818465</td>\n",
       "      <td>-0.177589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.750453</td>\n",
       "      <td>0.00806119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>-0.0510043</td>\n",
       "      <td>-0.929798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>three</td>\n",
       "      <td>-1.38243</td>\n",
       "      <td>-0.91971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foofoo</td>\n",
       "      <td>twotwo</td>\n",
       "      <td>0.746652</td>\n",
       "      <td>0.00859052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>0.257448</td>\n",
       "      <td>0.00571688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>foofoo</td>\n",
       "      <td>oneone</td>\n",
       "      <td>0.62493</td>\n",
       "      <td>0.124816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foo</td>\n",
       "      <td>three</td>\n",
       "      <td>0.831086</td>\n",
       "      <td>-0.662253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A       B          C           D\n",
       "0     foo     one   0.818465   -0.177589\n",
       "1     bar     one  -0.750453  0.00806119\n",
       "2     foo     two -0.0510043   -0.929798\n",
       "3     bar   three   -1.38243    -0.91971\n",
       "4  foofoo  twotwo   0.746652  0.00859052\n",
       "5     bar     two   0.257448  0.00571688\n",
       "6  foofoo  oneone    0.62493    0.124816\n",
       "7     foo   three   0.831086   -0.662253"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['A', 'B']).apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas.util.testing as tm; tm.N = 3\n",
    "def unpivot(frame):\n",
    "    N, K = frame.shape\n",
    "    data = {'value' : frame.values.ravel('F'),\n",
    "            'variable' : np.asarray(frame.columns).repeat(N),\n",
    "            'date' : np.tile(np.asarray(frame.index), K)}\n",
    "    return pd.DataFrame(data, columns=['date', 'variable', 'value'])\n",
    "df = unpivot(tm.makeTimeDataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>0.470422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>1.286901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.036826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>B</td>\n",
       "      <td>0.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>B</td>\n",
       "      <td>0.985982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.199990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.111952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>0.664046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>D</td>\n",
       "      <td>1.216088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>D</td>\n",
       "      <td>-1.127608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>D</td>\n",
       "      <td>-0.300289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date variable     value\n",
       "0  2000-01-03        A  0.470422\n",
       "1  2000-01-04        A  1.286901\n",
       "2  2000-01-05        A -0.036826\n",
       "3  2000-01-03        B  0.392200\n",
       "4  2000-01-04        B  0.985982\n",
       "5  2000-01-05        B -0.018447\n",
       "6  2000-01-03        C -0.199990\n",
       "7  2000-01-04        C  0.111952\n",
       "8  2000-01-05        C  0.664046\n",
       "9  2000-01-03        D  1.216088\n",
       "10 2000-01-04        D -1.127608\n",
       "11 2000-01-05        D -0.300289"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module pandas.util.testing in pandas.util:\n",
      "\n",
      "NAME\n",
      "    pandas.util.testing\n",
      "\n",
      "CLASSES\n",
      "    builtins.dict(builtins.object)\n",
      "        TestSubDict\n",
      "    builtins.object\n",
      "        RNGContext\n",
      "        SimpleMock\n",
      "    pandas.core.categorical.Categorical(pandas.core.base.PandasObject)\n",
      "        SubclassedCategorical\n",
      "    pandas.core.frame.DataFrame(pandas.core.generic.NDFrame)\n",
      "        SubclassedDataFrame\n",
      "    pandas.core.series.Series(pandas.core.base.IndexOpsMixin, pandas.core.generic.NDFrame)\n",
      "        SubclassedSeries\n",
      "    pandas.core.sparse.frame.SparseDataFrame(pandas.core.frame.DataFrame)\n",
      "        SubclassedSparseDataFrame\n",
      "    pandas.core.sparse.series.SparseSeries(pandas.core.series.Series)\n",
      "        SubclassedSparseSeries\n",
      "    \n",
      "    class RNGContext(builtins.object)\n",
      "     |  Context manager to set the numpy random number generator speed. Returns\n",
      "     |  to the original value upon exiting the context manager.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : int\n",
      "     |      Seed for numpy.random.seed\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  with RNGContext(42):\n",
      "     |      np.random.randn()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __init__(self, seed)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SimpleMock(builtins.object)\n",
      "     |  Poor man's mocking object\n",
      "     |  \n",
      "     |  Note: only works for new-style classes, assumes  __getattribute__ exists.\n",
      "     |  \n",
      "     |  >>> a = type(\"Duck\",(),{})\n",
      "     |  >>> a.attr1,a.attr2 =\"fizz\",\"buzz\"\n",
      "     |  >>> b = SimpleMock(a,\"attr1\",\"bar\")\n",
      "     |  >>> b.attr1 == \"bar\" and b.attr2 == \"buzz\"\n",
      "     |  True\n",
      "     |  >>> a.attr1 == \"fizz\" and a.attr2 == \"buzz\"\n",
      "     |  True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getattribute__(self, name)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __init__(self, obj, *args, **kwds)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SubclassedCategorical(pandas.core.categorical.Categorical)\n",
      "     |  Represents a categorical variable in classic R / S-plus fashion\n",
      "     |  \n",
      "     |  `Categoricals` can only take on only a limited, and usually fixed, number\n",
      "     |  of possible values (`categories`). In contrast to statistical categorical\n",
      "     |  variables, a `Categorical` might have an order, but numerical operations\n",
      "     |  (additions, divisions, ...) are not possible.\n",
      "     |  \n",
      "     |  All values of the `Categorical` are either in `categories` or `np.nan`.\n",
      "     |  Assigning values outside of `categories` will raise a `ValueError`. Order\n",
      "     |  is defined by the order of the `categories`, not lexical order of the\n",
      "     |  values.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  values : list-like\n",
      "     |      The values of the categorical. If categories are given, values not in\n",
      "     |      categories will be replaced with NaN.\n",
      "     |  categories : Index-like (unique), optional\n",
      "     |      The unique categories for this categorical. If not given, the\n",
      "     |      categories are assumed to be the unique values of values.\n",
      "     |  ordered : boolean, (default False)\n",
      "     |      Whether or not this categorical is treated as a ordered categorical.\n",
      "     |      If not given, the resulting categorical will not be ordered.\n",
      "     |  dtype : CategoricalDtype\n",
      "     |      An instance of ``CategoricalDtype`` to use for this categorical\n",
      "     |  \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  categories : Index\n",
      "     |      The categories of this categorical\n",
      "     |  codes : ndarray\n",
      "     |      The codes (integer positions, which point to the categories) of this\n",
      "     |      categorical, read only.\n",
      "     |  ordered : boolean\n",
      "     |      Whether or not this Categorical is ordered.\n",
      "     |  dtype : CategoricalDtype\n",
      "     |      The instance of ``CategoricalDtype`` storing the ``categories``\n",
      "     |      and ``ordered``.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |  \n",
      "     |  Raises\n",
      "     |  ------\n",
      "     |  ValueError\n",
      "     |      If the categories do not validate.\n",
      "     |  TypeError\n",
      "     |      If an explicit ``ordered=True`` is given but no `categories` and the\n",
      "     |      `values` are not sortable.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> pd.Categorical([1, 2, 3, 1, 2, 3])\n",
      "     |  [1, 2, 3, 1, 2, 3]\n",
      "     |  Categories (3, int64): [1, 2, 3]\n",
      "     |  \n",
      "     |  >>> pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'])\n",
      "     |  [a, b, c, a, b, c]\n",
      "     |  Categories (3, object): [a, b, c]\n",
      "     |  \n",
      "     |  Ordered `Categoricals` can be sorted according to the custom order\n",
      "     |  of the categories and can have a min and max value.\n",
      "     |  \n",
      "     |  >>> c = pd.Categorical(['a','b','c','a','b','c'], ordered=True,\n",
      "     |  ...                    categories=['c', 'b', 'a'])\n",
      "     |  >>> c\n",
      "     |  [a, b, c, a, b, c]\n",
      "     |  Categories (3, object): [c < b < a]\n",
      "     |  >>> c.min()\n",
      "     |  'c'\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  See the `user guide\n",
      "     |  <http://pandas.pydata.org/pandas-docs/stable/categorical.html>`_ for more.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  pandas.api.types.CategoricalDtype : Type for categorical data\n",
      "     |  CategoricalIndex : An Index with an underlying ``Categorical``\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SubclassedCategorical\n",
      "     |      pandas.core.categorical.Categorical\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.base.StringMixin\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from pandas.core.categorical.Categorical:\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |      The numpy array interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : numpy array\n",
      "     |          A numpy array of either the specified dtype or,\n",
      "     |          if dtype==None (default), the same dtype as\n",
      "     |          categorical.categories.dtype\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return an item.\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |  \n",
      "     |  __init__(self, values, categories=None, ordered=None, dtype=None, fastpath=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Returns an Iterator over the values of this Categorical.\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The length of this Categorical.\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Item assignment.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If (one or more) Value is not in categories or if a assigned\n",
      "     |          `Categorical` does not have the same categories\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Necessary for making this object picklable\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Unicode representation.\n",
      "     |  \n",
      "     |  add_categories(self, new_categories, inplace=False)\n",
      "     |      Add new categories.\n",
      "     |      \n",
      "     |      `new_categories` will be included at the last/highest place in the\n",
      "     |      categories and will be unused directly after this call.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the new categories include old categories or do not validate as\n",
      "     |          categories\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_categories : category or list-like of category\n",
      "     |         The new categories to be included.\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to add the categories inplace or return a copy of\n",
      "     |         this categorical with added categories.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat : Categorical with new categories added or None if inplace.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      rename_categories\n",
      "     |      reorder_categories\n",
      "     |      remove_categories\n",
      "     |      remove_unused_categories\n",
      "     |      set_categories\n",
      "     |  \n",
      "     |  argsort(self, ascending=True, kind='quicksort', *args, **kwargs)\n",
      "     |      Returns the indices that would sort the Categorical instance if\n",
      "     |      'sort_values' was called. This function is implemented to provide\n",
      "     |      compatibility with numpy ndarray objects.\n",
      "     |      \n",
      "     |      While an ordering is applied to the category values, arg-sorting\n",
      "     |      in this context refers more to organizing and grouping together\n",
      "     |      based on matching category values. Thus, this function can be\n",
      "     |      called on an unordered Categorical instance unlike the functions\n",
      "     |      'Categorical.min' and 'Categorical.max'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      argsorted : numpy array\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.argsort\n",
      "     |  \n",
      "     |  as_ordered(self, inplace=False)\n",
      "     |      Sets the Categorical to be ordered\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to set the ordered attribute inplace or return a copy\n",
      "     |         of this categorical with ordered set to True\n",
      "     |  \n",
      "     |  as_unordered(self, inplace=False)\n",
      "     |      Sets the Categorical to be unordered\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to set the ordered attribute inplace or return a copy\n",
      "     |         of this categorical with ordered set to False\n",
      "     |  \n",
      "     |  astype(self, dtype, copy=True)\n",
      "     |      Coerce this type to another dtype\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : numpy dtype or pandas type\n",
      "     |      copy : bool, default True\n",
      "     |          By default, astype always returns a newly allocated object.\n",
      "     |          If copy is set to False and dtype is categorical, the original\n",
      "     |          object is returned.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |  \n",
      "     |  check_for_ordered(self, op)\n",
      "     |      assert that we are ordered\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Copy constructor.\n",
      "     |  \n",
      "     |  describe(self)\n",
      "     |      Describes this Categorical\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      description: `DataFrame`\n",
      "     |          A dataframe with frequency and counts by category.\n",
      "     |  \n",
      "     |  dropna(self)\n",
      "     |      Return the Categorical without null values.\n",
      "     |      \n",
      "     |      Both missing values (-1 in .codes) and NA as a category are detected.\n",
      "     |      NA is removed from the categories if present.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : Categorical\n",
      "     |  \n",
      "     |  equals(self, other)\n",
      "     |      Returns True if categorical arrays are equal.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : `Categorical`\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      are_equal : boolean\n",
      "     |  \n",
      "     |  fillna(self, value=None, method=None, limit=None)\n",
      "     |      Fill NA/NaN values using the specified method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use NEXT valid observation to fill gap\n",
      "     |      value : scalar\n",
      "     |          Value to use to fill holes (e.g. 0)\n",
      "     |      limit : int, default None\n",
      "     |          (Not implemented yet for Categorical!)\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : Categorical with NA/NaN filled\n",
      "     |  \n",
      "     |  get_values(self)\n",
      "     |      Return the values.\n",
      "     |      \n",
      "     |      For internal compatibility with pandas formatting.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : numpy array\n",
      "     |          A numpy array of the same dtype as categorical.categories.dtype or\n",
      "     |          Index if datetime / periods\n",
      "     |  \n",
      "     |  is_dtype_equal(self, other)\n",
      "     |      Returns True if categoricals are the same dtype\n",
      "     |        same categories, and same ordered\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Categorical\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      are_equal : boolean\n",
      "     |  \n",
      "     |  isna(self)\n",
      "     |      Detect missing values\n",
      "     |      \n",
      "     |      Both missing values (-1 in .codes) and NA as a category are detected.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a boolean array of whether my values are null\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      isna : top-level isna\n",
      "     |      isnull : alias of isna\n",
      "     |      Categorical.notna : boolean inverse of Categorical.isna\n",
      "     |  \n",
      "     |  isnull = isna(self)\n",
      "     |      Detect missing values\n",
      "     |      \n",
      "     |      Both missing values (-1 in .codes) and NA as a category are detected.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a boolean array of whether my values are null\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      isna : top-level isna\n",
      "     |      isnull : alias of isna\n",
      "     |      Categorical.notna : boolean inverse of Categorical.isna\n",
      "     |  \n",
      "     |  map(self, mapper)\n",
      "     |      Apply mapper function to its categories (not codes).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper : callable\n",
      "     |          Function to be applied. When all categories are mapped\n",
      "     |          to different categories, the result will be Categorical which has\n",
      "     |          the same order property as the original. Otherwise, the result will\n",
      "     |          be np.ndarray.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : Categorical or Index.\n",
      "     |  \n",
      "     |  max(self, numeric_only=None, **kwargs)\n",
      "     |      The maximum value of the object.\n",
      "     |      \n",
      "     |      Only ordered `Categoricals` have a maximum!\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the `Categorical` is not `ordered`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      max : the maximum of this `Categorical`\n",
      "     |  \n",
      "     |  memory_usage(self, deep=False)\n",
      "     |      Memory usage of my values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool\n",
      "     |          Introspect the data deeply, interrogate\n",
      "     |          `object` dtypes for system-level memory consumption\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bytes used\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Memory usage does not include memory consumed by elements that\n",
      "     |      are not components of the array if deep=False\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.nbytes\n",
      "     |  \n",
      "     |  min(self, numeric_only=None, **kwargs)\n",
      "     |      The minimum value of the object.\n",
      "     |      \n",
      "     |      Only ordered `Categoricals` have a minimum!\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the `Categorical` is not `ordered`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      min : the minimum of this `Categorical`\n",
      "     |  \n",
      "     |  mode(self)\n",
      "     |      Returns the mode(s) of the Categorical.\n",
      "     |      \n",
      "     |      Always returns `Categorical` even if only one value.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      modes : `Categorical` (sorted)\n",
      "     |  \n",
      "     |  notna(self)\n",
      "     |      Inverse of isna\n",
      "     |      \n",
      "     |      Both missing values (-1 in .codes) and NA as a category are detected as\n",
      "     |      null.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a boolean array of whether my values are not null\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      notna : top-level notna\n",
      "     |      notnull : alias of notna\n",
      "     |      Categorical.isna : boolean inverse of Categorical.notna\n",
      "     |  \n",
      "     |  notnull = notna(self)\n",
      "     |      Inverse of isna\n",
      "     |      \n",
      "     |      Both missing values (-1 in .codes) and NA as a category are detected as\n",
      "     |      null.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a boolean array of whether my values are not null\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      notna : top-level notna\n",
      "     |      notnull : alias of notna\n",
      "     |      Categorical.isna : boolean inverse of Categorical.notna\n",
      "     |  \n",
      "     |  put(self, *args, **kwargs)\n",
      "     |      Replace specific elements in the Categorical with given values.\n",
      "     |  \n",
      "     |  ravel(self, order='C')\n",
      "     |      Return a flattened (numpy) array.\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      raveled : numpy array\n",
      "     |  \n",
      "     |  remove_categories(self, removals, inplace=False)\n",
      "     |      Removes the specified categories.\n",
      "     |      \n",
      "     |      `removals` must be included in the old categories. Values which were in\n",
      "     |      the removed categories will be set to NaN\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the removals are not contained in the categories\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      removals : category or list of categories\n",
      "     |         The categories which should be removed.\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to remove the categories inplace or return a copy of\n",
      "     |         this categorical with removed categories.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat : Categorical with removed categories or None if inplace.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      rename_categories\n",
      "     |      reorder_categories\n",
      "     |      add_categories\n",
      "     |      remove_unused_categories\n",
      "     |      set_categories\n",
      "     |  \n",
      "     |  remove_unused_categories(self, inplace=False)\n",
      "     |      Removes categories which are not used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to drop unused categories inplace or return a copy of\n",
      "     |         this categorical with unused categories dropped.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat : Categorical with unused categories dropped or None if inplace.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      rename_categories\n",
      "     |      reorder_categories\n",
      "     |      add_categories\n",
      "     |      remove_categories\n",
      "     |      set_categories\n",
      "     |  \n",
      "     |  rename_categories(self, new_categories, inplace=False)\n",
      "     |      Renames categories.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If new categories are list-like and do not have the same number of\n",
      "     |          items than the current categories or do not validate as categories\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_categories : list-like or dict-like\n",
      "     |      \n",
      "     |         * list-like: all items must be unique and the number of items in\n",
      "     |           the new categories must match the existing number of categories.\n",
      "     |      \n",
      "     |         * dict-like: specifies a mapping from\n",
      "     |           old categories to new. Categories not contained in the mapping\n",
      "     |           are passed through and extra categories in the mapping are\n",
      "     |           ignored. *New in version 0.21.0*.\n",
      "     |      \n",
      "     |         .. warning::\n",
      "     |      \n",
      "     |            Currently, Series are considered list like. In a future version\n",
      "     |            of pandas they'll be considered dict-like.\n",
      "     |      \n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to rename the categories inplace or return a copy of\n",
      "     |         this categorical with renamed categories.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat : Categorical or None\n",
      "     |         With ``inplace=False``, the new categorical is returned.\n",
      "     |         With ``inplace=True``, there is no return value.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      reorder_categories\n",
      "     |      add_categories\n",
      "     |      remove_categories\n",
      "     |      remove_unused_categories\n",
      "     |      set_categories\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> c = Categorical(['a', 'a', 'b'])\n",
      "     |      >>> c.rename_categories([0, 1])\n",
      "     |      [0, 0, 1]\n",
      "     |      Categories (2, int64): [0, 1]\n",
      "     |      \n",
      "     |      For dict-like ``new_categories``, extra keys are ignored and\n",
      "     |      categories not in the dictionary are passed through\n",
      "     |      \n",
      "     |      >>> c.rename_categories({'a': 'A', 'c': 'C'})\n",
      "     |      [A, A, b]\n",
      "     |      Categories (2, object): [A, b]\n",
      "     |  \n",
      "     |  reorder_categories(self, new_categories, ordered=None, inplace=False)\n",
      "     |      Reorders categories as specified in new_categories.\n",
      "     |      \n",
      "     |      `new_categories` need to include all old categories and no new category\n",
      "     |      items.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the new categories do not contain all old category items or any\n",
      "     |          new ones\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_categories : Index-like\n",
      "     |         The categories in new order.\n",
      "     |      ordered : boolean, optional\n",
      "     |         Whether or not the categorical is treated as a ordered categorical.\n",
      "     |         If not given, do not change the ordered information.\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to reorder the categories inplace or return a copy of\n",
      "     |         this categorical with reordered categories.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat : Categorical with reordered categories or None if inplace.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      rename_categories\n",
      "     |      add_categories\n",
      "     |      remove_categories\n",
      "     |      remove_unused_categories\n",
      "     |      set_categories\n",
      "     |  \n",
      "     |  repeat(self, repeats, *args, **kwargs)\n",
      "     |      Repeat elements of a Categorical.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.repeat\n",
      "     |  \n",
      "     |  reshape(self, new_shape, *args, **kwargs)\n",
      "     |      .. deprecated:: 0.19.0\n",
      "     |         Calling this method will raise an error in a future release.\n",
      "     |      \n",
      "     |      An ndarray-compatible method that returns `self` because\n",
      "     |      `Categorical` instances cannot actually be reshaped.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_shape : int or tuple of ints\n",
      "     |          A 1-D array of integers that correspond to the new\n",
      "     |          shape of the `Categorical`. For more information on\n",
      "     |          the parameter, please refer to `np.reshape`.\n",
      "     |  \n",
      "     |  searchsorted(self, value, side='left', sorter=None)\n",
      "     |      Find indices where elements should be inserted to maintain order.\n",
      "     |      \n",
      "     |      Find the indices into a sorted Categorical `self` such that, if the\n",
      "     |      corresponding elements in `value` were inserted before the indices,\n",
      "     |      the order of `self` would be preserved.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : array_like\n",
      "     |          Values to insert into `self`.\n",
      "     |      side : {'left', 'right'}, optional\n",
      "     |          If 'left', the index of the first suitable location found is given.\n",
      "     |          If 'right', return the last such index.  If there is no suitable\n",
      "     |          index, return either 0 or N (where N is the length of `self`).\n",
      "     |      sorter : 1-D array_like, optional\n",
      "     |          Optional array of integer indices that sort `self` into ascending\n",
      "     |          order. They are typically the result of ``np.argsort``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      indices : array of ints\n",
      "     |          Array of insertion points with the same shape as `value`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Binary search is used to find the required insertion points.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> x = pd.Series([1, 2, 3])\n",
      "     |      >>> x\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> x.searchsorted(4)\n",
      "     |      array([3])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([0, 4])\n",
      "     |      array([0, 3])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([1, 3], side='left')\n",
      "     |      array([0, 2])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([1, 3], side='right')\n",
      "     |      array([1, 3])\n",
      "     |      \n",
      "     |      >>> x = pd.Categorical(['apple', 'bread', 'bread', 'cheese', 'milk' ])\n",
      "     |      [apple, bread, bread, cheese, milk]\n",
      "     |      Categories (4, object): [apple < bread < cheese < milk]\n",
      "     |      \n",
      "     |      >>> x.searchsorted('bread')\n",
      "     |      array([1])     # Note: an array, not a scalar\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread'])\n",
      "     |      array([1])\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread', 'eggs'])\n",
      "     |      array([1, 4])\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread', 'eggs'], side='right')\n",
      "     |      array([3, 4])    # eggs before milk\n",
      "     |  \n",
      "     |  set_categories(self, new_categories, ordered=None, rename=False, inplace=False)\n",
      "     |      Sets the categories to the specified new_categories.\n",
      "     |      \n",
      "     |      `new_categories` can include new categories (which will result in\n",
      "     |      unused categories) or remove old categories (which results in values\n",
      "     |      set to NaN). If `rename==True`, the categories will simple be renamed\n",
      "     |      (less or more items than in old categories will result in values set to\n",
      "     |      NaN or in unused categories respectively).\n",
      "     |      \n",
      "     |      This method can be used to perform more than one action of adding,\n",
      "     |      removing, and reordering simultaneously and is therefore faster than\n",
      "     |      performing the individual steps via the more specialised methods.\n",
      "     |      \n",
      "     |      On the other hand this methods does not do checks (e.g., whether the\n",
      "     |      old categories are included in the new categories on a reorder), which\n",
      "     |      can result in surprising changes, for example when using special string\n",
      "     |      dtypes on python3, which does not considers a S1 string equal to a\n",
      "     |      single char python string.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If new_categories does not validate as categories\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_categories : Index-like\n",
      "     |         The categories in new order.\n",
      "     |      ordered : boolean, (default: False)\n",
      "     |         Whether or not the categorical is treated as a ordered categorical.\n",
      "     |         If not given, do not change the ordered information.\n",
      "     |      rename : boolean (default: False)\n",
      "     |         Whether or not the new_categories should be considered as a rename\n",
      "     |         of the old  categories or as reordered categories.\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to reorder the categories inplace or return a copy of\n",
      "     |         this categorical with reordered categories.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat : Categorical with reordered categories or None if inplace.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      rename_categories\n",
      "     |      reorder_categories\n",
      "     |      add_categories\n",
      "     |      remove_categories\n",
      "     |      remove_unused_categories\n",
      "     |  \n",
      "     |  set_ordered(self, value, inplace=False)\n",
      "     |      Sets the ordered attribute to the boolean value\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : boolean to set whether this categorical is ordered (True) or\n",
      "     |         not (False)\n",
      "     |      inplace : boolean (default: False)\n",
      "     |         Whether or not to set the ordered attribute inplace or return a copy\n",
      "     |         of this categorical with ordered set to the value\n",
      "     |  \n",
      "     |  shift(self, periods)\n",
      "     |      Shift Categorical by desired number of periods.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : Categorical\n",
      "     |  \n",
      "     |  sort_values(self, inplace=False, ascending=True, na_position='last')\n",
      "     |      Sorts the Categorical by category value returning a new\n",
      "     |      Categorical by default.\n",
      "     |      \n",
      "     |      While an ordering is applied to the category values, sorting in this\n",
      "     |      context refers more to organizing and grouping together based on\n",
      "     |      matching category values. Thus, this function can be called on an\n",
      "     |      unordered Categorical instance unlike the functions 'Categorical.min'\n",
      "     |      and 'Categorical.max'.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : boolean, default False\n",
      "     |          Do operation in place.\n",
      "     |      ascending : boolean, default True\n",
      "     |          Order ascending. Passing False orders descending. The\n",
      "     |          ordering parameter provides the method by which the\n",
      "     |          category values are organized.\n",
      "     |      na_position : {'first', 'last'} (optional, default='last')\n",
      "     |          'first' puts NaNs at the beginning\n",
      "     |          'last' puts NaNs at the end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Categorical or None\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Categorical.sort\n",
      "     |      Series.sort_values\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> c = pd.Categorical([1, 2, 2, 1, 5])\n",
      "     |      >>> c\n",
      "     |      [1, 2, 2, 1, 5]\n",
      "     |      Categories (3, int64): [1, 2, 5]\n",
      "     |      >>> c.sort_values()\n",
      "     |      [1, 1, 2, 2, 5]\n",
      "     |      Categories (3, int64): [1, 2, 5]\n",
      "     |      >>> c.sort_values(ascending=False)\n",
      "     |      [5, 2, 2, 1, 1]\n",
      "     |      Categories (3, int64): [1, 2, 5]\n",
      "     |      \n",
      "     |      Inplace sorting can be done as well:\n",
      "     |      \n",
      "     |      >>> c.sort_values(inplace=True)\n",
      "     |      >>> c\n",
      "     |      [1, 1, 2, 2, 5]\n",
      "     |      Categories (3, int64): [1, 2, 5]\n",
      "     |      >>>\n",
      "     |      >>> c = pd.Categorical([1, 2, 2, 1, 5])\n",
      "     |      \n",
      "     |      'sort_values' behaviour with NaNs. Note that 'na_position'\n",
      "     |      is independent of the 'ascending' parameter:\n",
      "     |      \n",
      "     |      >>> c = pd.Categorical([np.nan, 2, 2, np.nan, 5])\n",
      "     |      >>> c\n",
      "     |      [NaN, 2.0, 2.0, NaN, 5.0]\n",
      "     |      Categories (2, int64): [2, 5]\n",
      "     |      >>> c.sort_values()\n",
      "     |      [2.0, 2.0, 5.0, NaN, NaN]\n",
      "     |      Categories (2, int64): [2, 5]\n",
      "     |      >>> c.sort_values(ascending=False)\n",
      "     |      [5.0, 2.0, 2.0, NaN, NaN]\n",
      "     |      Categories (2, int64): [2, 5]\n",
      "     |      >>> c.sort_values(na_position='first')\n",
      "     |      [NaN, NaN, 2.0, 2.0, 5.0]\n",
      "     |      Categories (2, int64): [2, 5]\n",
      "     |      >>> c.sort_values(ascending=False, na_position='first')\n",
      "     |      [NaN, NaN, 5.0, 2.0, 2.0]\n",
      "     |      Categories (2, int64): [2, 5]\n",
      "     |  \n",
      "     |  take = take_nd(self, indexer, allow_fill=True, fill_value=None)\n",
      "     |      Take the codes by the indexer, fill with the fill_value.\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |  \n",
      "     |  take_nd(self, indexer, allow_fill=True, fill_value=None)\n",
      "     |      Take the codes by the indexer, fill with the fill_value.\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |  \n",
      "     |  to_dense(self)\n",
      "     |      Return my 'dense' representation\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dense : array\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Return a list of the values.\n",
      "     |      \n",
      "     |      These are each a scalar type, which is a Python scalar\n",
      "     |      (for str, int, float) or a pandas scalar\n",
      "     |      (for Timestamp/Timedelta/Interval/Period)\n",
      "     |  \n",
      "     |  unique(self)\n",
      "     |      Return the ``Categorical`` which ``categories`` and ``codes`` are\n",
      "     |      unique. Unused categories are NOT returned.\n",
      "     |      \n",
      "     |      - unordered category: values and categories are sorted by appearance\n",
      "     |        order.\n",
      "     |      - ordered category: values are sorted by appearance order, categories\n",
      "     |        keeps existing order.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unique values : ``Categorical``\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      An unordered Categorical will return categories in the\n",
      "     |      order of appearance.\n",
      "     |      \n",
      "     |      >>> pd.Categorical(list('baabc'))\n",
      "     |      [b, a, c]\n",
      "     |      Categories (3, object): [b, a, c]\n",
      "     |      \n",
      "     |      >>> pd.Categorical(list('baabc'), categories=list('abc'))\n",
      "     |      [b, a, c]\n",
      "     |      Categories (3, object): [b, a, c]\n",
      "     |      \n",
      "     |      An ordered Categorical preserves the category ordering.\n",
      "     |      \n",
      "     |      >>> pd.Categorical(list('baabc'),\n",
      "     |      ...                categories=list('abc'),\n",
      "     |      ...                ordered=True)\n",
      "     |      [b, a, c]\n",
      "     |      Categories (3, object): [a < b < c]\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      unique\n",
      "     |      CategoricalIndex.unique\n",
      "     |      Series.unique\n",
      "     |  \n",
      "     |  value_counts(self, dropna=True)\n",
      "     |      Returns a Series containing counts of each category.\n",
      "     |      \n",
      "     |      Every category will have an entry, even those with a count of 0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include counts of NaN, even if NaN is a category.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      counts : Series\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.value_counts\n",
      "     |  \n",
      "     |  view(self)\n",
      "     |      Return a view of myself.\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      view : Categorical\n",
      "     |         Returns `self`!\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pandas.core.categorical.Categorical:\n",
      "     |  \n",
      "     |  from_array(data, **kwargs) from builtins.type\n",
      "     |      .. deprecated:: 0.19.0\n",
      "     |         Use ``Categorical`` instead.\n",
      "     |      \n",
      "     |      Make a Categorical type from a single array-like object.\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array-like\n",
      "     |          Can be an Index or array-like. The categories are assumed to be\n",
      "     |          the unique values of `data`.\n",
      "     |  \n",
      "     |  from_codes(codes, categories, ordered=False) from builtins.type\n",
      "     |      Make a Categorical type from codes and categories arrays.\n",
      "     |      \n",
      "     |      This constructor is useful if you already have codes and categories and\n",
      "     |      so do not need the (computation intensive) factorization step, which is\n",
      "     |      usually done on the constructor.\n",
      "     |      \n",
      "     |      If your data does not follow this convention, please use the normal\n",
      "     |      constructor.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      codes : array-like, integers\n",
      "     |          An integer array, where each integer points to a category in\n",
      "     |          categories or -1 for NaN\n",
      "     |      categories : index-like\n",
      "     |          The categories for the categorical. Items need to be unique.\n",
      "     |      ordered : boolean, (default False)\n",
      "     |          Whether or not this categorical is treated as a ordered\n",
      "     |          categorical. If not given, the resulting categorical will be\n",
      "     |          unordered.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.categorical.Categorical:\n",
      "     |  \n",
      "     |  T\n",
      "     |  \n",
      "     |  base\n",
      "     |      compat, we are always our own object\n",
      "     |  \n",
      "     |  categories\n",
      "     |      The categories of this categorical.\n",
      "     |      \n",
      "     |      Setting assigns new values to each category (effectively a rename of\n",
      "     |      each individual category).\n",
      "     |      \n",
      "     |      The assigned value has to be a list-like object. All items must be\n",
      "     |      unique and the number of items in the new categories must be the same\n",
      "     |      as the number of items in the old categories.\n",
      "     |      \n",
      "     |      Assigning to `categories` is a inplace operation!\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the new categories do not validate as categories or if the\n",
      "     |          number of new categories is unequal the number of old categories\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      rename_categories\n",
      "     |      reorder_categories\n",
      "     |      add_categories\n",
      "     |      remove_categories\n",
      "     |      remove_unused_categories\n",
      "     |      set_categories\n",
      "     |  \n",
      "     |  codes\n",
      "     |      The category codes of this categorical.\n",
      "     |      \n",
      "     |      Level codes are an array if integer which are the positions of the real\n",
      "     |      values in the categories array.\n",
      "     |      \n",
      "     |      There is not setter, use the other categorical methods and the normal item\n",
      "     |      setter to change values in the categorical.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The :ref:`~pandas.api.types.CategoricalDtype` for this instance\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |  \n",
      "     |  labels\n",
      "     |      Get the category labels (deprecated).\n",
      "     |      \n",
      "     |      Deprecated, use .codes!\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |  \n",
      "     |  ndim\n",
      "     |  \n",
      "     |  ordered\n",
      "     |      Whether the categories have an ordered relationship\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the Categorical.\n",
      "     |      \n",
      "     |      For internal compatibility with numpy arrays.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shape : tuple\n",
      "     |  \n",
      "     |  size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.categorical.Categorical:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for a object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __bytes__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Invoked by bytes(obj) in py3 only.\n",
      "     |      Yields a bytestring in both py2/py3.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return a string representation for a particular Object\n",
      "     |      \n",
      "     |      Invoked by str(df) in both py2/py3.\n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion\n",
      "     |      Only provide 'public' methods\n",
      "    \n",
      "    class SubclassedDataFrame(pandas.core.frame.DataFrame)\n",
      "     |  Two-dimensional size-mutable, potentially heterogeneous tabular data\n",
      "     |  structure with labeled axes (rows and columns). Arithmetic operations\n",
      "     |  align on both row and column labels. Can be thought of as a dict-like\n",
      "     |  container for Series objects. The primary pandas data structure\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : numpy ndarray (structured or homogeneous), dict, or DataFrame\n",
      "     |      Dict can contain Series, arrays, constants, or list-like objects\n",
      "     |  index : Index or array-like\n",
      "     |      Index to use for resulting frame. Will default to np.arange(n) if\n",
      "     |      no indexing information part of input data and no index provided\n",
      "     |  columns : Index or array-like\n",
      "     |      Column labels to use for resulting frame. Will default to\n",
      "     |      np.arange(n) if no column labels are provided\n",
      "     |  dtype : dtype, default None\n",
      "     |      Data type to force. Only a single dtype is allowed. If None, infer\n",
      "     |  copy : boolean, default False\n",
      "     |      Copy data from inputs. Only affects DataFrame / 2d ndarray input\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Constructing DataFrame from a dictionary.\n",
      "     |  \n",
      "     |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      "     |  >>> df = pd.DataFrame(data=d)\n",
      "     |  >>> df\n",
      "     |     col1  col2\n",
      "     |  0     1     3\n",
      "     |  1     2     4\n",
      "     |  \n",
      "     |  Notice that the inferred dtype is int64.\n",
      "     |  \n",
      "     |  >>> df.dtypes\n",
      "     |  col1    int64\n",
      "     |  col2    int64\n",
      "     |  dtype: object\n",
      "     |  \n",
      "     |  To enforce a single dtype:\n",
      "     |  \n",
      "     |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      "     |  >>> df.dtypes\n",
      "     |  col1    int8\n",
      "     |  col2    int8\n",
      "     |  dtype: object\n",
      "     |  \n",
      "     |  Constructing DataFrame from numpy ndarray:\n",
      "     |  \n",
      "     |  >>> df2 = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)),\n",
      "     |  ...                    columns=['a', 'b', 'c', 'd', 'e'])\n",
      "     |  >>> df2\n",
      "     |      a   b   c   d   e\n",
      "     |  0   2   8   8   3   4\n",
      "     |  1   4   2   9   0   9\n",
      "     |  2   1   0   7   8   0\n",
      "     |  3   5   1   7   1   3\n",
      "     |  4   6   0   2   4   2\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  DataFrame.from_records : constructor from tuples, also record arrays\n",
      "     |  DataFrame.from_dict : from dicts of Series, arrays, or dicts\n",
      "     |  DataFrame.from_items : from sequence of (key, value) pairs\n",
      "     |  pandas.read_csv, pandas.read_table, pandas.read_clipboard\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SubclassedDataFrame\n",
      "     |      pandas.core.frame.DataFrame\n",
      "     |      pandas.core.generic.NDFrame\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.base.StringMixin\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  __add__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __add__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __and__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __and__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __div__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Wrapper for comparison method __eq__\n",
      "     |  \n",
      "     |  __floordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __floordiv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Wrapper for comparison method __ge__\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Wrapper for comparison method __gt__\n",
      "     |  \n",
      "     |  __iadd__ = f(self, other)\n",
      "     |  \n",
      "     |  __iand__ = f(self, other)\n",
      "     |  \n",
      "     |  __ifloordiv__ = f(self, other)\n",
      "     |  \n",
      "     |  __imod__ = f(self, other)\n",
      "     |  \n",
      "     |  __imul__ = f(self, other)\n",
      "     |  \n",
      "     |  __init__(self, data=None, index=None, columns=None, dtype=None, copy=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __ior__ = f(self, other)\n",
      "     |  \n",
      "     |  __ipow__ = f(self, other)\n",
      "     |  \n",
      "     |  __isub__ = f(self, other)\n",
      "     |  \n",
      "     |  __itruediv__ = f(self, other)\n",
      "     |  \n",
      "     |  __ixor__ = f(self, other)\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Wrapper for comparison method __le__\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns length of info axis, but here we use the index\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Wrapper for comparison method __lt__\n",
      "     |  \n",
      "     |  __mod__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __mod__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __mul__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __mul__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Wrapper for comparison method __ne__\n",
      "     |  \n",
      "     |  __or__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __or__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __pow__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __pow__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __radd__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __radd__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rand__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __rand__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rdiv__ = __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rfloordiv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rmod__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rmod__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rmul__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rmul__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __ror__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __ror__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rpow__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rpow__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rsub__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rsub__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rxor__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __rxor__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  __sub__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __sub__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Return a string representation for a particular DataFrame\n",
      "     |      \n",
      "     |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      "     |      py2/py3.\n",
      "     |  \n",
      "     |  __xor__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __xor__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Addition of dataframe and other, element-wise (binary operator `add`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.radd\n",
      "     |  \n",
      "     |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      >>> df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      Aggregate these functions across all columns\n",
      "     |      \n",
      "     |      >>> df.agg(['sum', 'min'])\n",
      "     |                  A         B         C\n",
      "     |      sum -0.182253 -0.614014 -2.909534\n",
      "     |      min -1.916563 -1.460076 -1.568297\n",
      "     |      \n",
      "     |      Different aggregations per column\n",
      "     |      \n",
      "     |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      "     |                  A         B\n",
      "     |      max       NaN  1.514318\n",
      "     |      min -1.916563 -1.460076\n",
      "     |      sum -0.182253       NaN\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.transform\n",
      "     |      pandas.DataFrame.groupby.aggregate\n",
      "     |      pandas.DataFrame.resample.aggregate\n",
      "     |      pandas.DataFrame.rolling.aggregate\n",
      "     |  \n",
      "     |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      >>> df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      Aggregate these functions across all columns\n",
      "     |      \n",
      "     |      >>> df.agg(['sum', 'min'])\n",
      "     |                  A         B         C\n",
      "     |      sum -0.182253 -0.614014 -2.909534\n",
      "     |      min -1.916563 -1.460076 -1.568297\n",
      "     |      \n",
      "     |      Different aggregations per column\n",
      "     |      \n",
      "     |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      "     |                  A         B\n",
      "     |      max       NaN  1.514318\n",
      "     |      min -1.916563 -1.460076\n",
      "     |      sum -0.182253       NaN\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.transform\n",
      "     |      pandas.DataFrame.groupby.aggregate\n",
      "     |      pandas.DataFrame.resample.aggregate\n",
      "     |      pandas.DataFrame.rolling.aggregate\n",
      "     |  \n",
      "     |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      "     |      Align two objects on their axes with the\n",
      "     |      specified join method for each axis Index\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series\n",
      "     |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      "     |      axis : allowed axis of the other object, default None\n",
      "     |          Align on index (0), columns (1), or both (None)\n",
      "     |      level : int or level name, default None\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      copy : boolean, default True\n",
      "     |          Always returns new objects. If copy=False and no reindexing is\n",
      "     |          required then original objects are returned.\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      method : str, default None\n",
      "     |      limit : int, default None\n",
      "     |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Filling axis, method and limit\n",
      "     |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      "     |          Broadcast values along this axis, if aligning two objects of\n",
      "     |          different dimensions\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      (left, right) : (DataFrame, type of other)\n",
      "     |          Aligned objects\n",
      "     |  \n",
      "     |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether all elements are True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      all : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether any element is True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      any : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  append(self, other, ignore_index=False, verify_integrity=False)\n",
      "     |      Append rows of `other` to the end of this frame, returning a new\n",
      "     |      object. Columns not in this frame are added as new columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series/dict-like object, or list of these\n",
      "     |          The data to append.\n",
      "     |      ignore_index : boolean, default False\n",
      "     |          If True, do not use the index labels.\n",
      "     |      verify_integrity : boolean, default False\n",
      "     |          If True, raise ValueError on creating index with duplicates.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      appended : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If a list of dict/series is passed and the keys are all contained in\n",
      "     |      the DataFrame's index, the order of the columns in the resulting\n",
      "     |      DataFrame will be unchanged.\n",
      "     |      \n",
      "     |      Iteratively appending rows to a DataFrame can be more computationally\n",
      "     |      intensive than a single concatenate. A better solution is to append\n",
      "     |      those rows to a list and then concatenate the list with the original\n",
      "     |      DataFrame all at once.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.concat : General function to concatenate DataFrame, Series\n",
      "     |          or Panel objects\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      1  3  4\n",
      "     |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      "     |      >>> df.append(df2)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      1  3  4\n",
      "     |      0  5  6\n",
      "     |      1  7  8\n",
      "     |      \n",
      "     |      With `ignore_index` set to True:\n",
      "     |      \n",
      "     |      >>> df.append(df2, ignore_index=True)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      1  3  4\n",
      "     |      2  5  6\n",
      "     |      3  7  8\n",
      "     |      \n",
      "     |      The following, while not recommended methods for generating DataFrames,\n",
      "     |      show two ways to generate a DataFrame from multiple data sources.\n",
      "     |      \n",
      "     |      Less efficient:\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(columns=['A'])\n",
      "     |      >>> for i in range(5):\n",
      "     |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  0\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      4  4\n",
      "     |      \n",
      "     |      More efficient:\n",
      "     |      \n",
      "     |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      "     |      ...           ignore_index=True)\n",
      "     |         A\n",
      "     |      0  0\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      4  4\n",
      "     |  \n",
      "     |  apply(self, func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)\n",
      "     |      Applies function along input axis of DataFrame.\n",
      "     |      \n",
      "     |      Objects passed to functions are Series objects having index\n",
      "     |      either the DataFrame's index (axis=0) or the columns (axis=1).\n",
      "     |      Return type depends on whether passed function aggregates, or the\n",
      "     |      reduce argument if the DataFrame is empty.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          Function to apply to each column/row\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          * 0 or 'index': apply function to each column\n",
      "     |          * 1 or 'columns': apply function to each row\n",
      "     |      broadcast : boolean, default False\n",
      "     |          For aggregation functions, return object of same size with values\n",
      "     |          propagated\n",
      "     |      raw : boolean, default False\n",
      "     |          If False, convert each row or column into a Series. If raw=True the\n",
      "     |          passed function will receive ndarray objects instead. If you are\n",
      "     |          just applying a NumPy reduction function this will achieve much\n",
      "     |          better performance\n",
      "     |      reduce : boolean or None, default None\n",
      "     |          Try to apply reduction procedures. If the DataFrame is empty,\n",
      "     |          apply will use reduce to determine whether the result should be a\n",
      "     |          Series or a DataFrame. If reduce is None (the default), apply's\n",
      "     |          return value will be guessed by calling func an empty Series (note:\n",
      "     |          while guessing, exceptions raised by func will be ignored). If\n",
      "     |          reduce is True a Series will always be returned, and if False a\n",
      "     |          DataFrame will always be returned.\n",
      "     |      args : tuple\n",
      "     |          Positional arguments to pass to function in addition to the\n",
      "     |          array/series\n",
      "     |      Additional keyword arguments will be passed as keywords to the function\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      In the current implementation apply calls func twice on the\n",
      "     |      first column/row to decide whether it can take a fast or slow\n",
      "     |      code path. This can lead to unexpected behavior if func has\n",
      "     |      side-effects, as they will take effect twice for the first\n",
      "     |      column/row.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df.apply(numpy.sqrt) # returns DataFrame\n",
      "     |      >>> df.apply(numpy.sum, axis=0) # equiv to df.sum(0)\n",
      "     |      >>> df.apply(numpy.sum, axis=1) # equiv to df.sum(1)\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.applymap: For elementwise operations\n",
      "     |      DataFrame.aggregate: only perform aggregating type operations\n",
      "     |      DataFrame.transform: only perform transformating type operations\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : Series or DataFrame\n",
      "     |  \n",
      "     |  applymap(self, func)\n",
      "     |      Apply a function to a DataFrame that is intended to operate\n",
      "     |      elementwise, i.e. like doing map(func, series) for each series in the\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          Python function, returns a single value from a single value\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.random.randn(3, 3))\n",
      "     |      >>> df\n",
      "     |          0         1          2\n",
      "     |      0  -0.029638  1.081563   1.280300\n",
      "     |      1   0.647747  0.831136  -1.549481\n",
      "     |      2   0.513416 -0.884417   0.195343\n",
      "     |      >>> df = df.applymap(lambda x: '%.2f' % x)\n",
      "     |      >>> df\n",
      "     |          0         1          2\n",
      "     |      0  -0.03      1.08       1.28\n",
      "     |      1   0.65      0.83      -1.55\n",
      "     |      2   0.51     -0.88       0.20\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.apply : For operations on rows/columns\n",
      "     |  \n",
      "     |  assign(self, **kwargs)\n",
      "     |      Assign new columns to a DataFrame, returning a new object\n",
      "     |      (a copy) with all the original columns in addition to the new ones.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kwargs : keyword, value pairs\n",
      "     |          keywords are the column names. If the values are\n",
      "     |          callable, they are computed on the DataFrame and\n",
      "     |          assigned to the new columns. The callable must not\n",
      "     |          change input DataFrame (though pandas doesn't check it).\n",
      "     |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      "     |          they are simply assigned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame\n",
      "     |          A new DataFrame with the new columns in addition to\n",
      "     |          all the existing columns.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For python 3.6 and above, the columns are inserted in the order of\n",
      "     |      \\*\\*kwargs. For python 3.5 and earlier, since \\*\\*kwargs is unordered,\n",
      "     |      the columns are inserted in alphabetical order at the end of your\n",
      "     |      DataFrame.  Assigning multiple columns within the same ``assign``\n",
      "     |      is possible, but you cannot reference other columns created within\n",
      "     |      the same ``assign`` call.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = DataFrame({'A': range(1, 11), 'B': np.random.randn(10)})\n",
      "     |      \n",
      "     |      Where the value is a callable, evaluated on `df`:\n",
      "     |      \n",
      "     |      >>> df.assign(ln_A = lambda x: np.log(x.A))\n",
      "     |          A         B      ln_A\n",
      "     |      0   1  0.426905  0.000000\n",
      "     |      1   2 -0.780949  0.693147\n",
      "     |      2   3 -0.418711  1.098612\n",
      "     |      3   4 -0.269708  1.386294\n",
      "     |      4   5 -0.274002  1.609438\n",
      "     |      5   6 -0.500792  1.791759\n",
      "     |      6   7  1.649697  1.945910\n",
      "     |      7   8 -1.495604  2.079442\n",
      "     |      8   9  0.549296  2.197225\n",
      "     |      9  10 -0.758542  2.302585\n",
      "     |      \n",
      "     |      Where the value already exists and is inserted:\n",
      "     |      \n",
      "     |      >>> newcol = np.log(df['A'])\n",
      "     |      >>> df.assign(ln_A=newcol)\n",
      "     |          A         B      ln_A\n",
      "     |      0   1  0.426905  0.000000\n",
      "     |      1   2 -0.780949  0.693147\n",
      "     |      2   3 -0.418711  1.098612\n",
      "     |      3   4 -0.269708  1.386294\n",
      "     |      4   5 -0.274002  1.609438\n",
      "     |      5   6 -0.500792  1.791759\n",
      "     |      6   7  1.649697  1.945910\n",
      "     |      7   8 -1.495604  2.079442\n",
      "     |      8   9  0.549296  2.197225\n",
      "     |      9  10 -0.758542  2.302585\n",
      "     |  \n",
      "     |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, **kwds)\n",
      "     |      Make a box plot from DataFrame column optionally grouped by some columns or\n",
      "     |      other inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : the pandas object holding the data\n",
      "     |      column : column name or list of names, or vector\n",
      "     |          Can be any valid input to groupby\n",
      "     |      by : string or sequence\n",
      "     |          Column in the DataFrame to group by\n",
      "     |      ax : Matplotlib axes object, optional\n",
      "     |      fontsize : int or string\n",
      "     |      rot : label rotation angle\n",
      "     |      figsize : A tuple (width, height) in inches\n",
      "     |      grid : Setting this to True will show the grid\n",
      "     |      layout : tuple (optional)\n",
      "     |          (rows, columns) for the layout of the plot\n",
      "     |      return_type : {None, 'axes', 'dict', 'both'}, default None\n",
      "     |          The kind of object to return. The default is ``axes``\n",
      "     |          'axes' returns the matplotlib axes the boxplot is drawn on;\n",
      "     |          'dict' returns a dictionary  whose values are the matplotlib\n",
      "     |          Lines of the boxplot;\n",
      "     |          'both' returns a namedtuple with the axes and dict.\n",
      "     |      \n",
      "     |          When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      "     |          is returned, unless ``return_type`` is None, in which case a NumPy\n",
      "     |          array of axes is returned with the same shape as ``layout``.\n",
      "     |          See the prose documentation for more.\n",
      "     |      \n",
      "     |      kwds : other plotting keyword arguments to be passed to matplotlib boxplot\n",
      "     |             function\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      lines : dict\n",
      "     |      ax : matplotlib Axes\n",
      "     |      (ax, lines): namedtuple\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      "     |      of the lines after plotting. In this case a dict containing the Lines\n",
      "     |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      "     |  \n",
      "     |  combine(self, other, func, fill_value=None, overwrite=True)\n",
      "     |      Add two DataFrame objects and do not propagate NaN values, so if for a\n",
      "     |      (column, time) one frame is missing a value, it will default to the\n",
      "     |      other frame's value (which might be NaN as well)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame\n",
      "     |      func : function\n",
      "     |          Function that takes two series as inputs and return a Series or a\n",
      "     |          scalar\n",
      "     |      fill_value : scalar value\n",
      "     |      overwrite : boolean, default True\n",
      "     |          If True then overwrite values for common keys in the calling frame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df1 = DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      "     |      >>> df2 = DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      "     |      >>> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2)\n",
      "     |         A  B\n",
      "     |      0  0  3\n",
      "     |      1  0  3\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      "     |          non-null values in frame calling the method\n",
      "     |  \n",
      "     |  combine_first(self, other)\n",
      "     |      Combine two DataFrame objects and default to non-null values in frame\n",
      "     |      calling the method. Result index columns will be the union of the\n",
      "     |      respective indexes and columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      combined : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      df1's values prioritized, use values from df2 to fill holes:\n",
      "     |      \n",
      "     |      >>> df1 = pd.DataFrame([[1, np.nan]])\n",
      "     |      >>> df2 = pd.DataFrame([[3, 4]])\n",
      "     |      >>> df1.combine_first(df2)\n",
      "     |         0    1\n",
      "     |      0  1  4.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      "     |          using a given function\n",
      "     |  \n",
      "     |  compound(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the compound percentage of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      compounded : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  corr(self, method='pearson', min_periods=1)\n",
      "     |      Compute pairwise correlation of columns, excluding NA/null values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'pearson', 'kendall', 'spearman'}\n",
      "     |          * pearson : standard correlation coefficient\n",
      "     |          * kendall : Kendall Tau correlation coefficient\n",
      "     |          * spearman : Spearman rank correlation\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations required per pair of columns\n",
      "     |          to have a valid result. Currently only available for pearson\n",
      "     |          and spearman correlation\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : DataFrame\n",
      "     |  \n",
      "     |  corrwith(self, other, axis=0, drop=False)\n",
      "     |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      "     |      objects.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      "     |      drop : boolean, default False\n",
      "     |          Drop missing indices from result, default returns union of all\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      correls : Series\n",
      "     |  \n",
      "     |  count(self, axis=0, level=None, numeric_only=False)\n",
      "     |      Return Series with number of non-NA/null observations over requested\n",
      "     |      axis. Works with non-floating point data as well (detects NaN and None)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a DataFrame\n",
      "     |      numeric_only : boolean, default False\n",
      "     |          Include only float, int, boolean data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      count : Series (or DataFrame if level specified)\n",
      "     |  \n",
      "     |  cov(self, min_periods=None)\n",
      "     |      Compute pairwise covariance of columns, excluding NA/null values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations required per pair of columns\n",
      "     |          to have a valid result.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `y` contains the covariance matrix of the DataFrame's time series.\n",
      "     |      The covariance is normalized by N-1 (unbiased estimator).\n",
      "     |  \n",
      "     |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative max over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummax : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.max : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative minimum over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummin : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.min : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative product over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumprod : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.prod : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative sum over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumsum : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.sum : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  diff(self, periods=1, axis=0)\n",
      "     |      1st discrete difference of object\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming difference\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Take difference over rows (0) or columns (1).\n",
      "     |      \n",
      "     |          .. versionadded: 0.16.1\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      diffed : DataFrame\n",
      "     |  \n",
      "     |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rtruediv\n",
      "     |  \n",
      "     |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rtruediv\n",
      "     |  \n",
      "     |  dot(self, other)\n",
      "     |      Matrix multiplication with DataFrame or Series objects\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dot_product : DataFrame or Series\n",
      "     |  \n",
      "     |  drop_duplicates(self, subset=None, keep='first', inplace=False)\n",
      "     |      Return DataFrame with duplicate rows removed, optionally only\n",
      "     |      considering certain columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      subset : column label or sequence of labels, optional\n",
      "     |          Only consider certain columns for identifying duplicates, by\n",
      "     |          default use all of the columns\n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      "     |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      "     |          - False : Drop all duplicates.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to drop duplicates in place or to return a copy\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      deduplicated : DataFrame\n",
      "     |  \n",
      "     |  dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      "     |      Return object with labels on given axis omitted where alternately any\n",
      "     |      or all of the data are missing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, or tuple/list thereof\n",
      "     |          Pass tuple or list to drop on multiple axes\n",
      "     |      how : {'any', 'all'}\n",
      "     |          * any : if any NA values are present, drop that label\n",
      "     |          * all : if all values are NA, drop that label\n",
      "     |      thresh : int, default None\n",
      "     |          int value : require that many non-NA values\n",
      "     |      subset : array-like\n",
      "     |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      "     |          these would be a list of columns to include\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, do operation inplace and return None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dropped : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0], [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5]],\n",
      "     |      ...                   columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      \n",
      "     |      Drop the columns where all elements are nan:\n",
      "     |      \n",
      "     |      >>> df.dropna(axis=1, how='all')\n",
      "     |           A    B  D\n",
      "     |      0  NaN  2.0  0\n",
      "     |      1  3.0  4.0  1\n",
      "     |      2  NaN  NaN  5\n",
      "     |      \n",
      "     |      Drop the columns where any of the elements is nan\n",
      "     |      \n",
      "     |      >>> df.dropna(axis=1, how='any')\n",
      "     |         D\n",
      "     |      0  0\n",
      "     |      1  1\n",
      "     |      2  5\n",
      "     |      \n",
      "     |      Drop the rows where all of the elements are nan\n",
      "     |      (there is no row to drop, so df stays the same):\n",
      "     |      \n",
      "     |      >>> df.dropna(axis=0, how='all')\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      \n",
      "     |      Keep only the rows with at least 2 non-na values:\n",
      "     |      \n",
      "     |      >>> df.dropna(thresh=2)\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |  \n",
      "     |  duplicated(self, subset=None, keep='first')\n",
      "     |      Return boolean Series denoting duplicate rows, optionally only\n",
      "     |      considering certain columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      subset : column label or sequence of labels, optional\n",
      "     |          Only consider certain columns for identifying duplicates, by\n",
      "     |          default use all of the columns\n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Mark duplicates as ``True`` except for the\n",
      "     |            first occurrence.\n",
      "     |          - ``last`` : Mark duplicates as ``True`` except for the\n",
      "     |            last occurrence.\n",
      "     |          - False : Mark all duplicates as ``True``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      duplicated : Series\n",
      "     |  \n",
      "     |  eq(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods eq\n",
      "     |  \n",
      "     |  eval(self, expr, inplace=False, **kwargs)\n",
      "     |      Evaluate an expression in the context of the calling DataFrame\n",
      "     |      instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      expr : string\n",
      "     |          The expression string to evaluate.\n",
      "     |      inplace : bool, default False\n",
      "     |          If the expression contains an assignment, whether to perform the\n",
      "     |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      "     |          a new DataFrame is returned.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      kwargs : dict\n",
      "     |          See the documentation for :func:`~pandas.eval` for complete details\n",
      "     |          on the keyword arguments accepted by\n",
      "     |          :meth:`~pandas.DataFrame.query`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ret : ndarray, scalar, or pandas object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.query\n",
      "     |      pandas.DataFrame.assign\n",
      "     |      pandas.eval\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For more details see the API documentation for :func:`~pandas.eval`.\n",
      "     |      For detailed examples see :ref:`enhancing performance with eval\n",
      "     |      <enhancingperf.eval>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from numpy.random import randn\n",
      "     |      >>> from pandas import DataFrame\n",
      "     |      >>> df = DataFrame(randn(10, 2), columns=list('ab'))\n",
      "     |      >>> df.eval('a + b')\n",
      "     |      >>> df.eval('c = a + b')\n",
      "     |  \n",
      "     |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, freq=None, adjust=True, ignore_na=False, axis=0)\n",
      "     |      Provides exponential weighted functions\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      com : float, optional\n",
      "     |          Specify decay in terms of center of mass,\n",
      "     |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      "     |      span : float, optional\n",
      "     |          Specify decay in terms of span,\n",
      "     |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      "     |      halflife : float, optional\n",
      "     |          Specify decay in terms of half-life,\n",
      "     |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      "     |      alpha : float, optional\n",
      "     |          Specify smoothing factor :math:`\\alpha` directly,\n",
      "     |          :math:`0 < \\alpha \\leq 1`\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      min_periods : int, default 0\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : None or string alias / date offset object, default=None\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform to before computing statistic\n",
      "     |      adjust : boolean, default True\n",
      "     |          Divide by decaying adjustment factor in beginning periods to account\n",
      "     |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      "     |      ignore_na : boolean, default False\n",
      "     |          Ignore missing values when calculating weights;\n",
      "     |          specify True to reproduce pre-0.15.0 behavior\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.ewm(com=0.5).mean()\n",
      "     |                B\n",
      "     |      0  0.000000\n",
      "     |      1  0.750000\n",
      "     |      2  1.615385\n",
      "     |      3  1.615385\n",
      "     |      4  3.670213\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      "     |      Allowed values and relationship between the parameters are specified in the\n",
      "     |      parameter descriptions above; see the link at the end of this section for\n",
      "     |      a detailed explanation.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      When adjust is True (default), weighted averages are calculated using\n",
      "     |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      "     |      \n",
      "     |      When adjust is False, weighted averages are calculated recursively as:\n",
      "     |         weighted_average[0] = arg[0];\n",
      "     |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      "     |      \n",
      "     |      When ignore_na is False (default), weights are based on absolute positions.\n",
      "     |      For example, the weights of x and y used in calculating the final weighted\n",
      "     |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      "     |      (1-alpha)**2 and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      "     |      on relative positions. For example, the weights of x and y used in\n",
      "     |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      "     |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      More details can be found at\n",
      "     |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      "     |  \n",
      "     |  expanding(self, min_periods=1, freq=None, center=False, axis=0)\n",
      "     |      Provides expanding transformations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.expanding(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  3.0\n",
      "     |      4  7.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |  \n",
      "     |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      "     |      Fill NA/NaN values using the specified method\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar, dict, Series, or DataFrame\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a\n",
      "     |          dict/Series/DataFrame of values specifying which value to use for\n",
      "     |          each index (for a Series) or column (for a DataFrame). (values not\n",
      "     |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      "     |          be a list.\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use NEXT valid observation to fill gap\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, fill in place. Note: this will modify any\n",
      "     |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      "     |          DataFrame).\n",
      "     |      limit : int, default None\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled. Must be greater than 0 if not None.\n",
      "     |      downcast : dict, default is None\n",
      "     |          a dict of item->dtype of what to downcast if possible,\n",
      "     |          or the string 'infer' which will try to downcast to an appropriate\n",
      "     |          equal type (e.g. float64 to int64 if possible)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, asfreq\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "     |      ...                    [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      "     |      ...                    [np.nan, 3, np.nan, 4]],\n",
      "     |      ...                    columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      3  NaN  3.0 NaN  4\n",
      "     |      \n",
      "     |      Replace all NaN elements with 0s.\n",
      "     |      \n",
      "     |      >>> df.fillna(0)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 0.0 0\n",
      "     |      1   3.0 4.0 0.0 1\n",
      "     |      2   0.0 0.0 0.0 5\n",
      "     |      3   0.0 3.0 0.0 4\n",
      "     |      \n",
      "     |      We can also propagate non-null values forward or backward.\n",
      "     |      \n",
      "     |      >>> df.fillna(method='ffill')\n",
      "     |          A   B   C   D\n",
      "     |      0   NaN 2.0 NaN 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   3.0 4.0 NaN 5\n",
      "     |      3   3.0 3.0 NaN 4\n",
      "     |      \n",
      "     |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "     |      2, and 3 respectively.\n",
      "     |      \n",
      "     |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "     |      >>> df.fillna(value=values)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 2.0 1\n",
      "     |      2   0.0 1.0 2.0 5\n",
      "     |      3   0.0 3.0 2.0 4\n",
      "     |      \n",
      "     |      Only replace the first NaN element.\n",
      "     |      \n",
      "     |      >>> df.fillna(value=values, limit=1)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   NaN 1.0 NaN 5\n",
      "     |      3   NaN 3.0 NaN 4\n",
      "     |  \n",
      "     |  first_valid_index(self)\n",
      "     |      Return index for first non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rfloordiv\n",
      "     |  \n",
      "     |  ge(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods ge\n",
      "     |  \n",
      "     |  get_value(self, index, col, takeable=False)\n",
      "     |      Quickly retrieve single value at passed column and index\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : row label\n",
      "     |      col : column label\n",
      "     |      takeable : interpret the index/col as indexers, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar value\n",
      "     |  \n",
      "     |  gt(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods gt\n",
      "     |  \n",
      "     |  hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, **kwds)\n",
      "     |      Draw histogram of the DataFrame's series using matplotlib / pylab.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : DataFrame\n",
      "     |      column : string or sequence\n",
      "     |          If passed, will be used to limit data to a subset of columns\n",
      "     |      by : object, optional\n",
      "     |          If passed, then used to form histograms for separate groups\n",
      "     |      grid : boolean, default True\n",
      "     |          Whether to show axis grid lines\n",
      "     |      xlabelsize : int, default None\n",
      "     |          If specified changes the x-axis label size\n",
      "     |      xrot : float, default None\n",
      "     |          rotation of x axis labels\n",
      "     |      ylabelsize : int, default None\n",
      "     |          If specified changes the y-axis label size\n",
      "     |      yrot : float, default None\n",
      "     |          rotation of y axis labels\n",
      "     |      ax : matplotlib axes object, default None\n",
      "     |      sharex : boolean, default True if ax is None else False\n",
      "     |          In case subplots=True, share x axis and set some x axis labels to\n",
      "     |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      "     |          is passed in; Be aware, that passing in both an ax and sharex=True\n",
      "     |          will alter all x axis labels for all subplots in a figure!\n",
      "     |      sharey : boolean, default False\n",
      "     |          In case subplots=True, share y axis and set some y axis labels to\n",
      "     |          invisible\n",
      "     |      figsize : tuple\n",
      "     |          The size of the figure to create in inches by default\n",
      "     |      layout : tuple, optional\n",
      "     |          Tuple of (rows, columns) for the layout of the histograms\n",
      "     |      bins : integer, default 10\n",
      "     |          Number of histogram bins to be used\n",
      "     |      kwds : other plotting keyword arguments\n",
      "     |          To be passed to hist function\n",
      "     |  \n",
      "     |  idxmax(self, axis=0, skipna=True)\n",
      "     |      Return index of first occurrence of maximum over requested axis.\n",
      "     |      NA/null values are excluded.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the row/column is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmax : Series\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.idxmax\n",
      "     |  \n",
      "     |  idxmin(self, axis=0, skipna=True)\n",
      "     |      Return index of first occurrence of minimum over requested axis.\n",
      "     |      NA/null values are excluded.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the row/column is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmin : Series\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.idxmin\n",
      "     |  \n",
      "     |  info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)\n",
      "     |      Concise summary of a DataFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : {None, True, False}, optional\n",
      "     |          Whether to print the full summary.\n",
      "     |          None follows the `display.max_info_columns` setting.\n",
      "     |          True or False overrides the `display.max_info_columns` setting.\n",
      "     |      buf : writable buffer, defaults to sys.stdout\n",
      "     |      max_cols : int, default None\n",
      "     |          Determines whether full summary or short summary is printed.\n",
      "     |          None follows the `display.max_info_columns` setting.\n",
      "     |      memory_usage : boolean/string, default None\n",
      "     |          Specifies whether total memory usage of the DataFrame\n",
      "     |          elements (including index) should be displayed. None follows\n",
      "     |          the `display.memory_usage` setting. True or False overrides\n",
      "     |          the `display.memory_usage` setting. A value of 'deep' is equivalent\n",
      "     |          of True, with deep introspection. Memory usage is shown in\n",
      "     |          human-readable units (base-2 representation).\n",
      "     |      null_counts : boolean, default None\n",
      "     |          Whether to show the non-null counts\n",
      "     |      \n",
      "     |          - If None, then only show if the frame is smaller than\n",
      "     |            max_info_rows and max_info_columns.\n",
      "     |          - If True, always show counts.\n",
      "     |          - If False, never show counts.\n",
      "     |  \n",
      "     |  insert(self, loc, column, value, allow_duplicates=False)\n",
      "     |      Insert column into DataFrame at specified location.\n",
      "     |      \n",
      "     |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      "     |      unless `allow_duplicates` is set to True.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : int\n",
      "     |          Insertion index. Must verify 0 <= loc <= len(columns)\n",
      "     |      column : string, number, or hashable object\n",
      "     |          label of the inserted column\n",
      "     |      value : int, Series, or array-like\n",
      "     |      allow_duplicates : bool, optional\n",
      "     |  \n",
      "     |  isin(self, values)\n",
      "     |      Return boolean DataFrame showing whether each element in the\n",
      "     |      DataFrame is contained in values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : iterable, Series, DataFrame or dictionary\n",
      "     |          The result will only be true at a location if all the\n",
      "     |          labels match. If `values` is a Series, that's the index. If\n",
      "     |          `values` is a dictionary, the keys must be the column names,\n",
      "     |          which must match. If `values` is a DataFrame,\n",
      "     |          then both the index and column labels must match.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      DataFrame of booleans\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      When ``values`` is a list:\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      "     |      >>> df.isin([1, 3, 12, 'a'])\n",
      "     |             A      B\n",
      "     |      0   True   True\n",
      "     |      1  False  False\n",
      "     |      2   True  False\n",
      "     |      \n",
      "     |      When ``values`` is a dict:\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\n",
      "     |      >>> df.isin({'A': [1, 3], 'B': [4, 7, 12]})\n",
      "     |             A      B\n",
      "     |      0   True  False  # Note that B didn't match the 1 here.\n",
      "     |      1  False   True\n",
      "     |      2   True   True\n",
      "     |      \n",
      "     |      When ``values`` is a Series or DataFrame:\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      "     |      >>> other = DataFrame({'A': [1, 3, 3, 2], 'B': ['e', 'f', 'f', 'e']})\n",
      "     |      >>> df.isin(other)\n",
      "     |             A      B\n",
      "     |      0   True  False\n",
      "     |      1  False  False  # Column A in `other` has a 3, but not at index 1.\n",
      "     |      2   True   True\n",
      "     |  \n",
      "     |  isna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.notna : boolean inverse of isna\n",
      "     |      DataFrame.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  isnull(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.notna : boolean inverse of isna\n",
      "     |      DataFrame.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  items = iteritems(self)\n",
      "     |      Iterator over (column name, Series) pairs.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      "     |  \n",
      "     |  iteritems(self)\n",
      "     |      Iterator over (column name, Series) pairs.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      "     |  \n",
      "     |  iterrows(self)\n",
      "     |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      1. Because ``iterrows`` returns a Series for each row,\n",
      "     |         it does **not** preserve dtypes across the rows (dtypes are\n",
      "     |         preserved across columns for DataFrames). For example,\n",
      "     |      \n",
      "     |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      "     |         >>> row = next(df.iterrows())[1]\n",
      "     |         >>> row\n",
      "     |         int      1.0\n",
      "     |         float    1.5\n",
      "     |         Name: 0, dtype: float64\n",
      "     |         >>> print(row['int'].dtype)\n",
      "     |         float64\n",
      "     |         >>> print(df['int'].dtype)\n",
      "     |         int64\n",
      "     |      \n",
      "     |         To preserve dtypes while iterating over the rows, it is better\n",
      "     |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      "     |         and which is generally faster than ``iterrows``.\n",
      "     |      \n",
      "     |      2. You should **never modify** something you are iterating over.\n",
      "     |         This is not guaranteed to work in all cases. Depending on the\n",
      "     |         data types, the iterator returns a copy and not a view, and writing\n",
      "     |         to it will have no effect.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it : generator\n",
      "     |          A generator that iterates over the rows of the frame.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      "     |      iteritems : Iterate over (column name, Series) pairs.\n",
      "     |  \n",
      "     |  itertuples(self, index=True, name='Pandas')\n",
      "     |      Iterate over DataFrame rows as namedtuples, with index value as first\n",
      "     |      element of the tuple.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : boolean, default True\n",
      "     |          If True, return the index as the first element of the tuple.\n",
      "     |      name : string, default \"Pandas\"\n",
      "     |          The name of the returned namedtuples or None to return regular\n",
      "     |          tuples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The column names will be renamed to positional names if they are\n",
      "     |      invalid Python identifiers, repeated, or start with an underscore.\n",
      "     |      With a large number of columns (>255), regular tuples are returned.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      iteritems : Iterate over (column name, Series) pairs.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]},\n",
      "     |                            index=['a', 'b'])\n",
      "     |      >>> df\n",
      "     |         col1  col2\n",
      "     |      a     1   0.1\n",
      "     |      b     2   0.2\n",
      "     |      >>> for row in df.itertuples():\n",
      "     |      ...     print(row)\n",
      "     |      ...\n",
      "     |      Pandas(Index='a', col1=1, col2=0.10000000000000001)\n",
      "     |      Pandas(Index='b', col1=2, col2=0.20000000000000001)\n",
      "     |  \n",
      "     |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
      "     |      Join columns with other DataFrame either on index or on a key\n",
      "     |      column. Efficiently Join multiple DataFrame objects by index at once by\n",
      "     |      passing a list.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame, Series with name field set, or list of DataFrame\n",
      "     |          Index should be similar to one of the columns in this one. If a\n",
      "     |          Series is passed, its name attribute must be set, and that will be\n",
      "     |          used as the column name in the resulting joined DataFrame\n",
      "     |      on : column name, tuple/list of column names, or array-like\n",
      "     |          Column(s) in the caller to join on the index in other,\n",
      "     |          otherwise joins index-on-index. If multiples\n",
      "     |          columns given, the passed DataFrame must have a MultiIndex. Can\n",
      "     |          pass an array as the join key if not already contained in the\n",
      "     |          calling DataFrame. Like an Excel VLOOKUP operation\n",
      "     |      how : {'left', 'right', 'outer', 'inner'}, default: 'left'\n",
      "     |          How to handle the operation of the two objects.\n",
      "     |      \n",
      "     |          * left: use calling frame's index (or column if on is specified)\n",
      "     |          * right: use other frame's index\n",
      "     |          * outer: form union of calling frame's index (or column if on is\n",
      "     |            specified) with other frame's index, and sort it\n",
      "     |            lexicographically\n",
      "     |          * inner: form intersection of calling frame's index (or column if\n",
      "     |            on is specified) with other frame's index, preserving the order\n",
      "     |            of the calling's one\n",
      "     |      lsuffix : string\n",
      "     |          Suffix to use from left frame's overlapping columns\n",
      "     |      rsuffix : string\n",
      "     |          Suffix to use from right frame's overlapping columns\n",
      "     |      sort : boolean, default False\n",
      "     |          Order result DataFrame lexicographically by the join key. If False,\n",
      "     |          the order of the join key depends on the join type (how keyword)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      on, lsuffix, and rsuffix options are not supported when passing a list\n",
      "     |      of DataFrame objects\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      "     |      ...                        'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      "     |      \n",
      "     |      >>> caller\n",
      "     |          A key\n",
      "     |      0  A0  K0\n",
      "     |      1  A1  K1\n",
      "     |      2  A2  K2\n",
      "     |      3  A3  K3\n",
      "     |      4  A4  K4\n",
      "     |      5  A5  K5\n",
      "     |      \n",
      "     |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      "     |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      "     |      \n",
      "     |      >>> other\n",
      "     |          B key\n",
      "     |      0  B0  K0\n",
      "     |      1  B1  K1\n",
      "     |      2  B2  K2\n",
      "     |      \n",
      "     |      Join DataFrames using their indexes.\n",
      "     |      \n",
      "     |      >>> caller.join(other, lsuffix='_caller', rsuffix='_other')\n",
      "     |      \n",
      "     |      >>>     A key_caller    B key_other\n",
      "     |          0  A0         K0   B0        K0\n",
      "     |          1  A1         K1   B1        K1\n",
      "     |          2  A2         K2   B2        K2\n",
      "     |          3  A3         K3  NaN       NaN\n",
      "     |          4  A4         K4  NaN       NaN\n",
      "     |          5  A5         K5  NaN       NaN\n",
      "     |      \n",
      "     |      \n",
      "     |      If we want to join using the key columns, we need to set key to be\n",
      "     |      the index in both caller and other. The joined DataFrame will have\n",
      "     |      key as its index.\n",
      "     |      \n",
      "     |      >>> caller.set_index('key').join(other.set_index('key'))\n",
      "     |      \n",
      "     |      >>>      A    B\n",
      "     |          key\n",
      "     |          K0   A0   B0\n",
      "     |          K1   A1   B1\n",
      "     |          K2   A2   B2\n",
      "     |          K3   A3  NaN\n",
      "     |          K4   A4  NaN\n",
      "     |          K5   A5  NaN\n",
      "     |      \n",
      "     |      Another option to join using the key columns is to use the on\n",
      "     |      parameter. DataFrame.join always uses other's index but we can use any\n",
      "     |      column in the caller. This method preserves the original caller's\n",
      "     |      index in the result.\n",
      "     |      \n",
      "     |      >>> caller.join(other.set_index('key'), on='key')\n",
      "     |      \n",
      "     |      >>>     A key    B\n",
      "     |          0  A0  K0   B0\n",
      "     |          1  A1  K1   B1\n",
      "     |          2  A2  K2   B2\n",
      "     |          3  A3  K3  NaN\n",
      "     |          4  A4  K4  NaN\n",
      "     |          5  A5  K5  NaN\n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.merge : For column(s)-on-columns(s) operations\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      joined : DataFrame\n",
      "     |  \n",
      "     |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  last_valid_index(self)\n",
      "     |      Return index for last non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  le(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods le\n",
      "     |  \n",
      "     |  lookup(self, row_labels, col_labels)\n",
      "     |      Label-based \"fancy indexing\" function for DataFrame.\n",
      "     |      Given equal-length arrays of row and column labels, return an\n",
      "     |      array of the values corresponding to each (row, col) pair.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      row_labels : sequence\n",
      "     |          The row labels to use for lookup\n",
      "     |      col_labels : sequence\n",
      "     |          The column labels to use for lookup\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Akin to::\n",
      "     |      \n",
      "     |          result = []\n",
      "     |          for row, col in zip(row_labels, col_labels):\n",
      "     |              result.append(df.get_value(row, col))\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      values : ndarray\n",
      "     |          The found values\n",
      "     |  \n",
      "     |  lt(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods lt\n",
      "     |  \n",
      "     |  mad(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the mean absolute deviation of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mad : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the maximum of the values in the object.\n",
      "     |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      max : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the mean of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the median of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n",
      "     |      \"Unpivots\" a DataFrame from wide format to long format, optionally\n",
      "     |      leaving identifier variables set.\n",
      "     |      \n",
      "     |      This function is useful to massage a DataFrame into a format where one\n",
      "     |      or more columns are identifier variables (`id_vars`), while all other\n",
      "     |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      "     |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      "     |      'value'.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      frame : DataFrame\n",
      "     |      id_vars : tuple, list, or ndarray, optional\n",
      "     |          Column(s) to use as identifier variables.\n",
      "     |      value_vars : tuple, list, or ndarray, optional\n",
      "     |          Column(s) to unpivot. If not specified, uses all columns that\n",
      "     |          are not set as `id_vars`.\n",
      "     |      var_name : scalar\n",
      "     |          Name to use for the 'variable' column. If None it uses\n",
      "     |          ``frame.columns.name`` or 'variable'.\n",
      "     |      value_name : scalar, default 'value'\n",
      "     |          Name to use for the 'value' column.\n",
      "     |      col_level : int or string, optional\n",
      "     |          If columns are a MultiIndex then use this level to melt.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      melt\n",
      "     |      pivot_table\n",
      "     |      DataFrame.pivot\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      "     |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      "     |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |      0  a  1  2\n",
      "     |      1  b  3  4\n",
      "     |      2  c  5  6\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      "     |         A variable  value\n",
      "     |      0  a        B      1\n",
      "     |      1  b        B      3\n",
      "     |      2  c        B      5\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      "     |         A variable  value\n",
      "     |      0  a        B      1\n",
      "     |      1  b        B      3\n",
      "     |      2  c        B      5\n",
      "     |      3  a        C      2\n",
      "     |      4  b        C      4\n",
      "     |      5  c        C      6\n",
      "     |      \n",
      "     |      The names of 'variable' and 'value' columns can be customized:\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      "     |      ...         var_name='myVarname', value_name='myValname')\n",
      "     |         A myVarname  myValname\n",
      "     |      0  a         B          1\n",
      "     |      1  b         B          3\n",
      "     |      2  c         B          5\n",
      "     |      \n",
      "     |      If you have multi-index columns:\n",
      "     |      \n",
      "     |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |         D  E  F\n",
      "     |      0  a  1  2\n",
      "     |      1  b  3  4\n",
      "     |      2  c  5  6\n",
      "     |      \n",
      "     |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      "     |         A variable  value\n",
      "     |      0  a        B      1\n",
      "     |      1  b        B      3\n",
      "     |      2  c        B      5\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      "     |        (A, D) variable_0 variable_1  value\n",
      "     |      0      a          B          E      1\n",
      "     |      1      b          B          E      3\n",
      "     |      2      c          B          E      5\n",
      "     |  \n",
      "     |  memory_usage(self, index=True, deep=False)\n",
      "     |      Memory usage of DataFrame columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : bool\n",
      "     |          Specifies whether to include memory usage of DataFrame's\n",
      "     |          index in returned Series. If `index=True` (default is False)\n",
      "     |          the first index of the Series is `Index`.\n",
      "     |      deep : bool\n",
      "     |          Introspect the data deeply, interrogate\n",
      "     |          `object` dtypes for system-level memory consumption\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sizes : Series\n",
      "     |          A series with column names as index and memory usage of\n",
      "     |          columns with units of bytes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Memory usage does not include memory consumed by elements that\n",
      "     |      are not components of the array if deep=False\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.nbytes\n",
      "     |  \n",
      "     |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
      "     |      Merge DataFrame objects by performing a database-style join operation by\n",
      "     |      columns or indexes.\n",
      "     |      \n",
      "     |      If joining columns on columns, the DataFrame indexes *will be\n",
      "     |      ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      "     |      columns, the index will be passed on.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      right : DataFrame\n",
      "     |      how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      "     |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "     |            preserve key order\n",
      "     |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "     |            preserve key order\n",
      "     |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "     |            join; sort keys lexicographically\n",
      "     |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "     |            join; preserve the order of the left keys\n",
      "     |      on : label or list\n",
      "     |          Field names to join on. Must be found in both DataFrames. If on is\n",
      "     |          None and not merging on indexes, then it merges on the intersection of\n",
      "     |          the columns by default.\n",
      "     |      left_on : label or list, or array-like\n",
      "     |          Field names to join on in left DataFrame. Can be a vector or list of\n",
      "     |          vectors of the length of the DataFrame to use a particular vector as\n",
      "     |          the join key instead of columns\n",
      "     |      right_on : label or list, or array-like\n",
      "     |          Field names to join on in right DataFrame or vector/list of vectors per\n",
      "     |          left_on docs\n",
      "     |      left_index : boolean, default False\n",
      "     |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      "     |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "     |          or a number of columns) must match the number of levels\n",
      "     |      right_index : boolean, default False\n",
      "     |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      "     |          left_index\n",
      "     |      sort : boolean, default False\n",
      "     |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "     |          the order of the join keys depends on the join type (how keyword)\n",
      "     |      suffixes : 2-length sequence (tuple, list, ...)\n",
      "     |          Suffix to apply to overlapping column names in the left and right\n",
      "     |          side, respectively\n",
      "     |      copy : boolean, default True\n",
      "     |          If False, do not copy data unnecessarily\n",
      "     |      indicator : boolean or string, default False\n",
      "     |          If True, adds a column to output DataFrame called \"_merge\" with\n",
      "     |          information on the source of each row.\n",
      "     |          If string, column with information on source of each row will be added to\n",
      "     |          output DataFrame, and column will be named value of string.\n",
      "     |          Information column is Categorical-type and takes on a value of \"left_only\"\n",
      "     |          for observations whose merge key only appears in 'left' DataFrame,\n",
      "     |          \"right_only\" for observations whose merge key only appears in 'right'\n",
      "     |          DataFrame, and \"both\" if the observation's merge key is found in both.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      validate : string, default None\n",
      "     |          If specified, checks if merge is of specified type.\n",
      "     |      \n",
      "     |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "     |            left and right datasets.\n",
      "     |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "     |            dataset.\n",
      "     |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "     |            dataset.\n",
      "     |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> A              >>> B\n",
      "     |          lkey value         rkey value\n",
      "     |      0   foo  1         0   foo  5\n",
      "     |      1   bar  2         1   bar  6\n",
      "     |      2   baz  3         2   qux  7\n",
      "     |      3   foo  4         3   bar  8\n",
      "     |      \n",
      "     |      >>> A.merge(B, left_on='lkey', right_on='rkey', how='outer')\n",
      "     |         lkey  value_x  rkey  value_y\n",
      "     |      0  foo   1        foo   5\n",
      "     |      1  foo   4        foo   5\n",
      "     |      2  bar   2        bar   6\n",
      "     |      3  bar   2        bar   8\n",
      "     |      4  baz   3        NaN   NaN\n",
      "     |      5  NaN   NaN      qux   7\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      merged : DataFrame\n",
      "     |          The output type will the be same as 'left', if it is a subclass\n",
      "     |          of DataFrame.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      merge_ordered\n",
      "     |      merge_asof\n",
      "     |  \n",
      "     |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the minimum of the values in the object.\n",
      "     |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      min : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rmod\n",
      "     |  \n",
      "     |  mode(self, axis=0, numeric_only=False)\n",
      "     |      Gets the mode(s) of each element along the axis selected. Adds a row\n",
      "     |      for each mode per label, fills in gaps with nan.\n",
      "     |      \n",
      "     |      Note that there could be multiple values returned for the selected\n",
      "     |      axis (when more than one item share the maximum frequency), which is\n",
      "     |      the reason why a dataframe is returned. If you want to impute missing\n",
      "     |      values with the mode in a dataframe ``df``, you can just do this:\n",
      "     |      ``df.fillna(df.mode().iloc[0])``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          * 0 or 'index' : get mode of each column\n",
      "     |          * 1 or 'columns' : get mode of each row\n",
      "     |      numeric_only : boolean, default False\n",
      "     |          if True, only apply to numeric columns\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      modes : DataFrame (sorted)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 1, 2, 1, 2, 3]})\n",
      "     |      >>> df.mode()\n",
      "     |         A\n",
      "     |      0  1\n",
      "     |      1  2\n",
      "     |  \n",
      "     |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rmul\n",
      "     |  \n",
      "     |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rmul\n",
      "     |  \n",
      "     |  ne(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods ne\n",
      "     |  \n",
      "     |  nlargest(self, n, columns, keep='first')\n",
      "     |      Get the rows of a DataFrame sorted by the `n` largest\n",
      "     |      values of `columns`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Number of items to retrieve\n",
      "     |      columns : list or str\n",
      "     |          Column name or names to order by\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = DataFrame({'a': [1, 10, 8, 11, -1],\n",
      "     |      ...                 'b': list('abdce'),\n",
      "     |      ...                 'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      "     |      >>> df.nlargest(3, 'a')\n",
      "     |          a  b   c\n",
      "     |      3  11  c   3\n",
      "     |      1  10  b   2\n",
      "     |      2   8  d NaN\n",
      "     |  \n",
      "     |  notna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.isna : boolean inverse of notna\n",
      "     |      DataFrame.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  notnull(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.isna : boolean inverse of notna\n",
      "     |      DataFrame.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  nsmallest(self, n, columns, keep='first')\n",
      "     |      Get the rows of a DataFrame sorted by the `n` smallest\n",
      "     |      values of `columns`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Number of items to retrieve\n",
      "     |      columns : list or str\n",
      "     |          Column name or names to order by\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = DataFrame({'a': [1, 10, 8, 11, -1],\n",
      "     |      ...                 'b': list('abdce'),\n",
      "     |      ...                 'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      "     |      >>> df.nsmallest(3, 'a')\n",
      "     |         a  b   c\n",
      "     |      4 -1  e   4\n",
      "     |      0  1  a   1\n",
      "     |      2  8  d NaN\n",
      "     |  \n",
      "     |  nunique(self, axis=0, dropna=True)\n",
      "     |      Return Series with number of distinct observations over requested\n",
      "     |      axis.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include NaN in the counts.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nunique : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n",
      "     |      >>> df.nunique()\n",
      "     |      A    3\n",
      "     |      B    1\n",
      "     |      \n",
      "     |      >>> df.nunique(axis=1)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    2\n",
      "     |  \n",
      "     |  pivot(self, index=None, columns=None, values=None)\n",
      "     |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      "     |      unique values from index / columns to form axes of the resulting\n",
      "     |      DataFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : string or object, optional\n",
      "     |          Column name to use to make new frame's index. If None, uses\n",
      "     |          existing index.\n",
      "     |      columns : string or object\n",
      "     |          Column name to use to make new frame's columns\n",
      "     |      values : string or object, optional\n",
      "     |          Column name to use for populating new frame's values. If not\n",
      "     |          specified, all remaining columns will be used and the result will\n",
      "     |          have hierarchically indexed columns\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pivoted : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pivot_table : generalization of pivot that can handle\n",
      "     |          duplicate values for one index/column pair\n",
      "     |      DataFrame.unstack : pivot based on the index values instead of a\n",
      "     |          column\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For finer-tuned control, see hierarchical indexing documentation along\n",
      "     |      with the related stack/unstack methods\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
      "     |                             'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      "     |                             'baz': [1, 2, 3, 4, 5, 6]})\n",
      "     |      >>> df\n",
      "     |          foo   bar  baz\n",
      "     |      0   one   A    1\n",
      "     |      1   one   B    2\n",
      "     |      2   one   C    3\n",
      "     |      3   two   A    4\n",
      "     |      4   two   B    5\n",
      "     |      5   two   C    6\n",
      "     |      \n",
      "     |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      "     |           A   B   C\n",
      "     |      one  1   2   3\n",
      "     |      two  4   5   6\n",
      "     |      \n",
      "     |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      "     |           A   B   C\n",
      "     |      one  1   2   3\n",
      "     |      two  4   5   6\n",
      "     |  \n",
      "     |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')\n",
      "     |      Create a spreadsheet-style pivot table as a DataFrame. The levels in\n",
      "     |      the pivot table will be stored in MultiIndex objects (hierarchical\n",
      "     |      indexes) on the index and columns of the result DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : column to aggregate, optional\n",
      "     |      index : column, Grouper, array, or list of the previous\n",
      "     |          If an array is passed, it must be the same length as the data. The\n",
      "     |          list can contain any of the other types (except list).\n",
      "     |          Keys to group by on the pivot table index.  If an array is passed,\n",
      "     |          it is being used as the same manner as column values.\n",
      "     |      columns : column, Grouper, array, or list of the previous\n",
      "     |          If an array is passed, it must be the same length as the data. The\n",
      "     |          list can contain any of the other types (except list).\n",
      "     |          Keys to group by on the pivot table column.  If an array is passed,\n",
      "     |          it is being used as the same manner as column values.\n",
      "     |      aggfunc : function or list of functions, default numpy.mean\n",
      "     |          If list of functions passed, the resulting pivot table will have\n",
      "     |          hierarchical columns whose top level are the function names\n",
      "     |          (inferred from the function objects themselves)\n",
      "     |      fill_value : scalar, default None\n",
      "     |          Value to replace missing values with\n",
      "     |      margins : boolean, default False\n",
      "     |          Add all row / columns (e.g. for subtotal / grand totals)\n",
      "     |      dropna : boolean, default True\n",
      "     |          Do not include columns whose entries are all NaN\n",
      "     |      margins_name : string, default 'All'\n",
      "     |          Name of the row / column that will contain the totals\n",
      "     |          when margins is True.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "     |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "     |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "     |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      "     |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "     |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      "     |      ...                          \"large\"],\n",
      "     |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7]})\n",
      "     |      >>> df\n",
      "     |           A    B      C  D\n",
      "     |      0  foo  one  small  1\n",
      "     |      1  foo  one  large  2\n",
      "     |      2  foo  one  large  2\n",
      "     |      3  foo  two  small  3\n",
      "     |      4  foo  two  small  3\n",
      "     |      5  bar  one  large  4\n",
      "     |      6  bar  one  small  5\n",
      "     |      7  bar  two  small  6\n",
      "     |      8  bar  two  large  7\n",
      "     |      \n",
      "     |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      "     |      ...                     columns=['C'], aggfunc=np.sum)\n",
      "     |      >>> table\n",
      "     |      ... # doctest: +NORMALIZE_WHITESPACE\n",
      "     |      C        large  small\n",
      "     |      A   B\n",
      "     |      bar one    4.0    5.0\n",
      "     |          two    7.0    6.0\n",
      "     |      foo one    4.0    1.0\n",
      "     |          two    NaN    6.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      table : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pivot : pivot without aggregation that can handle\n",
      "     |          non-numeric data\n",
      "     |  \n",
      "     |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rpow\n",
      "     |  \n",
      "     |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : Series or DataFrame (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : Series or DataFrame (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')\n",
      "     |      Return values at the given quantile over requested axis, a la\n",
      "     |      numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          0 <= q <= 1, the quantile(s) to compute\n",
      "     |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |          This optional parameter specifies the interpolation method to use,\n",
      "     |          when the desired quantile lies between two data points `i` and `j`:\n",
      "     |      \n",
      "     |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      "     |            fractional part of the index surrounded by `i` and `j`.\n",
      "     |          * lower: `i`.\n",
      "     |          * higher: `j`.\n",
      "     |          * nearest: `i` or `j` whichever is nearest.\n",
      "     |          * midpoint: (`i` + `j`) / 2.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      quantiles : Series or DataFrame\n",
      "     |      \n",
      "     |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      "     |            index is ``q``, the columns are the columns of self, and the\n",
      "     |            values are the quantiles.\n",
      "     |          - If ``q`` is a float, a Series will be returned where the\n",
      "     |            index is the columns of self and the values are the quantiles.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      "     |                         columns=['a', 'b'])\n",
      "     |      >>> df.quantile(.1)\n",
      "     |      a    1.3\n",
      "     |      b    3.7\n",
      "     |      dtype: float64\n",
      "     |      >>> df.quantile([.1, .5])\n",
      "     |             a     b\n",
      "     |      0.1  1.3   3.7\n",
      "     |      0.5  2.5  55.0\n",
      "     |  \n",
      "     |  query(self, expr, inplace=False, **kwargs)\n",
      "     |      Query the columns of a frame with a boolean expression.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      expr : string\n",
      "     |          The query string to evaluate.  You can refer to variables\n",
      "     |          in the environment by prefixing them with an '@' character like\n",
      "     |          ``@a + b``.\n",
      "     |      inplace : bool\n",
      "     |          Whether the query should modify the data in place or return\n",
      "     |          a modified copy\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      kwargs : dict\n",
      "     |          See the documentation for :func:`pandas.eval` for complete details\n",
      "     |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      q : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The result of the evaluation of this expression is first passed to\n",
      "     |      :attr:`DataFrame.loc` and if that fails because of a\n",
      "     |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      "     |      to :meth:`DataFrame.__getitem__`.\n",
      "     |      \n",
      "     |      This method uses the top-level :func:`pandas.eval` function to\n",
      "     |      evaluate the passed query.\n",
      "     |      \n",
      "     |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      "     |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      "     |      (bitwise) operators have the precedence of their boolean cousins,\n",
      "     |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      "     |      however the semantics are different.\n",
      "     |      \n",
      "     |      You can change the semantics of the expression by passing the keyword\n",
      "     |      argument ``parser='python'``. This enforces the same semantics as\n",
      "     |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      "     |      to evaluate an expression using Python itself as a backend. This is not\n",
      "     |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      "     |      engine.\n",
      "     |      \n",
      "     |      The :attr:`DataFrame.index` and\n",
      "     |      :attr:`DataFrame.columns` attributes of the\n",
      "     |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      "     |      by default, which allows you to treat both the index and columns of the\n",
      "     |      frame as a column in the frame.\n",
      "     |      The identifier ``index`` is used for the frame index; you can also\n",
      "     |      use the name of the index to identify it in a query.\n",
      "     |      \n",
      "     |      For further details and examples see the ``query`` documentation in\n",
      "     |      :ref:`indexing <indexing.query>`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.eval\n",
      "     |      DataFrame.eval\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from numpy.random import randn\n",
      "     |      >>> from pandas import DataFrame\n",
      "     |      >>> df = DataFrame(randn(10, 2), columns=list('ab'))\n",
      "     |      >>> df.query('a > b')\n",
      "     |      >>> df[df.a > df.b]  # same result as the previous expression\n",
      "     |  \n",
      "     |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      "     |      \n",
      "     |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.add\n",
      "     |  \n",
      "     |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.truediv\n",
      "     |  \n",
      "     |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      "     |      Conform DataFrame to new index with optional filling logic, placing\n",
      "     |      NA/NaN in locations having no value in the previous index. A new object\n",
      "     |      is produced unless the new index is equivalent to the current one and\n",
      "     |      copy=False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : array-like, optional\n",
      "     |          New labels / index to conform the axis specified by 'axis' to.\n",
      "     |      index, columns : array-like, optional (should be specified using keywords)\n",
      "     |          New labels / index to conform to. Preferably an Index object to\n",
      "     |          avoid duplicating data\n",
      "     |      axis : int or str, optional\n",
      "     |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      "     |          or number (0, 1).\n",
      "     |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "     |          method to use for filling holes in reindexed DataFrame.\n",
      "     |          Please note: this is only  applicable to DataFrames/Series with a\n",
      "     |          monotonically increasing/decreasing index.\n",
      "     |      \n",
      "     |          * default: don't fill gaps\n",
      "     |          * pad / ffill: propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * backfill / bfill: use next valid observation to fill gap\n",
      "     |          * nearest: use nearest valid observations to fill gap\n",
      "     |      \n",
      "     |      copy : boolean, default True\n",
      "     |          Return a new object, even if the passed indexes are the same\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive elements to forward or backward fill\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between original and new labels for inexact\n",
      "     |          matches. The values of the index at the matching locations most\n",
      "     |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "     |      \n",
      "     |          Tolerance may be a scalar value, which applies the same tolerance\n",
      "     |          to all values, or list-like, which applies variable tolerance per\n",
      "     |          element. List-like includes list, tuple, array, Series, and must be\n",
      "     |          the same size as the index and its dtype must exactly match the\n",
      "     |          index's type.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      ``DataFrame.reindex`` supports two calling conventions\n",
      "     |      \n",
      "     |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      "     |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      "     |      \n",
      "     |      We *highly* recommend using keyword arguments to clarify your\n",
      "     |      intent.\n",
      "     |      \n",
      "     |      Create a dataframe with some fictional data.\n",
      "     |      \n",
      "     |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...      'http_status': [200,200,404,404,301],\n",
      "     |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "     |      ...       index=index)\n",
      "     |      >>> df\n",
      "     |                 http_status  response_time\n",
      "     |      Firefox            200           0.04\n",
      "     |      Chrome             200           0.02\n",
      "     |      Safari             404           0.07\n",
      "     |      IE10               404           0.08\n",
      "     |      Konqueror          301           1.00\n",
      "     |      \n",
      "     |      Create a new index and reindex the dataframe. By default\n",
      "     |      values in the new index that do not have corresponding\n",
      "     |      records in the dataframe are assigned ``NaN``.\n",
      "     |      \n",
      "     |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "     |      ...             'Chrome']\n",
      "     |      >>> df.reindex(new_index)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari               404.0           0.07\n",
      "     |      Iceweasel              NaN            NaN\n",
      "     |      Comodo Dragon          NaN            NaN\n",
      "     |      IE10                 404.0           0.08\n",
      "     |      Chrome               200.0           0.02\n",
      "     |      \n",
      "     |      We can fill in the missing values by passing a value to\n",
      "     |      the keyword ``fill_value``. Because the index is not monotonically\n",
      "     |      increasing or decreasing, we cannot use arguments to the keyword\n",
      "     |      ``method`` to fill the ``NaN`` values.\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value=0)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari                 404           0.07\n",
      "     |      Iceweasel                0           0.00\n",
      "     |      Comodo Dragon            0           0.00\n",
      "     |      IE10                   404           0.08\n",
      "     |      Chrome                 200           0.02\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value='missing')\n",
      "     |                    http_status response_time\n",
      "     |      Safari                404          0.07\n",
      "     |      Iceweasel         missing       missing\n",
      "     |      Comodo Dragon     missing       missing\n",
      "     |      IE10                  404          0.08\n",
      "     |      Chrome                200          0.02\n",
      "     |      \n",
      "     |      We can also reindex the columns.\n",
      "     |      \n",
      "     |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      Or we can use \"axis-style\" keyword arguments\n",
      "     |      \n",
      "     |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      To further illustrate the filling functionality in\n",
      "     |      ``reindex``, we will create a dataframe with a\n",
      "     |      monotonically increasing index (for example, a sequence\n",
      "     |      of dates).\n",
      "     |      \n",
      "     |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "     |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "     |      ...                    index=date_index)\n",
      "     |      >>> df2\n",
      "     |                  prices\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      \n",
      "     |      Suppose we decide to expand the dataframe to cover a wider\n",
      "     |      date range.\n",
      "     |      \n",
      "     |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "     |      >>> df2.reindex(date_index2)\n",
      "     |                  prices\n",
      "     |      2009-12-29     NaN\n",
      "     |      2009-12-30     NaN\n",
      "     |      2009-12-31     NaN\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      The index entries that did not have a value in the original data frame\n",
      "     |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "     |      If desired, we can fill in the missing values using one of several\n",
      "     |      options.\n",
      "     |      \n",
      "     |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "     |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "     |      \n",
      "     |      >>> df2.reindex(date_index2, method='bfill')\n",
      "     |                  prices\n",
      "     |      2009-12-29     100\n",
      "     |      2009-12-30     100\n",
      "     |      2009-12-31     100\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      Please note that the ``NaN`` value present in the original dataframe\n",
      "     |      (at index value 2010-01-03) will not be filled by any of the\n",
      "     |      value propagation schemes. This is because filling while reindexing\n",
      "     |      does not look at dataframe values, but only compares the original and\n",
      "     |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "     |      in the original dataframe, use the ``fillna()`` method.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : DataFrame\n",
      "     |  \n",
      "     |  reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)\n",
      "     |      Conform input object to new index with optional\n",
      "     |      filling logic, placing NA/NaN in locations having no value in the\n",
      "     |      previous index. A new object is produced unless the new index is\n",
      "     |      equivalent to the current one and copy=False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : array-like\n",
      "     |          New labels / index to conform to. Preferably an Index object to\n",
      "     |          avoid duplicating data\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "     |          Method to use for filling holes in reindexed DataFrame:\n",
      "     |      \n",
      "     |          * default: don't fill gaps\n",
      "     |          * pad / ffill: propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * backfill / bfill: use next valid observation to fill gap\n",
      "     |          * nearest: use nearest valid observations to fill gap\n",
      "     |      \n",
      "     |      copy : boolean, default True\n",
      "     |          Return a new object, even if the passed indexes are the same\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive elements to forward or backward fill\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between original and new labels for inexact\n",
      "     |          matches. The values of the index at the matching locations most\n",
      "     |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "     |      \n",
      "     |          Tolerance may be a scalar value, which applies the same tolerance\n",
      "     |          to all values, or list-like, which applies variable tolerance per\n",
      "     |          element. List-like includes list, tuple, array, Series, and must be\n",
      "     |          the same size as the index and its dtype must exactly match the\n",
      "     |          index's type.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df.reindex_axis(['A', 'B', 'C'], axis=1)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, reindex_like\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : DataFrame\n",
      "     |  \n",
      "     |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None)\n",
      "     |      Alter axes labels.\n",
      "     |      \n",
      "     |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "     |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.rename>` for more.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper, index, columns : dict-like or function, optional\n",
      "     |          dict-like or functions transformations to apply to\n",
      "     |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      "     |          specify the axis to target with ``mapper``, or ``index`` and\n",
      "     |          ``columns``.\n",
      "     |      axis : int or str, optional\n",
      "     |          Axis to target with ``mapper``. Can be either the axis name\n",
      "     |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to return a new %(klass)s. If True then value of copy is\n",
      "     |          ignored.\n",
      "     |      level : int or level name, default None\n",
      "     |          In case of a MultiIndex, only rename labels in the specified\n",
      "     |          level.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.rename_axis\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      ``DataFrame.rename`` supports two calling conventions\n",
      "     |      \n",
      "     |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      "     |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      "     |      \n",
      "     |      We *highly* recommend using keyword arguments to clarify your\n",
      "     |      intent.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
      "     |         a  c\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      >>> df.rename(index=str, columns={\"A\": \"a\", \"C\": \"c\"})\n",
      "     |         a  B\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      Using axis-style parameters\n",
      "     |      \n",
      "     |      >>> df.rename(str.lower, axis='columns')\n",
      "     |         a  b\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      "     |         A  B\n",
      "     |      0  1  4\n",
      "     |      2  2  5\n",
      "     |      4  3  6\n",
      "     |  \n",
      "     |  reorder_levels(self, order, axis=0)\n",
      "     |      Rearrange index levels using input order.\n",
      "     |      May not drop or duplicate levels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : list of int or list of str\n",
      "     |          List representing new level order. Reference level by number\n",
      "     |          (position) or by key (label).\n",
      "     |      axis : int\n",
      "     |          Where to reorder levels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      type of caller (new object)\n",
      "     |  \n",
      "     |  reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
      "     |      For DataFrame with multi-level index, return new DataFrame with\n",
      "     |      labeling information in the columns under the index names, defaulting\n",
      "     |      to 'level_0', 'level_1', etc. if any are None. For a standard index,\n",
      "     |      the index name will be used (if set), otherwise a default 'index' or\n",
      "     |      'level_0' (if 'index' is already taken) will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, str, tuple, or list, default None\n",
      "     |          Only remove the given levels from the index. Removes all levels by\n",
      "     |          default\n",
      "     |      drop : boolean, default False\n",
      "     |          Do not try to insert index into dataframe columns. This resets\n",
      "     |          the index to the default integer index.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Modify the DataFrame in place (do not create a new object)\n",
      "     |      col_level : int or str, default 0\n",
      "     |          If the columns have multiple levels, determines which level the\n",
      "     |          labels are inserted into. By default it is inserted into the first\n",
      "     |          level.\n",
      "     |      col_fill : object, default ''\n",
      "     |          If the columns have multiple levels, determines how the other\n",
      "     |          levels are named. If None then the index name is repeated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      resetted : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('bird',    389.0),\n",
      "     |      ...                    ('bird',     24.0),\n",
      "     |      ...                    ('mammal',   80.5),\n",
      "     |      ...                    ('mammal', np.nan)],\n",
      "     |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      "     |      ...                   columns=('class', 'max_speed'))\n",
      "     |      >>> df\n",
      "     |               class  max_speed\n",
      "     |      falcon    bird      389.0\n",
      "     |      parrot    bird       24.0\n",
      "     |      lion    mammal       80.5\n",
      "     |      monkey  mammal        NaN\n",
      "     |      \n",
      "     |      When we reset the index, the old index is added as a column, and a\n",
      "     |      new sequential index is used:\n",
      "     |      \n",
      "     |      >>> df.reset_index()\n",
      "     |          index   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  parrot    bird       24.0\n",
      "     |      2    lion  mammal       80.5\n",
      "     |      3  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      We can use the `drop` parameter to avoid the old index being added as\n",
      "     |      a column:\n",
      "     |      \n",
      "     |      >>> df.reset_index(drop=True)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      1    bird       24.0\n",
      "     |      2  mammal       80.5\n",
      "     |      3  mammal        NaN\n",
      "     |      \n",
      "     |      You can also use `reset_index` with `MultiIndex`.\n",
      "     |      \n",
      "     |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      "     |      ...                                    ('bird', 'parrot'),\n",
      "     |      ...                                    ('mammal', 'lion'),\n",
      "     |      ...                                    ('mammal', 'monkey')],\n",
      "     |      ...                                   names=['class', 'name'])\n",
      "     |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      "     |      ...                                      ('species', 'type')])\n",
      "     |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      "     |      ...                    ( 24.0, 'fly'),\n",
      "     |      ...                    ( 80.5, 'run'),\n",
      "     |      ...                    (np.nan, 'jump')],\n",
      "     |      ...                   index=index,\n",
      "     |      ...                   columns=columns)\n",
      "     |      >>> df\n",
      "     |                     speed species\n",
      "     |                       max    type\n",
      "     |      class  name\n",
      "     |      bird   falcon  389.0     fly\n",
      "     |             parrot   24.0     fly\n",
      "     |      mammal lion     80.5     run\n",
      "     |             monkey    NaN    jump\n",
      "     |      \n",
      "     |      If the index has multiple levels, we can reset a subset of them:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class')\n",
      "     |               class  speed species\n",
      "     |                        max    type\n",
      "     |      name\n",
      "     |      falcon    bird  389.0     fly\n",
      "     |      parrot    bird   24.0     fly\n",
      "     |      lion    mammal   80.5     run\n",
      "     |      monkey  mammal    NaN    jump\n",
      "     |      \n",
      "     |      If we are not dropping the index, by default, it is placed in the top\n",
      "     |      level. We can place it in another level:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class', col_level=1)\n",
      "     |                      speed species\n",
      "     |               class    max    type\n",
      "     |      name\n",
      "     |      falcon    bird  389.0     fly\n",
      "     |      parrot    bird   24.0     fly\n",
      "     |      lion    mammal   80.5     run\n",
      "     |      monkey  mammal    NaN    jump\n",
      "     |      \n",
      "     |      When the index is inserted under another level, we can specify under\n",
      "     |      which one with the parameter `col_fill`:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      "     |                    species  speed species\n",
      "     |                      class    max    type\n",
      "     |      name\n",
      "     |      falcon           bird  389.0     fly\n",
      "     |      parrot           bird   24.0     fly\n",
      "     |      lion           mammal   80.5     run\n",
      "     |      monkey         mammal    NaN    jump\n",
      "     |      \n",
      "     |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      "     |                      genus  speed species\n",
      "     |                      class    max    type\n",
      "     |      name\n",
      "     |      falcon           bird  389.0     fly\n",
      "     |      parrot           bird   24.0     fly\n",
      "     |      lion           mammal   80.5     run\n",
      "     |      monkey         mammal    NaN    jump\n",
      "     |  \n",
      "     |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.floordiv\n",
      "     |  \n",
      "     |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      "     |      \n",
      "     |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.mod\n",
      "     |  \n",
      "     |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      "     |      \n",
      "     |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.mul\n",
      "     |  \n",
      "     |  rolling(self, window, min_periods=None, freq=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      "     |      Provides rolling window calculations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      window : int, or offset\n",
      "     |          Size of the moving window. This is the number of observations used for\n",
      "     |          calculating the statistic. Each window will be a fixed size.\n",
      "     |      \n",
      "     |          If its an offset then this will be the time period of each window. Each\n",
      "     |          window will be a variable sized based on the observations included in\n",
      "     |          the time-period. This is only valid for datetimelike indexes. This is\n",
      "     |          new in 0.19.0\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA). For a window that is specified by an offset,\n",
      "     |          this will default to 1.\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      win_type : string, default None\n",
      "     |          Provide a window type. See the notes below.\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column on which to calculate\n",
      "     |          the rolling window, rather than the index\n",
      "     |      closed : string, default None\n",
      "     |          Make the interval closed on the 'right', 'left', 'both' or\n",
      "     |          'neither' endpoints.\n",
      "     |          For offset-based windows, it defaults to 'right'.\n",
      "     |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      "     |          for fixed windows.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window or Rolling sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |      >>> df\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, using the 'triang'\n",
      "     |      window type.\n",
      "     |      \n",
      "     |      >>> df.rolling(2, win_type='triang').sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  2.5\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, min_periods defaults\n",
      "     |      to the window length.\n",
      "     |      \n",
      "     |      >>> df.rolling(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Same as above, but explicity set the min_periods\n",
      "     |      \n",
      "     |      >>> df.rolling(2, min_periods=1).sum()\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  2.0\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      "     |      ....:                 index = [pd.Timestamp('20130101 09:00:00'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:02'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:03'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:05'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:06')])\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  2.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      \n",
      "     |      Contrasting to an integer rolling window, this will roll a variable\n",
      "     |      length window corresponding to the time period.\n",
      "     |      The default for min_periods is 1.\n",
      "     |      \n",
      "     |      >>> df.rolling('2s').sum()\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  3.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      To learn more about the offsets & frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      The recognized win_types are:\n",
      "     |      \n",
      "     |      * ``boxcar``\n",
      "     |      * ``triang``\n",
      "     |      * ``blackman``\n",
      "     |      * ``hamming``\n",
      "     |      * ``bartlett``\n",
      "     |      * ``parzen``\n",
      "     |      * ``bohman``\n",
      "     |      * ``blackmanharris``\n",
      "     |      * ``nuttall``\n",
      "     |      * ``barthann``\n",
      "     |      * ``kaiser`` (needs beta)\n",
      "     |      * ``gaussian`` (needs std)\n",
      "     |      * ``general_gaussian`` (needs power, width)\n",
      "     |      * ``slepian`` (needs width).\n",
      "     |      \n",
      "     |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      "     |      different window types see `scipy.signal window functions\n",
      "     |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      "     |  \n",
      "     |  round(self, decimals=0, *args, **kwargs)\n",
      "     |      Round a DataFrame to a variable number of decimal places.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      decimals : int, dict, Series\n",
      "     |          Number of decimal places to round each column to. If an int is\n",
      "     |          given, round each column to the same number of places.\n",
      "     |          Otherwise dict and Series round to variable numbers of places.\n",
      "     |          Column names should be in the keys if `decimals` is a\n",
      "     |          dict-like, or in the index if `decimals` is a Series. Any\n",
      "     |          columns not included in `decimals` will be left as is. Elements\n",
      "     |          of `decimals` which are not columns of the input will be\n",
      "     |          ignored.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.random.random([3, 3]),\n",
      "     |      ...     columns=['A', 'B', 'C'], index=['first', 'second', 'third'])\n",
      "     |      >>> df\n",
      "     |                     A         B         C\n",
      "     |      first   0.028208  0.992815  0.173891\n",
      "     |      second  0.038683  0.645646  0.577595\n",
      "     |      third   0.877076  0.149370  0.491027\n",
      "     |      >>> df.round(2)\n",
      "     |                 A     B     C\n",
      "     |      first   0.03  0.99  0.17\n",
      "     |      second  0.04  0.65  0.58\n",
      "     |      third   0.88  0.15  0.49\n",
      "     |      >>> df.round({'A': 1, 'C': 2})\n",
      "     |                A         B     C\n",
      "     |      first   0.0  0.992815  0.17\n",
      "     |      second  0.0  0.645646  0.58\n",
      "     |      third   0.9  0.149370  0.49\n",
      "     |      >>> decimals = pd.Series([1, 0, 2], index=['A', 'B', 'C'])\n",
      "     |      >>> df.round(decimals)\n",
      "     |                A  B     C\n",
      "     |      first   0.0  1  0.17\n",
      "     |      second  0.0  1  0.58\n",
      "     |      third   0.9  0  0.49\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around\n",
      "     |      Series.round\n",
      "     |  \n",
      "     |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      "     |      \n",
      "     |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pow\n",
      "     |  \n",
      "     |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      "     |      \n",
      "     |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.sub\n",
      "     |  \n",
      "     |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.truediv\n",
      "     |  \n",
      "     |  select_dtypes(self, include=None, exclude=None)\n",
      "     |      Return a subset of a DataFrame including/excluding columns based on\n",
      "     |      their ``dtype``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      include, exclude : scalar or list-like\n",
      "     |          A selection of dtypes or strings to be included/excluded. At least\n",
      "     |          one of these parameters must be supplied.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If both of ``include`` and ``exclude`` are empty\n",
      "     |          * If ``include`` and ``exclude`` have overlapping elements\n",
      "     |          * If any kind of string dtype is passed in.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : DataFrame\n",
      "     |          The subset of the frame including the dtypes in ``include`` and\n",
      "     |          excluding the dtypes in ``exclude``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * To select all *numeric* types use the numpy dtype ``numpy.number``\n",
      "     |      * To select strings you must use the ``object`` dtype, but note that\n",
      "     |        this will return *all* object dtype columns\n",
      "     |      * See the `numpy dtype hierarchy\n",
      "     |        <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n",
      "     |      * To select datetimes, use np.datetime64, 'datetime' or 'datetime64'\n",
      "     |      * To select timedeltas, use np.timedelta64, 'timedelta' or\n",
      "     |        'timedelta64'\n",
      "     |      * To select Pandas categorical dtypes, use 'category'\n",
      "     |      * To select Pandas datetimetz dtypes, use 'datetimetz' (new in 0.20.0),\n",
      "     |        or a 'datetime64[ns, tz]' string\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'a': np.random.randn(6).astype('f4'),\n",
      "     |      ...                    'b': [True, False] * 3,\n",
      "     |      ...                    'c': [1.0, 2.0] * 3})\n",
      "     |      >>> df\n",
      "     |              a      b  c\n",
      "     |      0  0.3962   True  1\n",
      "     |      1  0.1459  False  2\n",
      "     |      2  0.2623   True  1\n",
      "     |      3  0.0764  False  2\n",
      "     |      4 -0.9703   True  1\n",
      "     |      5 -1.2094  False  2\n",
      "     |      >>> df.select_dtypes(include='bool')\n",
      "     |         c\n",
      "     |      0  True\n",
      "     |      1  False\n",
      "     |      2  True\n",
      "     |      3  False\n",
      "     |      4  True\n",
      "     |      5  False\n",
      "     |      >>> df.select_dtypes(include=['float64'])\n",
      "     |         c\n",
      "     |      0  1\n",
      "     |      1  2\n",
      "     |      2  1\n",
      "     |      3  2\n",
      "     |      4  1\n",
      "     |      5  2\n",
      "     |      >>> df.select_dtypes(exclude=['floating'])\n",
      "     |             b\n",
      "     |      0   True\n",
      "     |      1  False\n",
      "     |      2   True\n",
      "     |      3  False\n",
      "     |      4   True\n",
      "     |      5  False\n",
      "     |  \n",
      "     |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased standard error of the mean over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sem : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
      "     |      Set the DataFrame index (row labels) using one or more existing\n",
      "     |      columns. By default yields a new object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keys : column label or list of column labels / arrays\n",
      "     |      drop : boolean, default True\n",
      "     |          Delete columns to be used as the new index\n",
      "     |      append : boolean, default False\n",
      "     |          Whether to append columns to existing index\n",
      "     |      inplace : boolean, default False\n",
      "     |          Modify the DataFrame in place (do not create a new object)\n",
      "     |      verify_integrity : boolean, default False\n",
      "     |          Check the new index for duplicates. Otherwise defer the check until\n",
      "     |          necessary. Setting to False will improve the performance of this\n",
      "     |          method\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      "     |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      "     |      ...                    'sale':[55, 40, 84, 31]})\n",
      "     |         month  sale  year\n",
      "     |      0  1      55    2012\n",
      "     |      1  4      40    2014\n",
      "     |      2  7      84    2013\n",
      "     |      3  10     31    2014\n",
      "     |      \n",
      "     |      Set the index to become the 'month' column:\n",
      "     |      \n",
      "     |      >>> df.set_index('month')\n",
      "     |             sale  year\n",
      "     |      month\n",
      "     |      1      55    2012\n",
      "     |      4      40    2014\n",
      "     |      7      84    2013\n",
      "     |      10     31    2014\n",
      "     |      \n",
      "     |      Create a multi-index using columns 'year' and 'month':\n",
      "     |      \n",
      "     |      >>> df.set_index(['year', 'month'])\n",
      "     |                  sale\n",
      "     |      year  month\n",
      "     |      2012  1     55\n",
      "     |      2014  4     40\n",
      "     |      2013  7     84\n",
      "     |      2014  10    31\n",
      "     |      \n",
      "     |      Create a multi-index using a set of values and a column:\n",
      "     |      \n",
      "     |      >>> df.set_index([[1, 2, 3, 4], 'year'])\n",
      "     |               month  sale\n",
      "     |         year\n",
      "     |      1  2012  1      55\n",
      "     |      2  2014  4      40\n",
      "     |      3  2013  7      84\n",
      "     |      4  2014  10     31\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dataframe : DataFrame\n",
      "     |  \n",
      "     |  set_value(self, index, col, value, takeable=False)\n",
      "     |      Put single value at passed column and index\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : row label\n",
      "     |      col : column label\n",
      "     |      value : scalar value\n",
      "     |      takeable : interpret the index/col as indexers, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      frame : DataFrame\n",
      "     |          If label pair is contained, will be reference to calling DataFrame,\n",
      "     |          otherwise a new object\n",
      "     |  \n",
      "     |  shift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift index by desired number of periods with an optional time freq\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, optional\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      "     |          See Notes.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is specified then the index values are shifted but the data\n",
      "     |      is not realigned. That is, use freq if you would like to extend the\n",
      "     |      index when shifting and preserve the original data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : DataFrame\n",
      "     |  \n",
      "     |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased skew over requested axis\n",
      "     |      Normalized by N-1\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      skew : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)\n",
      "     |      Sort object by labels (along an axis)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : index, columns to direct sorting\n",
      "     |      level : int or level name or list of ints or list of level names\n",
      "     |          if not None, sort on values in specified index level(s)\n",
      "     |      ascending : boolean, default True\n",
      "     |          Sort ascending vs. descending\n",
      "     |      inplace : bool, default False\n",
      "     |          if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      "     |           Not implemented for MultiIndex.\n",
      "     |      sort_remaining : bool, default True\n",
      "     |          if true and sorting by level and index is multilevel, sort by other\n",
      "     |          levels too (in order) after sorting by specified level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : DataFrame\n",
      "     |  \n",
      "     |  sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      "     |      Sort by the values along either axis\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : str or list of str\n",
      "     |          Name or list of names which refer to the axis items.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Axis to direct sorting\n",
      "     |      ascending : bool or list of bool, default True\n",
      "     |           Sort ascending vs. descending. Specify list for multiple sort\n",
      "     |           orders.  If this is a list of bools, must match the length of\n",
      "     |           the by.\n",
      "     |      inplace : bool, default False\n",
      "     |           if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...     'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "     |      ...     'col2' : [2, 1, 9, 8, 7, 4],\n",
      "     |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "     |      ... })\n",
      "     |      >>> df\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      \n",
      "     |      Sort by col1\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1'])\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort by multiple columns\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1', 'col2'])\n",
      "     |          col1 col2 col3\n",
      "     |      1   A    1    1\n",
      "     |      0   A    2    0\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort Descending\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False)\n",
      "     |          col1 col2 col3\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Putting NAs first\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "     |          col1 col2 col3\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |  \n",
      "     |  sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)\n",
      "     |      DEPRECATED: use :meth:`DataFrame.sort_index`\n",
      "     |      \n",
      "     |      Sort multilevel index by chosen axis and primary level. Data will be\n",
      "     |      lexicographically sorted by the chosen level followed by the other\n",
      "     |      levels (in order)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |      ascending : boolean, default True\n",
      "     |      inplace : boolean, default False\n",
      "     |          Sort the DataFrame without creating a new instance\n",
      "     |      sort_remaining : boolean, default True\n",
      "     |          Sort by the other levels too.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted : DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.sort_index(level=...)\n",
      "     |  \n",
      "     |  stack(self, level=-1, dropna=True)\n",
      "     |      Pivot a level of the (possibly hierarchical) column labels, returning a\n",
      "     |      DataFrame (or Series in the case of an object with a single level of\n",
      "     |      column labels) having a hierarchical index with a new inner-most level\n",
      "     |      of row labels.\n",
      "     |      The level involved will automatically get sorted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, string, or list of these, default last level\n",
      "     |          Level(s) to stack, can pass level name\n",
      "     |      dropna : boolean, default True\n",
      "     |          Whether to drop rows in the resulting Frame/Series with no valid\n",
      "     |          values\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      >>> s\n",
      "     |           a   b\n",
      "     |      one  1.  2.\n",
      "     |      two  3.  4.\n",
      "     |      \n",
      "     |      >>> s.stack()\n",
      "     |      one a    1\n",
      "     |          b    2\n",
      "     |      two a    3\n",
      "     |          b    4\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stacked : DataFrame or Series\n",
      "     |  \n",
      "     |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return sample standard deviation over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rsub\n",
      "     |  \n",
      "     |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rsub\n",
      "     |  \n",
      "     |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the sum of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sum : Series or DataFrame (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      "     |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum()\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  swaplevel(self, i=-2, j=-1, axis=0)\n",
      "     |      Swap levels i and j in a MultiIndex on a particular axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      i, j : int, string (can be mixed)\n",
      "     |          Level of index to be swapped. Can pass level name as string.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      swapped : type of caller (new object)\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.18.1\n",
      "     |      \n",
      "     |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      "     |         the two innermost levels of the index.\n",
      "     |  \n",
      "     |  to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
      "     |      Write DataFrame to a comma-separated values (csv) file\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : string or file handle, default None\n",
      "     |          File path or object, if None is provided the result is returned as\n",
      "     |          a string.\n",
      "     |      sep : character, default ','\n",
      "     |          Field delimiter for the output file.\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      columns : sequence, optional\n",
      "     |          Columns to write\n",
      "     |      header : boolean or list of string, default True\n",
      "     |          Write out the column names. If a list of strings is given it is\n",
      "     |          assumed to be aliases for the column names\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, or False, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.  If\n",
      "     |          False do not print fields for index names. Use index_label=False\n",
      "     |          for easier importing in R\n",
      "     |      mode : str\n",
      "     |          Python write mode, default 'w'\n",
      "     |      encoding : string, optional\n",
      "     |          A string representing the encoding to use in the output file,\n",
      "     |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "     |      compression : string, optional\n",
      "     |          a string representing the compression to use in the output file,\n",
      "     |          allowed values are 'gzip', 'bz2', 'xz',\n",
      "     |          only used when the first argument is a filename\n",
      "     |      line_terminator : string, default ``'\\n'``\n",
      "     |          The newline character or character sequence to use in the output\n",
      "     |          file\n",
      "     |      quoting : optional constant from csv module\n",
      "     |          defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "     |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "     |          will treat them as non-numeric\n",
      "     |      quotechar : string (length 1), default '\\\"'\n",
      "     |          character used to quote fields\n",
      "     |      doublequote : boolean, default True\n",
      "     |          Control quoting of `quotechar` inside a field\n",
      "     |      escapechar : string (length 1), default None\n",
      "     |          character used to escape `sep` and `quotechar` when appropriate\n",
      "     |      chunksize : int or None\n",
      "     |          rows to write at a time\n",
      "     |      tupleize_cols : boolean, default False\n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |             This argument will be removed and will always write each row\n",
      "     |             of the multi-index as a separate row in the CSV file.\n",
      "     |      \n",
      "     |          Write MultiIndex columns as a list of tuples (if True) or in\n",
      "     |          the new, expanded format, where each MultiIndex column is a row\n",
      "     |          in the CSV (if False).\n",
      "     |      date_format : string, default None\n",
      "     |          Format string for datetime objects\n",
      "     |      decimal: string, default '.'\n",
      "     |          Character recognized as decimal separator. E.g. use ',' for\n",
      "     |          European data\n",
      "     |  \n",
      "     |  to_dict(self, orient='dict', into=<class 'dict'>)\n",
      "     |      Convert DataFrame to dictionary.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      "     |          Determines the type of the values of the dictionary.\n",
      "     |      \n",
      "     |          - dict (default) : dict like {column -> {index -> value}}\n",
      "     |          - list : dict like {column -> [values]}\n",
      "     |          - series : dict like {column -> Series(values)}\n",
      "     |          - split : dict like\n",
      "     |            {index -> [index], columns -> [columns], data -> [values]}\n",
      "     |          - records : list like\n",
      "     |            [{column -> value}, ... , {column -> value}]\n",
      "     |          - index : dict like {index -> {column -> value}}\n",
      "     |      \n",
      "     |            .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      "     |          indicates `split`.\n",
      "     |      \n",
      "     |      into : class, default dict\n",
      "     |          The collections.Mapping subclass used for all Mappings\n",
      "     |          in the return value.  Can be the actual class or an empty\n",
      "     |          instance of the mapping type you want.  If you want a\n",
      "     |          collections.defaultdict, you must pass it initialized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : collections.Mapping like {column -> {index -> value}}\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(\n",
      "     |              {'col1': [1, 2], 'col2': [0.5, 0.75]}, index=['a', 'b'])\n",
      "     |      >>> df\n",
      "     |         col1  col2\n",
      "     |      a     1   0.1\n",
      "     |      b     2   0.2\n",
      "     |      >>> df.to_dict()\n",
      "     |      {'col1': {'a': 1, 'b': 2}, 'col2': {'a': 0.5, 'b': 0.75}}\n",
      "     |      \n",
      "     |      You can specify the return orientation.\n",
      "     |      \n",
      "     |      >>> df.to_dict('series')\n",
      "     |      {'col1': a    1\n",
      "     |      b    2\n",
      "     |      Name: col1, dtype: int64, 'col2': a    0.50\n",
      "     |      b    0.75\n",
      "     |      Name: col2, dtype: float64}\n",
      "     |      >>> df.to_dict('split')\n",
      "     |      {'columns': ['col1', 'col2'],\n",
      "     |      'data': [[1.0, 0.5], [2.0, 0.75]],\n",
      "     |      'index': ['a', 'b']}\n",
      "     |      >>> df.to_dict('records')\n",
      "     |      [{'col1': 1.0, 'col2': 0.5}, {'col1': 2.0, 'col2': 0.75}]\n",
      "     |      >>> df.to_dict('index')\n",
      "     |      {'a': {'col1': 1.0, 'col2': 0.5}, 'b': {'col1': 2.0, 'col2': 0.75}}\n",
      "     |      \n",
      "     |      You can also specify the mapping type.\n",
      "     |      \n",
      "     |      >>> from collections import OrderedDict, defaultdict\n",
      "     |      >>> df.to_dict(into=OrderedDict)\n",
      "     |      OrderedDict([('col1', OrderedDict([('a', 1), ('b', 2)])),\n",
      "     |                 ('col2', OrderedDict([('a', 0.5), ('b', 0.75)]))])\n",
      "     |      \n",
      "     |      If you want a `defaultdict`, you need to initialize it:\n",
      "     |      \n",
      "     |      >>> dd = defaultdict(list)\n",
      "     |      >>> df.to_dict('records', into=dd)\n",
      "     |      [defaultdict(<type 'list'>, {'col2': 0.5, 'col1': 1.0}),\n",
      "     |      defaultdict(<type 'list'>, {'col2': 0.75, 'col1': 2.0})]\n",
      "     |  \n",
      "     |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)\n",
      "     |      Write DataFrame to an excel sheet\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel_writer : string or ExcelWriter object\n",
      "     |          File path or existing ExcelWriter\n",
      "     |      sheet_name : string, default 'Sheet1'\n",
      "     |          Name of sheet which will contain DataFrame\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      columns : sequence, optional\n",
      "     |          Columns to write\n",
      "     |      header : boolean or list of string, default True\n",
      "     |          Write out the column names. If a list of strings is given it is\n",
      "     |          assumed to be aliases for the column names\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      startrow :\n",
      "     |          upper left cell row to dump data frame\n",
      "     |      startcol :\n",
      "     |          upper left cell column to dump data frame\n",
      "     |      engine : string, default None\n",
      "     |          write engine to use - you can also set this via the options\n",
      "     |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      "     |          ``io.excel.xlsm.writer``.\n",
      "     |      merge_cells : boolean, default True\n",
      "     |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      "     |      encoding: string, default None\n",
      "     |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      "     |          other writers support unicode natively.\n",
      "     |      inf_rep : string, default 'inf'\n",
      "     |          Representation for infinity (there is no native representation for\n",
      "     |          infinity in Excel)\n",
      "     |      freeze_panes : tuple of integer (length 2), default None\n",
      "     |          Specifies the one-based bottommost row and rightmost column that\n",
      "     |          is to be frozen\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      "     |      to the existing workbook.  This can be used to save different\n",
      "     |      DataFrames to one workbook:\n",
      "     |      \n",
      "     |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      "     |      >>> df1.to_excel(writer,'Sheet1')\n",
      "     |      >>> df2.to_excel(writer,'Sheet2')\n",
      "     |      >>> writer.save()\n",
      "     |      \n",
      "     |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      "     |      strings before writing.\n",
      "     |  \n",
      "     |  to_feather(self, fname)\n",
      "     |      write out the binary feather-format for DataFrames\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : str\n",
      "     |          string file path\n",
      "     |  \n",
      "     |  to_gbq(self, destination_table, project_id, chunksize=10000, verbose=True, reauth=False, if_exists='fail', private_key=None)\n",
      "     |      Write a DataFrame to a Google BigQuery table.\n",
      "     |      \n",
      "     |      The main method a user calls to export pandas DataFrame contents to\n",
      "     |      Google BigQuery table.\n",
      "     |      \n",
      "     |      Google BigQuery API Client Library v2 for Python is used.\n",
      "     |      Documentation is available `here\n",
      "     |      <https://developers.google.com/api-client-library/python/apis/bigquery/v2>`__\n",
      "     |      \n",
      "     |      Authentication to the Google BigQuery service is via OAuth 2.0.\n",
      "     |      \n",
      "     |      - If \"private_key\" is not provided:\n",
      "     |      \n",
      "     |        By default \"application default credentials\" are used.\n",
      "     |      \n",
      "     |        If default application credentials are not found or are restrictive,\n",
      "     |        user account credentials are used. In this case, you will be asked to\n",
      "     |        grant permissions for product name 'pandas GBQ'.\n",
      "     |      \n",
      "     |      - If \"private_key\" is provided:\n",
      "     |      \n",
      "     |        Service account credentials will be used to authenticate.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataframe : DataFrame\n",
      "     |          DataFrame to be written\n",
      "     |      destination_table : string\n",
      "     |          Name of table to be written, in the form 'dataset.tablename'\n",
      "     |      project_id : str\n",
      "     |          Google BigQuery Account project ID.\n",
      "     |      chunksize : int (default 10000)\n",
      "     |          Number of rows to be inserted in each chunk from the dataframe.\n",
      "     |      verbose : boolean (default True)\n",
      "     |          Show percentage complete\n",
      "     |      reauth : boolean (default False)\n",
      "     |          Force Google BigQuery to reauthenticate the user. This is useful\n",
      "     |          if multiple accounts are used.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          'fail': If table exists, do nothing.\n",
      "     |          'replace': If table exists, drop it, recreate it, and insert data.\n",
      "     |          'append': If table exists, insert data. Create if does not exist.\n",
      "     |      private_key : str (optional)\n",
      "     |          Service account private key in JSON format. Can be file path\n",
      "     |          or string contents. This is useful for remote server\n",
      "     |          authentication (eg. jupyter iPython notebook on remote host)\n",
      "     |  \n",
      "     |  to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None, escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False, decimal='.', border=None)\n",
      "     |      Render a DataFrame as an HTML table.\n",
      "     |      \n",
      "     |      `to_html`-specific options:\n",
      "     |      \n",
      "     |      bold_rows : boolean, default True\n",
      "     |          Make the row labels bold in the output\n",
      "     |      classes : str or list or tuple, default None\n",
      "     |          CSS class(es) to apply to the resulting html table\n",
      "     |      escape : boolean, default True\n",
      "     |          Convert the characters <, >, and & to HTML-safe sequences.=\n",
      "     |      max_rows : int, optional\n",
      "     |          Maximum number of rows to show before truncating. If None, show\n",
      "     |          all.\n",
      "     |      max_cols : int, optional\n",
      "     |          Maximum number of columns to show before truncating. If None, show\n",
      "     |          all.\n",
      "     |      decimal : string, default '.'\n",
      "     |          Character recognized as decimal separator, e.g. ',' in Europe\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      border : int\n",
      "     |          A ``border=border`` attribute is included in the opening\n",
      "     |          `<table>` tag. Default ``pd.options.html.border``.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      buf : StringIO-like, optional\n",
      "     |          buffer to write to\n",
      "     |      columns : sequence, optional\n",
      "     |          the subset of columns to write; default None writes all columns\n",
      "     |      col_space : int, optional\n",
      "     |          the minimum width of each column\n",
      "     |      header : bool, optional\n",
      "     |          whether to print column labels, default True\n",
      "     |      index : bool, optional\n",
      "     |          whether to print index (row) labels, default True\n",
      "     |      na_rep : string, optional\n",
      "     |          string representation of NAN to use, default 'NaN'\n",
      "     |      formatters : list or dict of one-parameter functions, optional\n",
      "     |          formatter functions to apply to columns' elements by position or name,\n",
      "     |          default None. The result of each function must be a unicode string.\n",
      "     |          List must be of length equal to the number of columns.\n",
      "     |      float_format : one-parameter function, optional\n",
      "     |          formatter function to apply to columns' elements if they are floats,\n",
      "     |          default None. The result of this function must be a unicode string.\n",
      "     |      sparsify : bool, optional\n",
      "     |          Set to False for a DataFrame with a hierarchical index to print every\n",
      "     |          multiindex key at each row, default True\n",
      "     |      index_names : bool, optional\n",
      "     |          Prints the names of the indexes, default True\n",
      "     |      line_width : int, optional\n",
      "     |          Width to wrap a line in characters, default no wrap\n",
      "     |      justify : {'left', 'right', 'center', 'justify',\n",
      "     |                 'justify-all', 'start', 'end', 'inherit',\n",
      "     |                 'match-parent', 'initial', 'unset'}, default None\n",
      "     |          How to justify the column labels. If None uses the option from\n",
      "     |          the print configuration (controlled by set_option), 'right' out\n",
      "     |          of the box.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      formatted : string (or unicode, depending on data and options)\n",
      "     |  \n",
      "     |  to_panel(self)\n",
      "     |      Transform long (stacked) format (DataFrame) into wide (3D, Panel)\n",
      "     |      format.\n",
      "     |      \n",
      "     |      Currently the index of the DataFrame must be a 2-level MultiIndex. This\n",
      "     |      may be generalized later\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      panel : Panel\n",
      "     |  \n",
      "     |  to_parquet(self, fname, engine='auto', compression='snappy', **kwargs)\n",
      "     |      Write a DataFrame to the binary parquet format.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : str\n",
      "     |          string file path\n",
      "     |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      "     |          Parquet reader library to use. If 'auto', then the option\n",
      "     |          'io.parquet.engine' is used. If 'auto', then the first\n",
      "     |          library to be installed is used.\n",
      "     |      compression : str, optional, default 'snappy'\n",
      "     |          compression method, includes {'gzip', 'snappy', 'brotli'}\n",
      "     |      kwargs\n",
      "     |          Additional keyword arguments passed to the engine\n",
      "     |  \n",
      "     |  to_period(self, freq=None, axis=0, copy=True)\n",
      "     |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      "     |      frequency (inferred from index if not passed)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to convert (the index by default)\n",
      "     |      copy : boolean, default True\n",
      "     |          If False then underlying input data is not copied\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ts : TimeSeries with PeriodIndex\n",
      "     |  \n",
      "     |  to_records(self, index=True, convert_datetime64=True)\n",
      "     |      Convert DataFrame to record array. Index will be put in the\n",
      "     |      'index' field of the record array if requested\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : boolean, default True\n",
      "     |          Include index in resulting record array, stored in 'index' field\n",
      "     |      convert_datetime64 : boolean, default True\n",
      "     |          Whether to convert the index to datetime.datetime if it is a\n",
      "     |          DatetimeIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : recarray\n",
      "     |  \n",
      "     |  to_sparse(self, fill_value=None, kind='block')\n",
      "     |      Convert to SparseDataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fill_value : float, default NaN\n",
      "     |      kind : {'block', 'integer'}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : SparseDataFrame\n",
      "     |  \n",
      "     |  to_stata(self, fname, convert_dates=None, write_index=True, encoding='latin-1', byteorder=None, time_stamp=None, data_label=None, variable_labels=None)\n",
      "     |      A class for writing Stata binary dta files from array-like objects\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : str or buffer\n",
      "     |          String path of file-like object\n",
      "     |      convert_dates : dict\n",
      "     |          Dictionary mapping columns containing datetime types to stata\n",
      "     |          internal format to use when wirting the dates. Options are 'tc',\n",
      "     |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      "     |          or a name. Datetime columns that do not have a conversion type\n",
      "     |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      "     |          a datetime column has timezone information\n",
      "     |      write_index : bool\n",
      "     |          Write the index to Stata dataset.\n",
      "     |      encoding : str\n",
      "     |          Default is latin-1. Unicode is not supported\n",
      "     |      byteorder : str\n",
      "     |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`\n",
      "     |      time_stamp : datetime\n",
      "     |          A datetime to use as file creation date.  Default is the current\n",
      "     |          time.\n",
      "     |      dataset_label : str\n",
      "     |          A label for the data set.  Must be 80 characters or smaller.\n",
      "     |      variable_labels : dict\n",
      "     |          Dictionary containing columns as keys and variable labels as\n",
      "     |          values. Each label must be 80 characters or smaller.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      NotImplementedError\n",
      "     |          * If datetimes contain timezone information\n",
      "     |          * Column dtype is not representable in Stata\n",
      "     |      ValueError\n",
      "     |          * Columns listed in convert_dates are noth either datetime64[ns]\n",
      "     |            or datetime.datetime\n",
      "     |          * Column listed in convert_dates is not in DataFrame\n",
      "     |          * Categorical label contains more than 32,000 characters\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> writer = StataWriter('./data_file.dta', data)\n",
      "     |      >>> writer.write_file()\n",
      "     |      \n",
      "     |      Or with dates\n",
      "     |      \n",
      "     |      >>> writer = StataWriter('./date_data_file.dta', data, {2 : 'tw'})\n",
      "     |      >>> writer.write_file()\n",
      "     |  \n",
      "     |  to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None, show_dimensions=False)\n",
      "     |      Render a DataFrame to a console-friendly tabular output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      buf : StringIO-like, optional\n",
      "     |          buffer to write to\n",
      "     |      columns : sequence, optional\n",
      "     |          the subset of columns to write; default None writes all columns\n",
      "     |      col_space : int, optional\n",
      "     |          the minimum width of each column\n",
      "     |      header : bool, optional\n",
      "     |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names\n",
      "     |      index : bool, optional\n",
      "     |          whether to print index (row) labels, default True\n",
      "     |      na_rep : string, optional\n",
      "     |          string representation of NAN to use, default 'NaN'\n",
      "     |      formatters : list or dict of one-parameter functions, optional\n",
      "     |          formatter functions to apply to columns' elements by position or name,\n",
      "     |          default None. The result of each function must be a unicode string.\n",
      "     |          List must be of length equal to the number of columns.\n",
      "     |      float_format : one-parameter function, optional\n",
      "     |          formatter function to apply to columns' elements if they are floats,\n",
      "     |          default None. The result of this function must be a unicode string.\n",
      "     |      sparsify : bool, optional\n",
      "     |          Set to False for a DataFrame with a hierarchical index to print every\n",
      "     |          multiindex key at each row, default True\n",
      "     |      index_names : bool, optional\n",
      "     |          Prints the names of the indexes, default True\n",
      "     |      line_width : int, optional\n",
      "     |          Width to wrap a line in characters, default no wrap\n",
      "     |      justify : {'left', 'right', 'center', 'justify',\n",
      "     |                 'justify-all', 'start', 'end', 'inherit',\n",
      "     |                 'match-parent', 'initial', 'unset'}, default None\n",
      "     |          How to justify the column labels. If None uses the option from\n",
      "     |          the print configuration (controlled by set_option), 'right' out\n",
      "     |          of the box.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      formatted : string (or unicode, depending on data and options)\n",
      "     |  \n",
      "     |  to_timestamp(self, freq=None, how='start', axis=0, copy=True)\n",
      "     |      Cast to DatetimeIndex of timestamps, at *beginning* of period\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default frequency of PeriodIndex\n",
      "     |          Desired frequency\n",
      "     |      how : {'s', 'e', 'start', 'end'}\n",
      "     |          Convention for converting period to timestamp; start of period\n",
      "     |          vs. end\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to convert (the index by default)\n",
      "     |      copy : boolean, default True\n",
      "     |          If false then underlying input data is not copied\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame with DatetimeIndex\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |      Call function producing a like-indexed NDFrame\n",
      "     |      and return a NDFrame with the transformed values\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          To apply to column\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      transformed : NDFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      "     |                         A         B         C\n",
      "     |      2000-01-01  0.579457  1.236184  0.123424\n",
      "     |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      "     |      2000-01-03  1.455756 -0.277446  0.288967\n",
      "     |      2000-01-04       NaN       NaN       NaN\n",
      "     |      2000-01-05       NaN       NaN       NaN\n",
      "     |      2000-01-06       NaN       NaN       NaN\n",
      "     |      2000-01-07       NaN       NaN       NaN\n",
      "     |      2000-01-08 -0.498658  1.274522  1.642524\n",
      "     |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      "     |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.aggregate\n",
      "     |      pandas.NDFrame.apply\n",
      "     |  \n",
      "     |  transpose(self, *args, **kwargs)\n",
      "     |      Transpose index and columns\n",
      "     |  \n",
      "     |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rtruediv\n",
      "     |  \n",
      "     |  unstack(self, level=-1, fill_value=None)\n",
      "     |      Pivot a level of the (necessarily hierarchical) index labels, returning\n",
      "     |      a DataFrame having a new level of column labels whose inner-most level\n",
      "     |      consists of the pivoted index labels. If the index is not a MultiIndex,\n",
      "     |      the output will be a Series (the analogue of stack when the columns are\n",
      "     |      not a MultiIndex).\n",
      "     |      The level involved will automatically get sorted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, string, or list of these, default -1 (last level)\n",
      "     |          Level(s) of index to unstack, can pass level name\n",
      "     |      fill_value : replace NaN with this value if the unstack produces\n",
      "     |          missing values\n",
      "     |      \n",
      "     |          .. versionadded: 0.18.0\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pivot : Pivot a table based on column values.\n",
      "     |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      "     |          from `unstack`).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      "     |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      "     |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      "     |      >>> s\n",
      "     |      one  a   1.0\n",
      "     |           b   2.0\n",
      "     |      two  a   3.0\n",
      "     |           b   4.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> s.unstack(level=-1)\n",
      "     |           a   b\n",
      "     |      one  1.0  2.0\n",
      "     |      two  3.0  4.0\n",
      "     |      \n",
      "     |      >>> s.unstack(level=0)\n",
      "     |         one  two\n",
      "     |      a  1.0   3.0\n",
      "     |      b  2.0   4.0\n",
      "     |      \n",
      "     |      >>> df = s.unstack(level=0)\n",
      "     |      >>> df.unstack()\n",
      "     |      one  a  1.0\n",
      "     |           b  2.0\n",
      "     |      two  a  3.0\n",
      "     |           b  4.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unstacked : DataFrame or Series\n",
      "     |  \n",
      "     |  update(self, other, join='left', overwrite=True, filter_func=None, raise_conflict=False)\n",
      "     |      Modify DataFrame in place using non-NA values from passed\n",
      "     |      DataFrame. Aligns on indices\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame, or object coercible into a DataFrame\n",
      "     |      join : {'left'}, default 'left'\n",
      "     |      overwrite : boolean, default True\n",
      "     |          If True then overwrite values for common keys in the calling frame\n",
      "     |      filter_func : callable(1d-array) -> 1d-array<boolean>, default None\n",
      "     |          Can choose to replace values other than NA. Return True for values\n",
      "     |          that should be updated\n",
      "     |      raise_conflict : boolean\n",
      "     |          If True, will raise an error if the DataFrame and other both\n",
      "     |          contain data in the same place.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      "     |      ...                    'B': [400, 500, 600]})\n",
      "     |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      "     |      ...                        'C': [7, 8, 9]})\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      "     |      ...                    'B': ['x', 'y', 'z']})\n",
      "     |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  d\n",
      "     |      1  b  e\n",
      "     |      2  c  f\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      "     |      ...                    'B': ['x', 'y', 'z']})\n",
      "     |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      "     |      >>> df.update(new_column)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  d\n",
      "     |      1  b  y\n",
      "     |      2  c  e\n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      "     |      ...                    'B': ['x', 'y', 'z']})\n",
      "     |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  x\n",
      "     |      1  b  d\n",
      "     |      2  c  e\n",
      "     |      \n",
      "     |      If ``other`` contains NaNs the corresponding values are not updated\n",
      "     |      in the original dataframe.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      "     |      ...                    'B': [400, 500, 600]})\n",
      "     |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A      B\n",
      "     |      0  1    4.0\n",
      "     |      1  2  500.0\n",
      "     |      2  3    6.0\n",
      "     |  \n",
      "     |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased variance over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  from_csv(path, header=0, sep=',', index_col=0, parse_dates=True, encoding=None, tupleize_cols=None, infer_datetime_format=False) from builtins.type\n",
      "     |      Read CSV file (DEPRECATED, please use :func:`pandas.read_csv`\n",
      "     |      instead).\n",
      "     |      \n",
      "     |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      "     |      for most general purposes, but ``from_csv`` makes for an easy\n",
      "     |      roundtrip to and from a file (the exact counterpart of\n",
      "     |      ``to_csv``), especially with a DataFrame of time series data.\n",
      "     |      \n",
      "     |      This method only differs from the preferred :func:`pandas.read_csv`\n",
      "     |      in some defaults:\n",
      "     |      \n",
      "     |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      "     |        by default)\n",
      "     |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      "     |        as datetime by default)\n",
      "     |      \n",
      "     |      So a ``pd.DataFrame.from_csv(path)`` can be replaced by\n",
      "     |      ``pd.read_csv(path, index_col=0, parse_dates=True)``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string file path or file handle / StringIO\n",
      "     |      header : int, default 0\n",
      "     |          Row to use as header (skip prior rows)\n",
      "     |      sep : string, default ','\n",
      "     |          Field delimiter\n",
      "     |      index_col : int or sequence, default 0\n",
      "     |          Column to use for index. If a sequence is given, a MultiIndex\n",
      "     |          is used. Different default from read_table\n",
      "     |      parse_dates : boolean, default True\n",
      "     |          Parse dates. Different default from read_table\n",
      "     |      tupleize_cols : boolean, default False\n",
      "     |          write multi_index columns as a list of tuples (if True)\n",
      "     |          or new (expanded format) if False)\n",
      "     |      infer_datetime_format: boolean, default False\n",
      "     |          If True and `parse_dates` is True for a column, try to infer the\n",
      "     |          datetime format based on the first datetime string. If the format\n",
      "     |          can be inferred, there often will be a large parsing speed-up.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.read_csv\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : DataFrame\n",
      "     |  \n",
      "     |  from_dict(data, orient='columns', dtype=None) from builtins.type\n",
      "     |      Construct DataFrame from dict of array-like or dicts\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : dict\n",
      "     |          {field : array-like} or {field : dict}\n",
      "     |      orient : {'columns', 'index'}, default 'columns'\n",
      "     |          The \"orientation\" of the data. If the keys of the passed dict\n",
      "     |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      "     |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      "     |      dtype : dtype, default None\n",
      "     |          Data type to force, otherwise infer\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |  \n",
      "     |  from_items(items, columns=None, orient='columns') from builtins.type\n",
      "     |      Convert (key, value) pairs to DataFrame. The keys will be the axis\n",
      "     |      index (usually the columns, but depends on the specified\n",
      "     |      orientation). The values should be arrays or Series.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      items : sequence of (key, value) pairs\n",
      "     |          Values should be arrays or Series.\n",
      "     |      columns : sequence of column labels, optional\n",
      "     |          Must be passed if orient='index'.\n",
      "     |      orient : {'columns', 'index'}, default 'columns'\n",
      "     |          The \"orientation\" of the data. If the keys of the\n",
      "     |          input correspond to column labels, pass 'columns'\n",
      "     |          (default). Otherwise if the keys correspond to the index,\n",
      "     |          pass 'index'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      frame : DataFrame\n",
      "     |  \n",
      "     |  from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from builtins.type\n",
      "     |      Convert structured or record ndarray to DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n",
      "     |      index : string, list of fields, array-like\n",
      "     |          Field of array to use as the index, alternately a specific set of\n",
      "     |          input labels to use\n",
      "     |      exclude : sequence, default None\n",
      "     |          Columns or fields to exclude\n",
      "     |      columns : sequence, default None\n",
      "     |          Column names to use. If the passed data do not have names\n",
      "     |          associated with them, this argument provides names for the\n",
      "     |          columns. Otherwise this argument indicates the order of the columns\n",
      "     |          in the result (any names not found in the data will become all-NA\n",
      "     |          columns)\n",
      "     |      coerce_float : boolean, default False\n",
      "     |          Attempt to convert values of non-string, non-numeric objects (like\n",
      "     |          decimal.Decimal) to floating point, useful for SQL result sets\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Transpose index and columns\n",
      "     |  \n",
      "     |  axes\n",
      "     |      Return a list with the row axis labels and column axis labels as the\n",
      "     |      only members. They are returned in that order.\n",
      "     |  \n",
      "     |  columns\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Return a tuple representing the dimensionality of the DataFrame.\n",
      "     |  \n",
      "     |  style\n",
      "     |      Property returning a Styler object containing methods for\n",
      "     |      building a styled HTML representation fo the DataFrame.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.io.formats.style.Styler\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  plot = <class 'pandas.plotting._core.FramePlotMethods'>\n",
      "     |      DataFrame plotting accessor and method\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df.plot.line()\n",
      "     |      >>> df.plot.scatter('x', 'y')\n",
      "     |      >>> df.plot.hexbin()\n",
      "     |      \n",
      "     |      These plotting methods can also be accessed by calling the accessor as a\n",
      "     |      method with the ``kind`` argument:\n",
      "     |      ``df.plot(kind='line')`` is equivalent to ``df.plot.line()``\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  __abs__(self)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, result, context=None)\n",
      "     |  \n",
      "     |  __bool__ = __nonzero__(self)\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      True if the key is in the info axis\n",
      "     |  \n",
      "     |  __copy__(self, deep=True)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete item\n",
      "     |  \n",
      "     |  __finalize__(self, other, method=None, **kwargs)\n",
      "     |      Propagate metadata from other to self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : the object from which to get the attributes that we are going\n",
      "     |          to propagate\n",
      "     |      method : optional, a passed method name ; possibly to take different\n",
      "     |          types of propagation actions based on this\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |      After regular attribute access, try looking up the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__(self)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate over infor axis\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |  \n",
      "     |  __round__(self, decimals=0)\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      After regular attribute access, try setting the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |      Return an object with absolute value taken--only applicable to objects\n",
      "     |      that are all numeric.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      abs: type of caller\n",
      "     |  \n",
      "     |  add_prefix(self, prefix)\n",
      "     |      Concatenate prefix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      prefix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_prefix : type of caller\n",
      "     |  \n",
      "     |  add_suffix(self, suffix)\n",
      "     |      Concatenate suffix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      suffix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_suffix : type of caller\n",
      "     |  \n",
      "     |  as_blocks(self, copy=True)\n",
      "     |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      "     |      a homogeneous dtype.\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      "     |            as_matrix)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : a dict of dtype -> Constructor Types\n",
      "     |  \n",
      "     |  as_matrix(self, columns=None)\n",
      "     |      Convert the frame to its Numpy-array representation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns: list, optional, default:None\n",
      "     |          If None, return all columns, otherwise, returns specified columns.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : ndarray\n",
      "     |          If the caller is heterogeneous and contains booleans or objects,\n",
      "     |          the result will be of dtype=object. See Notes.\n",
      "     |      \n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      "     |      \n",
      "     |      The dtype will be a lower-common-denominator dtype (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen. Use this\n",
      "     |      with care if you are not dealing with the blocks.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      "     |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      "     |      will result in a flot64 dtype.\n",
      "     |      \n",
      "     |      This method is provided for backwards compatibility. Generally,\n",
      "     |      it is recommended to use '.values'.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.values\n",
      "     |  \n",
      "     |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      "     |      Convert TimeSeries to specified frequency.\n",
      "     |      \n",
      "     |      Optionally provide filling method to pad/backfill missing values.\n",
      "     |      \n",
      "     |      Returns the original data conformed to a new index with the specified\n",
      "     |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      "     |      summarization, is necessary to represent the data at the new frequency.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : DateOffset object, or string\n",
      "     |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      "     |          Method to use for filling holes in reindexed Series (note this\n",
      "     |          does not fill NaNs that already were present):\n",
      "     |      \n",
      "     |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      "     |      how : {'start', 'end'}, default end\n",
      "     |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      "     |      normalize : bool, default False\n",
      "     |          Whether to reset output index to midnight\n",
      "     |      fill_value: scalar, optional\n",
      "     |          Value to use for missing values, applied during upsampling (note\n",
      "     |          this does not fill NaNs that already were present).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 4 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      "     |      >>> df = pd.DataFrame({'s':series})\n",
      "     |      >>> df\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    NaN\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``fill value``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    9.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    9.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    9.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``method``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', method='bfill')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    2.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    3.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |  \n",
      "     |  asof(self, where, subset=None)\n",
      "     |      The last row without any NaN is taken (or the last row without\n",
      "     |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0 For DataFrame\n",
      "     |      \n",
      "     |      If there is no good value, NaN is returned for a Series\n",
      "     |      a Series of NaN values for a DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      where : date or array of dates\n",
      "     |      subset : string or list of strings, default None\n",
      "     |         if not None use these columns for NaN propagation\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Dates are assumed to be sorted\n",
      "     |      Raises if this is not the case\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      where is scalar\n",
      "     |      \n",
      "     |        - value or NaN if input is Series\n",
      "     |        - Series if input is DataFrame\n",
      "     |      \n",
      "     |      where is Index: same shape object as input\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      merge_asof\n",
      "     |  \n",
      "     |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      "     |      Cast a pandas object to a specified dtype ``dtype``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data type, or dict of column name -> data type\n",
      "     |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      "     |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      "     |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      "     |          or more of the DataFrame's columns to column-specific types.\n",
      "     |      copy : bool, default True.\n",
      "     |          Return a copy when ``copy=True`` (be very careful setting\n",
      "     |          ``copy=False`` as changes to values then may propagate to other\n",
      "     |          pandas objects).\n",
      "     |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      "     |          Control raising of exceptions on invalid data for provided dtype.\n",
      "     |      \n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      raise_on_error : raise on invalid input\n",
      "     |          .. deprecated:: 0.20.0\n",
      "     |             Use ``errors`` instead\n",
      "     |      kwargs : keyword arguments to pass on to the constructor\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      casted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      "     |      >>> ser\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int32\n",
      "     |      >>> ser.astype('int64')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Convert to categorical type:\n",
      "     |      \n",
      "     |      >>> ser.astype('category')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [1, 2]\n",
      "     |      \n",
      "     |      Convert to ordered categorical type with custom ordering:\n",
      "     |      \n",
      "     |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [2 < 1]\n",
      "     |      \n",
      "     |      Note that using ``copy=False`` and changing data on a new\n",
      "     |      pandas object may propagate changes:\n",
      "     |      \n",
      "     |      >>> s1 = pd.Series([1,2])\n",
      "     |      >>> s2 = s1.astype('int', copy=False)\n",
      "     |      >>> s2[0] = 10\n",
      "     |      >>> s1  # note that s1[0] has changed too\n",
      "     |      0    10\n",
      "     |      1     2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to a numeric type.\n",
      "     |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      "     |  \n",
      "     |  at_time(self, time, asof=False)\n",
      "     |      Select values at particular time of day (e.g. 9:30AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      time : datetime.time or string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_at_time : type of caller\n",
      "     |  \n",
      "     |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      "     |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_time : datetime.time or string\n",
      "     |      end_time : datetime.time or string\n",
      "     |      include_start : boolean, default True\n",
      "     |      include_end : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_between_time : type of caller\n",
      "     |  \n",
      "     |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Return the bool of a single element PandasObject.\n",
      "     |      \n",
      "     |      This must be a boolean scalar value, either True or False.  Raise a\n",
      "     |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      "     |      element is not boolean\n",
      "     |  \n",
      "     |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      "     |      Trim values at input threshold(s).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lower : float or array_like, default None\n",
      "     |      upper : float or array_like, default None\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with lower and upper along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.256177\n",
      "     |      1 -1.367855  0.746646\n",
      "     |      2  0.027753 -1.176076\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  1.261967  0.570967\n",
      "     |      \n",
      "     |      >>> df.clip(-1.0, 0.5)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.000000\n",
      "     |      1 -1.000000  0.500000\n",
      "     |      2  0.027753 -1.000000\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  0.500000  0.500000\n",
      "     |      \n",
      "     |      >>> t\n",
      "     |      0   -0.3\n",
      "     |      1   -0.2\n",
      "     |      2   -0.1\n",
      "     |      3    0.0\n",
      "     |      4    0.1\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> df.clip(t, t + 1, axis=0)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -0.300000\n",
      "     |      1 -0.200000  0.746646\n",
      "     |      2  0.027753 -0.100000\n",
      "     |      3  0.230930  0.000000\n",
      "     |      4  1.100000  0.570967\n",
      "     |  \n",
      "     |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of the input with values below given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of input with values above given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  consolidate(self, inplace=False)\n",
      "     |      DEPRECATED: consolidate will be an internal implementation only.\n",
      "     |  \n",
      "     |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      "     |      Deprecated.\n",
      "     |      Attempt to infer better dtype for object columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      convert_dates : boolean, default True\n",
      "     |          If True, convert to date where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      convert_numeric : boolean, default False\n",
      "     |          If True, attempt to coerce to numbers (including strings), with\n",
      "     |          unconvertible values becoming NaN.\n",
      "     |      convert_timedeltas : boolean, default True\n",
      "     |          If True, convert to timedelta where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      copy : boolean, default True\n",
      "     |          If True, return a copy even if no copy is necessary (e.g. no\n",
      "     |          conversion was done). Note: This is meant for internal use, and\n",
      "     |          should not be confused with inplace.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      "     |          with day as the default.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same as input object\n",
      "     |  \n",
      "     |  copy(self, deep=True)\n",
      "     |      Make a copy of this objects data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean or string, default True\n",
      "     |          Make a deep copy, including a copy of the data and the indices.\n",
      "     |          With ``deep=False`` neither the indices or the data are copied.\n",
      "     |      \n",
      "     |          Note that when ``deep=True`` data is copied, actual python objects\n",
      "     |          will not be copied recursively, only the reference to the object.\n",
      "     |          This is in contrast to ``copy.deepcopy`` in the Standard Library,\n",
      "     |          which recursively copies object data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      copy : type of caller\n",
      "     |  \n",
      "     |  describe(self, percentiles=None, include=None, exclude=None)\n",
      "     |      Generates descriptive statistics that summarize the central tendency,\n",
      "     |      dispersion and shape of a dataset's distribution, excluding\n",
      "     |      ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      summary:  Series/DataFrame of summary statistics\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      "     |      ...                     'numeric': [1, 2, 3],\n",
      "     |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |              categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count\n",
      "     |      DataFrame.max\n",
      "     |      DataFrame.min\n",
      "     |      DataFrame.mean\n",
      "     |      DataFrame.std\n",
      "     |      DataFrame.select_dtypes\n",
      "     |  \n",
      "     |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      "     |      Return new object with labels in requested axis removed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : single label or list-like\n",
      "     |          Index or column labels to drop.\n",
      "     |      axis : int or axis name\n",
      "     |          Whether to drop labels from the index (0 / 'index') or\n",
      "     |          columns (1 / 'columns').\n",
      "     |      index, columns : single label or list-like\n",
      "     |          Alternative to specifying `axis` (``labels, axis=1`` is\n",
      "     |          equivalent to ``columns=labels``).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      level : int or level name, default None\n",
      "     |          For MultiIndex\n",
      "     |      inplace : bool, default False\n",
      "     |          If True, do operation inplace and return None.\n",
      "     |      errors : {'ignore', 'raise'}, default 'raise'\n",
      "     |          If 'ignore', suppress error and existing labels are dropped.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dropped : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      "     |                            columns=['A', 'B', 'C', 'D'])\n",
      "     |      >>> df\n",
      "     |         A  B   C   D\n",
      "     |      0  0  1   2   3\n",
      "     |      1  4  5   6   7\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Drop columns\n",
      "     |      \n",
      "     |      >>> df.drop(['B', 'C'], axis=1)\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      >>> df.drop(columns=['B', 'C'])\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      Drop a row by index\n",
      "     |      \n",
      "     |      >>> df.drop([0, 1])\n",
      "     |         A  B   C   D\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Specifying both `labels` and `index` or `columns` will raise a\n",
      "     |      ValueError.\n",
      "     |  \n",
      "     |  equals(self, other)\n",
      "     |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      "     |      the same location are considered equal.\n",
      "     |  \n",
      "     |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      "     |      Subset rows or columns of dataframe according to labels in\n",
      "     |      the specified index.\n",
      "     |      \n",
      "     |      Note that this routine does not filter a dataframe on its\n",
      "     |      contents. The filter is applied to the labels of the index.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      items : list-like\n",
      "     |          List of info axis to restrict to (must not all be present)\n",
      "     |      like : string\n",
      "     |          Keep info axis where \"arg in col == True\"\n",
      "     |      regex : string (regular expression)\n",
      "     |          Keep info axis with re.search(regex, col) == True\n",
      "     |      axis : int or string axis name\n",
      "     |          The axis to filter on.  By default this is the info axis,\n",
      "     |          'index' for Series, 'columns' for DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |      one  two  three\n",
      "     |      mouse     1    2      3\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      >>> # select columns by name\n",
      "     |      >>> df.filter(items=['one', 'three'])\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select columns by regular expression\n",
      "     |      >>> df.filter(regex='e$', axis=1)\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select rows containing 'bbi'\n",
      "     |      >>> df.filter(like='bbi', axis=0)\n",
      "     |      one  two  three\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.loc\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The ``items``, ``like``, and ``regex`` parameters are\n",
      "     |      enforced to be mutually exclusive.\n",
      "     |      \n",
      "     |      ``axis`` defaults to the info axis that is used when indexing\n",
      "     |      with ``[]``.\n",
      "     |  \n",
      "     |  first(self, offset)\n",
      "     |      Convenience method for subsetting initial periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.first('10D') -> First 10 days\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Get item from object for given key (DataFrame column, Panel slice,\n",
      "     |      etc.). Returns default value if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : object\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : type of items contained in object\n",
      "     |  \n",
      "     |  get_dtype_counts(self)\n",
      "     |      Return the counts of dtypes in this object.\n",
      "     |  \n",
      "     |  get_ftype_counts(self)\n",
      "     |      Return the counts of ftypes in this object.\n",
      "     |  \n",
      "     |  get_values(self)\n",
      "     |      same as values (but handles sparseness conversions)\n",
      "     |  \n",
      "     |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      "     |      Group series using mapper (dict or key function, apply given function\n",
      "     |      to group, return result as series) or by a series of columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : mapping, function, str, or iterable\n",
      "     |          Used to determine the groups for the groupby.\n",
      "     |          If ``by`` is a function, it's called on each value of the object's\n",
      "     |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      "     |          will be used to determine the groups (the Series' values are first\n",
      "     |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      "     |          values are used as-is determine the groups. A str or list of strs\n",
      "     |          may be passed to group by the columns in ``self``\n",
      "     |      axis : int, default 0\n",
      "     |      level : int, level name, or sequence of such, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      "     |          level or levels\n",
      "     |      as_index : boolean, default True\n",
      "     |          For aggregated output, return object with group labels as the\n",
      "     |          index. Only relevant for DataFrame input. as_index=False is\n",
      "     |          effectively \"SQL-style\" grouped output\n",
      "     |      sort : boolean, default True\n",
      "     |          Sort group keys. Get better performance by turning this off.\n",
      "     |          Note this does not influence the order of observations within each\n",
      "     |          group.  groupby preserves the order of rows within each group.\n",
      "     |      group_keys : boolean, default True\n",
      "     |          When calling apply, add group keys to index to identify pieces\n",
      "     |      squeeze : boolean, default False\n",
      "     |          reduce the dimensionality of the return type if possible,\n",
      "     |          otherwise return a consistent type\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      DataFrame results\n",
      "     |      \n",
      "     |      >>> data.groupby(func, axis=0).mean()\n",
      "     |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      "     |      \n",
      "     |      DataFrame with hierarchical index\n",
      "     |      \n",
      "     |      >>> data.groupby(['col1', 'col2']).mean()\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GroupBy object\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return the first n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_head : type of caller\n",
      "     |          The first n rows of the caller object.\n",
      "     |  \n",
      "     |  infer_objects(self)\n",
      "     |      Attempt to infer better dtypes for object columns.\n",
      "     |      \n",
      "     |      Attempts soft conversion of object-dtyped\n",
      "     |      columns, leaving non-object and unconvertible\n",
      "     |      columns unchanged. The inference rules are the\n",
      "     |      same as during normal Series/DataFrame construction.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to numeric typeR\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      "     |      >>> df = df.iloc[1:]\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      \n",
      "     |      >>> df.dtypes\n",
      "     |      A    object\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> df.infer_objects().dtypes\n",
      "     |      A    int64\n",
      "     |      dtype: object\n",
      "     |  \n",
      "     |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      "     |      Interpolate values according to different methods.\n",
      "     |      \n",
      "     |      Please note that only ``method='linear'`` is supported for\n",
      "     |      DataFrames/Series with a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      "     |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      "     |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      "     |                'from_derivatives', 'pchip', 'akima'}\n",
      "     |      \n",
      "     |          * 'linear': ignore the index and treat the values as equally\n",
      "     |            spaced. This is the only method supported on MultiIndexes.\n",
      "     |            default\n",
      "     |          * 'time': interpolation works on daily and higher resolution\n",
      "     |            data to interpolate given length of interval\n",
      "     |          * 'index', 'values': use the actual numerical values of the index\n",
      "     |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      "     |            'barycentric', 'polynomial' is passed to\n",
      "     |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      "     |            require that you also specify an `order` (int),\n",
      "     |            e.g. df.interpolate(method='polynomial', order=4).\n",
      "     |            These use the actual numerical values of the index.\n",
      "     |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      "     |            are all wrappers around the scipy interpolation methods of\n",
      "     |            similar names. These use the actual numerical values of the\n",
      "     |            index. For more information on their behavior, see the\n",
      "     |            `scipy documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      "     |            and `tutorial documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      "     |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      "     |            replaces 'piecewise_polynomial' interpolation method in\n",
      "     |            scipy 0.18\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |      \n",
      "     |             Added support for the 'akima' method\n",
      "     |             Added interpolate method 'from_derivatives' which replaces\n",
      "     |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      "     |             scipy < 0.18\n",
      "     |      \n",
      "     |      axis : {0, 1}, default 0\n",
      "     |          * 0: fill column-by-column\n",
      "     |          * 1: fill row-by-row\n",
      "     |      limit : int, default None.\n",
      "     |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      "     |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      "     |          If limit is specified, consecutive NaNs will be filled in this\n",
      "     |          direction.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      inplace : bool, default False\n",
      "     |          Update the NDFrame in place if possible.\n",
      "     |      downcast : optional, 'infer' or None, defaults to None\n",
      "     |          Downcast dtypes if possible.\n",
      "     |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame of same shape interpolated at the NaNs\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, replace, fillna\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Filling in NaNs\n",
      "     |      \n",
      "     |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      "     |      >>> s.interpolate()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    3\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      Get the 'info axis' (see Indexing for more)\n",
      "     |      \n",
      "     |      This is index for Series, columns for DataFrame and major_axis for\n",
      "     |      Panel.\n",
      "     |  \n",
      "     |  last(self, offset)\n",
      "     |      Convenience method for subsetting final periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.last('5M') -> Last 5 months\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is False and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is False, keep the original value. Where\n",
      "     |          True, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is True are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The mask method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``mask`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.where`\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      "     |      Percent change over given number of periods.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming percent change\n",
      "     |      fill_method : str, default 'pad'\n",
      "     |          How to handle NAs before computing percent changes\n",
      "     |      limit : int, default None\n",
      "     |          The number of consecutive NAs to fill before stopping\n",
      "     |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      "     |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chg : NDFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      By default, the percentage change is calculated along the stat\n",
      "     |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      "     |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          function to apply to the NDFrame.\n",
      "     |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      "     |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      "     |          ``data_keyword`` is a string indicating the keyword of\n",
      "     |          ``callable`` that expects the NDFrame.\n",
      "     |      args : iterable, optional\n",
      "     |          positional arguments passed into ``func``.\n",
      "     |      kwargs : mapping, optional\n",
      "     |          a dictionary of keyword arguments passed into ``func``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of ``func``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Use ``.pipe`` when chaining together functions that expect\n",
      "     |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      "     |      \n",
      "     |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(f, arg2=b, arg3=c)\n",
      "     |      ... )\n",
      "     |      \n",
      "     |      If you have a function that takes the data as (say) the second\n",
      "     |      argument, pass a tuple indicating which keyword expects the\n",
      "     |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      "     |      ...  )\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.applymap\n",
      "     |      pandas.Series.map\n",
      "     |  \n",
      "     |  pop(self, item)\n",
      "     |      Return item and drop from frame. Raise KeyError if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      item : str\n",
      "     |          Column label to be popped\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      popped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |      ...                    ('parrot', 'bird',     24.0),\n",
      "     |      ...                    ('lion',   'mammal',   80.5),\n",
      "     |      ...                    ('monkey', 'mammal', np.nan)],\n",
      "     |      ...                   columns=('name', 'class', 'max_speed'))\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  parrot    bird       24.0\n",
      "     |      2    lion  mammal       80.5\n",
      "     |      3  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      >>> df.pop('class')\n",
      "     |      0      bird\n",
      "     |      1      bird\n",
      "     |      2    mammal\n",
      "     |      3    mammal\n",
      "     |      Name: class, dtype: object\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |           name  max_speed\n",
      "     |      0  falcon      389.0\n",
      "     |      1  parrot       24.0\n",
      "     |      2    lion       80.5\n",
      "     |      3  monkey        NaN\n",
      "     |  \n",
      "     |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      "     |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      "     |      assigned a rank that is the average of the ranks of those values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          index to direct ranking\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      "     |          * average: average rank of group\n",
      "     |          * min: lowest rank in group\n",
      "     |          * max: highest rank in group\n",
      "     |          * first: ranks assigned in order they appear in the array\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      "     |          Panel objects\n",
      "     |      na_option : {'keep', 'top', 'bottom'}\n",
      "     |          * keep: leave NA values where they are\n",
      "     |          * top: smallest rank if ascending\n",
      "     |          * bottom: smallest rank if descending\n",
      "     |      ascending : boolean, default True\n",
      "     |          False for ranks by high (1) to low (N)\n",
      "     |      pct : boolean, default False\n",
      "     |          Computes percentage rank of data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ranks : same type as caller\n",
      "     |  \n",
      "     |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      "     |      Return an object with matching indices to myself.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Object\n",
      "     |      method : string or None\n",
      "     |      copy : boolean, default True\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive labels to fill for inexact matches.\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between labels of the other object and this\n",
      "     |          object for inexact matches. Can be list-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      "     |                             method=...)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : same as input\n",
      "     |  \n",
      "     |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      "     |      Alter the name of the index or columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper : scalar, list-like, optional\n",
      "     |          Value to set the axis name attribute.\n",
      "     |      axis : int or string, default 0\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : type of caller or None if inplace=True\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      "     |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      "     |      deprecated and will be removed in a future version. Use ``rename``\n",
      "     |      instead.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.rename, pandas.DataFrame.rename\n",
      "     |      pandas.Index.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.rename_axis(\"foo\")\n",
      "     |           A  B\n",
      "     |      foo\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |      \n",
      "     |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      "     |      bar  A  B\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |  \n",
      "     |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      "     |      Replace values given in 'to_replace' with 'value'.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      "     |      \n",
      "     |          * str or regex:\n",
      "     |      \n",
      "     |              - str: string exactly matching `to_replace` will be replaced\n",
      "     |                with `value`\n",
      "     |              - regex: regexs matching `to_replace` will be replaced with\n",
      "     |                `value`\n",
      "     |      \n",
      "     |          * list of str, regex, or numeric:\n",
      "     |      \n",
      "     |              - First, if `to_replace` and `value` are both lists, they\n",
      "     |                **must** be the same length.\n",
      "     |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      "     |                lists will be interpreted as regexs otherwise they will match\n",
      "     |                directly. This doesn't matter much for `value` since there\n",
      "     |                are only a few possible substitution regexes you can use.\n",
      "     |              - str and regex rules apply as above.\n",
      "     |      \n",
      "     |          * dict:\n",
      "     |      \n",
      "     |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      "     |                follows: look in column 'a' for the value 'b' and replace it\n",
      "     |                with nan. You can nest regular expressions as well. Note that\n",
      "     |                column names (the top-level dictionary keys in a nested\n",
      "     |                dictionary) **cannot** be regular expressions.\n",
      "     |              - Keys map to column names and values map to substitution\n",
      "     |                values. You can treat this as a special case of passing two\n",
      "     |                lists except that you are specifying the column to search in.\n",
      "     |      \n",
      "     |          * None:\n",
      "     |      \n",
      "     |              - This means that the ``regex`` argument must be a string,\n",
      "     |                compiled regular expression, or list, dict, ndarray or Series\n",
      "     |                of such elements. If `value` is also ``None`` then this\n",
      "     |                **must** be a nested dictionary or ``Series``.\n",
      "     |      \n",
      "     |          See the examples section for examples of each of these.\n",
      "     |      value : scalar, dict, list, str, regex, default None\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      "     |          specifying which value to use for each column (columns not in the\n",
      "     |          dict will not be filled). Regular expressions, strings and lists or\n",
      "     |          dicts of such objects are also allowed.\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, in place. Note: this will modify any\n",
      "     |          other views on this object (e.g. a column from a DataFrame).\n",
      "     |          Returns the caller if this is True.\n",
      "     |      limit : int, default None\n",
      "     |          Maximum size gap to forward or backward fill\n",
      "     |      regex : bool or same types as `to_replace`, default False\n",
      "     |          Whether to interpret `to_replace` and/or `value` as regular\n",
      "     |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      "     |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      "     |          parameter will be interpreted as a regular expression or a list,\n",
      "     |          dict, or array of regular expressions.\n",
      "     |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      "     |          The method to use when for replacement, when ``to_replace`` is a\n",
      "     |          ``list``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      NDFrame.reindex\n",
      "     |      NDFrame.asfreq\n",
      "     |      NDFrame.fillna\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : NDFrame\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      AssertionError\n",
      "     |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      "     |      TypeError\n",
      "     |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      "     |            ``dict``, ``ndarray``, or ``Series``\n",
      "     |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      "     |            regular expression or is a list, dict, ndarray, or Series.\n",
      "     |      ValueError\n",
      "     |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      "     |            they are not the same length.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      "     |        rules for substitution for ``re.sub`` are the same.\n",
      "     |      * Regular expressions will only substitute on strings, meaning you\n",
      "     |        cannot provide, for example, a regular expression matching floating\n",
      "     |        point numbers and expect the columns in your frame that have a\n",
      "     |        numeric dtype to be matched. However, if those floating point numbers\n",
      "     |        *are* strings, then you can do this.\n",
      "     |      * This method has *a lot* of options. You are encouraged to experiment\n",
      "     |        and play with this method to gain intuition about how it works.\n",
      "     |  \n",
      "     |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      "     |      Convenience method for frequency conversion and resampling of time\n",
      "     |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      "     |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      "     |      to the on or level keyword.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : string\n",
      "     |          the offset string or object representing target conversion\n",
      "     |      axis : int, optional, default 0\n",
      "     |      closed : {'right', 'left'}\n",
      "     |          Which side of bin interval is closed. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      label : {'right', 'left'}\n",
      "     |          Which bin edge label to label bucket with. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      convention : {'start', 'end', 's', 'e'}\n",
      "     |          For PeriodIndex only, controls whether to use the start or end of\n",
      "     |          `rule`\n",
      "     |      loffset : timedelta\n",
      "     |          Adjust the resampled time labels\n",
      "     |      base : int, default 0\n",
      "     |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      "     |          aggregated intervals. For example, for '5min' frequency, base could\n",
      "     |          range from 0 through 4. Defaults to 0\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column to use instead of index for resampling.\n",
      "     |          Column must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      level : string or int, optional\n",
      "     |          For a MultiIndex, level (name or number) to use for\n",
      "     |          resampling.  Level must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the offset strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 9 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> series = pd.Series(range(9), index=index)\n",
      "     |      >>> series\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      2000-01-01 00:03:00    3\n",
      "     |      2000-01-01 00:04:00    4\n",
      "     |      2000-01-01 00:05:00    5\n",
      "     |      2000-01-01 00:06:00    6\n",
      "     |      2000-01-01 00:07:00    7\n",
      "     |      2000-01-01 00:08:00    8\n",
      "     |      Freq: T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and sum the values\n",
      "     |      of the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> series.resample('3T').sum()\n",
      "     |      2000-01-01 00:00:00     3\n",
      "     |      2000-01-01 00:03:00    12\n",
      "     |      2000-01-01 00:06:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but label each\n",
      "     |      bin using the right edge instead of the left. Please note that the\n",
      "     |      value in the bucket used as the label is not included in the bucket,\n",
      "     |      which it labels. For example, in the original series the\n",
      "     |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      "     |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      "     |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      "     |      To include this value close the right side of the bin interval as\n",
      "     |      illustrated in the example below this one.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right').sum()\n",
      "     |      2000-01-01 00:03:00     3\n",
      "     |      2000-01-01 00:06:00    12\n",
      "     |      2000-01-01 00:09:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      "     |      2000-01-01 00:00:00     0\n",
      "     |      2000-01-01 00:03:00     6\n",
      "     |      2000-01-01 00:06:00    15\n",
      "     |      2000-01-01 00:09:00    15\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      "     |      2000-01-01 00:00:00   0.0\n",
      "     |      2000-01-01 00:00:30   NaN\n",
      "     |      2000-01-01 00:01:00   1.0\n",
      "     |      2000-01-01 00:01:30   NaN\n",
      "     |      2000-01-01 00:02:00   2.0\n",
      "     |      Freq: 30S, dtype: float64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      "     |      values using the ``pad`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').pad()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the\n",
      "     |      ``NaN`` values using the ``bfill`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').bfill()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    1\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    2\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Pass a custom function via ``apply``\n",
      "     |      \n",
      "     |      >>> def custom_resampler(array_like):\n",
      "     |      ...     return np.sum(array_like)+5\n",
      "     |      \n",
      "     |      >>> series.resample('3T').apply(custom_resampler)\n",
      "     |      2000-01-01 00:00:00     8\n",
      "     |      2000-01-01 00:03:00    17\n",
      "     |      2000-01-01 00:06:00    26\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      "     |      used to control whether to use the start or end of `rule`.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      "     |                                                      freq='A',\n",
      "     |                                                      periods=2))\n",
      "     |      >>> s\n",
      "     |      2012    1\n",
      "     |      2013    2\n",
      "     |      Freq: A-DEC, dtype: int64\n",
      "     |      \n",
      "     |      Resample by month using 'start' `convention`. Values are assigned to\n",
      "     |      the first month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='start').asfreq().head()\n",
      "     |      2012-01    1.0\n",
      "     |      2012-02    NaN\n",
      "     |      2012-03    NaN\n",
      "     |      2012-04    NaN\n",
      "     |      2012-05    NaN\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      Resample by month using 'end' `convention`. Values are assigned to\n",
      "     |      the last month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='end').asfreq()\n",
      "     |      2012-12    1.0\n",
      "     |      2013-01    NaN\n",
      "     |      2013-02    NaN\n",
      "     |      2013-03    NaN\n",
      "     |      2013-04    NaN\n",
      "     |      2013-05    NaN\n",
      "     |      2013-06    NaN\n",
      "     |      2013-07    NaN\n",
      "     |      2013-08    NaN\n",
      "     |      2013-09    NaN\n",
      "     |      2013-10    NaN\n",
      "     |      2013-11    NaN\n",
      "     |      2013-12    2.0\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      "     |      column instead of the index for resampling.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      "     |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> df.resample('3T', on='time').sum()\n",
      "     |                           a  b  c  d\n",
      "     |      time\n",
      "     |      2000-01-01 00:00:00  0  3  6  9\n",
      "     |      2000-01-01 00:03:00  0  3  6  9\n",
      "     |      2000-01-01 00:06:00  0  3  6  9\n",
      "     |      \n",
      "     |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      "     |      specify on level the resampling needs to take place.\n",
      "     |      \n",
      "     |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      "     |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      "     |                             columns=['a', 'b', 'c', 'd'],\n",
      "     |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      "     |                             )\n",
      "     |      >>> df2.resample('3T', level=0).sum()\n",
      "     |                           a  b   c   d\n",
      "     |      2000-01-01 00:00:00  0  6  12  18\n",
      "     |      2000-01-01 00:03:00  0  4   8  12\n",
      "     |  \n",
      "     |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      "     |      Returns a random sample of items from an axis of object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, optional\n",
      "     |          Number of items from axis to return. Cannot be used with `frac`.\n",
      "     |          Default = 1 if `frac` = None.\n",
      "     |      frac : float, optional\n",
      "     |          Fraction of axis items to return. Cannot be used with `n`.\n",
      "     |      replace : boolean, optional\n",
      "     |          Sample with or without replacement. Default = False.\n",
      "     |      weights : str or ndarray-like, optional\n",
      "     |          Default 'None' results in equal probability weighting.\n",
      "     |          If passed a Series, will align with target object on index. Index\n",
      "     |          values in weights not found in sampled object will be ignored and\n",
      "     |          index values in sampled object not in weights will be assigned\n",
      "     |          weights of zero.\n",
      "     |          If called on a DataFrame, will accept the name of a column\n",
      "     |          when axis = 0.\n",
      "     |          Unless weights are a Series, weights must be same length as axis\n",
      "     |          being sampled.\n",
      "     |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      "     |          Missing values in the weights column will be treated as zero.\n",
      "     |          inf and -inf values not allowed.\n",
      "     |      random_state : int or numpy.random.RandomState, optional\n",
      "     |          Seed for the random number generator (if int), or numpy RandomState\n",
      "     |          object.\n",
      "     |      axis : int or string, optional\n",
      "     |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      "     |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A new object of same type as caller.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Generate an example ``Series`` and ``DataFrame``:\n",
      "     |      \n",
      "     |      >>> s = pd.Series(np.random.randn(50))\n",
      "     |      >>> s.head()\n",
      "     |      0   -0.038497\n",
      "     |      1    1.820773\n",
      "     |      2   -0.972766\n",
      "     |      3   -1.598270\n",
      "     |      4   -1.095526\n",
      "     |      dtype: float64\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      "     |      >>> df.head()\n",
      "     |                A         B         C         D\n",
      "     |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      "     |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      "     |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      "     |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      "     |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      "     |      \n",
      "     |      Next extract a random sample from both of these objects...\n",
      "     |      \n",
      "     |      3 random elements from the ``Series``:\n",
      "     |      \n",
      "     |      >>> s.sample(n=3)\n",
      "     |      27   -0.994689\n",
      "     |      55   -1.049016\n",
      "     |      67   -0.224565\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      And a random 10% of the ``DataFrame`` with replacement:\n",
      "     |      \n",
      "     |      >>> df.sample(frac=0.1, replace=True)\n",
      "     |                 A         B         C         D\n",
      "     |      35  1.981780  0.142106  1.817165 -0.290805\n",
      "     |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      "     |      40  0.823173 -0.078816  1.009536  1.015108\n",
      "     |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      "     |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      "     |  \n",
      "     |  select(self, crit, axis=0)\n",
      "     |      Return data corresponding to axis labels matching criteria\n",
      "     |      \n",
      "     |      DEPRECATED: use df.loc[df.index.map(crit)] to select via labels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      crit : function\n",
      "     |          To be called on each index (label). Should return True or False\n",
      "     |      axis : int\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      selection : type of caller\n",
      "     |  \n",
      "     |  set_axis(self, labels, axis=0, inplace=None)\n",
      "     |      Assign desired index to given axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels: list-like or Index\n",
      "     |          The values for the new index\n",
      "     |      axis : int or string, default 0\n",
      "     |      inplace : boolean, default None\n",
      "     |          Whether to return a new NDFrame instance.\n",
      "     |      \n",
      "     |          WARNING: inplace=None currently falls back to to True, but\n",
      "     |          in a future version, will default to False.  Use inplace=True\n",
      "     |          explicitly rather than relying on the default.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |          The signature is make consistent to the rest of the API.\n",
      "     |          Previously, the \"axis\" and \"labels\" arguments were respectively\n",
      "     |          the first and second positional arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : NDFrame or None\n",
      "     |          An object of same type as caller if inplace=False, None otherwise.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |      a    1\n",
      "     |      b    2\n",
      "     |      c    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |         A  B\n",
      "     |      a  1  4\n",
      "     |      b  2  5\n",
      "     |      c  3  6\n",
      "     |      >>> df.set_axis(['I', 'II'], axis=1, inplace=False)\n",
      "     |         I  II\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |      >>> df.set_axis(['i', 'ii'], axis=1, inplace=True)\n",
      "     |      >>> df\n",
      "     |         i  ii\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |  \n",
      "     |  slice_shift(self, periods=1, axis=0)\n",
      "     |      Equivalent to `shift` without copying data. The shifted data will\n",
      "     |      not include the dropped periods and the shifted axis will be smaller\n",
      "     |      than the original.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      "     |      later during alignment.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : same type as caller\n",
      "     |  \n",
      "     |  squeeze(self, axis=None)\n",
      "     |      Squeeze length 1 dimensions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : None, integer or string axis name, optional\n",
      "     |          The axis to squeeze if 1-sized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar if 1-sized, else original object\n",
      "     |  \n",
      "     |  swapaxes(self, axis1, axis2, copy=True)\n",
      "     |      Interchange axes and swap values axes appropriately\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : same as input\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return the last n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_tail : type of caller\n",
      "     |          The last n rows of the caller object.\n",
      "     |  \n",
      "     |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      "     |      Return the elements in the given *positional* indices along an axis.\n",
      "     |      \n",
      "     |      This means that we are not indexing according to actual values in\n",
      "     |      the index attribute of the object. We are indexing according to the\n",
      "     |      actual position of the element in the object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      indices : array-like\n",
      "     |          An array of ints indicating which positions to take.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis on which to select elements. \"0\" means that we are\n",
      "     |          selecting rows, \"1\" means that we are selecting columns, etc.\n",
      "     |      convert : bool, default True\n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |             In the future, negative indices will always be converted.\n",
      "     |      \n",
      "     |          Whether to convert negative indices into positive ones.\n",
      "     |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      "     |          The conversions are similar to the behavior of indexing a\n",
      "     |          regular Python list.\n",
      "     |      is_copy : bool, default True\n",
      "     |          Whether to return a copy of the original object or not.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |                             ('parrot', 'bird',     24.0),\n",
      "     |                             ('lion',   'mammal',   80.5),\n",
      "     |                             ('monkey', 'mammal', np.nan)],\n",
      "     |                            columns=('name', 'class', 'max_speed'),\n",
      "     |                            index=[0, 2, 3, 1])\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      2  parrot    bird       24.0\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      "     |      \n",
      "     |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      "     |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      "     |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      "     |      \n",
      "     |      >>> df.take([0, 3])\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      "     |      \n",
      "     |      >>> df.take([1, 2], axis=1)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      2    bird       24.0\n",
      "     |      3  mammal       80.5\n",
      "     |      1  mammal        NaN\n",
      "     |      \n",
      "     |      We may take elements using negative integers for positive indices,\n",
      "     |      starting from the end of the object, just like with Python lists.\n",
      "     |      \n",
      "     |      >>> df.take([-1, -2])\n",
      "     |           name   class  max_speed\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      taken : type of caller\n",
      "     |          An array-like containing the elements taken from the object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.take\n",
      "     |      numpy.take\n",
      "     |  \n",
      "     |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      "     |      Attempt to write text representation of object to the system clipboard\n",
      "     |      This can be pasted into Excel, for example.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel : boolean, defaults to True\n",
      "     |              if True, use the provided separator, writing in a csv\n",
      "     |              format for allowing easy pasting into excel.\n",
      "     |              if False, write a string representation of the object\n",
      "     |              to the clipboard\n",
      "     |      sep : optional, defaults to tab\n",
      "     |      other keywords are passed to to_csv\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Requirements for your platform\n",
      "     |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      "     |        - Windows: none\n",
      "     |        - OS X: none\n",
      "     |  \n",
      "     |  to_dense(self)\n",
      "     |      Return dense representation of NDFrame (as opposed to sparse)\n",
      "     |  \n",
      "     |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      "     |      Write the contained data to an HDF5 file using HDFStore.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path (string) or HDFStore object\n",
      "     |      key : string\n",
      "     |          identifier for the group in the store\n",
      "     |      mode : optional, {'a', 'w', 'r+'}, default 'a'\n",
      "     |      \n",
      "     |        ``'w'``\n",
      "     |            Write; a new file is created (an existing file with the same\n",
      "     |            name would be deleted).\n",
      "     |        ``'a'``\n",
      "     |            Append; an existing file is opened for reading and writing,\n",
      "     |            and if the file does not exist it is created.\n",
      "     |        ``'r+'``\n",
      "     |            It is similar to ``'a'``, but the file must already exist.\n",
      "     |      format : 'fixed(f)|table(t)', default is 'fixed'\n",
      "     |          fixed(f) : Fixed format\n",
      "     |                     Fast writing/reading. Not-appendable, nor searchable\n",
      "     |          table(t) : Table format\n",
      "     |                     Write as a PyTables Table structure which may perform\n",
      "     |                     worse but allow more flexible operations like searching\n",
      "     |                     / selecting subsets of the data\n",
      "     |      append : boolean, default False\n",
      "     |          For Table formats, append the input data to the existing\n",
      "     |      data_columns :  list of columns, or True, default None\n",
      "     |          List of columns to create as indexed data columns for on-disk\n",
      "     |          queries, or True to use all columns. By default only the axes\n",
      "     |          of the object are indexed. See `here\n",
      "     |          <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
      "     |      \n",
      "     |          Applicable only to format='table'.\n",
      "     |      complevel : int, 0-9, default None\n",
      "     |          Specifies a compression level for data.\n",
      "     |          A value of 0 disables compression.\n",
      "     |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      "     |          Specifies the compression library to be used.\n",
      "     |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      "     |          (default if no compressor specified: 'blosc:blosclz'):\n",
      "     |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      "     |          'blosc:zlib', 'blosc:zstd'}.\n",
      "     |          Specifying a compression library which is not available issues\n",
      "     |          a ValueError.\n",
      "     |      fletcher32 : bool, default False\n",
      "     |          If applying compression use the fletcher32 checksum\n",
      "     |      dropna : boolean, default False.\n",
      "     |          If true, ALL nan rows will not be written to store.\n",
      "     |  \n",
      "     |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None)\n",
      "     |      Convert the object to a JSON string.\n",
      "     |      \n",
      "     |      Note NaN's and None will be converted to null and datetime objects\n",
      "     |      will be converted to UNIX timestamps.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path or buffer to write the result string\n",
      "     |          if this is None, return the converted string\n",
      "     |      orient : string\n",
      "     |      \n",
      "     |          * Series\n",
      "     |      \n",
      "     |            - default is 'index'\n",
      "     |            - allowed values are: {'split','records','index'}\n",
      "     |      \n",
      "     |          * DataFrame\n",
      "     |      \n",
      "     |            - default is 'columns'\n",
      "     |            - allowed values are:\n",
      "     |              {'split','records','index','columns','values'}\n",
      "     |      \n",
      "     |          * The format of the JSON string\n",
      "     |      \n",
      "     |            - split : dict like\n",
      "     |              {index -> [index], columns -> [columns], data -> [values]}\n",
      "     |            - records : list like\n",
      "     |              [{column -> value}, ... , {column -> value}]\n",
      "     |            - index : dict like {index -> {column -> value}}\n",
      "     |            - columns : dict like {column -> {index -> value}}\n",
      "     |            - values : just the values array\n",
      "     |            - table : dict like {'schema': {schema}, 'data': {data}}\n",
      "     |              describing the data, and the data component is\n",
      "     |              like ``orient='records'``.\n",
      "     |      \n",
      "     |              .. versionchanged:: 0.20.0\n",
      "     |      \n",
      "     |      date_format : {None, 'epoch', 'iso'}\n",
      "     |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      "     |          `iso` = ISO8601. The default depends on the `orient`. For\n",
      "     |          `orient='table'`, the default is `'iso'`. For all other orients,\n",
      "     |          the default is `'epoch'`.\n",
      "     |      double_precision : The number of decimal places to use when encoding\n",
      "     |          floating point values, default 10.\n",
      "     |      force_ascii : force encoded string to be ASCII, default True.\n",
      "     |      date_unit : string, default 'ms' (milliseconds)\n",
      "     |          The time unit to encode to, governs timestamp and ISO8601\n",
      "     |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "     |          microsecond, and nanosecond respectively.\n",
      "     |      default_handler : callable, default None\n",
      "     |          Handler to call if object cannot otherwise be converted to a\n",
      "     |          suitable format for JSON. Should receive a single argument which is\n",
      "     |          the object to convert and return a serialisable object.\n",
      "     |      lines : boolean, default False\n",
      "     |          If 'orient' is 'records' write out line delimited json format. Will\n",
      "     |          throw ValueError if incorrect 'orient' since others are not list\n",
      "     |          like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      compression : {None, 'gzip', 'bz2', 'xz'}\n",
      "     |          A string representing the compression to use in the output file,\n",
      "     |          only used when the first argument is a filename\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object with filtered info axis\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pd.read_json\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "     |      ...                   index=['row 1', 'row 2'],\n",
      "     |      ...                   columns=['col 1', 'col 2'])\n",
      "     |      >>> df.to_json(orient='split')\n",
      "     |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      "     |        \"index\":[\"row 1\",\"row 2\"],\n",
      "     |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='index')\n",
      "     |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "     |      Note that index labels are not preserved with this encoding.\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='records')\n",
      "     |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      "     |      \n",
      "     |      Encoding with Table Schema\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='table')\n",
      "     |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      "     |                   \"primaryKey\": \"index\",\n",
      "     |                   \"pandas_version\": \"0.20.0\"},\n",
      "     |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      "     |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      "     |  \n",
      "     |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      "     |      Render an object to a tabular environment table. You can splice\n",
      "     |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.20.2\n",
      "     |         Added to Series\n",
      "     |      \n",
      "     |      `to_latex`-specific options:\n",
      "     |      \n",
      "     |      bold_rows : boolean, default False\n",
      "     |          Make the row labels bold in the output\n",
      "     |      column_format : str, default None\n",
      "     |          The columns format as specified in `LaTeX table format\n",
      "     |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      "     |          columns\n",
      "     |      longtable : boolean, default will be read from the pandas config module\n",
      "     |          Default: False.\n",
      "     |          Use a longtable environment instead of tabular. Requires adding\n",
      "     |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      "     |      escape : boolean, default will be read from the pandas config module\n",
      "     |          Default: True.\n",
      "     |          When set to False prevents from escaping latex special\n",
      "     |          characters in column names.\n",
      "     |      encoding : str, default None\n",
      "     |          A string representing the encoding to use in the output file,\n",
      "     |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "     |      decimal : string, default '.'\n",
      "     |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      multicolumn : boolean, default True\n",
      "     |          Use \\multicolumn to enhance MultiIndex columns.\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multicolumn_format : str, default 'l'\n",
      "     |          The alignment for multicolumns, similar to `column_format`\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multirow : boolean, default False\n",
      "     |          Use \\multirow to enhance MultiIndex rows.\n",
      "     |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      "     |          Will print centered labels (instead of top-aligned)\n",
      "     |          across the contained rows, separating groups via clines.\n",
      "     |          The default will be read from the pandas config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |  \n",
      "     |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      "     |      msgpack (serialize) object to input file path\n",
      "     |      \n",
      "     |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      "     |      may not be stable until a future release.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string File path, buffer-like, or None\n",
      "     |          if None, return generated string\n",
      "     |      append : boolean whether to append to an existing msgpack\n",
      "     |          (default is False)\n",
      "     |      compress : type of compressor (zlib or blosc), default to None (no\n",
      "     |          compression)\n",
      "     |  \n",
      "     |  to_pickle(self, path, compression='infer', protocol=4)\n",
      "     |      Pickle (serialize) object to input file path.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string\n",
      "     |          File path\n",
      "     |      compression : {'infer', 'gzip', 'bz2', 'xz', None}, default 'infer'\n",
      "     |          a string representing the compression to use in the output file\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      protocol : int\n",
      "     |          Int which indicates which protocol should be used by the pickler,\n",
      "     |          default HIGHEST_PROTOCOL (see [1], paragraph 12.1.2). The possible\n",
      "     |          values for this parameter depend on the version of Python. For\n",
      "     |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      "     |          valid value. For Python >= 3.4, 4 is a valid value.A negative value\n",
      "     |          for the protocol parameter is equivalent to setting its value to\n",
      "     |          HIGHEST_PROTOCOL.\n",
      "     |      \n",
      "     |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |  \n",
      "     |  to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : string\n",
      "     |          Name of SQL table\n",
      "     |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      "     |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "     |          library. If a DBAPI2 object, only sqlite3 is supported.\n",
      "     |      flavor : 'sqlite', default None\n",
      "     |          .. deprecated:: 0.19.0\n",
      "     |             'sqlite' is the only supported option if SQLAlchemy is not\n",
      "     |             used.\n",
      "     |      schema : string, default None\n",
      "     |          Specify the schema (if database flavor supports this). If None, use\n",
      "     |          default schema.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          - fail: If table exists, do nothing.\n",
      "     |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          - append: If table exists, insert data. Create if does not exist.\n",
      "     |      index : boolean, default True\n",
      "     |          Write DataFrame index as a column.\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s). If None is given (default) and\n",
      "     |          `index` is True, then the index names are used.\n",
      "     |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      chunksize : int, default None\n",
      "     |          If not None, then rows will be written in batches of this size at a\n",
      "     |          time.  If None, all rows will be written at once.\n",
      "     |      dtype : dict of column name to SQL type, default None\n",
      "     |          Optional specifying the datatype for columns. The SQL type should\n",
      "     |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      "     |  \n",
      "     |  to_xarray(self)\n",
      "     |      Return an xarray object from the pandas object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a DataArray for a Series\n",
      "     |      a Dataset for a DataFrame\n",
      "     |      a DataArray for higher dims\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)})\n",
      "     |      >>> df\n",
      "     |         A    B    C\n",
      "     |      0  1  foo  4.0\n",
      "     |      1  1  bar  5.0\n",
      "     |      2  2  foo  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (index: 3)\n",
      "     |      Coordinates:\n",
      "     |        * index    (index) int64 0 1 2\n",
      "     |      Data variables:\n",
      "     |          A        (index) int64 1 1 2\n",
      "     |          B        (index) object 'foo' 'bar' 'foo'\n",
      "     |          C        (index) float64 4.0 5.0 6.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)}\n",
      "     |                           ).set_index(['B','A'])\n",
      "     |      >>> df\n",
      "     |               C\n",
      "     |      B   A\n",
      "     |      foo 1  4.0\n",
      "     |      bar 1  5.0\n",
      "     |      foo 2  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (A: 2, B: 2)\n",
      "     |      Coordinates:\n",
      "     |        * B        (B) object 'bar' 'foo'\n",
      "     |        * A        (A) int64 1 2\n",
      "     |      Data variables:\n",
      "     |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      "     |      \n",
      "     |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      "     |                       items=list('ABCD'),\n",
      "     |                       major_axis=pd.date_range('20130101', periods=3),\n",
      "     |                       minor_axis=['first', 'second'])\n",
      "     |      >>> p\n",
      "     |      <class 'pandas.core.panel.Panel'>\n",
      "     |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      "     |      Items axis: A to D\n",
      "     |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      "     |      Minor_axis axis: first to second\n",
      "     |      \n",
      "     |      >>> p.to_xarray()\n",
      "     |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      "     |      array([[[ 0,  1],\n",
      "     |              [ 2,  3],\n",
      "     |              [ 4,  5]],\n",
      "     |             [[ 6,  7],\n",
      "     |              [ 8,  9],\n",
      "     |              [10, 11]],\n",
      "     |             [[12, 13],\n",
      "     |              [14, 15],\n",
      "     |              [16, 17]],\n",
      "     |             [[18, 19],\n",
      "     |              [20, 21],\n",
      "     |              [22, 23]]])\n",
      "     |      Coordinates:\n",
      "     |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      "     |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      "     |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      "     |  \n",
      "     |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      "     |      Truncates a sorted DataFrame/Series before and/or after some\n",
      "     |      particular index value. If the axis contains only datetime values,\n",
      "     |      before/after parameters are converted to datetime values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      before : date, string, int\n",
      "     |          Truncate all rows before this index value\n",
      "     |      after : date, string, int\n",
      "     |          Truncate all rows after this index value\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      \n",
      "     |          * 0 or 'index': apply truncation to rows\n",
      "     |          * 1 or 'columns': apply truncation to columns\n",
      "     |          Default is stat axis for given data type (0 for Series and\n",
      "     |          DataFrames, 1 for Panels)\n",
      "     |      copy : boolean, default is True,\n",
      "     |          return a copy of the truncated section\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      truncated : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      "     |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      "     |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      "     |      ...                    index=[1, 2, 3, 4, 5])\n",
      "     |      >>> df.truncate(before=2, after=4)\n",
      "     |         A  B  C\n",
      "     |      2  b  g  l\n",
      "     |      3  c  h  m\n",
      "     |      4  d  i  n\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
      "     |      ...                    'B': [6, 7, 8, 9, 10],\n",
      "     |      ...                    'C': [11, 12, 13, 14, 15]},\n",
      "     |      ...                    index=['a', 'b', 'c', 'd', 'e'])\n",
      "     |      >>> df.truncate(before='b', after='d')\n",
      "     |         A  B   C\n",
      "     |      b  2  7  12\n",
      "     |      c  3  8  13\n",
      "     |      d  4  9  14\n",
      "     |      \n",
      "     |      The index values in ``truncate`` can be datetimes or string\n",
      "     |      dates. Note that ``truncate`` assumes a 0 value for any unspecified\n",
      "     |      date component in a ``DatetimeIndex`` in contrast to slicing which\n",
      "     |      returns any partially matching dates.\n",
      "     |      \n",
      "     |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      "     |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      "     |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      "     |                           A\n",
      "     |      2016-01-09 23:59:56  1\n",
      "     |      2016-01-09 23:59:57  1\n",
      "     |      2016-01-09 23:59:58  1\n",
      "     |      2016-01-09 23:59:59  1\n",
      "     |      2016-01-10 00:00:00  1\n",
      "     |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      "     |                           A\n",
      "     |      2016-01-10 23:59:55  1\n",
      "     |      2016-01-10 23:59:56  1\n",
      "     |      2016-01-10 23:59:57  1\n",
      "     |      2016-01-10 23:59:58  1\n",
      "     |      2016-01-10 23:59:59  1\n",
      "     |  \n",
      "     |  tshift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift the time index, using the index's frequency if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, default None\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      "     |      axis : int or basestring\n",
      "     |          Corresponds to the axis that contains the Index\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is not specified then tries to use the freq or inferred_freq\n",
      "     |      attributes of the index. If neither of those attributes exist, a\n",
      "     |      ValueError is thrown\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : NDFrame\n",
      "     |  \n",
      "     |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      "     |      Convert tz-aware axis to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to convert\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the axis is tz-naive.\n",
      "     |  \n",
      "     |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      "     |      Localize tz-naive TimeSeries to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to localize\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      "     |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      "     |            order\n",
      "     |          - bool-ndarray where True signifies a DST time, False designates\n",
      "     |            a non-DST time (note that this flag is only applicable for\n",
      "     |            ambiguous times)\n",
      "     |          - 'NaT' will return NaT where there are ambiguous times\n",
      "     |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      "     |            times\n",
      "     |      infer_dst : boolean, default False\n",
      "     |          .. deprecated:: 0.15.0\n",
      "     |             Attempt to infer fall dst-transition hours based on order\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the TimeSeries is tz-aware and tz is not None.\n",
      "     |  \n",
      "     |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is True and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is True, keep the original value. Where\n",
      "     |          False, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is False are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The where method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``where`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.mask`\n",
      "     |  \n",
      "     |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      "     |      Returns a cross-section (row(s) or column(s)) from the\n",
      "     |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : object\n",
      "     |          Some label contained in the index, or partially in a MultiIndex\n",
      "     |      axis : int, default 0\n",
      "     |          Axis to retrieve cross-section on\n",
      "     |      level : object, defaults to first n levels (n=1 or len(key))\n",
      "     |          In case of a key partially contained in a MultiIndex, indicate\n",
      "     |          which levels are used. Levels can be referred by label or position.\n",
      "     |      drop_level : boolean, default True\n",
      "     |          If False, returns object with same levels as self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |      a  4  5  2\n",
      "     |      b  4  0  9\n",
      "     |      c  9  7  3\n",
      "     |      >>> df.xs('a')\n",
      "     |      A    4\n",
      "     |      B    5\n",
      "     |      C    2\n",
      "     |      Name: a\n",
      "     |      >>> df.xs('C', axis=1)\n",
      "     |      a    2\n",
      "     |      b    9\n",
      "     |      c    3\n",
      "     |      Name: C\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                          A  B  C  D\n",
      "     |      first second third\n",
      "     |      bar   one    1      4  1  8  9\n",
      "     |            two    1      7  5  5  0\n",
      "     |      baz   one    1      6  6  8  0\n",
      "     |            three  2      5  3  5  3\n",
      "     |      >>> df.xs(('baz', 'three'))\n",
      "     |             A  B  C  D\n",
      "     |      third\n",
      "     |      2      5  3  5  3\n",
      "     |      >>> df.xs('one', level=1)\n",
      "     |                   A  B  C  D\n",
      "     |      first third\n",
      "     |      bar   1      4  1  8  9\n",
      "     |      baz   1      6  6  8  0\n",
      "     |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      "     |              A  B  C  D\n",
      "     |      second\n",
      "     |      three   5  3  5  3\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      xs : Series or DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      xs is only for getting, not setting values.\n",
      "     |      \n",
      "     |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      "     |      levels.  It is a superset of xs functionality, see\n",
      "     |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  at\n",
      "     |      Fast label-based scalar accessor\n",
      "     |      \n",
      "     |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  blocks\n",
      "     |      Internal property, property synonym for as_blocks()\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      Return the dtypes in this object.\n",
      "     |  \n",
      "     |  empty\n",
      "     |      True if NDFrame is entirely empty [no items], meaning any of the\n",
      "     |      axes are of length 0.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If NDFrame contains only NaNs, it is still not considered empty. See\n",
      "     |      the example below.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      "     |      \n",
      "     |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      "     |      >>> df_empty\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A]\n",
      "     |      Index: []\n",
      "     |      >>> df_empty.empty\n",
      "     |      True\n",
      "     |      \n",
      "     |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      "     |      will need to drop the NaNs to make the DataFrame empty:\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      "     |      >>> df\n",
      "     |          A\n",
      "     |      0 NaN\n",
      "     |      >>> df.empty\n",
      "     |      False\n",
      "     |      >>> df.dropna().empty\n",
      "     |      True\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.Series.dropna\n",
      "     |      pandas.DataFrame.dropna\n",
      "     |  \n",
      "     |  ftypes\n",
      "     |      Return the ftypes (indication of sparse/dense and dtype)\n",
      "     |      in this object.\n",
      "     |  \n",
      "     |  iat\n",
      "     |      Fast integer location scalar accessor.\n",
      "     |      \n",
      "     |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  iloc\n",
      "     |      Purely integer-location based indexing for selection by position.\n",
      "     |      \n",
      "     |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      "     |      ``length-1`` of the axis), but may also be used with a boolean\n",
      "     |      array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - An integer, e.g. ``5``.\n",
      "     |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      "     |      - A slice object with ints, e.g. ``1:7``.\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      "     |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      "     |      indexing (this conforms with python/numpy *slice* semantics).\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      "     |  \n",
      "     |  ix\n",
      "     |      A primarily label-location based indexer, with integer position\n",
      "     |      fallback.\n",
      "     |      \n",
      "     |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      "     |      primarily label based, but will fall back to integer positional\n",
      "     |      access unless the corresponding axis is of integer type.\n",
      "     |      \n",
      "     |      ``.ix`` is the most general indexer and will support any of the\n",
      "     |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      "     |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      "     |      with mixed positional and label based hierachical indexes.\n",
      "     |      \n",
      "     |      However, when an axis is integer based, ONLY label based access\n",
      "     |      and not positional access is supported. Thus, in such cases, it's\n",
      "     |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      "     |      \n",
      "     |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      "     |  \n",
      "     |  loc\n",
      "     |      Purely label-location based indexer for selection by label.\n",
      "     |      \n",
      "     |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      "     |      boolean array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      "     |        interpreted as a *label* of the index, and **never** as an\n",
      "     |        integer position along the index).\n",
      "     |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      "     |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      "     |        to usual python slices, **both** the start and the stop are included!).\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Label <indexing.label>`\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Number of axes / array dimensions\n",
      "     |  \n",
      "     |  size\n",
      "     |      number of elements in the NDFrame\n",
      "     |  \n",
      "     |  values\n",
      "     |      Numpy representation of NDFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The dtype will be a lower-common-denominator dtype (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen. Use this\n",
      "     |      with care if you are not dealing with the blocks.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      "     |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      "     |      will result in a flot64 dtype.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  is_copy = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for a object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __bytes__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Invoked by bytes(obj) in py3 only.\n",
      "     |      Yields a bytestring in both py2/py3.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return a string representation for a particular Object\n",
      "     |      \n",
      "     |      Invoked by str(df) in both py2/py3.\n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion\n",
      "     |      Only provide 'public' methods\n",
      "    \n",
      "    class SubclassedSeries(pandas.core.series.Series)\n",
      "     |  One-dimensional ndarray with axis labels (including time series).\n",
      "     |  \n",
      "     |  Labels need not be unique but must be a hashable type. The object\n",
      "     |  supports both integer- and label-based indexing and provides a host of\n",
      "     |  methods for performing operations involving the index. Statistical\n",
      "     |  methods from ndarray have been overridden to automatically exclude\n",
      "     |  missing data (currently represented as NaN).\n",
      "     |  \n",
      "     |  Operations between Series (+, -, /, *, **) align values based on their\n",
      "     |  associated index values-- they need not be the same length. The result\n",
      "     |  index will be the sorted union of the two indexes.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array-like, dict, or scalar value\n",
      "     |      Contains data stored in Series\n",
      "     |  index : array-like or Index (1d)\n",
      "     |      Values must be hashable and have the same length as `data`.\n",
      "     |      Non-unique index values are allowed. Will default to\n",
      "     |      RangeIndex(len(data)) if not provided. If both a dict and index\n",
      "     |      sequence are used, the index will override the keys found in the\n",
      "     |      dict.\n",
      "     |  dtype : numpy.dtype or None\n",
      "     |      If None, dtype will be inferred\n",
      "     |  copy : boolean, default False\n",
      "     |      Copy input data\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SubclassedSeries\n",
      "     |      pandas.core.series.Series\n",
      "     |      pandas.core.base.IndexOpsMixin\n",
      "     |      pandas.core.generic.NDFrame\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.base.StringMixin\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  __add__ = wrapper(left, right, name='__add__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CCBB70>)\n",
      "     |  \n",
      "     |  __and__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __array__(self, result=None)\n",
      "     |      the array interface, return my values\n",
      "     |  \n",
      "     |  __array_prepare__(self, result, context=None)\n",
      "     |      Gets called prior to a ufunc\n",
      "     |  \n",
      "     |  __array_wrap__(self, result, context=None)\n",
      "     |      Gets called after a ufunc\n",
      "     |  \n",
      "     |  __div__ = wrapper(left, right, name='__truediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE32F0>)\n",
      "     |  \n",
      "     |  __divmod__ = wrapper(left, right, name='__divmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE8510>)\n",
      "     |  \n",
      "     |  __eq__ = wrapper(self, other, axis=None)\n",
      "     |  \n",
      "     |  __float__ = wrapper(self)\n",
      "     |  \n",
      "     |  __floordiv__ = wrapper(left, right, name='__floordiv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3488>)\n",
      "     |  \n",
      "     |  __ge__ = wrapper(self, other, axis=None)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __gt__ = wrapper(self, other, axis=None)\n",
      "     |  \n",
      "     |  __iadd__ = f(self, other)\n",
      "     |  \n",
      "     |  __iand__ = f(self, other)\n",
      "     |  \n",
      "     |  __ifloordiv__ = f(self, other)\n",
      "     |  \n",
      "     |  __imod__ = f(self, other)\n",
      "     |  \n",
      "     |  __imul__ = f(self, other)\n",
      "     |  \n",
      "     |  __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __int__ = wrapper(self)\n",
      "     |  \n",
      "     |  __ior__ = f(self, other)\n",
      "     |  \n",
      "     |  __ipow__ = f(self, other)\n",
      "     |  \n",
      "     |  __isub__ = f(self, other)\n",
      "     |  \n",
      "     |  __itruediv__ = f(self, other)\n",
      "     |  \n",
      "     |  __ixor__ = f(self, other)\n",
      "     |  \n",
      "     |  __le__ = wrapper(self, other, axis=None)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      return the length of the Series\n",
      "     |  \n",
      "     |  __long__ = wrapper(self)\n",
      "     |  \n",
      "     |  __lt__ = wrapper(self, other, axis=None)\n",
      "     |  \n",
      "     |  __mod__ = wrapper(left, right, name='__mod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3620>)\n",
      "     |  \n",
      "     |  __mul__ = wrapper(left, right, name='__mul__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3158>)\n",
      "     |  \n",
      "     |  __ne__ = wrapper(self, other, axis=None)\n",
      "     |  \n",
      "     |  __or__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __pow__ = wrapper(left, right, name='__pow__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE37B8>)\n",
      "     |  \n",
      "     |  __radd__ = wrapper(left, right, name='__radd__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CCBD90>)\n",
      "     |  \n",
      "     |  __rand__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __rdiv__ = wrapper(left, right, name='__rtruediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3D90>)\n",
      "     |  \n",
      "     |  __rfloordiv__ = wrapper(left, right, name='__rfloordiv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE6048>)\n",
      "     |  \n",
      "     |  __rmod__ = wrapper(left, right, name='__rmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE6488>)\n",
      "     |  \n",
      "     |  __rmul__ = wrapper(left, right, name='__rmul__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3950>)\n",
      "     |  \n",
      "     |  __ror__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __rpow__ = wrapper(left, right, name='__rpow__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE6268>)\n",
      "     |  \n",
      "     |  __rsub__ = wrapper(left, right, name='__rsub__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3B70>)\n",
      "     |  \n",
      "     |  __rtruediv__ = wrapper(left, right, name='__rtruediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE3D90>)\n",
      "     |  \n",
      "     |  __rxor__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  __sub__ = wrapper(left, right, name='__sub__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CCBF28>)\n",
      "     |  \n",
      "     |  __truediv__ = wrapper(left, right, name='__truediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021ED9CE32F0>)\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Return a string representation for a particular DataFrame\n",
      "     |      \n",
      "     |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      "     |      py2/py3.\n",
      "     |  \n",
      "     |  __xor__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  add(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Addition of series and other, element-wise (binary operator `add`).\n",
      "     |      \n",
      "     |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.radd\n",
      "     |  \n",
      "     |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a Series or when passed to Series.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = Series(np.random.randn(10))\n",
      "     |      \n",
      "     |      >>> s.agg('min')\n",
      "     |      -1.3018049988556679\n",
      "     |      \n",
      "     |      >>> s.agg(['min', 'max'])\n",
      "     |      min   -1.301805\n",
      "     |      max    1.127688\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.Series.apply\n",
      "     |      pandas.Series.transform\n",
      "     |  \n",
      "     |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a Series or when passed to Series.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = Series(np.random.randn(10))\n",
      "     |      \n",
      "     |      >>> s.agg('min')\n",
      "     |      -1.3018049988556679\n",
      "     |      \n",
      "     |      >>> s.agg(['min', 'max'])\n",
      "     |      min   -1.301805\n",
      "     |      max    1.127688\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.Series.apply\n",
      "     |      pandas.Series.transform\n",
      "     |  \n",
      "     |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      "     |      Align two objects on their axes with the\n",
      "     |      specified join method for each axis Index\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series\n",
      "     |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      "     |      axis : allowed axis of the other object, default None\n",
      "     |          Align on index (0), columns (1), or both (None)\n",
      "     |      level : int or level name, default None\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      copy : boolean, default True\n",
      "     |          Always returns new objects. If copy=False and no reindexing is\n",
      "     |          required then original objects are returned.\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      method : str, default None\n",
      "     |      limit : int, default None\n",
      "     |      fill_axis : {0, 'index'}, default 0\n",
      "     |          Filling axis, method and limit\n",
      "     |      broadcast_axis : {0, 'index'}, default None\n",
      "     |          Broadcast values along this axis, if aligning two objects of\n",
      "     |          different dimensions\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      (left, right) : (Series, type of other)\n",
      "     |          Aligned objects\n",
      "     |  \n",
      "     |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether all elements are True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      all : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether any element is True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      any : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      "     |      Concatenate two or more Series.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      to_append : Series or list/tuple of Series\n",
      "     |      ignore_index : boolean, default False\n",
      "     |          If True, do not use the index labels.\n",
      "     |      \n",
      "     |          .. versionadded: 0.19.0\n",
      "     |      \n",
      "     |      verify_integrity : boolean, default False\n",
      "     |          If True, raise Exception on creating index with duplicates\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Iteratively appending to a Series can be more computationally intensive\n",
      "     |      than a single concatenate. A better solution is to append values to a\n",
      "     |      list and then concatenate the list with the original Series all at\n",
      "     |      once.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.concat : General function to concatenate DataFrame, Series\n",
      "     |          or Panel objects\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      appended : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s1 = pd.Series([1, 2, 3])\n",
      "     |      >>> s2 = pd.Series([4, 5, 6])\n",
      "     |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      "     |      >>> s1.append(s2)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      0    4\n",
      "     |      1    5\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s1.append(s3)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      3    4\n",
      "     |      4    5\n",
      "     |      5    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      With `ignore_index` set to True:\n",
      "     |      \n",
      "     |      >>> s1.append(s2, ignore_index=True)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      3    4\n",
      "     |      4    5\n",
      "     |      5    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      With `verify_integrity` set to True:\n",
      "     |      \n",
      "     |      >>> s1.append(s2, verify_integrity=True)\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      "     |  \n",
      "     |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      "     |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      "     |      that applies to the entire Series) or a Python function that only works\n",
      "     |      on single values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |      convert_dtype : boolean, default True\n",
      "     |          Try to find better dtype for elementwise function results. If\n",
      "     |          False, leave as dtype=object\n",
      "     |      args : tuple\n",
      "     |          Positional arguments to pass to function in addition to the value\n",
      "     |      Additional keyword arguments will be passed as keywords to the function\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series or DataFrame if func returns a Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.map: For element-wise operations\n",
      "     |      Series.agg: only perform aggregating type operations\n",
      "     |      Series.transform: only perform transformating type operations\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Create a series with typical summer temperatures for each city.\n",
      "     |      \n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      "     |      ... 'New York','Helsinki'])\n",
      "     |      >>> series\n",
      "     |      London      20\n",
      "     |      New York    21\n",
      "     |      Helsinki    12\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Square the values by defining a function and passing it as an\n",
      "     |      argument to ``apply()``.\n",
      "     |      \n",
      "     |      >>> def square(x):\n",
      "     |      ...     return x**2\n",
      "     |      >>> series.apply(square)\n",
      "     |      London      400\n",
      "     |      New York    441\n",
      "     |      Helsinki    144\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Square the values by passing an anonymous function as an\n",
      "     |      argument to ``apply()``.\n",
      "     |      \n",
      "     |      >>> series.apply(lambda x: x**2)\n",
      "     |      London      400\n",
      "     |      New York    441\n",
      "     |      Helsinki    144\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Define a custom function that needs additional positional\n",
      "     |      arguments and pass these additional arguments using the\n",
      "     |      ``args`` keyword.\n",
      "     |      \n",
      "     |      >>> def subtract_custom_value(x, custom_value):\n",
      "     |      ...     return x-custom_value\n",
      "     |      \n",
      "     |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      "     |      London      15\n",
      "     |      New York    16\n",
      "     |      Helsinki     7\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Define a custom function that takes keyword arguments\n",
      "     |      and pass these arguments to ``apply``.\n",
      "     |      \n",
      "     |      >>> def add_custom_values(x, **kwargs):\n",
      "     |      ...     for month in kwargs:\n",
      "     |      ...         x+=kwargs[month]\n",
      "     |      ...         return x\n",
      "     |      \n",
      "     |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      "     |      London      95\n",
      "     |      New York    96\n",
      "     |      Helsinki    87\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Use a function from the Numpy library.\n",
      "     |      \n",
      "     |      >>> series.apply(np.log)\n",
      "     |      London      2.995732\n",
      "     |      New York    3.044522\n",
      "     |      Helsinki    2.484907\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  argmax = wrapper(*args, **kwargs)\n",
      "     |  \n",
      "     |  argmin = wrapper(*args, **kwargs)\n",
      "     |  \n",
      "     |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      "     |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      "     |      and places the result in the same locations as the non-NA values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int (can only be zero)\n",
      "     |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      "     |          Choice of sorting algorithm. See np.sort for more\n",
      "     |          information. 'mergesort' is the only stable algorithm\n",
      "     |      order : ignored\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      argsorted : Series, with -1 indicated where nan values are present\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.argsort\n",
      "     |  \n",
      "     |  autocorr(self, lag=1)\n",
      "     |      Lag-N autocorrelation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lag : int, default 1\n",
      "     |          Number of lags to apply before performing autocorrelation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      autocorr : float\n",
      "     |  \n",
      "     |  between(self, left, right, inclusive=True)\n",
      "     |      Return boolean Series equivalent to left <= series <= right. NA values\n",
      "     |      will be treated as False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      left : scalar\n",
      "     |          Left boundary\n",
      "     |      right : scalar\n",
      "     |          Right boundary\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_between : Series\n",
      "     |  \n",
      "     |  combine(self, other, func, fill_value=nan)\n",
      "     |      Perform elementwise binary operation on two Series using given function\n",
      "     |      with optional fill value when an index is missing from one Series or\n",
      "     |      the other\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      func : function\n",
      "     |          Function that takes two scalars as inputs and return a scalar\n",
      "     |      fill_value : scalar value\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s1 = Series([1, 2])\n",
      "     |      >>> s2 = Series([0, 3])\n",
      "     |      >>> s1.combine(s2, lambda x1, x2: x1 if x1 < x2 else x2)\n",
      "     |      0    0\n",
      "     |      1    2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.combine_first : Combine Series values, choosing the calling\n",
      "     |          Series's values first\n",
      "     |  \n",
      "     |  combine_first(self, other)\n",
      "     |      Combine Series values, choosing the calling Series's values\n",
      "     |      first. Result index will be the union of the two indexes\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      combined : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s1 = pd.Series([1, np.nan])\n",
      "     |      >>> s2 = pd.Series([3, 4])\n",
      "     |      >>> s1.combine_first(s2)\n",
      "     |      0    1.0\n",
      "     |      1    4.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.combine : Perform elementwise operation on two Series\n",
      "     |          using a given function\n",
      "     |  \n",
      "     |  compound(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the compound percentage of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      compounded : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  compress(self, condition, *args, **kwargs)\n",
      "     |      Return selected slices of an array along given axis as a Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.compress\n",
      "     |  \n",
      "     |  corr(self, other, method='pearson', min_periods=None)\n",
      "     |      Compute correlation with `other` Series, excluding missing values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      method : {'pearson', 'kendall', 'spearman'}\n",
      "     |          * pearson : standard correlation coefficient\n",
      "     |          * kendall : Kendall Tau correlation coefficient\n",
      "     |          * spearman : Spearman rank correlation\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations needed to have a valid result\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      correlation : float\n",
      "     |  \n",
      "     |  count(self, level=None)\n",
      "     |      Return number of non-NA/null observations in the Series\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a smaller Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nobs : int or Series (if level specified)\n",
      "     |  \n",
      "     |  cov(self, other, min_periods=None)\n",
      "     |      Compute covariance with Series, excluding missing values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations needed to have a valid result\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      covariance : float\n",
      "     |      \n",
      "     |      Normalized by N-1 (unbiased estimator).\n",
      "     |  \n",
      "     |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative max over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummax : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.max : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative minimum over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummin : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.min : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative product over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumprod : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.prod : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative sum over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumsum : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.sum : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  diff(self, periods=1)\n",
      "     |      1st discrete difference of object\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming difference\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      diffed : Series\n",
      "     |  \n",
      "     |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rtruediv\n",
      "     |  \n",
      "     |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rtruediv\n",
      "     |  \n",
      "     |  dot(self, other)\n",
      "     |      Matrix multiplication with DataFrame or inner-product with Series\n",
      "     |      objects\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dot_product : scalar or Series\n",
      "     |  \n",
      "     |  drop_duplicates(self, keep='first', inplace=False)\n",
      "     |      Return Series with duplicate values removed\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      "     |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      "     |          - False : Drop all duplicates.\n",
      "     |      inplace : boolean, default False\n",
      "     |      If True, performs operation inplace and returns None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      deduplicated : Series\n",
      "     |  \n",
      "     |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      "     |      Return Series without null values\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : Series\n",
      "     |      inplace : boolean, default False\n",
      "     |          Do operation in place.\n",
      "     |  \n",
      "     |  duplicated(self, keep='first')\n",
      "     |      Return boolean Series denoting duplicate values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Mark duplicates as ``True`` except for the first\n",
      "     |            occurrence.\n",
      "     |          - ``last`` : Mark duplicates as ``True`` except for the last\n",
      "     |            occurrence.\n",
      "     |          - False : Mark all duplicates as ``True``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      duplicated : Series\n",
      "     |  \n",
      "     |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      "     |      \n",
      "     |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, freq=None, adjust=True, ignore_na=False, axis=0)\n",
      "     |      Provides exponential weighted functions\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      com : float, optional\n",
      "     |          Specify decay in terms of center of mass,\n",
      "     |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      "     |      span : float, optional\n",
      "     |          Specify decay in terms of span,\n",
      "     |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      "     |      halflife : float, optional\n",
      "     |          Specify decay in terms of half-life,\n",
      "     |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      "     |      alpha : float, optional\n",
      "     |          Specify smoothing factor :math:`\\alpha` directly,\n",
      "     |          :math:`0 < \\alpha \\leq 1`\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      min_periods : int, default 0\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : None or string alias / date offset object, default=None\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform to before computing statistic\n",
      "     |      adjust : boolean, default True\n",
      "     |          Divide by decaying adjustment factor in beginning periods to account\n",
      "     |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      "     |      ignore_na : boolean, default False\n",
      "     |          Ignore missing values when calculating weights;\n",
      "     |          specify True to reproduce pre-0.15.0 behavior\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.ewm(com=0.5).mean()\n",
      "     |                B\n",
      "     |      0  0.000000\n",
      "     |      1  0.750000\n",
      "     |      2  1.615385\n",
      "     |      3  1.615385\n",
      "     |      4  3.670213\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      "     |      Allowed values and relationship between the parameters are specified in the\n",
      "     |      parameter descriptions above; see the link at the end of this section for\n",
      "     |      a detailed explanation.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      When adjust is True (default), weighted averages are calculated using\n",
      "     |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      "     |      \n",
      "     |      When adjust is False, weighted averages are calculated recursively as:\n",
      "     |         weighted_average[0] = arg[0];\n",
      "     |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      "     |      \n",
      "     |      When ignore_na is False (default), weights are based on absolute positions.\n",
      "     |      For example, the weights of x and y used in calculating the final weighted\n",
      "     |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      "     |      (1-alpha)**2 and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      "     |      on relative positions. For example, the weights of x and y used in\n",
      "     |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      "     |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      More details can be found at\n",
      "     |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      "     |  \n",
      "     |  expanding(self, min_periods=1, freq=None, center=False, axis=0)\n",
      "     |      Provides expanding transformations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.expanding(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  3.0\n",
      "     |      4  7.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |  \n",
      "     |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      "     |      Fill NA/NaN values using the specified method\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar, dict, Series, or DataFrame\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a\n",
      "     |          dict/Series/DataFrame of values specifying which value to use for\n",
      "     |          each index (for a Series) or column (for a DataFrame). (values not\n",
      "     |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      "     |          be a list.\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use NEXT valid observation to fill gap\n",
      "     |      axis : {0, 'index'}\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, fill in place. Note: this will modify any\n",
      "     |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      "     |          DataFrame).\n",
      "     |      limit : int, default None\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled. Must be greater than 0 if not None.\n",
      "     |      downcast : dict, default is None\n",
      "     |          a dict of item->dtype of what to downcast if possible,\n",
      "     |          or the string 'infer' which will try to downcast to an appropriate\n",
      "     |          equal type (e.g. float64 to int64 if possible)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, asfreq\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "     |      ...                    [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      "     |      ...                    [np.nan, 3, np.nan, 4]],\n",
      "     |      ...                    columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      3  NaN  3.0 NaN  4\n",
      "     |      \n",
      "     |      Replace all NaN elements with 0s.\n",
      "     |      \n",
      "     |      >>> df.fillna(0)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 0.0 0\n",
      "     |      1   3.0 4.0 0.0 1\n",
      "     |      2   0.0 0.0 0.0 5\n",
      "     |      3   0.0 3.0 0.0 4\n",
      "     |      \n",
      "     |      We can also propagate non-null values forward or backward.\n",
      "     |      \n",
      "     |      >>> df.fillna(method='ffill')\n",
      "     |          A   B   C   D\n",
      "     |      0   NaN 2.0 NaN 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   3.0 4.0 NaN 5\n",
      "     |      3   3.0 3.0 NaN 4\n",
      "     |      \n",
      "     |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "     |      2, and 3 respectively.\n",
      "     |      \n",
      "     |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "     |      >>> df.fillna(value=values)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 2.0 1\n",
      "     |      2   0.0 1.0 2.0 5\n",
      "     |      3   0.0 3.0 2.0 4\n",
      "     |      \n",
      "     |      Only replace the first NaN element.\n",
      "     |      \n",
      "     |      >>> df.fillna(value=values, limit=1)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   NaN 1.0 NaN 5\n",
      "     |      3   NaN 3.0 NaN 4\n",
      "     |  \n",
      "     |  first_valid_index(self)\n",
      "     |      Return index for first non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rfloordiv\n",
      "     |  \n",
      "     |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      "     |      \n",
      "     |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  get_value(self, label, takeable=False)\n",
      "     |      Quickly retrieve single value at passed index label\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : label\n",
      "     |      takeable : interpret the index as indexers, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar value\n",
      "     |  \n",
      "     |  get_values(self)\n",
      "     |      same as values (but handles sparseness conversions); is a view\n",
      "     |  \n",
      "     |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      "     |      \n",
      "     |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      "     |      Draw histogram of the input series using matplotlib\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : object, optional\n",
      "     |          If passed, then used to form histograms for separate groups\n",
      "     |      ax : matplotlib axis object\n",
      "     |          If not passed, uses gca()\n",
      "     |      grid : boolean, default True\n",
      "     |          Whether to show axis grid lines\n",
      "     |      xlabelsize : int, default None\n",
      "     |          If specified changes the x-axis label size\n",
      "     |      xrot : float, default None\n",
      "     |          rotation of x axis labels\n",
      "     |      ylabelsize : int, default None\n",
      "     |          If specified changes the y-axis label size\n",
      "     |      yrot : float, default None\n",
      "     |          rotation of y axis labels\n",
      "     |      figsize : tuple, default None\n",
      "     |          figure size in inches by default\n",
      "     |      bins: integer, default 10\n",
      "     |          Number of histogram bins to be used\n",
      "     |      kwds : keywords\n",
      "     |          To be passed to the actual plotting function\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See matplotlib documentation online for more on this\n",
      "     |  \n",
      "     |  idxmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Index *label* of the first occurrence of maximum of values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If the entire Series is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the Series is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmax : Index of maximum of values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the Series version of ``ndarray.argmax``. This method\n",
      "     |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      "     |      the position. To get the position, use ``series.values.argmax()``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.idxmax\n",
      "     |      numpy.ndarray.argmax\n",
      "     |  \n",
      "     |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Index *label* of the first occurrence of minimum of values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If the entire Series is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the Series is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmin : Index of minimum of values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the Series version of ``ndarray.argmin``. This method\n",
      "     |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      "     |      the position. To get the position, use ``series.values.argmin()``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.idxmin\n",
      "     |      numpy.ndarray.argmin\n",
      "     |  \n",
      "     |  isin(self, values)\n",
      "     |      Return a boolean :class:`~pandas.Series` showing whether each element\n",
      "     |      in the :class:`~pandas.Series` is exactly contained in the passed\n",
      "     |      sequence of ``values``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : set or list-like\n",
      "     |          The sequence of values to test. Passing in a single string will\n",
      "     |          raise a ``TypeError``. Instead, turn a single string into a\n",
      "     |          ``list`` of one element.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |      \n",
      "     |          Support for values as a set\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      isin : Series (bool dtype)\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |        * If ``values`` is a string\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.isin\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = pd.Series(list('abc'))\n",
      "     |      >>> s.isin(['a', 'c', 'e'])\n",
      "     |      0     True\n",
      "     |      1    False\n",
      "     |      2     True\n",
      "     |      dtype: bool\n",
      "     |      \n",
      "     |      Passing a single string as ``s.isin('a')`` will raise an error. Use\n",
      "     |      a list of one element instead:\n",
      "     |      \n",
      "     |      >>> s.isin(['a'])\n",
      "     |      0     True\n",
      "     |      1    False\n",
      "     |      2    False\n",
      "     |      dtype: bool\n",
      "     |  \n",
      "     |  isna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.notna : boolean inverse of isna\n",
      "     |      Series.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  isnull(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.notna : boolean inverse of isna\n",
      "     |      Series.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  items = iteritems(self)\n",
      "     |      Lazily iterate over (index, value) tuples\n",
      "     |  \n",
      "     |  iteritems(self)\n",
      "     |      Lazily iterate over (index, value) tuples\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      Alias for index\n",
      "     |  \n",
      "     |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  last_valid_index(self)\n",
      "     |      Return index for last non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  le(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      "     |      \n",
      "     |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Less than of series and other, element-wise (binary operator `lt`).\n",
      "     |      \n",
      "     |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  mad(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the mean absolute deviation of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mad : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  map(self, arg, na_action=None)\n",
      "     |      Map values of Series using input correspondence (which can be\n",
      "     |      a dict, Series, or function)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg : function, dict, or Series\n",
      "     |      na_action : {None, 'ignore'}\n",
      "     |          If 'ignore', propagate NA values, without passing them to the\n",
      "     |          mapping function\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series\n",
      "     |          same index as caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Map inputs to outputs (both of type `Series`)\n",
      "     |      \n",
      "     |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      "     |      >>> x\n",
      "     |      one      1\n",
      "     |      two      2\n",
      "     |      three    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      "     |      >>> y\n",
      "     |      1    foo\n",
      "     |      2    bar\n",
      "     |      3    baz\n",
      "     |      \n",
      "     |      >>> x.map(y)\n",
      "     |      one   foo\n",
      "     |      two   bar\n",
      "     |      three baz\n",
      "     |      \n",
      "     |      If `arg` is a dictionary, return a new Series with values converted\n",
      "     |      according to the dictionary's mapping:\n",
      "     |      \n",
      "     |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      "     |      \n",
      "     |      >>> x.map(z)\n",
      "     |      one   A\n",
      "     |      two   B\n",
      "     |      three C\n",
      "     |      \n",
      "     |      Use na_action to control whether NA values are affected by the mapping\n",
      "     |      function.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      "     |      \n",
      "     |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      "     |      0    this is a string 1.0\n",
      "     |      1    this is a string 2.0\n",
      "     |      2    this is a string 3.0\n",
      "     |      3    this is a string nan\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      "     |      0    this is a string 1.0\n",
      "     |      1    this is a string 2.0\n",
      "     |      2    this is a string 3.0\n",
      "     |      3                     NaN\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.apply: For applying more complex functions on a Series\n",
      "     |      DataFrame.apply: Apply a function row-/column-wise\n",
      "     |      DataFrame.applymap: Apply a function elementwise on a whole DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When `arg` is a dictionary, values in Series that are not in the\n",
      "     |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      "     |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      "     |      provides a method for default values), then this default is used\n",
      "     |      rather than ``NaN``:\n",
      "     |      \n",
      "     |      >>> from collections import Counter\n",
      "     |      >>> counter = Counter()\n",
      "     |      >>> counter['bar'] += 1\n",
      "     |      >>> y.map(counter)\n",
      "     |      1    0\n",
      "     |      2    1\n",
      "     |      3    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the maximum of the values in the object.\n",
      "     |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      max : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the mean of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the median of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  memory_usage(self, index=True, deep=False)\n",
      "     |      Memory usage of the Series\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : bool\n",
      "     |          Specifies whether to include memory usage of Series index\n",
      "     |      deep : bool\n",
      "     |          Introspect the data deeply, interrogate\n",
      "     |          `object` dtypes for system-level memory consumption\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar bytes of memory consumed\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Memory usage does not include memory consumed by elements that\n",
      "     |      are not components of the array if deep=False\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.nbytes\n",
      "     |  \n",
      "     |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the minimum of the values in the object.\n",
      "     |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      min : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      "     |      \n",
      "     |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rmod\n",
      "     |  \n",
      "     |  mode(self)\n",
      "     |      Return the mode(s) of the dataset.\n",
      "     |      \n",
      "     |      Always returns Series even if only one value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      modes : Series (sorted)\n",
      "     |  \n",
      "     |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rmul\n",
      "     |  \n",
      "     |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rmul\n",
      "     |  \n",
      "     |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      "     |      \n",
      "     |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  nlargest(self, n=5, keep='first')\n",
      "     |      Return the largest `n` elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Return this many descending sorted values\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      top_n : Series\n",
      "     |          The n largest values in the Series, in sorted order\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      "     |      relative to the size of the ``Series`` object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.nsmallest\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> s = pd.Series(np.random.randn(10**6))\n",
      "     |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      "     |      219921    4.644710\n",
      "     |      82124     4.608745\n",
      "     |      421689    4.564644\n",
      "     |      425277    4.447014\n",
      "     |      718691    4.414137\n",
      "     |      43154     4.403520\n",
      "     |      283187    4.313922\n",
      "     |      595519    4.273635\n",
      "     |      503969    4.250236\n",
      "     |      121637    4.240952\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  nonzero(self)\n",
      "     |      Return the indices of the elements that are non-zero\n",
      "     |      \n",
      "     |      This method is equivalent to calling `numpy.nonzero` on the\n",
      "     |      series data. For compatability with NumPy, the return value is\n",
      "     |      the same (a tuple with an array of indices for each dimension),\n",
      "     |      but it will always be a one-item tuple because series only have\n",
      "     |      one dimension.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([0, 3, 0, 4])\n",
      "     |      >>> s.nonzero()\n",
      "     |      (array([1, 3]),)\n",
      "     |      >>> s.iloc[s.nonzero()[0]]\n",
      "     |      1    3\n",
      "     |      3    4\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.nonzero\n",
      "     |  \n",
      "     |  notna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.isna : boolean inverse of notna\n",
      "     |      Series.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  notnull(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.isna : boolean inverse of notna\n",
      "     |      Series.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  nsmallest(self, n=5, keep='first')\n",
      "     |      Return the smallest `n` elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Return this many ascending sorted values\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bottom_n : Series\n",
      "     |          The n smallest values in the Series, in sorted order\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      "     |      the size of the ``Series`` object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.nlargest\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> s = pd.Series(np.random.randn(10**6))\n",
      "     |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      "     |      288532   -4.954580\n",
      "     |      732345   -4.835960\n",
      "     |      64803    -4.812550\n",
      "     |      446457   -4.609998\n",
      "     |      501225   -4.483945\n",
      "     |      669476   -4.472935\n",
      "     |      973615   -4.401699\n",
      "     |      621279   -4.355126\n",
      "     |      773916   -4.347355\n",
      "     |      359919   -4.331927\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      "     |      \n",
      "     |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rpow\n",
      "     |  \n",
      "     |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : scalar or Series (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : scalar or Series (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Returns the difference between the maximum value and the\n",
      "     |                  minimum value in the object. This is the equivalent of the\n",
      "     |                  ``numpy.ndarray`` method ``ptp``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ptp : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  put(self, *args, **kwargs)\n",
      "     |      Applies the `put` method to its `values` attribute\n",
      "     |      if it has one.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.put\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, interpolation='linear')\n",
      "     |      Return value at the given quantile, a la numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          0 <= q <= 1, the quantile(s) to compute\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |          This optional parameter specifies the interpolation method to use,\n",
      "     |          when the desired quantile lies between two data points `i` and `j`:\n",
      "     |      \n",
      "     |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      "     |                fractional part of the index surrounded by `i` and `j`.\n",
      "     |              * lower: `i`.\n",
      "     |              * higher: `j`.\n",
      "     |              * nearest: `i` or `j` whichever is nearest.\n",
      "     |              * midpoint: (`i` + `j`) / 2.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      quantile : float or Series\n",
      "     |          if ``q`` is an array, a Series will be returned where the\n",
      "     |          index is ``q`` and the values are the quantiles.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = Series([1, 2, 3, 4])\n",
      "     |      >>> s.quantile(.5)\n",
      "     |      2.5\n",
      "     |      >>> s.quantile([.25, .5, .75])\n",
      "     |      0.25    1.75\n",
      "     |      0.50    2.50\n",
      "     |      0.75    3.25\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Addition of series and other, element-wise (binary operator `radd`).\n",
      "     |      \n",
      "     |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.add\n",
      "     |  \n",
      "     |  ravel(self, order='C')\n",
      "     |      Return the flattened underlying data as an ndarray\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.ravel\n",
      "     |  \n",
      "     |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.truediv\n",
      "     |  \n",
      "     |  reindex(self, index=None, **kwargs)\n",
      "     |      Conform Series to new index with optional filling logic, placing\n",
      "     |      NA/NaN in locations having no value in the previous index. A new object\n",
      "     |      is produced unless the new index is equivalent to the current one and\n",
      "     |      copy=False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      index : array-like, optional (should be specified using keywords)\n",
      "     |          New labels / index to conform to. Preferably an Index object to\n",
      "     |          avoid duplicating data\n",
      "     |      \n",
      "     |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "     |          method to use for filling holes in reindexed DataFrame.\n",
      "     |          Please note: this is only  applicable to DataFrames/Series with a\n",
      "     |          monotonically increasing/decreasing index.\n",
      "     |      \n",
      "     |          * default: don't fill gaps\n",
      "     |          * pad / ffill: propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * backfill / bfill: use next valid observation to fill gap\n",
      "     |          * nearest: use nearest valid observations to fill gap\n",
      "     |      \n",
      "     |      copy : boolean, default True\n",
      "     |          Return a new object, even if the passed indexes are the same\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive elements to forward or backward fill\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between original and new labels for inexact\n",
      "     |          matches. The values of the index at the matching locations most\n",
      "     |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "     |      \n",
      "     |          Tolerance may be a scalar value, which applies the same tolerance\n",
      "     |          to all values, or list-like, which applies variable tolerance per\n",
      "     |          element. List-like includes list, tuple, array, Series, and must be\n",
      "     |          the same size as the index and its dtype must exactly match the\n",
      "     |          index's type.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      ``DataFrame.reindex`` supports two calling conventions\n",
      "     |      \n",
      "     |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      "     |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      "     |      \n",
      "     |      We *highly* recommend using keyword arguments to clarify your\n",
      "     |      intent.\n",
      "     |      \n",
      "     |      Create a dataframe with some fictional data.\n",
      "     |      \n",
      "     |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...      'http_status': [200,200,404,404,301],\n",
      "     |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "     |      ...       index=index)\n",
      "     |      >>> df\n",
      "     |                 http_status  response_time\n",
      "     |      Firefox            200           0.04\n",
      "     |      Chrome             200           0.02\n",
      "     |      Safari             404           0.07\n",
      "     |      IE10               404           0.08\n",
      "     |      Konqueror          301           1.00\n",
      "     |      \n",
      "     |      Create a new index and reindex the dataframe. By default\n",
      "     |      values in the new index that do not have corresponding\n",
      "     |      records in the dataframe are assigned ``NaN``.\n",
      "     |      \n",
      "     |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "     |      ...             'Chrome']\n",
      "     |      >>> df.reindex(new_index)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari               404.0           0.07\n",
      "     |      Iceweasel              NaN            NaN\n",
      "     |      Comodo Dragon          NaN            NaN\n",
      "     |      IE10                 404.0           0.08\n",
      "     |      Chrome               200.0           0.02\n",
      "     |      \n",
      "     |      We can fill in the missing values by passing a value to\n",
      "     |      the keyword ``fill_value``. Because the index is not monotonically\n",
      "     |      increasing or decreasing, we cannot use arguments to the keyword\n",
      "     |      ``method`` to fill the ``NaN`` values.\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value=0)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari                 404           0.07\n",
      "     |      Iceweasel                0           0.00\n",
      "     |      Comodo Dragon            0           0.00\n",
      "     |      IE10                   404           0.08\n",
      "     |      Chrome                 200           0.02\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value='missing')\n",
      "     |                    http_status response_time\n",
      "     |      Safari                404          0.07\n",
      "     |      Iceweasel         missing       missing\n",
      "     |      Comodo Dragon     missing       missing\n",
      "     |      IE10                  404          0.08\n",
      "     |      Chrome                200          0.02\n",
      "     |      \n",
      "     |      We can also reindex the columns.\n",
      "     |      \n",
      "     |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      Or we can use \"axis-style\" keyword arguments\n",
      "     |      \n",
      "     |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      To further illustrate the filling functionality in\n",
      "     |      ``reindex``, we will create a dataframe with a\n",
      "     |      monotonically increasing index (for example, a sequence\n",
      "     |      of dates).\n",
      "     |      \n",
      "     |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "     |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "     |      ...                    index=date_index)\n",
      "     |      >>> df2\n",
      "     |                  prices\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      \n",
      "     |      Suppose we decide to expand the dataframe to cover a wider\n",
      "     |      date range.\n",
      "     |      \n",
      "     |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "     |      >>> df2.reindex(date_index2)\n",
      "     |                  prices\n",
      "     |      2009-12-29     NaN\n",
      "     |      2009-12-30     NaN\n",
      "     |      2009-12-31     NaN\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      The index entries that did not have a value in the original data frame\n",
      "     |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "     |      If desired, we can fill in the missing values using one of several\n",
      "     |      options.\n",
      "     |      \n",
      "     |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "     |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "     |      \n",
      "     |      >>> df2.reindex(date_index2, method='bfill')\n",
      "     |                  prices\n",
      "     |      2009-12-29     100\n",
      "     |      2009-12-30     100\n",
      "     |      2009-12-31     100\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      Please note that the ``NaN`` value present in the original dataframe\n",
      "     |      (at index value 2010-01-03) will not be filled by any of the\n",
      "     |      value propagation schemes. This is because filling while reindexing\n",
      "     |      does not look at dataframe values, but only compares the original and\n",
      "     |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "     |      in the original dataframe, use the ``fillna()`` method.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : Series\n",
      "     |  \n",
      "     |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      "     |      for compatibility with higher dims\n",
      "     |  \n",
      "     |  rename(self, index=None, **kwargs)\n",
      "     |      Alter Series index labels or name\n",
      "     |      \n",
      "     |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "     |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      Alternatively, change ``Series.name`` with a scalar value.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.rename>` for more.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : scalar, hashable sequence, dict-like or function, optional\n",
      "     |          dict-like or functions are transformations to apply to\n",
      "     |          the index.\n",
      "     |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      "     |          attribute.\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to return a new %(klass)s. If True then value of copy is\n",
      "     |          ignored.\n",
      "     |      level : int or level name, default None\n",
      "     |          In case of a MultiIndex, only rename labels in the specified\n",
      "     |          level.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : Series (new object)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.rename_axis\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      Name: my_name, dtype: int64\n",
      "     |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      4    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      "     |      0    1\n",
      "     |      3    2\n",
      "     |      5    3\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  reorder_levels(self, order)\n",
      "     |      Rearrange index levels using input order. May not drop or duplicate\n",
      "     |      levels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : list of int representing new level order.\n",
      "     |             (reference level by number or key)\n",
      "     |      axis : where to reorder levels\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      type of caller (new object)\n",
      "     |  \n",
      "     |  repeat(self, repeats, *args, **kwargs)\n",
      "     |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      "     |      for more information about the `repeats` argument.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.repeat\n",
      "     |  \n",
      "     |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      "     |      Analogous to the :meth:`pandas.DataFrame.reset_index` function, see\n",
      "     |      docstring there.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, str, tuple, or list, default None\n",
      "     |          Only remove the given levels from the index. Removes all levels by\n",
      "     |          default\n",
      "     |      drop : boolean, default False\n",
      "     |          Do not try to insert index into dataframe columns\n",
      "     |      name : object, default None\n",
      "     |          The name of the column corresponding to the Series values\n",
      "     |      inplace : boolean, default False\n",
      "     |          Modify the Series in place (do not create a new object)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      ----------\n",
      "     |      resetted : DataFrame, or Series if drop == True\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4], index=pd.Index(['a', 'b', 'c', 'd'],\n",
      "     |      ...                                            name = 'idx'))\n",
      "     |      >>> s.reset_index()\n",
      "     |         index  0\n",
      "     |      0      0  1\n",
      "     |      1      1  2\n",
      "     |      2      2  3\n",
      "     |      3      3  4\n",
      "     |      \n",
      "     |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo',\n",
      "     |      ...                     'foo', 'qux', 'qux']),\n",
      "     |      ...           np.array(['one', 'two', 'one', 'two', 'one', 'two',\n",
      "     |      ...                     'one', 'two'])]\n",
      "     |      >>> s2 = pd.Series(\n",
      "     |      ...     np.random.randn(8),\n",
      "     |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      "     |      ...                                     names=['a', 'b']))\n",
      "     |      >>> s2.reset_index(level='a')\n",
      "     |             a         0\n",
      "     |      b\n",
      "     |      one  bar -0.286320\n",
      "     |      two  bar -0.587934\n",
      "     |      one  baz  0.710491\n",
      "     |      two  baz -1.429006\n",
      "     |      one  foo  0.790700\n",
      "     |      two  foo  0.824863\n",
      "     |      one  qux -0.718963\n",
      "     |      two  qux -0.055028\n",
      "     |  \n",
      "     |  reshape(self, *args, **kwargs)\n",
      "     |      .. deprecated:: 0.19.0\n",
      "     |         Calling this method will raise an error. Please call\n",
      "     |         ``.values.reshape(...)`` instead.\n",
      "     |      \n",
      "     |      return an ndarray with the values shape\n",
      "     |      if the specified shape matches exactly the current shape, then\n",
      "     |      return self (for compat)\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.reshape\n",
      "     |  \n",
      "     |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.floordiv\n",
      "     |  \n",
      "     |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      "     |      \n",
      "     |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.mod\n",
      "     |  \n",
      "     |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      "     |      \n",
      "     |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.mul\n",
      "     |  \n",
      "     |  rolling(self, window, min_periods=None, freq=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      "     |      Provides rolling window calculations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      window : int, or offset\n",
      "     |          Size of the moving window. This is the number of observations used for\n",
      "     |          calculating the statistic. Each window will be a fixed size.\n",
      "     |      \n",
      "     |          If its an offset then this will be the time period of each window. Each\n",
      "     |          window will be a variable sized based on the observations included in\n",
      "     |          the time-period. This is only valid for datetimelike indexes. This is\n",
      "     |          new in 0.19.0\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA). For a window that is specified by an offset,\n",
      "     |          this will default to 1.\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      win_type : string, default None\n",
      "     |          Provide a window type. See the notes below.\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column on which to calculate\n",
      "     |          the rolling window, rather than the index\n",
      "     |      closed : string, default None\n",
      "     |          Make the interval closed on the 'right', 'left', 'both' or\n",
      "     |          'neither' endpoints.\n",
      "     |          For offset-based windows, it defaults to 'right'.\n",
      "     |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      "     |          for fixed windows.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window or Rolling sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |      >>> df\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, using the 'triang'\n",
      "     |      window type.\n",
      "     |      \n",
      "     |      >>> df.rolling(2, win_type='triang').sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  2.5\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, min_periods defaults\n",
      "     |      to the window length.\n",
      "     |      \n",
      "     |      >>> df.rolling(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Same as above, but explicity set the min_periods\n",
      "     |      \n",
      "     |      >>> df.rolling(2, min_periods=1).sum()\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  2.0\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      "     |      ....:                 index = [pd.Timestamp('20130101 09:00:00'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:02'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:03'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:05'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:06')])\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  2.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      \n",
      "     |      Contrasting to an integer rolling window, this will roll a variable\n",
      "     |      length window corresponding to the time period.\n",
      "     |      The default for min_periods is 1.\n",
      "     |      \n",
      "     |      >>> df.rolling('2s').sum()\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  3.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      To learn more about the offsets & frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      The recognized win_types are:\n",
      "     |      \n",
      "     |      * ``boxcar``\n",
      "     |      * ``triang``\n",
      "     |      * ``blackman``\n",
      "     |      * ``hamming``\n",
      "     |      * ``bartlett``\n",
      "     |      * ``parzen``\n",
      "     |      * ``bohman``\n",
      "     |      * ``blackmanharris``\n",
      "     |      * ``nuttall``\n",
      "     |      * ``barthann``\n",
      "     |      * ``kaiser`` (needs beta)\n",
      "     |      * ``gaussian`` (needs std)\n",
      "     |      * ``general_gaussian`` (needs power, width)\n",
      "     |      * ``slepian`` (needs width).\n",
      "     |      \n",
      "     |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      "     |      different window types see `scipy.signal window functions\n",
      "     |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      "     |  \n",
      "     |  round(self, decimals=0, *args, **kwargs)\n",
      "     |      Round each value in a Series to the given number of decimals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      decimals : int\n",
      "     |          Number of decimal places to round to (default: 0).\n",
      "     |          If decimals is negative, it specifies the number of\n",
      "     |          positions to the left of the decimal point.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around\n",
      "     |      DataFrame.round\n",
      "     |  \n",
      "     |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      "     |      \n",
      "     |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.pow\n",
      "     |  \n",
      "     |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      "     |      \n",
      "     |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.sub\n",
      "     |  \n",
      "     |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.truediv\n",
      "     |  \n",
      "     |  searchsorted(self, value, side='left', sorter=None)\n",
      "     |      Find indices where elements should be inserted to maintain order.\n",
      "     |      \n",
      "     |      Find the indices into a sorted Series `self` such that, if the\n",
      "     |      corresponding elements in `value` were inserted before the indices,\n",
      "     |      the order of `self` would be preserved.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : array_like\n",
      "     |          Values to insert into `self`.\n",
      "     |      side : {'left', 'right'}, optional\n",
      "     |          If 'left', the index of the first suitable location found is given.\n",
      "     |          If 'right', return the last such index.  If there is no suitable\n",
      "     |          index, return either 0 or N (where N is the length of `self`).\n",
      "     |      sorter : 1-D array_like, optional\n",
      "     |          Optional array of integer indices that sort `self` into ascending\n",
      "     |          order. They are typically the result of ``np.argsort``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      indices : array of ints\n",
      "     |          Array of insertion points with the same shape as `value`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Binary search is used to find the required insertion points.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> x = pd.Series([1, 2, 3])\n",
      "     |      >>> x\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> x.searchsorted(4)\n",
      "     |      array([3])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([0, 4])\n",
      "     |      array([0, 3])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([1, 3], side='left')\n",
      "     |      array([0, 2])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([1, 3], side='right')\n",
      "     |      array([1, 3])\n",
      "     |      \n",
      "     |      >>> x = pd.Categorical(['apple', 'bread', 'bread', 'cheese', 'milk' ])\n",
      "     |      [apple, bread, bread, cheese, milk]\n",
      "     |      Categories (4, object): [apple < bread < cheese < milk]\n",
      "     |      \n",
      "     |      >>> x.searchsorted('bread')\n",
      "     |      array([1])     # Note: an array, not a scalar\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread'])\n",
      "     |      array([1])\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread', 'eggs'])\n",
      "     |      array([1, 4])\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread', 'eggs'], side='right')\n",
      "     |      array([3, 4])    # eggs before milk\n",
      "     |  \n",
      "     |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased standard error of the mean over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sem : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  set_value(self, label, value, takeable=False)\n",
      "     |      Quickly set single value at passed label. If label is not contained, a\n",
      "     |      new object is created with the label placed at the end of the result\n",
      "     |      index\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label : object\n",
      "     |          Partial indexing with MultiIndex not allowed\n",
      "     |      value : object\n",
      "     |          Scalar value\n",
      "     |      takeable : interpret the index as indexers, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      series : Series\n",
      "     |          If label is contained, will be reference to calling Series,\n",
      "     |          otherwise a new object\n",
      "     |  \n",
      "     |  shift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift index by desired number of periods with an optional time freq\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, optional\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      "     |          See Notes.\n",
      "     |      axis : {0, 'index'}\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is specified then the index values are shifted but the data\n",
      "     |      is not realigned. That is, use freq if you would like to extend the\n",
      "     |      index when shifting and preserve the original data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : Series\n",
      "     |  \n",
      "     |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased skew over requested axis\n",
      "     |      Normalized by N-1\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      skew : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      "     |      Sort object by labels (along an axis)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : index to direct sorting\n",
      "     |      level : int or level name or list of ints or list of level names\n",
      "     |          if not None, sort on values in specified index level(s)\n",
      "     |      ascending : boolean, default True\n",
      "     |          Sort ascending vs. descending\n",
      "     |      inplace : bool, default False\n",
      "     |          if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      "     |           Not implemented for MultiIndex.\n",
      "     |      sort_remaining : bool, default True\n",
      "     |          if true and sorting by level and index is multilevel, sort by other\n",
      "     |          levels too (in order) after sorting by specified level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : Series\n",
      "     |  \n",
      "     |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      "     |      Sort by the values along either axis\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0, 'index'}, default 0\n",
      "     |          Axis to direct sorting\n",
      "     |      ascending : bool or list of bool, default True\n",
      "     |           Sort ascending vs. descending. Specify list for multiple sort\n",
      "     |           orders.  If this is a list of bools, must match the length of\n",
      "     |           the by.\n",
      "     |      inplace : bool, default False\n",
      "     |           if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...     'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "     |      ...     'col2' : [2, 1, 9, 8, 7, 4],\n",
      "     |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "     |      ... })\n",
      "     |      >>> df\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      \n",
      "     |      Sort by col1\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1'])\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort by multiple columns\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1', 'col2'])\n",
      "     |          col1 col2 col3\n",
      "     |      1   A    1    1\n",
      "     |      0   A    2    0\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort Descending\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False)\n",
      "     |          col1 col2 col3\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Putting NAs first\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "     |          col1 col2 col3\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |  \n",
      "     |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      "     |      DEPRECATED: use :meth:`Series.sort_index`\n",
      "     |      \n",
      "     |      Sort Series with MultiIndex by chosen level. Data will be\n",
      "     |      lexicographically sorted by the chosen level followed by the other\n",
      "     |      levels (in order)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int or level name, default None\n",
      "     |      ascending : bool, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted : Series\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.sort_index(level=...)\n",
      "     |  \n",
      "     |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return sample standard deviation over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rsub\n",
      "     |  \n",
      "     |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rsub\n",
      "     |  \n",
      "     |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the sum of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sum : scalar or Series (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      "     |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum()\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      "     |      Swap levels i and j in a MultiIndex\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      i, j : int, string (can be mixed)\n",
      "     |          Level of index to be swapped. Can pass level name as string.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      swapped : Series\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.18.1\n",
      "     |      \n",
      "     |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      "     |         the two innermost levels of the index.\n",
      "     |  \n",
      "     |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, date_format=None, decimal='.')\n",
      "     |      Write Series to a comma-separated values (csv) file\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string or file handle, default None\n",
      "     |          File path or object, if None is provided the result is returned as\n",
      "     |          a string.\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      header : boolean, default False\n",
      "     |          Write out series name\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      mode : Python write mode, default 'w'\n",
      "     |      sep : character, default \",\"\n",
      "     |          Field delimiter for the output file.\n",
      "     |      encoding : string, optional\n",
      "     |          a string representing the encoding to use if the contents are\n",
      "     |          non-ascii, for python versions prior to 3\n",
      "     |      date_format: string, default None\n",
      "     |          Format string for datetime objects.\n",
      "     |      decimal: string, default '.'\n",
      "     |          Character recognized as decimal separator. E.g. use ',' for\n",
      "     |          European data\n",
      "     |  \n",
      "     |  to_dict(self, into=<class 'dict'>)\n",
      "     |      Convert Series to {label -> value} dict or dict-like object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      into : class, default dict\n",
      "     |          The collections.Mapping subclass to use as the return\n",
      "     |          object. Can be the actual class or an empty\n",
      "     |          instance of the mapping type you want.  If you want a\n",
      "     |          collections.defaultdict, you must pass it initialized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value_dict : collections.Mapping\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4])\n",
      "     |      >>> s.to_dict()\n",
      "     |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      "     |      >>> from collections import OrderedDict, defaultdict\n",
      "     |      >>> s.to_dict(OrderedDict)\n",
      "     |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      "     |      >>> dd = defaultdict(list)\n",
      "     |      >>> s.to_dict(dd)\n",
      "     |      defaultdict(<type 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      "     |  \n",
      "     |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      "     |      Write Series to an excel sheet\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel_writer : string or ExcelWriter object\n",
      "     |          File path or existing ExcelWriter\n",
      "     |      sheet_name : string, default 'Sheet1'\n",
      "     |          Name of sheet which will contain DataFrame\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      columns : sequence, optional\n",
      "     |          Columns to write\n",
      "     |      header : boolean or list of string, default True\n",
      "     |          Write out the column names. If a list of strings is given it is\n",
      "     |          assumed to be aliases for the column names\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      startrow :\n",
      "     |          upper left cell row to dump data frame\n",
      "     |      startcol :\n",
      "     |          upper left cell column to dump data frame\n",
      "     |      engine : string, default None\n",
      "     |          write engine to use - you can also set this via the options\n",
      "     |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      "     |          ``io.excel.xlsm.writer``.\n",
      "     |      merge_cells : boolean, default True\n",
      "     |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      "     |      encoding: string, default None\n",
      "     |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      "     |          other writers support unicode natively.\n",
      "     |      inf_rep : string, default 'inf'\n",
      "     |          Representation for infinity (there is no native representation for\n",
      "     |          infinity in Excel)\n",
      "     |      freeze_panes : tuple of integer (length 2), default None\n",
      "     |          Specifies the one-based bottommost row and rightmost column that\n",
      "     |          is to be frozen\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      "     |      to the existing workbook.  This can be used to save different\n",
      "     |      DataFrames to one workbook:\n",
      "     |      \n",
      "     |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      "     |      >>> df1.to_excel(writer,'Sheet1')\n",
      "     |      >>> df2.to_excel(writer,'Sheet2')\n",
      "     |      >>> writer.save()\n",
      "     |      \n",
      "     |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      "     |      strings before writing.\n",
      "     |  \n",
      "     |  to_frame(self, name=None)\n",
      "     |      Convert Series to DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : object, default None\n",
      "     |          The passed name should substitute for the series name (if it has\n",
      "     |          one).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data_frame : DataFrame\n",
      "     |  \n",
      "     |  to_period(self, freq=None, copy=True)\n",
      "     |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      "     |      frequency (inferred from index if not passed)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ts : Series with PeriodIndex\n",
      "     |  \n",
      "     |  to_sparse(self, kind='block', fill_value=None)\n",
      "     |      Convert Series to SparseSeries\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kind : {'block', 'integer'}\n",
      "     |      fill_value : float, defaults to NaN (missing)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sp : SparseSeries\n",
      "     |  \n",
      "     |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      "     |      Render a string representation of the Series\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      buf : StringIO-like, optional\n",
      "     |          buffer to write to\n",
      "     |      na_rep : string, optional\n",
      "     |          string representation of NAN to use, default 'NaN'\n",
      "     |      float_format : one-parameter function, optional\n",
      "     |          formatter function to apply to columns' elements if they are floats\n",
      "     |          default None\n",
      "     |      header: boolean, default True\n",
      "     |          Add the Series header (index name)\n",
      "     |      index : bool, optional\n",
      "     |          Add index (row) labels, default True\n",
      "     |      length : boolean, default False\n",
      "     |          Add the Series length\n",
      "     |      dtype : boolean, default False\n",
      "     |          Add the Series dtype\n",
      "     |      name : boolean, default False\n",
      "     |          Add the Series name if not None\n",
      "     |      max_rows : int, optional\n",
      "     |          Maximum number of rows to show before truncating. If None, show\n",
      "     |          all.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      formatted : string (if not buffer passed)\n",
      "     |  \n",
      "     |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      "     |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default frequency of PeriodIndex\n",
      "     |          Desired frequency\n",
      "     |      how : {'s', 'e', 'start', 'end'}\n",
      "     |          Convention for converting period to timestamp; start of period\n",
      "     |          vs. end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ts : Series with DatetimeIndex\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |      Call function producing a like-indexed NDFrame\n",
      "     |      and return a NDFrame with the transformed values\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          To apply to column\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      transformed : NDFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      "     |                         A         B         C\n",
      "     |      2000-01-01  0.579457  1.236184  0.123424\n",
      "     |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      "     |      2000-01-03  1.455756 -0.277446  0.288967\n",
      "     |      2000-01-04       NaN       NaN       NaN\n",
      "     |      2000-01-05       NaN       NaN       NaN\n",
      "     |      2000-01-06       NaN       NaN       NaN\n",
      "     |      2000-01-07       NaN       NaN       NaN\n",
      "     |      2000-01-08 -0.498658  1.274522  1.642524\n",
      "     |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      "     |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.aggregate\n",
      "     |      pandas.NDFrame.apply\n",
      "     |  \n",
      "     |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rtruediv\n",
      "     |  \n",
      "     |  unique(self)\n",
      "     |      Return unique values in the object. Uniques are returned in order\n",
      "     |      of appearance, this does NOT sort. Hash table-based unique.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : 1d array-like\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unique values.\n",
      "     |        - If the input is an Index, the return is an Index\n",
      "     |        - If the input is a Categorical dtype, the return is a Categorical\n",
      "     |        - If the input is a Series/ndarray, the return will be an ndarray\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      unique\n",
      "     |      Index.unique\n",
      "     |      Series.unique\n",
      "     |  \n",
      "     |  unstack(self, level=-1, fill_value=None)\n",
      "     |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      "     |      The level involved will automatically get sorted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, string, or list of these, default last level\n",
      "     |          Level(s) to unstack, can pass level name\n",
      "     |      fill_value : replace NaN with this value if the unstack produces\n",
      "     |          missing values\n",
      "     |      \n",
      "     |          .. versionadded: 0.18.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4],\n",
      "     |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      "     |      >>> s\n",
      "     |      one  a    1\n",
      "     |           b    2\n",
      "     |      two  a    3\n",
      "     |           b    4\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s.unstack(level=-1)\n",
      "     |           a  b\n",
      "     |      one  1  2\n",
      "     |      two  3  4\n",
      "     |      \n",
      "     |      >>> s.unstack(level=0)\n",
      "     |         one  two\n",
      "     |      a    1    3\n",
      "     |      b    2    4\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unstacked : DataFrame\n",
      "     |  \n",
      "     |  update(self, other)\n",
      "     |      Modify Series in place using non-NA values from passed\n",
      "     |      Series. Aligns on index\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.update(pd.Series([4, 5, 6]))\n",
      "     |      >>> s\n",
      "     |      0    4\n",
      "     |      1    5\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      "     |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      "     |      >>> s\n",
      "     |      0    d\n",
      "     |      1    b\n",
      "     |      2    e\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      "     |      >>> s\n",
      "     |      0    4\n",
      "     |      1    5\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      If ``other`` contains NaNs the corresponding values are not updated\n",
      "     |      in the original Series.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      "     |      >>> s\n",
      "     |      0    4\n",
      "     |      1    2\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  valid lambda self, inplace=False, **kwargs\n",
      "     |  \n",
      "     |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased variance over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  view(self, dtype=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type\n",
      "     |  \n",
      "     |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      "     |      Read CSV file (DEPRECATED, please use :func:`pandas.read_csv`\n",
      "     |      instead).\n",
      "     |      \n",
      "     |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      "     |      for most general purposes, but ``from_csv`` makes for an easy\n",
      "     |      roundtrip to and from a file (the exact counterpart of\n",
      "     |      ``to_csv``), especially with a time Series.\n",
      "     |      \n",
      "     |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      "     |      \n",
      "     |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      "     |        by default)\n",
      "     |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      "     |        the column names)\n",
      "     |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      "     |        as datetime by default)\n",
      "     |      \n",
      "     |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      "     |      to return a Series like ``from_csv``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string file path or file handle / StringIO\n",
      "     |      sep : string, default ','\n",
      "     |          Field delimiter\n",
      "     |      parse_dates : boolean, default True\n",
      "     |          Parse dates. Different default from read_table\n",
      "     |      header : int, default None\n",
      "     |          Row to use as header (skip prior rows)\n",
      "     |      index_col : int or sequence, default 0\n",
      "     |          Column to use for index. If a sequence is given, a MultiIndex\n",
      "     |          is used. Different default from read_table\n",
      "     |      encoding : string, optional\n",
      "     |          a string representing the encoding to use if the contents are\n",
      "     |          non-ascii, for python versions prior to 3\n",
      "     |      infer_datetime_format: boolean, default False\n",
      "     |          If True and `parse_dates` is True for a column, try to infer the\n",
      "     |          datetime format based on the first datetime string. If the format\n",
      "     |          can be inferred, there often will be a large parsing speed-up.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.read_csv\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  asobject\n",
      "     |      return object Series which contains boxed values\n",
      "     |      \n",
      "     |      *this is an internal non-public method*\n",
      "     |  \n",
      "     |  axes\n",
      "     |      Return a list of the row axis labels\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      return the dtype object of the underlying data\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      return the dtype object of the underlying data\n",
      "     |  \n",
      "     |  ftype\n",
      "     |      return if the data is sparse|dense\n",
      "     |  \n",
      "     |  ftypes\n",
      "     |      return if the data is sparse|dense\n",
      "     |  \n",
      "     |  imag\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  real\n",
      "     |  \n",
      "     |  values\n",
      "     |      Return Series as ndarray or ndarray-like\n",
      "     |      depending on the dtype\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      arr : numpy.ndarray or ndarray-like\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> pd.Series([1, 2, 3]).values\n",
      "     |      array([1, 2, 3])\n",
      "     |      \n",
      "     |      >>> pd.Series(list('aabc')).values\n",
      "     |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      "     |      \n",
      "     |      >>> pd.Series(list('aabc')).astype('category').values\n",
      "     |      [a, a, b, c]\n",
      "     |      Categories (3, object): [a, b, c]\n",
      "     |      \n",
      "     |      Timezone aware datetime data is converted to UTC:\n",
      "     |      \n",
      "     |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      "     |      ...                         tz='US/Eastern')).values\n",
      "     |      array(['2013-01-01T05:00:00.000000000',\n",
      "     |             '2013-01-02T05:00:00.000000000',\n",
      "     |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  cat = <class 'pandas.core.categorical.CategoricalAccessor'>\n",
      "     |      Accessor object for categorical properties of the Series values.\n",
      "     |      \n",
      "     |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      "     |      methods return new categorical data per default (but can be called with\n",
      "     |      `inplace=True`).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.cat.categories\n",
      "     |      >>> s.cat.categories = list('abc')\n",
      "     |      >>> s.cat.rename_categories(list('cab'))\n",
      "     |      >>> s.cat.reorder_categories(list('cab'))\n",
      "     |      >>> s.cat.add_categories(['d','e'])\n",
      "     |      >>> s.cat.remove_categories(['d'])\n",
      "     |      >>> s.cat.remove_unused_categories()\n",
      "     |      >>> s.cat.set_categories(list('abcde'))\n",
      "     |      >>> s.cat.as_ordered()\n",
      "     |      >>> s.cat.as_unordered()\n",
      "     |  \n",
      "     |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      "     |      Accessor object for datetimelike properties of the Series values.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.dt.hour\n",
      "     |      >>> s.dt.second\n",
      "     |      >>> s.dt.quarter\n",
      "     |      \n",
      "     |      Returns a Series indexed like the original Series.\n",
      "     |      Raises TypeError if the Series does not contain datetimelike values.\n",
      "     |  \n",
      "     |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      "     |      Series plotting accessor and method\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.plot.line()\n",
      "     |      >>> s.plot.bar()\n",
      "     |      >>> s.plot.hist()\n",
      "     |      \n",
      "     |      Plotting methods can also be accessed by calling the accessor as a method\n",
      "     |      with the ``kind`` argument:\n",
      "     |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      "     |  \n",
      "     |  str = <class 'pandas.core.strings.StringMethods'>\n",
      "     |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      "     |      handled otherwise by a particular method. Patterned after Python's string\n",
      "     |      methods, with some inspiration from R's stringr package.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.str.split('_')\n",
      "     |      >>> s.str.replace('_', '')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Return an iterator of the values.\n",
      "     |      \n",
      "     |      These are each a scalar type, which is a Python scalar\n",
      "     |      (for str, int, float) or a pandas scalar\n",
      "     |      (for Timestamp/Timedelta/Interval/Period)\n",
      "     |  \n",
      "     |  factorize(self, sort=False, na_sentinel=-1)\n",
      "     |      Encode the object as an enumerated type or categorical variable\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sort : boolean, default False\n",
      "     |          Sort by values\n",
      "     |      na_sentinel: int, default -1\n",
      "     |          Value to mark \"not found\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      labels : the indexer to the original array\n",
      "     |      uniques : the unique Index\n",
      "     |  \n",
      "     |  item(self)\n",
      "     |      return the first element of the underlying data as a python\n",
      "     |      scalar\n",
      "     |  \n",
      "     |  nunique(self, dropna=True)\n",
      "     |      Return number of unique elements in the object.\n",
      "     |      \n",
      "     |      Excludes NA values by default.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include NaN in the count.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nunique : int\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Return a list of the values.\n",
      "     |      \n",
      "     |      These are each a scalar type, which is a Python scalar\n",
      "     |      (for str, int, float) or a pandas scalar\n",
      "     |      (for Timestamp/Timedelta/Interval/Period)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.tolist\n",
      "     |  \n",
      "     |  transpose(self, *args, **kwargs)\n",
      "     |      return the transpose, which is by definition self\n",
      "     |  \n",
      "     |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      "     |      Returns object containing counts of unique values.\n",
      "     |      \n",
      "     |      The resulting object will be in descending order so that the\n",
      "     |      first element is the most frequently-occurring element.\n",
      "     |      Excludes NA values by default.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      normalize : boolean, default False\n",
      "     |          If True then the object returned will contain the relative\n",
      "     |          frequencies of the unique values.\n",
      "     |      sort : boolean, default True\n",
      "     |          Sort by values\n",
      "     |      ascending : boolean, default False\n",
      "     |          Sort in ascending order\n",
      "     |      bins : integer, optional\n",
      "     |          Rather than count values, group them into half-open bins,\n",
      "     |          a convenience for pd.cut, only works with numeric data\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include counts of NaN.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      counts : Series\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      "     |  \n",
      "     |  T\n",
      "     |      return the transpose, which is by definition self\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  base\n",
      "     |      return the base object if the memory of the underlying data is\n",
      "     |      shared\n",
      "     |  \n",
      "     |  data\n",
      "     |      return the data pointer of the underlying data\n",
      "     |  \n",
      "     |  empty\n",
      "     |  \n",
      "     |  flags\n",
      "     |      return the ndarray.flags for the underlying data\n",
      "     |  \n",
      "     |  hasnans\n",
      "     |  \n",
      "     |  is_monotonic\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_increasing\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_monotonic : boolean\n",
      "     |  \n",
      "     |  is_monotonic_decreasing\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_decreasing\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_monotonic_decreasing : boolean\n",
      "     |  \n",
      "     |  is_monotonic_increasing\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_increasing\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_monotonic : boolean\n",
      "     |  \n",
      "     |  is_unique\n",
      "     |      Return boolean if values in the object are unique\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_unique : boolean\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |      return the size of the dtype of the item of the underlying data\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |      return the number of bytes in the underlying data\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      return the number of dimensions of the underlying data,\n",
      "     |      by definition 1\n",
      "     |  \n",
      "     |  shape\n",
      "     |      return a tuple of the shape of the underlying data\n",
      "     |  \n",
      "     |  size\n",
      "     |      return the number of elements in the underlying data\n",
      "     |  \n",
      "     |  strides\n",
      "     |      return the strides of the underlying data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  __abs__(self)\n",
      "     |  \n",
      "     |  __bool__ = __nonzero__(self)\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      True if the key is in the info axis\n",
      "     |  \n",
      "     |  __copy__(self, deep=True)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete item\n",
      "     |  \n",
      "     |  __finalize__(self, other, method=None, **kwargs)\n",
      "     |      Propagate metadata from other to self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : the object from which to get the attributes that we are going\n",
      "     |          to propagate\n",
      "     |      method : optional, a passed method name ; possibly to take different\n",
      "     |          types of propagation actions based on this\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |      After regular attribute access, try looking up the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__(self)\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |  \n",
      "     |  __round__(self, decimals=0)\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      After regular attribute access, try setting the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |      Return an object with absolute value taken--only applicable to objects\n",
      "     |      that are all numeric.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      abs: type of caller\n",
      "     |  \n",
      "     |  add_prefix(self, prefix)\n",
      "     |      Concatenate prefix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      prefix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_prefix : type of caller\n",
      "     |  \n",
      "     |  add_suffix(self, suffix)\n",
      "     |      Concatenate suffix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      suffix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_suffix : type of caller\n",
      "     |  \n",
      "     |  as_blocks(self, copy=True)\n",
      "     |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      "     |      a homogeneous dtype.\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      "     |            as_matrix)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : a dict of dtype -> Constructor Types\n",
      "     |  \n",
      "     |  as_matrix(self, columns=None)\n",
      "     |      Convert the frame to its Numpy-array representation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns: list, optional, default:None\n",
      "     |          If None, return all columns, otherwise, returns specified columns.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : ndarray\n",
      "     |          If the caller is heterogeneous and contains booleans or objects,\n",
      "     |          the result will be of dtype=object. See Notes.\n",
      "     |      \n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      "     |      \n",
      "     |      The dtype will be a lower-common-denominator dtype (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen. Use this\n",
      "     |      with care if you are not dealing with the blocks.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      "     |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      "     |      will result in a flot64 dtype.\n",
      "     |      \n",
      "     |      This method is provided for backwards compatibility. Generally,\n",
      "     |      it is recommended to use '.values'.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.values\n",
      "     |  \n",
      "     |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      "     |      Convert TimeSeries to specified frequency.\n",
      "     |      \n",
      "     |      Optionally provide filling method to pad/backfill missing values.\n",
      "     |      \n",
      "     |      Returns the original data conformed to a new index with the specified\n",
      "     |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      "     |      summarization, is necessary to represent the data at the new frequency.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : DateOffset object, or string\n",
      "     |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      "     |          Method to use for filling holes in reindexed Series (note this\n",
      "     |          does not fill NaNs that already were present):\n",
      "     |      \n",
      "     |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      "     |      how : {'start', 'end'}, default end\n",
      "     |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      "     |      normalize : bool, default False\n",
      "     |          Whether to reset output index to midnight\n",
      "     |      fill_value: scalar, optional\n",
      "     |          Value to use for missing values, applied during upsampling (note\n",
      "     |          this does not fill NaNs that already were present).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 4 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      "     |      >>> df = pd.DataFrame({'s':series})\n",
      "     |      >>> df\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    NaN\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``fill value``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    9.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    9.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    9.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``method``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', method='bfill')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    2.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    3.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |  \n",
      "     |  asof(self, where, subset=None)\n",
      "     |      The last row without any NaN is taken (or the last row without\n",
      "     |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0 For DataFrame\n",
      "     |      \n",
      "     |      If there is no good value, NaN is returned for a Series\n",
      "     |      a Series of NaN values for a DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      where : date or array of dates\n",
      "     |      subset : string or list of strings, default None\n",
      "     |         if not None use these columns for NaN propagation\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Dates are assumed to be sorted\n",
      "     |      Raises if this is not the case\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      where is scalar\n",
      "     |      \n",
      "     |        - value or NaN if input is Series\n",
      "     |        - Series if input is DataFrame\n",
      "     |      \n",
      "     |      where is Index: same shape object as input\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      merge_asof\n",
      "     |  \n",
      "     |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      "     |      Cast a pandas object to a specified dtype ``dtype``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data type, or dict of column name -> data type\n",
      "     |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      "     |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      "     |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      "     |          or more of the DataFrame's columns to column-specific types.\n",
      "     |      copy : bool, default True.\n",
      "     |          Return a copy when ``copy=True`` (be very careful setting\n",
      "     |          ``copy=False`` as changes to values then may propagate to other\n",
      "     |          pandas objects).\n",
      "     |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      "     |          Control raising of exceptions on invalid data for provided dtype.\n",
      "     |      \n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      raise_on_error : raise on invalid input\n",
      "     |          .. deprecated:: 0.20.0\n",
      "     |             Use ``errors`` instead\n",
      "     |      kwargs : keyword arguments to pass on to the constructor\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      casted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      "     |      >>> ser\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int32\n",
      "     |      >>> ser.astype('int64')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Convert to categorical type:\n",
      "     |      \n",
      "     |      >>> ser.astype('category')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [1, 2]\n",
      "     |      \n",
      "     |      Convert to ordered categorical type with custom ordering:\n",
      "     |      \n",
      "     |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [2 < 1]\n",
      "     |      \n",
      "     |      Note that using ``copy=False`` and changing data on a new\n",
      "     |      pandas object may propagate changes:\n",
      "     |      \n",
      "     |      >>> s1 = pd.Series([1,2])\n",
      "     |      >>> s2 = s1.astype('int', copy=False)\n",
      "     |      >>> s2[0] = 10\n",
      "     |      >>> s1  # note that s1[0] has changed too\n",
      "     |      0    10\n",
      "     |      1     2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to a numeric type.\n",
      "     |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      "     |  \n",
      "     |  at_time(self, time, asof=False)\n",
      "     |      Select values at particular time of day (e.g. 9:30AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      time : datetime.time or string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_at_time : type of caller\n",
      "     |  \n",
      "     |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      "     |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_time : datetime.time or string\n",
      "     |      end_time : datetime.time or string\n",
      "     |      include_start : boolean, default True\n",
      "     |      include_end : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_between_time : type of caller\n",
      "     |  \n",
      "     |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Return the bool of a single element PandasObject.\n",
      "     |      \n",
      "     |      This must be a boolean scalar value, either True or False.  Raise a\n",
      "     |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      "     |      element is not boolean\n",
      "     |  \n",
      "     |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      "     |      Trim values at input threshold(s).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lower : float or array_like, default None\n",
      "     |      upper : float or array_like, default None\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with lower and upper along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.256177\n",
      "     |      1 -1.367855  0.746646\n",
      "     |      2  0.027753 -1.176076\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  1.261967  0.570967\n",
      "     |      \n",
      "     |      >>> df.clip(-1.0, 0.5)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.000000\n",
      "     |      1 -1.000000  0.500000\n",
      "     |      2  0.027753 -1.000000\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  0.500000  0.500000\n",
      "     |      \n",
      "     |      >>> t\n",
      "     |      0   -0.3\n",
      "     |      1   -0.2\n",
      "     |      2   -0.1\n",
      "     |      3    0.0\n",
      "     |      4    0.1\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> df.clip(t, t + 1, axis=0)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -0.300000\n",
      "     |      1 -0.200000  0.746646\n",
      "     |      2  0.027753 -0.100000\n",
      "     |      3  0.230930  0.000000\n",
      "     |      4  1.100000  0.570967\n",
      "     |  \n",
      "     |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of the input with values below given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of input with values above given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  consolidate(self, inplace=False)\n",
      "     |      DEPRECATED: consolidate will be an internal implementation only.\n",
      "     |  \n",
      "     |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      "     |      Deprecated.\n",
      "     |      Attempt to infer better dtype for object columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      convert_dates : boolean, default True\n",
      "     |          If True, convert to date where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      convert_numeric : boolean, default False\n",
      "     |          If True, attempt to coerce to numbers (including strings), with\n",
      "     |          unconvertible values becoming NaN.\n",
      "     |      convert_timedeltas : boolean, default True\n",
      "     |          If True, convert to timedelta where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      copy : boolean, default True\n",
      "     |          If True, return a copy even if no copy is necessary (e.g. no\n",
      "     |          conversion was done). Note: This is meant for internal use, and\n",
      "     |          should not be confused with inplace.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      "     |          with day as the default.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same as input object\n",
      "     |  \n",
      "     |  copy(self, deep=True)\n",
      "     |      Make a copy of this objects data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean or string, default True\n",
      "     |          Make a deep copy, including a copy of the data and the indices.\n",
      "     |          With ``deep=False`` neither the indices or the data are copied.\n",
      "     |      \n",
      "     |          Note that when ``deep=True`` data is copied, actual python objects\n",
      "     |          will not be copied recursively, only the reference to the object.\n",
      "     |          This is in contrast to ``copy.deepcopy`` in the Standard Library,\n",
      "     |          which recursively copies object data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      copy : type of caller\n",
      "     |  \n",
      "     |  describe(self, percentiles=None, include=None, exclude=None)\n",
      "     |      Generates descriptive statistics that summarize the central tendency,\n",
      "     |      dispersion and shape of a dataset's distribution, excluding\n",
      "     |      ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      summary:  Series/DataFrame of summary statistics\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      "     |      ...                     'numeric': [1, 2, 3],\n",
      "     |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |              categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count\n",
      "     |      DataFrame.max\n",
      "     |      DataFrame.min\n",
      "     |      DataFrame.mean\n",
      "     |      DataFrame.std\n",
      "     |      DataFrame.select_dtypes\n",
      "     |  \n",
      "     |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      "     |      Return new object with labels in requested axis removed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : single label or list-like\n",
      "     |          Index or column labels to drop.\n",
      "     |      axis : int or axis name\n",
      "     |          Whether to drop labels from the index (0 / 'index') or\n",
      "     |          columns (1 / 'columns').\n",
      "     |      index, columns : single label or list-like\n",
      "     |          Alternative to specifying `axis` (``labels, axis=1`` is\n",
      "     |          equivalent to ``columns=labels``).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      level : int or level name, default None\n",
      "     |          For MultiIndex\n",
      "     |      inplace : bool, default False\n",
      "     |          If True, do operation inplace and return None.\n",
      "     |      errors : {'ignore', 'raise'}, default 'raise'\n",
      "     |          If 'ignore', suppress error and existing labels are dropped.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dropped : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      "     |                            columns=['A', 'B', 'C', 'D'])\n",
      "     |      >>> df\n",
      "     |         A  B   C   D\n",
      "     |      0  0  1   2   3\n",
      "     |      1  4  5   6   7\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Drop columns\n",
      "     |      \n",
      "     |      >>> df.drop(['B', 'C'], axis=1)\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      >>> df.drop(columns=['B', 'C'])\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      Drop a row by index\n",
      "     |      \n",
      "     |      >>> df.drop([0, 1])\n",
      "     |         A  B   C   D\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Specifying both `labels` and `index` or `columns` will raise a\n",
      "     |      ValueError.\n",
      "     |  \n",
      "     |  equals(self, other)\n",
      "     |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      "     |      the same location are considered equal.\n",
      "     |  \n",
      "     |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      "     |      Subset rows or columns of dataframe according to labels in\n",
      "     |      the specified index.\n",
      "     |      \n",
      "     |      Note that this routine does not filter a dataframe on its\n",
      "     |      contents. The filter is applied to the labels of the index.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      items : list-like\n",
      "     |          List of info axis to restrict to (must not all be present)\n",
      "     |      like : string\n",
      "     |          Keep info axis where \"arg in col == True\"\n",
      "     |      regex : string (regular expression)\n",
      "     |          Keep info axis with re.search(regex, col) == True\n",
      "     |      axis : int or string axis name\n",
      "     |          The axis to filter on.  By default this is the info axis,\n",
      "     |          'index' for Series, 'columns' for DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |      one  two  three\n",
      "     |      mouse     1    2      3\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      >>> # select columns by name\n",
      "     |      >>> df.filter(items=['one', 'three'])\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select columns by regular expression\n",
      "     |      >>> df.filter(regex='e$', axis=1)\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select rows containing 'bbi'\n",
      "     |      >>> df.filter(like='bbi', axis=0)\n",
      "     |      one  two  three\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.loc\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The ``items``, ``like``, and ``regex`` parameters are\n",
      "     |      enforced to be mutually exclusive.\n",
      "     |      \n",
      "     |      ``axis`` defaults to the info axis that is used when indexing\n",
      "     |      with ``[]``.\n",
      "     |  \n",
      "     |  first(self, offset)\n",
      "     |      Convenience method for subsetting initial periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.first('10D') -> First 10 days\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Get item from object for given key (DataFrame column, Panel slice,\n",
      "     |      etc.). Returns default value if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : object\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : type of items contained in object\n",
      "     |  \n",
      "     |  get_dtype_counts(self)\n",
      "     |      Return the counts of dtypes in this object.\n",
      "     |  \n",
      "     |  get_ftype_counts(self)\n",
      "     |      Return the counts of ftypes in this object.\n",
      "     |  \n",
      "     |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      "     |      Group series using mapper (dict or key function, apply given function\n",
      "     |      to group, return result as series) or by a series of columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : mapping, function, str, or iterable\n",
      "     |          Used to determine the groups for the groupby.\n",
      "     |          If ``by`` is a function, it's called on each value of the object's\n",
      "     |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      "     |          will be used to determine the groups (the Series' values are first\n",
      "     |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      "     |          values are used as-is determine the groups. A str or list of strs\n",
      "     |          may be passed to group by the columns in ``self``\n",
      "     |      axis : int, default 0\n",
      "     |      level : int, level name, or sequence of such, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      "     |          level or levels\n",
      "     |      as_index : boolean, default True\n",
      "     |          For aggregated output, return object with group labels as the\n",
      "     |          index. Only relevant for DataFrame input. as_index=False is\n",
      "     |          effectively \"SQL-style\" grouped output\n",
      "     |      sort : boolean, default True\n",
      "     |          Sort group keys. Get better performance by turning this off.\n",
      "     |          Note this does not influence the order of observations within each\n",
      "     |          group.  groupby preserves the order of rows within each group.\n",
      "     |      group_keys : boolean, default True\n",
      "     |          When calling apply, add group keys to index to identify pieces\n",
      "     |      squeeze : boolean, default False\n",
      "     |          reduce the dimensionality of the return type if possible,\n",
      "     |          otherwise return a consistent type\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      DataFrame results\n",
      "     |      \n",
      "     |      >>> data.groupby(func, axis=0).mean()\n",
      "     |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      "     |      \n",
      "     |      DataFrame with hierarchical index\n",
      "     |      \n",
      "     |      >>> data.groupby(['col1', 'col2']).mean()\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GroupBy object\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return the first n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_head : type of caller\n",
      "     |          The first n rows of the caller object.\n",
      "     |  \n",
      "     |  infer_objects(self)\n",
      "     |      Attempt to infer better dtypes for object columns.\n",
      "     |      \n",
      "     |      Attempts soft conversion of object-dtyped\n",
      "     |      columns, leaving non-object and unconvertible\n",
      "     |      columns unchanged. The inference rules are the\n",
      "     |      same as during normal Series/DataFrame construction.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to numeric typeR\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      "     |      >>> df = df.iloc[1:]\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      \n",
      "     |      >>> df.dtypes\n",
      "     |      A    object\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> df.infer_objects().dtypes\n",
      "     |      A    int64\n",
      "     |      dtype: object\n",
      "     |  \n",
      "     |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      "     |      Interpolate values according to different methods.\n",
      "     |      \n",
      "     |      Please note that only ``method='linear'`` is supported for\n",
      "     |      DataFrames/Series with a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      "     |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      "     |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      "     |                'from_derivatives', 'pchip', 'akima'}\n",
      "     |      \n",
      "     |          * 'linear': ignore the index and treat the values as equally\n",
      "     |            spaced. This is the only method supported on MultiIndexes.\n",
      "     |            default\n",
      "     |          * 'time': interpolation works on daily and higher resolution\n",
      "     |            data to interpolate given length of interval\n",
      "     |          * 'index', 'values': use the actual numerical values of the index\n",
      "     |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      "     |            'barycentric', 'polynomial' is passed to\n",
      "     |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      "     |            require that you also specify an `order` (int),\n",
      "     |            e.g. df.interpolate(method='polynomial', order=4).\n",
      "     |            These use the actual numerical values of the index.\n",
      "     |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      "     |            are all wrappers around the scipy interpolation methods of\n",
      "     |            similar names. These use the actual numerical values of the\n",
      "     |            index. For more information on their behavior, see the\n",
      "     |            `scipy documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      "     |            and `tutorial documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      "     |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      "     |            replaces 'piecewise_polynomial' interpolation method in\n",
      "     |            scipy 0.18\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |      \n",
      "     |             Added support for the 'akima' method\n",
      "     |             Added interpolate method 'from_derivatives' which replaces\n",
      "     |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      "     |             scipy < 0.18\n",
      "     |      \n",
      "     |      axis : {0, 1}, default 0\n",
      "     |          * 0: fill column-by-column\n",
      "     |          * 1: fill row-by-row\n",
      "     |      limit : int, default None.\n",
      "     |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      "     |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      "     |          If limit is specified, consecutive NaNs will be filled in this\n",
      "     |          direction.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      inplace : bool, default False\n",
      "     |          Update the NDFrame in place if possible.\n",
      "     |      downcast : optional, 'infer' or None, defaults to None\n",
      "     |          Downcast dtypes if possible.\n",
      "     |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame of same shape interpolated at the NaNs\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, replace, fillna\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Filling in NaNs\n",
      "     |      \n",
      "     |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      "     |      >>> s.interpolate()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    3\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  last(self, offset)\n",
      "     |      Convenience method for subsetting final periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.last('5M') -> Last 5 months\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is False and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is False, keep the original value. Where\n",
      "     |          True, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is True are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The mask method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``mask`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.where`\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      "     |      Percent change over given number of periods.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming percent change\n",
      "     |      fill_method : str, default 'pad'\n",
      "     |          How to handle NAs before computing percent changes\n",
      "     |      limit : int, default None\n",
      "     |          The number of consecutive NAs to fill before stopping\n",
      "     |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      "     |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chg : NDFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      By default, the percentage change is calculated along the stat\n",
      "     |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      "     |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          function to apply to the NDFrame.\n",
      "     |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      "     |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      "     |          ``data_keyword`` is a string indicating the keyword of\n",
      "     |          ``callable`` that expects the NDFrame.\n",
      "     |      args : iterable, optional\n",
      "     |          positional arguments passed into ``func``.\n",
      "     |      kwargs : mapping, optional\n",
      "     |          a dictionary of keyword arguments passed into ``func``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of ``func``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Use ``.pipe`` when chaining together functions that expect\n",
      "     |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      "     |      \n",
      "     |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(f, arg2=b, arg3=c)\n",
      "     |      ... )\n",
      "     |      \n",
      "     |      If you have a function that takes the data as (say) the second\n",
      "     |      argument, pass a tuple indicating which keyword expects the\n",
      "     |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      "     |      ...  )\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.applymap\n",
      "     |      pandas.Series.map\n",
      "     |  \n",
      "     |  pop(self, item)\n",
      "     |      Return item and drop from frame. Raise KeyError if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      item : str\n",
      "     |          Column label to be popped\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      popped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |      ...                    ('parrot', 'bird',     24.0),\n",
      "     |      ...                    ('lion',   'mammal',   80.5),\n",
      "     |      ...                    ('monkey', 'mammal', np.nan)],\n",
      "     |      ...                   columns=('name', 'class', 'max_speed'))\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  parrot    bird       24.0\n",
      "     |      2    lion  mammal       80.5\n",
      "     |      3  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      >>> df.pop('class')\n",
      "     |      0      bird\n",
      "     |      1      bird\n",
      "     |      2    mammal\n",
      "     |      3    mammal\n",
      "     |      Name: class, dtype: object\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |           name  max_speed\n",
      "     |      0  falcon      389.0\n",
      "     |      1  parrot       24.0\n",
      "     |      2    lion       80.5\n",
      "     |      3  monkey        NaN\n",
      "     |  \n",
      "     |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      "     |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      "     |      assigned a rank that is the average of the ranks of those values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          index to direct ranking\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      "     |          * average: average rank of group\n",
      "     |          * min: lowest rank in group\n",
      "     |          * max: highest rank in group\n",
      "     |          * first: ranks assigned in order they appear in the array\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      "     |          Panel objects\n",
      "     |      na_option : {'keep', 'top', 'bottom'}\n",
      "     |          * keep: leave NA values where they are\n",
      "     |          * top: smallest rank if ascending\n",
      "     |          * bottom: smallest rank if descending\n",
      "     |      ascending : boolean, default True\n",
      "     |          False for ranks by high (1) to low (N)\n",
      "     |      pct : boolean, default False\n",
      "     |          Computes percentage rank of data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ranks : same type as caller\n",
      "     |  \n",
      "     |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      "     |      Return an object with matching indices to myself.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Object\n",
      "     |      method : string or None\n",
      "     |      copy : boolean, default True\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive labels to fill for inexact matches.\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between labels of the other object and this\n",
      "     |          object for inexact matches. Can be list-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      "     |                             method=...)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : same as input\n",
      "     |  \n",
      "     |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      "     |      Alter the name of the index or columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper : scalar, list-like, optional\n",
      "     |          Value to set the axis name attribute.\n",
      "     |      axis : int or string, default 0\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : type of caller or None if inplace=True\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      "     |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      "     |      deprecated and will be removed in a future version. Use ``rename``\n",
      "     |      instead.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.rename, pandas.DataFrame.rename\n",
      "     |      pandas.Index.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.rename_axis(\"foo\")\n",
      "     |           A  B\n",
      "     |      foo\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |      \n",
      "     |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      "     |      bar  A  B\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |  \n",
      "     |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      "     |      Replace values given in 'to_replace' with 'value'.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      "     |      \n",
      "     |          * str or regex:\n",
      "     |      \n",
      "     |              - str: string exactly matching `to_replace` will be replaced\n",
      "     |                with `value`\n",
      "     |              - regex: regexs matching `to_replace` will be replaced with\n",
      "     |                `value`\n",
      "     |      \n",
      "     |          * list of str, regex, or numeric:\n",
      "     |      \n",
      "     |              - First, if `to_replace` and `value` are both lists, they\n",
      "     |                **must** be the same length.\n",
      "     |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      "     |                lists will be interpreted as regexs otherwise they will match\n",
      "     |                directly. This doesn't matter much for `value` since there\n",
      "     |                are only a few possible substitution regexes you can use.\n",
      "     |              - str and regex rules apply as above.\n",
      "     |      \n",
      "     |          * dict:\n",
      "     |      \n",
      "     |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      "     |                follows: look in column 'a' for the value 'b' and replace it\n",
      "     |                with nan. You can nest regular expressions as well. Note that\n",
      "     |                column names (the top-level dictionary keys in a nested\n",
      "     |                dictionary) **cannot** be regular expressions.\n",
      "     |              - Keys map to column names and values map to substitution\n",
      "     |                values. You can treat this as a special case of passing two\n",
      "     |                lists except that you are specifying the column to search in.\n",
      "     |      \n",
      "     |          * None:\n",
      "     |      \n",
      "     |              - This means that the ``regex`` argument must be a string,\n",
      "     |                compiled regular expression, or list, dict, ndarray or Series\n",
      "     |                of such elements. If `value` is also ``None`` then this\n",
      "     |                **must** be a nested dictionary or ``Series``.\n",
      "     |      \n",
      "     |          See the examples section for examples of each of these.\n",
      "     |      value : scalar, dict, list, str, regex, default None\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      "     |          specifying which value to use for each column (columns not in the\n",
      "     |          dict will not be filled). Regular expressions, strings and lists or\n",
      "     |          dicts of such objects are also allowed.\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, in place. Note: this will modify any\n",
      "     |          other views on this object (e.g. a column from a DataFrame).\n",
      "     |          Returns the caller if this is True.\n",
      "     |      limit : int, default None\n",
      "     |          Maximum size gap to forward or backward fill\n",
      "     |      regex : bool or same types as `to_replace`, default False\n",
      "     |          Whether to interpret `to_replace` and/or `value` as regular\n",
      "     |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      "     |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      "     |          parameter will be interpreted as a regular expression or a list,\n",
      "     |          dict, or array of regular expressions.\n",
      "     |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      "     |          The method to use when for replacement, when ``to_replace`` is a\n",
      "     |          ``list``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      NDFrame.reindex\n",
      "     |      NDFrame.asfreq\n",
      "     |      NDFrame.fillna\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : NDFrame\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      AssertionError\n",
      "     |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      "     |      TypeError\n",
      "     |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      "     |            ``dict``, ``ndarray``, or ``Series``\n",
      "     |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      "     |            regular expression or is a list, dict, ndarray, or Series.\n",
      "     |      ValueError\n",
      "     |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      "     |            they are not the same length.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      "     |        rules for substitution for ``re.sub`` are the same.\n",
      "     |      * Regular expressions will only substitute on strings, meaning you\n",
      "     |        cannot provide, for example, a regular expression matching floating\n",
      "     |        point numbers and expect the columns in your frame that have a\n",
      "     |        numeric dtype to be matched. However, if those floating point numbers\n",
      "     |        *are* strings, then you can do this.\n",
      "     |      * This method has *a lot* of options. You are encouraged to experiment\n",
      "     |        and play with this method to gain intuition about how it works.\n",
      "     |  \n",
      "     |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      "     |      Convenience method for frequency conversion and resampling of time\n",
      "     |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      "     |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      "     |      to the on or level keyword.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : string\n",
      "     |          the offset string or object representing target conversion\n",
      "     |      axis : int, optional, default 0\n",
      "     |      closed : {'right', 'left'}\n",
      "     |          Which side of bin interval is closed. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      label : {'right', 'left'}\n",
      "     |          Which bin edge label to label bucket with. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      convention : {'start', 'end', 's', 'e'}\n",
      "     |          For PeriodIndex only, controls whether to use the start or end of\n",
      "     |          `rule`\n",
      "     |      loffset : timedelta\n",
      "     |          Adjust the resampled time labels\n",
      "     |      base : int, default 0\n",
      "     |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      "     |          aggregated intervals. For example, for '5min' frequency, base could\n",
      "     |          range from 0 through 4. Defaults to 0\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column to use instead of index for resampling.\n",
      "     |          Column must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      level : string or int, optional\n",
      "     |          For a MultiIndex, level (name or number) to use for\n",
      "     |          resampling.  Level must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the offset strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 9 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> series = pd.Series(range(9), index=index)\n",
      "     |      >>> series\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      2000-01-01 00:03:00    3\n",
      "     |      2000-01-01 00:04:00    4\n",
      "     |      2000-01-01 00:05:00    5\n",
      "     |      2000-01-01 00:06:00    6\n",
      "     |      2000-01-01 00:07:00    7\n",
      "     |      2000-01-01 00:08:00    8\n",
      "     |      Freq: T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and sum the values\n",
      "     |      of the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> series.resample('3T').sum()\n",
      "     |      2000-01-01 00:00:00     3\n",
      "     |      2000-01-01 00:03:00    12\n",
      "     |      2000-01-01 00:06:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but label each\n",
      "     |      bin using the right edge instead of the left. Please note that the\n",
      "     |      value in the bucket used as the label is not included in the bucket,\n",
      "     |      which it labels. For example, in the original series the\n",
      "     |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      "     |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      "     |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      "     |      To include this value close the right side of the bin interval as\n",
      "     |      illustrated in the example below this one.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right').sum()\n",
      "     |      2000-01-01 00:03:00     3\n",
      "     |      2000-01-01 00:06:00    12\n",
      "     |      2000-01-01 00:09:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      "     |      2000-01-01 00:00:00     0\n",
      "     |      2000-01-01 00:03:00     6\n",
      "     |      2000-01-01 00:06:00    15\n",
      "     |      2000-01-01 00:09:00    15\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      "     |      2000-01-01 00:00:00   0.0\n",
      "     |      2000-01-01 00:00:30   NaN\n",
      "     |      2000-01-01 00:01:00   1.0\n",
      "     |      2000-01-01 00:01:30   NaN\n",
      "     |      2000-01-01 00:02:00   2.0\n",
      "     |      Freq: 30S, dtype: float64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      "     |      values using the ``pad`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').pad()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the\n",
      "     |      ``NaN`` values using the ``bfill`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').bfill()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    1\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    2\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Pass a custom function via ``apply``\n",
      "     |      \n",
      "     |      >>> def custom_resampler(array_like):\n",
      "     |      ...     return np.sum(array_like)+5\n",
      "     |      \n",
      "     |      >>> series.resample('3T').apply(custom_resampler)\n",
      "     |      2000-01-01 00:00:00     8\n",
      "     |      2000-01-01 00:03:00    17\n",
      "     |      2000-01-01 00:06:00    26\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      "     |      used to control whether to use the start or end of `rule`.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      "     |                                                      freq='A',\n",
      "     |                                                      periods=2))\n",
      "     |      >>> s\n",
      "     |      2012    1\n",
      "     |      2013    2\n",
      "     |      Freq: A-DEC, dtype: int64\n",
      "     |      \n",
      "     |      Resample by month using 'start' `convention`. Values are assigned to\n",
      "     |      the first month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='start').asfreq().head()\n",
      "     |      2012-01    1.0\n",
      "     |      2012-02    NaN\n",
      "     |      2012-03    NaN\n",
      "     |      2012-04    NaN\n",
      "     |      2012-05    NaN\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      Resample by month using 'end' `convention`. Values are assigned to\n",
      "     |      the last month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='end').asfreq()\n",
      "     |      2012-12    1.0\n",
      "     |      2013-01    NaN\n",
      "     |      2013-02    NaN\n",
      "     |      2013-03    NaN\n",
      "     |      2013-04    NaN\n",
      "     |      2013-05    NaN\n",
      "     |      2013-06    NaN\n",
      "     |      2013-07    NaN\n",
      "     |      2013-08    NaN\n",
      "     |      2013-09    NaN\n",
      "     |      2013-10    NaN\n",
      "     |      2013-11    NaN\n",
      "     |      2013-12    2.0\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      "     |      column instead of the index for resampling.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      "     |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> df.resample('3T', on='time').sum()\n",
      "     |                           a  b  c  d\n",
      "     |      time\n",
      "     |      2000-01-01 00:00:00  0  3  6  9\n",
      "     |      2000-01-01 00:03:00  0  3  6  9\n",
      "     |      2000-01-01 00:06:00  0  3  6  9\n",
      "     |      \n",
      "     |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      "     |      specify on level the resampling needs to take place.\n",
      "     |      \n",
      "     |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      "     |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      "     |                             columns=['a', 'b', 'c', 'd'],\n",
      "     |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      "     |                             )\n",
      "     |      >>> df2.resample('3T', level=0).sum()\n",
      "     |                           a  b   c   d\n",
      "     |      2000-01-01 00:00:00  0  6  12  18\n",
      "     |      2000-01-01 00:03:00  0  4   8  12\n",
      "     |  \n",
      "     |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      "     |      Returns a random sample of items from an axis of object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, optional\n",
      "     |          Number of items from axis to return. Cannot be used with `frac`.\n",
      "     |          Default = 1 if `frac` = None.\n",
      "     |      frac : float, optional\n",
      "     |          Fraction of axis items to return. Cannot be used with `n`.\n",
      "     |      replace : boolean, optional\n",
      "     |          Sample with or without replacement. Default = False.\n",
      "     |      weights : str or ndarray-like, optional\n",
      "     |          Default 'None' results in equal probability weighting.\n",
      "     |          If passed a Series, will align with target object on index. Index\n",
      "     |          values in weights not found in sampled object will be ignored and\n",
      "     |          index values in sampled object not in weights will be assigned\n",
      "     |          weights of zero.\n",
      "     |          If called on a DataFrame, will accept the name of a column\n",
      "     |          when axis = 0.\n",
      "     |          Unless weights are a Series, weights must be same length as axis\n",
      "     |          being sampled.\n",
      "     |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      "     |          Missing values in the weights column will be treated as zero.\n",
      "     |          inf and -inf values not allowed.\n",
      "     |      random_state : int or numpy.random.RandomState, optional\n",
      "     |          Seed for the random number generator (if int), or numpy RandomState\n",
      "     |          object.\n",
      "     |      axis : int or string, optional\n",
      "     |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      "     |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A new object of same type as caller.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Generate an example ``Series`` and ``DataFrame``:\n",
      "     |      \n",
      "     |      >>> s = pd.Series(np.random.randn(50))\n",
      "     |      >>> s.head()\n",
      "     |      0   -0.038497\n",
      "     |      1    1.820773\n",
      "     |      2   -0.972766\n",
      "     |      3   -1.598270\n",
      "     |      4   -1.095526\n",
      "     |      dtype: float64\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      "     |      >>> df.head()\n",
      "     |                A         B         C         D\n",
      "     |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      "     |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      "     |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      "     |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      "     |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      "     |      \n",
      "     |      Next extract a random sample from both of these objects...\n",
      "     |      \n",
      "     |      3 random elements from the ``Series``:\n",
      "     |      \n",
      "     |      >>> s.sample(n=3)\n",
      "     |      27   -0.994689\n",
      "     |      55   -1.049016\n",
      "     |      67   -0.224565\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      And a random 10% of the ``DataFrame`` with replacement:\n",
      "     |      \n",
      "     |      >>> df.sample(frac=0.1, replace=True)\n",
      "     |                 A         B         C         D\n",
      "     |      35  1.981780  0.142106  1.817165 -0.290805\n",
      "     |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      "     |      40  0.823173 -0.078816  1.009536  1.015108\n",
      "     |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      "     |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      "     |  \n",
      "     |  select(self, crit, axis=0)\n",
      "     |      Return data corresponding to axis labels matching criteria\n",
      "     |      \n",
      "     |      DEPRECATED: use df.loc[df.index.map(crit)] to select via labels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      crit : function\n",
      "     |          To be called on each index (label). Should return True or False\n",
      "     |      axis : int\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      selection : type of caller\n",
      "     |  \n",
      "     |  set_axis(self, labels, axis=0, inplace=None)\n",
      "     |      Assign desired index to given axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels: list-like or Index\n",
      "     |          The values for the new index\n",
      "     |      axis : int or string, default 0\n",
      "     |      inplace : boolean, default None\n",
      "     |          Whether to return a new NDFrame instance.\n",
      "     |      \n",
      "     |          WARNING: inplace=None currently falls back to to True, but\n",
      "     |          in a future version, will default to False.  Use inplace=True\n",
      "     |          explicitly rather than relying on the default.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |          The signature is make consistent to the rest of the API.\n",
      "     |          Previously, the \"axis\" and \"labels\" arguments were respectively\n",
      "     |          the first and second positional arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : NDFrame or None\n",
      "     |          An object of same type as caller if inplace=False, None otherwise.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |      a    1\n",
      "     |      b    2\n",
      "     |      c    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |         A  B\n",
      "     |      a  1  4\n",
      "     |      b  2  5\n",
      "     |      c  3  6\n",
      "     |      >>> df.set_axis(['I', 'II'], axis=1, inplace=False)\n",
      "     |         I  II\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |      >>> df.set_axis(['i', 'ii'], axis=1, inplace=True)\n",
      "     |      >>> df\n",
      "     |         i  ii\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |  \n",
      "     |  slice_shift(self, periods=1, axis=0)\n",
      "     |      Equivalent to `shift` without copying data. The shifted data will\n",
      "     |      not include the dropped periods and the shifted axis will be smaller\n",
      "     |      than the original.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      "     |      later during alignment.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : same type as caller\n",
      "     |  \n",
      "     |  squeeze(self, axis=None)\n",
      "     |      Squeeze length 1 dimensions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : None, integer or string axis name, optional\n",
      "     |          The axis to squeeze if 1-sized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar if 1-sized, else original object\n",
      "     |  \n",
      "     |  swapaxes(self, axis1, axis2, copy=True)\n",
      "     |      Interchange axes and swap values axes appropriately\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : same as input\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return the last n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_tail : type of caller\n",
      "     |          The last n rows of the caller object.\n",
      "     |  \n",
      "     |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      "     |      Return the elements in the given *positional* indices along an axis.\n",
      "     |      \n",
      "     |      This means that we are not indexing according to actual values in\n",
      "     |      the index attribute of the object. We are indexing according to the\n",
      "     |      actual position of the element in the object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      indices : array-like\n",
      "     |          An array of ints indicating which positions to take.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis on which to select elements. \"0\" means that we are\n",
      "     |          selecting rows, \"1\" means that we are selecting columns, etc.\n",
      "     |      convert : bool, default True\n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |             In the future, negative indices will always be converted.\n",
      "     |      \n",
      "     |          Whether to convert negative indices into positive ones.\n",
      "     |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      "     |          The conversions are similar to the behavior of indexing a\n",
      "     |          regular Python list.\n",
      "     |      is_copy : bool, default True\n",
      "     |          Whether to return a copy of the original object or not.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |                             ('parrot', 'bird',     24.0),\n",
      "     |                             ('lion',   'mammal',   80.5),\n",
      "     |                             ('monkey', 'mammal', np.nan)],\n",
      "     |                            columns=('name', 'class', 'max_speed'),\n",
      "     |                            index=[0, 2, 3, 1])\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      2  parrot    bird       24.0\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      "     |      \n",
      "     |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      "     |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      "     |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      "     |      \n",
      "     |      >>> df.take([0, 3])\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      "     |      \n",
      "     |      >>> df.take([1, 2], axis=1)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      2    bird       24.0\n",
      "     |      3  mammal       80.5\n",
      "     |      1  mammal        NaN\n",
      "     |      \n",
      "     |      We may take elements using negative integers for positive indices,\n",
      "     |      starting from the end of the object, just like with Python lists.\n",
      "     |      \n",
      "     |      >>> df.take([-1, -2])\n",
      "     |           name   class  max_speed\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      taken : type of caller\n",
      "     |          An array-like containing the elements taken from the object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.take\n",
      "     |      numpy.take\n",
      "     |  \n",
      "     |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      "     |      Attempt to write text representation of object to the system clipboard\n",
      "     |      This can be pasted into Excel, for example.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel : boolean, defaults to True\n",
      "     |              if True, use the provided separator, writing in a csv\n",
      "     |              format for allowing easy pasting into excel.\n",
      "     |              if False, write a string representation of the object\n",
      "     |              to the clipboard\n",
      "     |      sep : optional, defaults to tab\n",
      "     |      other keywords are passed to to_csv\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Requirements for your platform\n",
      "     |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      "     |        - Windows: none\n",
      "     |        - OS X: none\n",
      "     |  \n",
      "     |  to_dense(self)\n",
      "     |      Return dense representation of NDFrame (as opposed to sparse)\n",
      "     |  \n",
      "     |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      "     |      Write the contained data to an HDF5 file using HDFStore.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path (string) or HDFStore object\n",
      "     |      key : string\n",
      "     |          identifier for the group in the store\n",
      "     |      mode : optional, {'a', 'w', 'r+'}, default 'a'\n",
      "     |      \n",
      "     |        ``'w'``\n",
      "     |            Write; a new file is created (an existing file with the same\n",
      "     |            name would be deleted).\n",
      "     |        ``'a'``\n",
      "     |            Append; an existing file is opened for reading and writing,\n",
      "     |            and if the file does not exist it is created.\n",
      "     |        ``'r+'``\n",
      "     |            It is similar to ``'a'``, but the file must already exist.\n",
      "     |      format : 'fixed(f)|table(t)', default is 'fixed'\n",
      "     |          fixed(f) : Fixed format\n",
      "     |                     Fast writing/reading. Not-appendable, nor searchable\n",
      "     |          table(t) : Table format\n",
      "     |                     Write as a PyTables Table structure which may perform\n",
      "     |                     worse but allow more flexible operations like searching\n",
      "     |                     / selecting subsets of the data\n",
      "     |      append : boolean, default False\n",
      "     |          For Table formats, append the input data to the existing\n",
      "     |      data_columns :  list of columns, or True, default None\n",
      "     |          List of columns to create as indexed data columns for on-disk\n",
      "     |          queries, or True to use all columns. By default only the axes\n",
      "     |          of the object are indexed. See `here\n",
      "     |          <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
      "     |      \n",
      "     |          Applicable only to format='table'.\n",
      "     |      complevel : int, 0-9, default None\n",
      "     |          Specifies a compression level for data.\n",
      "     |          A value of 0 disables compression.\n",
      "     |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      "     |          Specifies the compression library to be used.\n",
      "     |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      "     |          (default if no compressor specified: 'blosc:blosclz'):\n",
      "     |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      "     |          'blosc:zlib', 'blosc:zstd'}.\n",
      "     |          Specifying a compression library which is not available issues\n",
      "     |          a ValueError.\n",
      "     |      fletcher32 : bool, default False\n",
      "     |          If applying compression use the fletcher32 checksum\n",
      "     |      dropna : boolean, default False.\n",
      "     |          If true, ALL nan rows will not be written to store.\n",
      "     |  \n",
      "     |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None)\n",
      "     |      Convert the object to a JSON string.\n",
      "     |      \n",
      "     |      Note NaN's and None will be converted to null and datetime objects\n",
      "     |      will be converted to UNIX timestamps.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path or buffer to write the result string\n",
      "     |          if this is None, return the converted string\n",
      "     |      orient : string\n",
      "     |      \n",
      "     |          * Series\n",
      "     |      \n",
      "     |            - default is 'index'\n",
      "     |            - allowed values are: {'split','records','index'}\n",
      "     |      \n",
      "     |          * DataFrame\n",
      "     |      \n",
      "     |            - default is 'columns'\n",
      "     |            - allowed values are:\n",
      "     |              {'split','records','index','columns','values'}\n",
      "     |      \n",
      "     |          * The format of the JSON string\n",
      "     |      \n",
      "     |            - split : dict like\n",
      "     |              {index -> [index], columns -> [columns], data -> [values]}\n",
      "     |            - records : list like\n",
      "     |              [{column -> value}, ... , {column -> value}]\n",
      "     |            - index : dict like {index -> {column -> value}}\n",
      "     |            - columns : dict like {column -> {index -> value}}\n",
      "     |            - values : just the values array\n",
      "     |            - table : dict like {'schema': {schema}, 'data': {data}}\n",
      "     |              describing the data, and the data component is\n",
      "     |              like ``orient='records'``.\n",
      "     |      \n",
      "     |              .. versionchanged:: 0.20.0\n",
      "     |      \n",
      "     |      date_format : {None, 'epoch', 'iso'}\n",
      "     |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      "     |          `iso` = ISO8601. The default depends on the `orient`. For\n",
      "     |          `orient='table'`, the default is `'iso'`. For all other orients,\n",
      "     |          the default is `'epoch'`.\n",
      "     |      double_precision : The number of decimal places to use when encoding\n",
      "     |          floating point values, default 10.\n",
      "     |      force_ascii : force encoded string to be ASCII, default True.\n",
      "     |      date_unit : string, default 'ms' (milliseconds)\n",
      "     |          The time unit to encode to, governs timestamp and ISO8601\n",
      "     |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "     |          microsecond, and nanosecond respectively.\n",
      "     |      default_handler : callable, default None\n",
      "     |          Handler to call if object cannot otherwise be converted to a\n",
      "     |          suitable format for JSON. Should receive a single argument which is\n",
      "     |          the object to convert and return a serialisable object.\n",
      "     |      lines : boolean, default False\n",
      "     |          If 'orient' is 'records' write out line delimited json format. Will\n",
      "     |          throw ValueError if incorrect 'orient' since others are not list\n",
      "     |          like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      compression : {None, 'gzip', 'bz2', 'xz'}\n",
      "     |          A string representing the compression to use in the output file,\n",
      "     |          only used when the first argument is a filename\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object with filtered info axis\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pd.read_json\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "     |      ...                   index=['row 1', 'row 2'],\n",
      "     |      ...                   columns=['col 1', 'col 2'])\n",
      "     |      >>> df.to_json(orient='split')\n",
      "     |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      "     |        \"index\":[\"row 1\",\"row 2\"],\n",
      "     |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='index')\n",
      "     |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "     |      Note that index labels are not preserved with this encoding.\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='records')\n",
      "     |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      "     |      \n",
      "     |      Encoding with Table Schema\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='table')\n",
      "     |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      "     |                   \"primaryKey\": \"index\",\n",
      "     |                   \"pandas_version\": \"0.20.0\"},\n",
      "     |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      "     |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      "     |  \n",
      "     |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      "     |      Render an object to a tabular environment table. You can splice\n",
      "     |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.20.2\n",
      "     |         Added to Series\n",
      "     |      \n",
      "     |      `to_latex`-specific options:\n",
      "     |      \n",
      "     |      bold_rows : boolean, default False\n",
      "     |          Make the row labels bold in the output\n",
      "     |      column_format : str, default None\n",
      "     |          The columns format as specified in `LaTeX table format\n",
      "     |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      "     |          columns\n",
      "     |      longtable : boolean, default will be read from the pandas config module\n",
      "     |          Default: False.\n",
      "     |          Use a longtable environment instead of tabular. Requires adding\n",
      "     |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      "     |      escape : boolean, default will be read from the pandas config module\n",
      "     |          Default: True.\n",
      "     |          When set to False prevents from escaping latex special\n",
      "     |          characters in column names.\n",
      "     |      encoding : str, default None\n",
      "     |          A string representing the encoding to use in the output file,\n",
      "     |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "     |      decimal : string, default '.'\n",
      "     |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      multicolumn : boolean, default True\n",
      "     |          Use \\multicolumn to enhance MultiIndex columns.\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multicolumn_format : str, default 'l'\n",
      "     |          The alignment for multicolumns, similar to `column_format`\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multirow : boolean, default False\n",
      "     |          Use \\multirow to enhance MultiIndex rows.\n",
      "     |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      "     |          Will print centered labels (instead of top-aligned)\n",
      "     |          across the contained rows, separating groups via clines.\n",
      "     |          The default will be read from the pandas config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |  \n",
      "     |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      "     |      msgpack (serialize) object to input file path\n",
      "     |      \n",
      "     |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      "     |      may not be stable until a future release.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string File path, buffer-like, or None\n",
      "     |          if None, return generated string\n",
      "     |      append : boolean whether to append to an existing msgpack\n",
      "     |          (default is False)\n",
      "     |      compress : type of compressor (zlib or blosc), default to None (no\n",
      "     |          compression)\n",
      "     |  \n",
      "     |  to_pickle(self, path, compression='infer', protocol=4)\n",
      "     |      Pickle (serialize) object to input file path.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string\n",
      "     |          File path\n",
      "     |      compression : {'infer', 'gzip', 'bz2', 'xz', None}, default 'infer'\n",
      "     |          a string representing the compression to use in the output file\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      protocol : int\n",
      "     |          Int which indicates which protocol should be used by the pickler,\n",
      "     |          default HIGHEST_PROTOCOL (see [1], paragraph 12.1.2). The possible\n",
      "     |          values for this parameter depend on the version of Python. For\n",
      "     |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      "     |          valid value. For Python >= 3.4, 4 is a valid value.A negative value\n",
      "     |          for the protocol parameter is equivalent to setting its value to\n",
      "     |          HIGHEST_PROTOCOL.\n",
      "     |      \n",
      "     |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |  \n",
      "     |  to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : string\n",
      "     |          Name of SQL table\n",
      "     |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      "     |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "     |          library. If a DBAPI2 object, only sqlite3 is supported.\n",
      "     |      flavor : 'sqlite', default None\n",
      "     |          .. deprecated:: 0.19.0\n",
      "     |             'sqlite' is the only supported option if SQLAlchemy is not\n",
      "     |             used.\n",
      "     |      schema : string, default None\n",
      "     |          Specify the schema (if database flavor supports this). If None, use\n",
      "     |          default schema.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          - fail: If table exists, do nothing.\n",
      "     |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          - append: If table exists, insert data. Create if does not exist.\n",
      "     |      index : boolean, default True\n",
      "     |          Write DataFrame index as a column.\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s). If None is given (default) and\n",
      "     |          `index` is True, then the index names are used.\n",
      "     |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      chunksize : int, default None\n",
      "     |          If not None, then rows will be written in batches of this size at a\n",
      "     |          time.  If None, all rows will be written at once.\n",
      "     |      dtype : dict of column name to SQL type, default None\n",
      "     |          Optional specifying the datatype for columns. The SQL type should\n",
      "     |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      "     |  \n",
      "     |  to_xarray(self)\n",
      "     |      Return an xarray object from the pandas object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a DataArray for a Series\n",
      "     |      a Dataset for a DataFrame\n",
      "     |      a DataArray for higher dims\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)})\n",
      "     |      >>> df\n",
      "     |         A    B    C\n",
      "     |      0  1  foo  4.0\n",
      "     |      1  1  bar  5.0\n",
      "     |      2  2  foo  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (index: 3)\n",
      "     |      Coordinates:\n",
      "     |        * index    (index) int64 0 1 2\n",
      "     |      Data variables:\n",
      "     |          A        (index) int64 1 1 2\n",
      "     |          B        (index) object 'foo' 'bar' 'foo'\n",
      "     |          C        (index) float64 4.0 5.0 6.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)}\n",
      "     |                           ).set_index(['B','A'])\n",
      "     |      >>> df\n",
      "     |               C\n",
      "     |      B   A\n",
      "     |      foo 1  4.0\n",
      "     |      bar 1  5.0\n",
      "     |      foo 2  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (A: 2, B: 2)\n",
      "     |      Coordinates:\n",
      "     |        * B        (B) object 'bar' 'foo'\n",
      "     |        * A        (A) int64 1 2\n",
      "     |      Data variables:\n",
      "     |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      "     |      \n",
      "     |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      "     |                       items=list('ABCD'),\n",
      "     |                       major_axis=pd.date_range('20130101', periods=3),\n",
      "     |                       minor_axis=['first', 'second'])\n",
      "     |      >>> p\n",
      "     |      <class 'pandas.core.panel.Panel'>\n",
      "     |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      "     |      Items axis: A to D\n",
      "     |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      "     |      Minor_axis axis: first to second\n",
      "     |      \n",
      "     |      >>> p.to_xarray()\n",
      "     |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      "     |      array([[[ 0,  1],\n",
      "     |              [ 2,  3],\n",
      "     |              [ 4,  5]],\n",
      "     |             [[ 6,  7],\n",
      "     |              [ 8,  9],\n",
      "     |              [10, 11]],\n",
      "     |             [[12, 13],\n",
      "     |              [14, 15],\n",
      "     |              [16, 17]],\n",
      "     |             [[18, 19],\n",
      "     |              [20, 21],\n",
      "     |              [22, 23]]])\n",
      "     |      Coordinates:\n",
      "     |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      "     |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      "     |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      "     |  \n",
      "     |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      "     |      Truncates a sorted DataFrame/Series before and/or after some\n",
      "     |      particular index value. If the axis contains only datetime values,\n",
      "     |      before/after parameters are converted to datetime values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      before : date, string, int\n",
      "     |          Truncate all rows before this index value\n",
      "     |      after : date, string, int\n",
      "     |          Truncate all rows after this index value\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      \n",
      "     |          * 0 or 'index': apply truncation to rows\n",
      "     |          * 1 or 'columns': apply truncation to columns\n",
      "     |          Default is stat axis for given data type (0 for Series and\n",
      "     |          DataFrames, 1 for Panels)\n",
      "     |      copy : boolean, default is True,\n",
      "     |          return a copy of the truncated section\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      truncated : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      "     |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      "     |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      "     |      ...                    index=[1, 2, 3, 4, 5])\n",
      "     |      >>> df.truncate(before=2, after=4)\n",
      "     |         A  B  C\n",
      "     |      2  b  g  l\n",
      "     |      3  c  h  m\n",
      "     |      4  d  i  n\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
      "     |      ...                    'B': [6, 7, 8, 9, 10],\n",
      "     |      ...                    'C': [11, 12, 13, 14, 15]},\n",
      "     |      ...                    index=['a', 'b', 'c', 'd', 'e'])\n",
      "     |      >>> df.truncate(before='b', after='d')\n",
      "     |         A  B   C\n",
      "     |      b  2  7  12\n",
      "     |      c  3  8  13\n",
      "     |      d  4  9  14\n",
      "     |      \n",
      "     |      The index values in ``truncate`` can be datetimes or string\n",
      "     |      dates. Note that ``truncate`` assumes a 0 value for any unspecified\n",
      "     |      date component in a ``DatetimeIndex`` in contrast to slicing which\n",
      "     |      returns any partially matching dates.\n",
      "     |      \n",
      "     |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      "     |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      "     |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      "     |                           A\n",
      "     |      2016-01-09 23:59:56  1\n",
      "     |      2016-01-09 23:59:57  1\n",
      "     |      2016-01-09 23:59:58  1\n",
      "     |      2016-01-09 23:59:59  1\n",
      "     |      2016-01-10 00:00:00  1\n",
      "     |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      "     |                           A\n",
      "     |      2016-01-10 23:59:55  1\n",
      "     |      2016-01-10 23:59:56  1\n",
      "     |      2016-01-10 23:59:57  1\n",
      "     |      2016-01-10 23:59:58  1\n",
      "     |      2016-01-10 23:59:59  1\n",
      "     |  \n",
      "     |  tshift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift the time index, using the index's frequency if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, default None\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      "     |      axis : int or basestring\n",
      "     |          Corresponds to the axis that contains the Index\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is not specified then tries to use the freq or inferred_freq\n",
      "     |      attributes of the index. If neither of those attributes exist, a\n",
      "     |      ValueError is thrown\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : NDFrame\n",
      "     |  \n",
      "     |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      "     |      Convert tz-aware axis to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to convert\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the axis is tz-naive.\n",
      "     |  \n",
      "     |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      "     |      Localize tz-naive TimeSeries to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to localize\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      "     |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      "     |            order\n",
      "     |          - bool-ndarray where True signifies a DST time, False designates\n",
      "     |            a non-DST time (note that this flag is only applicable for\n",
      "     |            ambiguous times)\n",
      "     |          - 'NaT' will return NaT where there are ambiguous times\n",
      "     |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      "     |            times\n",
      "     |      infer_dst : boolean, default False\n",
      "     |          .. deprecated:: 0.15.0\n",
      "     |             Attempt to infer fall dst-transition hours based on order\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the TimeSeries is tz-aware and tz is not None.\n",
      "     |  \n",
      "     |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is True and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is True, keep the original value. Where\n",
      "     |          False, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is False are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The where method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``where`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.mask`\n",
      "     |  \n",
      "     |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      "     |      Returns a cross-section (row(s) or column(s)) from the\n",
      "     |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : object\n",
      "     |          Some label contained in the index, or partially in a MultiIndex\n",
      "     |      axis : int, default 0\n",
      "     |          Axis to retrieve cross-section on\n",
      "     |      level : object, defaults to first n levels (n=1 or len(key))\n",
      "     |          In case of a key partially contained in a MultiIndex, indicate\n",
      "     |          which levels are used. Levels can be referred by label or position.\n",
      "     |      drop_level : boolean, default True\n",
      "     |          If False, returns object with same levels as self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |      a  4  5  2\n",
      "     |      b  4  0  9\n",
      "     |      c  9  7  3\n",
      "     |      >>> df.xs('a')\n",
      "     |      A    4\n",
      "     |      B    5\n",
      "     |      C    2\n",
      "     |      Name: a\n",
      "     |      >>> df.xs('C', axis=1)\n",
      "     |      a    2\n",
      "     |      b    9\n",
      "     |      c    3\n",
      "     |      Name: C\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                          A  B  C  D\n",
      "     |      first second third\n",
      "     |      bar   one    1      4  1  8  9\n",
      "     |            two    1      7  5  5  0\n",
      "     |      baz   one    1      6  6  8  0\n",
      "     |            three  2      5  3  5  3\n",
      "     |      >>> df.xs(('baz', 'three'))\n",
      "     |             A  B  C  D\n",
      "     |      third\n",
      "     |      2      5  3  5  3\n",
      "     |      >>> df.xs('one', level=1)\n",
      "     |                   A  B  C  D\n",
      "     |      first third\n",
      "     |      bar   1      4  1  8  9\n",
      "     |      baz   1      6  6  8  0\n",
      "     |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      "     |              A  B  C  D\n",
      "     |      second\n",
      "     |      three   5  3  5  3\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      xs : Series or DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      xs is only for getting, not setting values.\n",
      "     |      \n",
      "     |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      "     |      levels.  It is a superset of xs functionality, see\n",
      "     |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  at\n",
      "     |      Fast label-based scalar accessor\n",
      "     |      \n",
      "     |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  blocks\n",
      "     |      Internal property, property synonym for as_blocks()\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |  \n",
      "     |  iat\n",
      "     |      Fast integer location scalar accessor.\n",
      "     |      \n",
      "     |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  iloc\n",
      "     |      Purely integer-location based indexing for selection by position.\n",
      "     |      \n",
      "     |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      "     |      ``length-1`` of the axis), but may also be used with a boolean\n",
      "     |      array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - An integer, e.g. ``5``.\n",
      "     |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      "     |      - A slice object with ints, e.g. ``1:7``.\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      "     |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      "     |      indexing (this conforms with python/numpy *slice* semantics).\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      "     |  \n",
      "     |  ix\n",
      "     |      A primarily label-location based indexer, with integer position\n",
      "     |      fallback.\n",
      "     |      \n",
      "     |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      "     |      primarily label based, but will fall back to integer positional\n",
      "     |      access unless the corresponding axis is of integer type.\n",
      "     |      \n",
      "     |      ``.ix`` is the most general indexer and will support any of the\n",
      "     |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      "     |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      "     |      with mixed positional and label based hierachical indexes.\n",
      "     |      \n",
      "     |      However, when an axis is integer based, ONLY label based access\n",
      "     |      and not positional access is supported. Thus, in such cases, it's\n",
      "     |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      "     |      \n",
      "     |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      "     |  \n",
      "     |  loc\n",
      "     |      Purely label-location based indexer for selection by label.\n",
      "     |      \n",
      "     |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      "     |      boolean array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      "     |        interpreted as a *label* of the index, and **never** as an\n",
      "     |        integer position along the index).\n",
      "     |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      "     |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      "     |        to usual python slices, **both** the start and the stop are included!).\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Label <indexing.label>`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  is_copy = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for a object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __bytes__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Invoked by bytes(obj) in py3 only.\n",
      "     |      Yields a bytestring in both py2/py3.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return a string representation for a particular Object\n",
      "     |      \n",
      "     |      Invoked by str(df) in both py2/py3.\n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion\n",
      "     |      Only provide 'public' methods\n",
      "    \n",
      "    class SubclassedSparseDataFrame(pandas.core.sparse.frame.SparseDataFrame)\n",
      "     |  DataFrame containing sparse floating point data in the form of SparseSeries\n",
      "     |  objects\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : same types as can be passed to DataFrame or scipy.sparse.spmatrix\n",
      "     |  index : array-like, optional\n",
      "     |  column : array-like, optional\n",
      "     |  default_kind : {'block', 'integer'}, default 'block'\n",
      "     |      Default sparse kind for converting Series to SparseSeries. Will not\n",
      "     |      override SparseSeries passed into constructor\n",
      "     |  default_fill_value : float\n",
      "     |      Default fill_value for converting Series to SparseSeries\n",
      "     |      (default: nan). Will not override SparseSeries passed in.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SubclassedSparseDataFrame\n",
      "     |      pandas.core.sparse.frame.SparseDataFrame\n",
      "     |      pandas.core.frame.DataFrame\n",
      "     |      pandas.core.generic.NDFrame\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.base.StringMixin\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from pandas.core.sparse.frame.SparseDataFrame:\n",
      "     |  \n",
      "     |  __add__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __add__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __and__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __and__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __array_wrap__(self, result)\n",
      "     |  \n",
      "     |  __div__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Wrapper for comparison method __eq__\n",
      "     |  \n",
      "     |  __floordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __floordiv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Wrapper for comparison method __ge__\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Retrieve column or slice from DataFrame\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Wrapper for comparison method __gt__\n",
      "     |  \n",
      "     |  __iadd__ = f(self, other)\n",
      "     |  \n",
      "     |  __iand__ = f(self, other)\n",
      "     |  \n",
      "     |  __ifloordiv__ = f(self, other)\n",
      "     |  \n",
      "     |  __imod__ = f(self, other)\n",
      "     |  \n",
      "     |  __imul__ = f(self, other)\n",
      "     |  \n",
      "     |  __init__(self, data=None, index=None, columns=None, default_kind=None, default_fill_value=None, dtype=None, copy=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __ior__ = f(self, other)\n",
      "     |  \n",
      "     |  __ipow__ = f(self, other)\n",
      "     |  \n",
      "     |  __isub__ = f(self, other)\n",
      "     |  \n",
      "     |  __itruediv__ = f(self, other)\n",
      "     |  \n",
      "     |  __ixor__ = f(self, other)\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Wrapper for comparison method __le__\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Wrapper for comparison method __lt__\n",
      "     |  \n",
      "     |  __mod__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __mod__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __mul__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __mul__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Wrapper for comparison method __ne__\n",
      "     |  \n",
      "     |  __or__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __or__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __pow__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __pow__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __radd__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __radd__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rand__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __rand__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rdiv__ = __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rfloordiv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rmod__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rmod__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rmul__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rmul__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __ror__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __ror__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rpow__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rpow__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rsub__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rsub__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __rxor__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __rxor__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __sub__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __sub__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      "     |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  __xor__(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Binary operator __xor__ with support to substitute a fill_value for missing data in\n",
      "     |      one of the inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |  \n",
      "     |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Addition of dataframe and other, element-wise (binary operator `add`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.radd\n",
      "     |  \n",
      "     |  apply(self, func, axis=0, broadcast=False, reduce=False)\n",
      "     |      Analogous to DataFrame.apply, for SparseDataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          Function to apply to each column\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |      broadcast : bool, default False\n",
      "     |          For aggregation functions, return object of same size with values\n",
      "     |          propagated\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : Series or SparseDataFrame\n",
      "     |  \n",
      "     |  applymap(self, func)\n",
      "     |      Apply a function to a DataFrame that is intended to operate\n",
      "     |      elementwise, i.e. like doing map(func, series) for each series in the\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          Python function, returns a single value from a single value\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : DataFrame\n",
      "     |  \n",
      "     |  astype(self, dtype)\n",
      "     |      Cast a pandas object to a specified dtype ``dtype``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data type, or dict of column name -> data type\n",
      "     |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      "     |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      "     |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      "     |          or more of the DataFrame's columns to column-specific types.\n",
      "     |      copy : bool, default True.\n",
      "     |          Return a copy when ``copy=True`` (be very careful setting\n",
      "     |          ``copy=False`` as changes to values then may propagate to other\n",
      "     |          pandas objects).\n",
      "     |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      "     |          Control raising of exceptions on invalid data for provided dtype.\n",
      "     |      \n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      raise_on_error : raise on invalid input\n",
      "     |          .. deprecated:: 0.20.0\n",
      "     |             Use ``errors`` instead\n",
      "     |      kwargs : keyword arguments to pass on to the constructor\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      casted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      "     |      >>> ser\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int32\n",
      "     |      >>> ser.astype('int64')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Convert to categorical type:\n",
      "     |      \n",
      "     |      >>> ser.astype('category')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [1, 2]\n",
      "     |      \n",
      "     |      Convert to ordered categorical type with custom ordering:\n",
      "     |      \n",
      "     |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [2 < 1]\n",
      "     |      \n",
      "     |      Note that using ``copy=False`` and changing data on a new\n",
      "     |      pandas object may propagate changes:\n",
      "     |      \n",
      "     |      >>> s1 = pd.Series([1,2])\n",
      "     |      >>> s2 = s1.astype('int', copy=False)\n",
      "     |      >>> s2[0] = 10\n",
      "     |      >>> s1  # note that s1[0] has changed too\n",
      "     |      0    10\n",
      "     |      1     2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to a numeric type.\n",
      "     |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      "     |  \n",
      "     |  copy(self, deep=True)\n",
      "     |      Make a copy of this SparseDataFrame\n",
      "     |  \n",
      "     |  count(self, axis=0, **kwds)\n",
      "     |      Return Series with number of non-NA/null observations over requested\n",
      "     |      axis. Works with non-floating point data as well (detects NaN and None)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a DataFrame\n",
      "     |      numeric_only : boolean, default False\n",
      "     |          Include only float, int, boolean data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      count : Series (or DataFrame if level specified)\n",
      "     |  \n",
      "     |  cumsum(self, axis=0, *args, **kwargs)\n",
      "     |      Return SparseDataFrame of cumulative sums over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0, 1}\n",
      "     |          0 for row-wise, 1 for column-wise\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : SparseDataFrame\n",
      "     |  \n",
      "     |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rtruediv\n",
      "     |  \n",
      "     |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rtruediv\n",
      "     |  \n",
      "     |  eq(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods eq\n",
      "     |  \n",
      "     |  fillna(self, value=None, method=None, axis=0, inplace=False, limit=None, downcast=None)\n",
      "     |      Fill NA/NaN values using the specified method\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar, dict, Series, or DataFrame\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a\n",
      "     |          dict/Series/DataFrame of values specifying which value to use for\n",
      "     |          each index (for a Series) or column (for a DataFrame). (values not\n",
      "     |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      "     |          be a list.\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use NEXT valid observation to fill gap\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, fill in place. Note: this will modify any\n",
      "     |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      "     |          DataFrame).\n",
      "     |      limit : int, default None\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled. Must be greater than 0 if not None.\n",
      "     |      downcast : dict, default is None\n",
      "     |          a dict of item->dtype of what to downcast if possible,\n",
      "     |          or the string 'infer' which will try to downcast to an appropriate\n",
      "     |          equal type (e.g. float64 to int64 if possible)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, asfreq\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "     |      ...                    [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      "     |      ...                    [np.nan, 3, np.nan, 4]],\n",
      "     |      ...                    columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      3  NaN  3.0 NaN  4\n",
      "     |      \n",
      "     |      Replace all NaN elements with 0s.\n",
      "     |      \n",
      "     |      >>> df.fillna(0)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 0.0 0\n",
      "     |      1   3.0 4.0 0.0 1\n",
      "     |      2   0.0 0.0 0.0 5\n",
      "     |      3   0.0 3.0 0.0 4\n",
      "     |      \n",
      "     |      We can also propagate non-null values forward or backward.\n",
      "     |      \n",
      "     |      >>> df.fillna(method='ffill')\n",
      "     |          A   B   C   D\n",
      "     |      0   NaN 2.0 NaN 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   3.0 4.0 NaN 5\n",
      "     |      3   3.0 3.0 NaN 4\n",
      "     |      \n",
      "     |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "     |      2, and 3 respectively.\n",
      "     |      \n",
      "     |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "     |      >>> df.fillna(value=values)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 2.0 1\n",
      "     |      2   0.0 1.0 2.0 5\n",
      "     |      3   0.0 3.0 2.0 4\n",
      "     |      \n",
      "     |      Only replace the first NaN element.\n",
      "     |      \n",
      "     |      >>> df.fillna(value=values, limit=1)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   NaN 1.0 NaN 5\n",
      "     |      3   NaN 3.0 NaN 4\n",
      "     |  \n",
      "     |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rfloordiv\n",
      "     |  \n",
      "     |  ge(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods ge\n",
      "     |  \n",
      "     |  get_value(self, index, col, takeable=False)\n",
      "     |      Quickly retrieve single value at passed column and index\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : row label\n",
      "     |      col : column label\n",
      "     |      takeable : interpret the index/col as indexers, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar value\n",
      "     |  \n",
      "     |  gt(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods gt\n",
      "     |  \n",
      "     |  isna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.notna : boolean inverse of isna\n",
      "     |      %(klass)s.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  isnull = isna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.notna : boolean inverse of isna\n",
      "     |      %(klass)s.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  le(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods le\n",
      "     |  \n",
      "     |  lt(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods lt\n",
      "     |  \n",
      "     |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rmod\n",
      "     |  \n",
      "     |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rmul\n",
      "     |  \n",
      "     |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rmul\n",
      "     |  \n",
      "     |  ne(self, other, axis='columns', level=None)\n",
      "     |      Wrapper for flexible comparison methods ne\n",
      "     |  \n",
      "     |  notna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.isna : boolean inverse of notna\n",
      "     |      %(klass)s.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  notnull = notna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.isna : boolean inverse of notna\n",
      "     |      %(klass)s.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rpow\n",
      "     |  \n",
      "     |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      "     |      \n",
      "     |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.add\n",
      "     |  \n",
      "     |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.truediv\n",
      "     |  \n",
      "     |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.floordiv\n",
      "     |  \n",
      "     |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      "     |      \n",
      "     |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.mod\n",
      "     |  \n",
      "     |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      "     |      \n",
      "     |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.mul\n",
      "     |  \n",
      "     |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      "     |      \n",
      "     |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pow\n",
      "     |  \n",
      "     |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      "     |      \n",
      "     |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.sub\n",
      "     |  \n",
      "     |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.truediv\n",
      "     |  \n",
      "     |  set_value(self, index, col, value, takeable=False)\n",
      "     |      Put single value at passed column and index\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : row label\n",
      "     |      col : column label\n",
      "     |      value : scalar value\n",
      "     |      takeable : interpret the index/col as indexers, default False\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method *always* returns a new object. It is currently not\n",
      "     |      particularly efficient (and potentially very expensive) but is provided\n",
      "     |      for API compatibility with DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      frame : DataFrame\n",
      "     |  \n",
      "     |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rsub\n",
      "     |  \n",
      "     |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rsub\n",
      "     |  \n",
      "     |  to_coo(self)\n",
      "     |      Return the contents of the frame as a sparse SciPy COO matrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coo_matrix : scipy.sparse.spmatrix\n",
      "     |          If the caller is heterogeneous and contains booleans or objects,\n",
      "     |          the result will be of dtype=object. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The dtype will be the lowest-common-denominator type (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32. By numpy.find_common_type convention, mixing int64 and\n",
      "     |      and uint64 will result in a float64 dtype.\n",
      "     |  \n",
      "     |  to_dense(self)\n",
      "     |      Convert to dense DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame\n",
      "     |  \n",
      "     |  transpose(self, *args, **kwargs)\n",
      "     |      Returns a DataFrame with the rows/columns switched.\n",
      "     |  \n",
      "     |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      "     |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series, DataFrame, or constant\n",
      "     |      axis : {0, 1, 'index', 'columns'}\n",
      "     |          For Series input, axis to match Series index on\n",
      "     |      fill_value : None or float value, default None\n",
      "     |          Fill missing (NaN) values with this value. If both DataFrame\n",
      "     |          locations are missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Mismatched indices will be unioned together\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.rtruediv\n",
      "     |  \n",
      "     |  xs(self, key, axis=0, copy=False)\n",
      "     |      Returns a row (cross-section) from the SparseDataFrame as a Series\n",
      "     |      object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : some index contained in the index\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      xs : Series\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.sparse.frame.SparseDataFrame:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Returns a DataFrame with the rows/columns switched.\n",
      "     |  \n",
      "     |  default_fill_value\n",
      "     |  \n",
      "     |  default_kind\n",
      "     |  \n",
      "     |  density\n",
      "     |      Ratio of non-sparse points to total (dense) data points\n",
      "     |      represented in the frame\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns length of info axis, but here we use the index\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Return a string representation for a particular DataFrame\n",
      "     |      \n",
      "     |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      "     |      py2/py3.\n",
      "     |  \n",
      "     |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      >>> df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      Aggregate these functions across all columns\n",
      "     |      \n",
      "     |      >>> df.agg(['sum', 'min'])\n",
      "     |                  A         B         C\n",
      "     |      sum -0.182253 -0.614014 -2.909534\n",
      "     |      min -1.916563 -1.460076 -1.568297\n",
      "     |      \n",
      "     |      Different aggregations per column\n",
      "     |      \n",
      "     |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      "     |                  A         B\n",
      "     |      max       NaN  1.514318\n",
      "     |      min -1.916563 -1.460076\n",
      "     |      sum -0.182253       NaN\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.transform\n",
      "     |      pandas.DataFrame.groupby.aggregate\n",
      "     |      pandas.DataFrame.resample.aggregate\n",
      "     |      pandas.DataFrame.rolling.aggregate\n",
      "     |  \n",
      "     |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      >>> df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      Aggregate these functions across all columns\n",
      "     |      \n",
      "     |      >>> df.agg(['sum', 'min'])\n",
      "     |                  A         B         C\n",
      "     |      sum -0.182253 -0.614014 -2.909534\n",
      "     |      min -1.916563 -1.460076 -1.568297\n",
      "     |      \n",
      "     |      Different aggregations per column\n",
      "     |      \n",
      "     |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      "     |                  A         B\n",
      "     |      max       NaN  1.514318\n",
      "     |      min -1.916563 -1.460076\n",
      "     |      sum -0.182253       NaN\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.transform\n",
      "     |      pandas.DataFrame.groupby.aggregate\n",
      "     |      pandas.DataFrame.resample.aggregate\n",
      "     |      pandas.DataFrame.rolling.aggregate\n",
      "     |  \n",
      "     |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      "     |      Align two objects on their axes with the\n",
      "     |      specified join method for each axis Index\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series\n",
      "     |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      "     |      axis : allowed axis of the other object, default None\n",
      "     |          Align on index (0), columns (1), or both (None)\n",
      "     |      level : int or level name, default None\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      copy : boolean, default True\n",
      "     |          Always returns new objects. If copy=False and no reindexing is\n",
      "     |          required then original objects are returned.\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      method : str, default None\n",
      "     |      limit : int, default None\n",
      "     |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Filling axis, method and limit\n",
      "     |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      "     |          Broadcast values along this axis, if aligning two objects of\n",
      "     |          different dimensions\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      (left, right) : (DataFrame, type of other)\n",
      "     |          Aligned objects\n",
      "     |  \n",
      "     |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether all elements are True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      all : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether any element is True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      any : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  append(self, other, ignore_index=False, verify_integrity=False)\n",
      "     |      Append rows of `other` to the end of this frame, returning a new\n",
      "     |      object. Columns not in this frame are added as new columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series/dict-like object, or list of these\n",
      "     |          The data to append.\n",
      "     |      ignore_index : boolean, default False\n",
      "     |          If True, do not use the index labels.\n",
      "     |      verify_integrity : boolean, default False\n",
      "     |          If True, raise ValueError on creating index with duplicates.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      appended : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If a list of dict/series is passed and the keys are all contained in\n",
      "     |      the DataFrame's index, the order of the columns in the resulting\n",
      "     |      DataFrame will be unchanged.\n",
      "     |      \n",
      "     |      Iteratively appending rows to a DataFrame can be more computationally\n",
      "     |      intensive than a single concatenate. A better solution is to append\n",
      "     |      those rows to a list and then concatenate the list with the original\n",
      "     |      DataFrame all at once.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.concat : General function to concatenate DataFrame, Series\n",
      "     |          or Panel objects\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      1  3  4\n",
      "     |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      "     |      >>> df.append(df2)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      1  3  4\n",
      "     |      0  5  6\n",
      "     |      1  7  8\n",
      "     |      \n",
      "     |      With `ignore_index` set to True:\n",
      "     |      \n",
      "     |      >>> df.append(df2, ignore_index=True)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      1  3  4\n",
      "     |      2  5  6\n",
      "     |      3  7  8\n",
      "     |      \n",
      "     |      The following, while not recommended methods for generating DataFrames,\n",
      "     |      show two ways to generate a DataFrame from multiple data sources.\n",
      "     |      \n",
      "     |      Less efficient:\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(columns=['A'])\n",
      "     |      >>> for i in range(5):\n",
      "     |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  0\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      4  4\n",
      "     |      \n",
      "     |      More efficient:\n",
      "     |      \n",
      "     |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      "     |      ...           ignore_index=True)\n",
      "     |         A\n",
      "     |      0  0\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      4  4\n",
      "     |  \n",
      "     |  assign(self, **kwargs)\n",
      "     |      Assign new columns to a DataFrame, returning a new object\n",
      "     |      (a copy) with all the original columns in addition to the new ones.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kwargs : keyword, value pairs\n",
      "     |          keywords are the column names. If the values are\n",
      "     |          callable, they are computed on the DataFrame and\n",
      "     |          assigned to the new columns. The callable must not\n",
      "     |          change input DataFrame (though pandas doesn't check it).\n",
      "     |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      "     |          they are simply assigned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame\n",
      "     |          A new DataFrame with the new columns in addition to\n",
      "     |          all the existing columns.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For python 3.6 and above, the columns are inserted in the order of\n",
      "     |      \\*\\*kwargs. For python 3.5 and earlier, since \\*\\*kwargs is unordered,\n",
      "     |      the columns are inserted in alphabetical order at the end of your\n",
      "     |      DataFrame.  Assigning multiple columns within the same ``assign``\n",
      "     |      is possible, but you cannot reference other columns created within\n",
      "     |      the same ``assign`` call.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = DataFrame({'A': range(1, 11), 'B': np.random.randn(10)})\n",
      "     |      \n",
      "     |      Where the value is a callable, evaluated on `df`:\n",
      "     |      \n",
      "     |      >>> df.assign(ln_A = lambda x: np.log(x.A))\n",
      "     |          A         B      ln_A\n",
      "     |      0   1  0.426905  0.000000\n",
      "     |      1   2 -0.780949  0.693147\n",
      "     |      2   3 -0.418711  1.098612\n",
      "     |      3   4 -0.269708  1.386294\n",
      "     |      4   5 -0.274002  1.609438\n",
      "     |      5   6 -0.500792  1.791759\n",
      "     |      6   7  1.649697  1.945910\n",
      "     |      7   8 -1.495604  2.079442\n",
      "     |      8   9  0.549296  2.197225\n",
      "     |      9  10 -0.758542  2.302585\n",
      "     |      \n",
      "     |      Where the value already exists and is inserted:\n",
      "     |      \n",
      "     |      >>> newcol = np.log(df['A'])\n",
      "     |      >>> df.assign(ln_A=newcol)\n",
      "     |          A         B      ln_A\n",
      "     |      0   1  0.426905  0.000000\n",
      "     |      1   2 -0.780949  0.693147\n",
      "     |      2   3 -0.418711  1.098612\n",
      "     |      3   4 -0.269708  1.386294\n",
      "     |      4   5 -0.274002  1.609438\n",
      "     |      5   6 -0.500792  1.791759\n",
      "     |      6   7  1.649697  1.945910\n",
      "     |      7   8 -1.495604  2.079442\n",
      "     |      8   9  0.549296  2.197225\n",
      "     |      9  10 -0.758542  2.302585\n",
      "     |  \n",
      "     |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, **kwds)\n",
      "     |      Make a box plot from DataFrame column optionally grouped by some columns or\n",
      "     |      other inputs\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : the pandas object holding the data\n",
      "     |      column : column name or list of names, or vector\n",
      "     |          Can be any valid input to groupby\n",
      "     |      by : string or sequence\n",
      "     |          Column in the DataFrame to group by\n",
      "     |      ax : Matplotlib axes object, optional\n",
      "     |      fontsize : int or string\n",
      "     |      rot : label rotation angle\n",
      "     |      figsize : A tuple (width, height) in inches\n",
      "     |      grid : Setting this to True will show the grid\n",
      "     |      layout : tuple (optional)\n",
      "     |          (rows, columns) for the layout of the plot\n",
      "     |      return_type : {None, 'axes', 'dict', 'both'}, default None\n",
      "     |          The kind of object to return. The default is ``axes``\n",
      "     |          'axes' returns the matplotlib axes the boxplot is drawn on;\n",
      "     |          'dict' returns a dictionary  whose values are the matplotlib\n",
      "     |          Lines of the boxplot;\n",
      "     |          'both' returns a namedtuple with the axes and dict.\n",
      "     |      \n",
      "     |          When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      "     |          is returned, unless ``return_type`` is None, in which case a NumPy\n",
      "     |          array of axes is returned with the same shape as ``layout``.\n",
      "     |          See the prose documentation for more.\n",
      "     |      \n",
      "     |      kwds : other plotting keyword arguments to be passed to matplotlib boxplot\n",
      "     |             function\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      lines : dict\n",
      "     |      ax : matplotlib Axes\n",
      "     |      (ax, lines): namedtuple\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      "     |      of the lines after plotting. In this case a dict containing the Lines\n",
      "     |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      "     |  \n",
      "     |  combine(self, other, func, fill_value=None, overwrite=True)\n",
      "     |      Add two DataFrame objects and do not propagate NaN values, so if for a\n",
      "     |      (column, time) one frame is missing a value, it will default to the\n",
      "     |      other frame's value (which might be NaN as well)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame\n",
      "     |      func : function\n",
      "     |          Function that takes two series as inputs and return a Series or a\n",
      "     |          scalar\n",
      "     |      fill_value : scalar value\n",
      "     |      overwrite : boolean, default True\n",
      "     |          If True then overwrite values for common keys in the calling frame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df1 = DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      "     |      >>> df2 = DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      "     |      >>> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2)\n",
      "     |         A  B\n",
      "     |      0  0  3\n",
      "     |      1  0  3\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      "     |          non-null values in frame calling the method\n",
      "     |  \n",
      "     |  combine_first(self, other)\n",
      "     |      Combine two DataFrame objects and default to non-null values in frame\n",
      "     |      calling the method. Result index columns will be the union of the\n",
      "     |      respective indexes and columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      combined : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      df1's values prioritized, use values from df2 to fill holes:\n",
      "     |      \n",
      "     |      >>> df1 = pd.DataFrame([[1, np.nan]])\n",
      "     |      >>> df2 = pd.DataFrame([[3, 4]])\n",
      "     |      >>> df1.combine_first(df2)\n",
      "     |         0    1\n",
      "     |      0  1  4.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      "     |          using a given function\n",
      "     |  \n",
      "     |  compound(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the compound percentage of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      compounded : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  corr(self, method='pearson', min_periods=1)\n",
      "     |      Compute pairwise correlation of columns, excluding NA/null values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'pearson', 'kendall', 'spearman'}\n",
      "     |          * pearson : standard correlation coefficient\n",
      "     |          * kendall : Kendall Tau correlation coefficient\n",
      "     |          * spearman : Spearman rank correlation\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations required per pair of columns\n",
      "     |          to have a valid result. Currently only available for pearson\n",
      "     |          and spearman correlation\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : DataFrame\n",
      "     |  \n",
      "     |  corrwith(self, other, axis=0, drop=False)\n",
      "     |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      "     |      objects.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      "     |      drop : boolean, default False\n",
      "     |          Drop missing indices from result, default returns union of all\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      correls : Series\n",
      "     |  \n",
      "     |  cov(self, min_periods=None)\n",
      "     |      Compute pairwise covariance of columns, excluding NA/null values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations required per pair of columns\n",
      "     |          to have a valid result.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `y` contains the covariance matrix of the DataFrame's time series.\n",
      "     |      The covariance is normalized by N-1 (unbiased estimator).\n",
      "     |  \n",
      "     |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative max over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummax : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.max : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative minimum over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummin : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.min : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative product over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumprod : Series\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.prod : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  diff(self, periods=1, axis=0)\n",
      "     |      1st discrete difference of object\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming difference\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Take difference over rows (0) or columns (1).\n",
      "     |      \n",
      "     |          .. versionadded: 0.16.1\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      diffed : DataFrame\n",
      "     |  \n",
      "     |  dot(self, other)\n",
      "     |      Matrix multiplication with DataFrame or Series objects\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dot_product : DataFrame or Series\n",
      "     |  \n",
      "     |  drop_duplicates(self, subset=None, keep='first', inplace=False)\n",
      "     |      Return DataFrame with duplicate rows removed, optionally only\n",
      "     |      considering certain columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      subset : column label or sequence of labels, optional\n",
      "     |          Only consider certain columns for identifying duplicates, by\n",
      "     |          default use all of the columns\n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      "     |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      "     |          - False : Drop all duplicates.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to drop duplicates in place or to return a copy\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      deduplicated : DataFrame\n",
      "     |  \n",
      "     |  dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      "     |      Return object with labels on given axis omitted where alternately any\n",
      "     |      or all of the data are missing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, or tuple/list thereof\n",
      "     |          Pass tuple or list to drop on multiple axes\n",
      "     |      how : {'any', 'all'}\n",
      "     |          * any : if any NA values are present, drop that label\n",
      "     |          * all : if all values are NA, drop that label\n",
      "     |      thresh : int, default None\n",
      "     |          int value : require that many non-NA values\n",
      "     |      subset : array-like\n",
      "     |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      "     |          these would be a list of columns to include\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, do operation inplace and return None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dropped : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0], [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5]],\n",
      "     |      ...                   columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      \n",
      "     |      Drop the columns where all elements are nan:\n",
      "     |      \n",
      "     |      >>> df.dropna(axis=1, how='all')\n",
      "     |           A    B  D\n",
      "     |      0  NaN  2.0  0\n",
      "     |      1  3.0  4.0  1\n",
      "     |      2  NaN  NaN  5\n",
      "     |      \n",
      "     |      Drop the columns where any of the elements is nan\n",
      "     |      \n",
      "     |      >>> df.dropna(axis=1, how='any')\n",
      "     |         D\n",
      "     |      0  0\n",
      "     |      1  1\n",
      "     |      2  5\n",
      "     |      \n",
      "     |      Drop the rows where all of the elements are nan\n",
      "     |      (there is no row to drop, so df stays the same):\n",
      "     |      \n",
      "     |      >>> df.dropna(axis=0, how='all')\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      \n",
      "     |      Keep only the rows with at least 2 non-na values:\n",
      "     |      \n",
      "     |      >>> df.dropna(thresh=2)\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |  \n",
      "     |  duplicated(self, subset=None, keep='first')\n",
      "     |      Return boolean Series denoting duplicate rows, optionally only\n",
      "     |      considering certain columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      subset : column label or sequence of labels, optional\n",
      "     |          Only consider certain columns for identifying duplicates, by\n",
      "     |          default use all of the columns\n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Mark duplicates as ``True`` except for the\n",
      "     |            first occurrence.\n",
      "     |          - ``last`` : Mark duplicates as ``True`` except for the\n",
      "     |            last occurrence.\n",
      "     |          - False : Mark all duplicates as ``True``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      duplicated : Series\n",
      "     |  \n",
      "     |  eval(self, expr, inplace=False, **kwargs)\n",
      "     |      Evaluate an expression in the context of the calling DataFrame\n",
      "     |      instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      expr : string\n",
      "     |          The expression string to evaluate.\n",
      "     |      inplace : bool, default False\n",
      "     |          If the expression contains an assignment, whether to perform the\n",
      "     |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      "     |          a new DataFrame is returned.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      kwargs : dict\n",
      "     |          See the documentation for :func:`~pandas.eval` for complete details\n",
      "     |          on the keyword arguments accepted by\n",
      "     |          :meth:`~pandas.DataFrame.query`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ret : ndarray, scalar, or pandas object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.query\n",
      "     |      pandas.DataFrame.assign\n",
      "     |      pandas.eval\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For more details see the API documentation for :func:`~pandas.eval`.\n",
      "     |      For detailed examples see :ref:`enhancing performance with eval\n",
      "     |      <enhancingperf.eval>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from numpy.random import randn\n",
      "     |      >>> from pandas import DataFrame\n",
      "     |      >>> df = DataFrame(randn(10, 2), columns=list('ab'))\n",
      "     |      >>> df.eval('a + b')\n",
      "     |      >>> df.eval('c = a + b')\n",
      "     |  \n",
      "     |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, freq=None, adjust=True, ignore_na=False, axis=0)\n",
      "     |      Provides exponential weighted functions\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      com : float, optional\n",
      "     |          Specify decay in terms of center of mass,\n",
      "     |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      "     |      span : float, optional\n",
      "     |          Specify decay in terms of span,\n",
      "     |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      "     |      halflife : float, optional\n",
      "     |          Specify decay in terms of half-life,\n",
      "     |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      "     |      alpha : float, optional\n",
      "     |          Specify smoothing factor :math:`\\alpha` directly,\n",
      "     |          :math:`0 < \\alpha \\leq 1`\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      min_periods : int, default 0\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : None or string alias / date offset object, default=None\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform to before computing statistic\n",
      "     |      adjust : boolean, default True\n",
      "     |          Divide by decaying adjustment factor in beginning periods to account\n",
      "     |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      "     |      ignore_na : boolean, default False\n",
      "     |          Ignore missing values when calculating weights;\n",
      "     |          specify True to reproduce pre-0.15.0 behavior\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.ewm(com=0.5).mean()\n",
      "     |                B\n",
      "     |      0  0.000000\n",
      "     |      1  0.750000\n",
      "     |      2  1.615385\n",
      "     |      3  1.615385\n",
      "     |      4  3.670213\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      "     |      Allowed values and relationship between the parameters are specified in the\n",
      "     |      parameter descriptions above; see the link at the end of this section for\n",
      "     |      a detailed explanation.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      When adjust is True (default), weighted averages are calculated using\n",
      "     |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      "     |      \n",
      "     |      When adjust is False, weighted averages are calculated recursively as:\n",
      "     |         weighted_average[0] = arg[0];\n",
      "     |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      "     |      \n",
      "     |      When ignore_na is False (default), weights are based on absolute positions.\n",
      "     |      For example, the weights of x and y used in calculating the final weighted\n",
      "     |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      "     |      (1-alpha)**2 and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      "     |      on relative positions. For example, the weights of x and y used in\n",
      "     |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      "     |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      More details can be found at\n",
      "     |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      "     |  \n",
      "     |  expanding(self, min_periods=1, freq=None, center=False, axis=0)\n",
      "     |      Provides expanding transformations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.expanding(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  3.0\n",
      "     |      4  7.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |  \n",
      "     |  first_valid_index(self)\n",
      "     |      Return index for first non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, **kwds)\n",
      "     |      Draw histogram of the DataFrame's series using matplotlib / pylab.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : DataFrame\n",
      "     |      column : string or sequence\n",
      "     |          If passed, will be used to limit data to a subset of columns\n",
      "     |      by : object, optional\n",
      "     |          If passed, then used to form histograms for separate groups\n",
      "     |      grid : boolean, default True\n",
      "     |          Whether to show axis grid lines\n",
      "     |      xlabelsize : int, default None\n",
      "     |          If specified changes the x-axis label size\n",
      "     |      xrot : float, default None\n",
      "     |          rotation of x axis labels\n",
      "     |      ylabelsize : int, default None\n",
      "     |          If specified changes the y-axis label size\n",
      "     |      yrot : float, default None\n",
      "     |          rotation of y axis labels\n",
      "     |      ax : matplotlib axes object, default None\n",
      "     |      sharex : boolean, default True if ax is None else False\n",
      "     |          In case subplots=True, share x axis and set some x axis labels to\n",
      "     |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      "     |          is passed in; Be aware, that passing in both an ax and sharex=True\n",
      "     |          will alter all x axis labels for all subplots in a figure!\n",
      "     |      sharey : boolean, default False\n",
      "     |          In case subplots=True, share y axis and set some y axis labels to\n",
      "     |          invisible\n",
      "     |      figsize : tuple\n",
      "     |          The size of the figure to create in inches by default\n",
      "     |      layout : tuple, optional\n",
      "     |          Tuple of (rows, columns) for the layout of the histograms\n",
      "     |      bins : integer, default 10\n",
      "     |          Number of histogram bins to be used\n",
      "     |      kwds : other plotting keyword arguments\n",
      "     |          To be passed to hist function\n",
      "     |  \n",
      "     |  idxmax(self, axis=0, skipna=True)\n",
      "     |      Return index of first occurrence of maximum over requested axis.\n",
      "     |      NA/null values are excluded.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the row/column is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmax : Series\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.idxmax\n",
      "     |  \n",
      "     |  idxmin(self, axis=0, skipna=True)\n",
      "     |      Return index of first occurrence of minimum over requested axis.\n",
      "     |      NA/null values are excluded.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the row/column is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmin : Series\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.idxmin\n",
      "     |  \n",
      "     |  info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)\n",
      "     |      Concise summary of a DataFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : {None, True, False}, optional\n",
      "     |          Whether to print the full summary.\n",
      "     |          None follows the `display.max_info_columns` setting.\n",
      "     |          True or False overrides the `display.max_info_columns` setting.\n",
      "     |      buf : writable buffer, defaults to sys.stdout\n",
      "     |      max_cols : int, default None\n",
      "     |          Determines whether full summary or short summary is printed.\n",
      "     |          None follows the `display.max_info_columns` setting.\n",
      "     |      memory_usage : boolean/string, default None\n",
      "     |          Specifies whether total memory usage of the DataFrame\n",
      "     |          elements (including index) should be displayed. None follows\n",
      "     |          the `display.memory_usage` setting. True or False overrides\n",
      "     |          the `display.memory_usage` setting. A value of 'deep' is equivalent\n",
      "     |          of True, with deep introspection. Memory usage is shown in\n",
      "     |          human-readable units (base-2 representation).\n",
      "     |      null_counts : boolean, default None\n",
      "     |          Whether to show the non-null counts\n",
      "     |      \n",
      "     |          - If None, then only show if the frame is smaller than\n",
      "     |            max_info_rows and max_info_columns.\n",
      "     |          - If True, always show counts.\n",
      "     |          - If False, never show counts.\n",
      "     |  \n",
      "     |  insert(self, loc, column, value, allow_duplicates=False)\n",
      "     |      Insert column into DataFrame at specified location.\n",
      "     |      \n",
      "     |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      "     |      unless `allow_duplicates` is set to True.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : int\n",
      "     |          Insertion index. Must verify 0 <= loc <= len(columns)\n",
      "     |      column : string, number, or hashable object\n",
      "     |          label of the inserted column\n",
      "     |      value : int, Series, or array-like\n",
      "     |      allow_duplicates : bool, optional\n",
      "     |  \n",
      "     |  isin(self, values)\n",
      "     |      Return boolean DataFrame showing whether each element in the\n",
      "     |      DataFrame is contained in values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : iterable, Series, DataFrame or dictionary\n",
      "     |          The result will only be true at a location if all the\n",
      "     |          labels match. If `values` is a Series, that's the index. If\n",
      "     |          `values` is a dictionary, the keys must be the column names,\n",
      "     |          which must match. If `values` is a DataFrame,\n",
      "     |          then both the index and column labels must match.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      DataFrame of booleans\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      When ``values`` is a list:\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      "     |      >>> df.isin([1, 3, 12, 'a'])\n",
      "     |             A      B\n",
      "     |      0   True   True\n",
      "     |      1  False  False\n",
      "     |      2   True  False\n",
      "     |      \n",
      "     |      When ``values`` is a dict:\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\n",
      "     |      >>> df.isin({'A': [1, 3], 'B': [4, 7, 12]})\n",
      "     |             A      B\n",
      "     |      0   True  False  # Note that B didn't match the 1 here.\n",
      "     |      1  False   True\n",
      "     |      2   True   True\n",
      "     |      \n",
      "     |      When ``values`` is a Series or DataFrame:\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      "     |      >>> other = DataFrame({'A': [1, 3, 3, 2], 'B': ['e', 'f', 'f', 'e']})\n",
      "     |      >>> df.isin(other)\n",
      "     |             A      B\n",
      "     |      0   True  False\n",
      "     |      1  False  False  # Column A in `other` has a 3, but not at index 1.\n",
      "     |      2   True   True\n",
      "     |  \n",
      "     |  items = iteritems(self)\n",
      "     |      Iterator over (column name, Series) pairs.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      "     |  \n",
      "     |  iteritems(self)\n",
      "     |      Iterator over (column name, Series) pairs.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      "     |  \n",
      "     |  iterrows(self)\n",
      "     |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      1. Because ``iterrows`` returns a Series for each row,\n",
      "     |         it does **not** preserve dtypes across the rows (dtypes are\n",
      "     |         preserved across columns for DataFrames). For example,\n",
      "     |      \n",
      "     |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      "     |         >>> row = next(df.iterrows())[1]\n",
      "     |         >>> row\n",
      "     |         int      1.0\n",
      "     |         float    1.5\n",
      "     |         Name: 0, dtype: float64\n",
      "     |         >>> print(row['int'].dtype)\n",
      "     |         float64\n",
      "     |         >>> print(df['int'].dtype)\n",
      "     |         int64\n",
      "     |      \n",
      "     |         To preserve dtypes while iterating over the rows, it is better\n",
      "     |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      "     |         and which is generally faster than ``iterrows``.\n",
      "     |      \n",
      "     |      2. You should **never modify** something you are iterating over.\n",
      "     |         This is not guaranteed to work in all cases. Depending on the\n",
      "     |         data types, the iterator returns a copy and not a view, and writing\n",
      "     |         to it will have no effect.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it : generator\n",
      "     |          A generator that iterates over the rows of the frame.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      "     |      iteritems : Iterate over (column name, Series) pairs.\n",
      "     |  \n",
      "     |  itertuples(self, index=True, name='Pandas')\n",
      "     |      Iterate over DataFrame rows as namedtuples, with index value as first\n",
      "     |      element of the tuple.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : boolean, default True\n",
      "     |          If True, return the index as the first element of the tuple.\n",
      "     |      name : string, default \"Pandas\"\n",
      "     |          The name of the returned namedtuples or None to return regular\n",
      "     |          tuples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The column names will be renamed to positional names if they are\n",
      "     |      invalid Python identifiers, repeated, or start with an underscore.\n",
      "     |      With a large number of columns (>255), regular tuples are returned.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      "     |      iteritems : Iterate over (column name, Series) pairs.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]},\n",
      "     |                            index=['a', 'b'])\n",
      "     |      >>> df\n",
      "     |         col1  col2\n",
      "     |      a     1   0.1\n",
      "     |      b     2   0.2\n",
      "     |      >>> for row in df.itertuples():\n",
      "     |      ...     print(row)\n",
      "     |      ...\n",
      "     |      Pandas(Index='a', col1=1, col2=0.10000000000000001)\n",
      "     |      Pandas(Index='b', col1=2, col2=0.20000000000000001)\n",
      "     |  \n",
      "     |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
      "     |      Join columns with other DataFrame either on index or on a key\n",
      "     |      column. Efficiently Join multiple DataFrame objects by index at once by\n",
      "     |      passing a list.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame, Series with name field set, or list of DataFrame\n",
      "     |          Index should be similar to one of the columns in this one. If a\n",
      "     |          Series is passed, its name attribute must be set, and that will be\n",
      "     |          used as the column name in the resulting joined DataFrame\n",
      "     |      on : column name, tuple/list of column names, or array-like\n",
      "     |          Column(s) in the caller to join on the index in other,\n",
      "     |          otherwise joins index-on-index. If multiples\n",
      "     |          columns given, the passed DataFrame must have a MultiIndex. Can\n",
      "     |          pass an array as the join key if not already contained in the\n",
      "     |          calling DataFrame. Like an Excel VLOOKUP operation\n",
      "     |      how : {'left', 'right', 'outer', 'inner'}, default: 'left'\n",
      "     |          How to handle the operation of the two objects.\n",
      "     |      \n",
      "     |          * left: use calling frame's index (or column if on is specified)\n",
      "     |          * right: use other frame's index\n",
      "     |          * outer: form union of calling frame's index (or column if on is\n",
      "     |            specified) with other frame's index, and sort it\n",
      "     |            lexicographically\n",
      "     |          * inner: form intersection of calling frame's index (or column if\n",
      "     |            on is specified) with other frame's index, preserving the order\n",
      "     |            of the calling's one\n",
      "     |      lsuffix : string\n",
      "     |          Suffix to use from left frame's overlapping columns\n",
      "     |      rsuffix : string\n",
      "     |          Suffix to use from right frame's overlapping columns\n",
      "     |      sort : boolean, default False\n",
      "     |          Order result DataFrame lexicographically by the join key. If False,\n",
      "     |          the order of the join key depends on the join type (how keyword)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      on, lsuffix, and rsuffix options are not supported when passing a list\n",
      "     |      of DataFrame objects\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      "     |      ...                        'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      "     |      \n",
      "     |      >>> caller\n",
      "     |          A key\n",
      "     |      0  A0  K0\n",
      "     |      1  A1  K1\n",
      "     |      2  A2  K2\n",
      "     |      3  A3  K3\n",
      "     |      4  A4  K4\n",
      "     |      5  A5  K5\n",
      "     |      \n",
      "     |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      "     |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      "     |      \n",
      "     |      >>> other\n",
      "     |          B key\n",
      "     |      0  B0  K0\n",
      "     |      1  B1  K1\n",
      "     |      2  B2  K2\n",
      "     |      \n",
      "     |      Join DataFrames using their indexes.\n",
      "     |      \n",
      "     |      >>> caller.join(other, lsuffix='_caller', rsuffix='_other')\n",
      "     |      \n",
      "     |      >>>     A key_caller    B key_other\n",
      "     |          0  A0         K0   B0        K0\n",
      "     |          1  A1         K1   B1        K1\n",
      "     |          2  A2         K2   B2        K2\n",
      "     |          3  A3         K3  NaN       NaN\n",
      "     |          4  A4         K4  NaN       NaN\n",
      "     |          5  A5         K5  NaN       NaN\n",
      "     |      \n",
      "     |      \n",
      "     |      If we want to join using the key columns, we need to set key to be\n",
      "     |      the index in both caller and other. The joined DataFrame will have\n",
      "     |      key as its index.\n",
      "     |      \n",
      "     |      >>> caller.set_index('key').join(other.set_index('key'))\n",
      "     |      \n",
      "     |      >>>      A    B\n",
      "     |          key\n",
      "     |          K0   A0   B0\n",
      "     |          K1   A1   B1\n",
      "     |          K2   A2   B2\n",
      "     |          K3   A3  NaN\n",
      "     |          K4   A4  NaN\n",
      "     |          K5   A5  NaN\n",
      "     |      \n",
      "     |      Another option to join using the key columns is to use the on\n",
      "     |      parameter. DataFrame.join always uses other's index but we can use any\n",
      "     |      column in the caller. This method preserves the original caller's\n",
      "     |      index in the result.\n",
      "     |      \n",
      "     |      >>> caller.join(other.set_index('key'), on='key')\n",
      "     |      \n",
      "     |      >>>     A key    B\n",
      "     |          0  A0  K0   B0\n",
      "     |          1  A1  K1   B1\n",
      "     |          2  A2  K2   B2\n",
      "     |          3  A3  K3  NaN\n",
      "     |          4  A4  K4  NaN\n",
      "     |          5  A5  K5  NaN\n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.merge : For column(s)-on-columns(s) operations\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      joined : DataFrame\n",
      "     |  \n",
      "     |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  last_valid_index(self)\n",
      "     |      Return index for last non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  lookup(self, row_labels, col_labels)\n",
      "     |      Label-based \"fancy indexing\" function for DataFrame.\n",
      "     |      Given equal-length arrays of row and column labels, return an\n",
      "     |      array of the values corresponding to each (row, col) pair.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      row_labels : sequence\n",
      "     |          The row labels to use for lookup\n",
      "     |      col_labels : sequence\n",
      "     |          The column labels to use for lookup\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Akin to::\n",
      "     |      \n",
      "     |          result = []\n",
      "     |          for row, col in zip(row_labels, col_labels):\n",
      "     |              result.append(df.get_value(row, col))\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      values : ndarray\n",
      "     |          The found values\n",
      "     |  \n",
      "     |  mad(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the mean absolute deviation of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mad : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the maximum of the values in the object.\n",
      "     |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      max : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the mean of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the median of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n",
      "     |      \"Unpivots\" a DataFrame from wide format to long format, optionally\n",
      "     |      leaving identifier variables set.\n",
      "     |      \n",
      "     |      This function is useful to massage a DataFrame into a format where one\n",
      "     |      or more columns are identifier variables (`id_vars`), while all other\n",
      "     |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      "     |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      "     |      'value'.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      frame : DataFrame\n",
      "     |      id_vars : tuple, list, or ndarray, optional\n",
      "     |          Column(s) to use as identifier variables.\n",
      "     |      value_vars : tuple, list, or ndarray, optional\n",
      "     |          Column(s) to unpivot. If not specified, uses all columns that\n",
      "     |          are not set as `id_vars`.\n",
      "     |      var_name : scalar\n",
      "     |          Name to use for the 'variable' column. If None it uses\n",
      "     |          ``frame.columns.name`` or 'variable'.\n",
      "     |      value_name : scalar, default 'value'\n",
      "     |          Name to use for the 'value' column.\n",
      "     |      col_level : int or string, optional\n",
      "     |          If columns are a MultiIndex then use this level to melt.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      melt\n",
      "     |      pivot_table\n",
      "     |      DataFrame.pivot\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      "     |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      "     |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |      0  a  1  2\n",
      "     |      1  b  3  4\n",
      "     |      2  c  5  6\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      "     |         A variable  value\n",
      "     |      0  a        B      1\n",
      "     |      1  b        B      3\n",
      "     |      2  c        B      5\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      "     |         A variable  value\n",
      "     |      0  a        B      1\n",
      "     |      1  b        B      3\n",
      "     |      2  c        B      5\n",
      "     |      3  a        C      2\n",
      "     |      4  b        C      4\n",
      "     |      5  c        C      6\n",
      "     |      \n",
      "     |      The names of 'variable' and 'value' columns can be customized:\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      "     |      ...         var_name='myVarname', value_name='myValname')\n",
      "     |         A myVarname  myValname\n",
      "     |      0  a         B          1\n",
      "     |      1  b         B          3\n",
      "     |      2  c         B          5\n",
      "     |      \n",
      "     |      If you have multi-index columns:\n",
      "     |      \n",
      "     |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |         D  E  F\n",
      "     |      0  a  1  2\n",
      "     |      1  b  3  4\n",
      "     |      2  c  5  6\n",
      "     |      \n",
      "     |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      "     |         A variable  value\n",
      "     |      0  a        B      1\n",
      "     |      1  b        B      3\n",
      "     |      2  c        B      5\n",
      "     |      \n",
      "     |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      "     |        (A, D) variable_0 variable_1  value\n",
      "     |      0      a          B          E      1\n",
      "     |      1      b          B          E      3\n",
      "     |      2      c          B          E      5\n",
      "     |  \n",
      "     |  memory_usage(self, index=True, deep=False)\n",
      "     |      Memory usage of DataFrame columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : bool\n",
      "     |          Specifies whether to include memory usage of DataFrame's\n",
      "     |          index in returned Series. If `index=True` (default is False)\n",
      "     |          the first index of the Series is `Index`.\n",
      "     |      deep : bool\n",
      "     |          Introspect the data deeply, interrogate\n",
      "     |          `object` dtypes for system-level memory consumption\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sizes : Series\n",
      "     |          A series with column names as index and memory usage of\n",
      "     |          columns with units of bytes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Memory usage does not include memory consumed by elements that\n",
      "     |      are not components of the array if deep=False\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.nbytes\n",
      "     |  \n",
      "     |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
      "     |      Merge DataFrame objects by performing a database-style join operation by\n",
      "     |      columns or indexes.\n",
      "     |      \n",
      "     |      If joining columns on columns, the DataFrame indexes *will be\n",
      "     |      ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      "     |      columns, the index will be passed on.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      right : DataFrame\n",
      "     |      how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      "     |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "     |            preserve key order\n",
      "     |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "     |            preserve key order\n",
      "     |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "     |            join; sort keys lexicographically\n",
      "     |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "     |            join; preserve the order of the left keys\n",
      "     |      on : label or list\n",
      "     |          Field names to join on. Must be found in both DataFrames. If on is\n",
      "     |          None and not merging on indexes, then it merges on the intersection of\n",
      "     |          the columns by default.\n",
      "     |      left_on : label or list, or array-like\n",
      "     |          Field names to join on in left DataFrame. Can be a vector or list of\n",
      "     |          vectors of the length of the DataFrame to use a particular vector as\n",
      "     |          the join key instead of columns\n",
      "     |      right_on : label or list, or array-like\n",
      "     |          Field names to join on in right DataFrame or vector/list of vectors per\n",
      "     |          left_on docs\n",
      "     |      left_index : boolean, default False\n",
      "     |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      "     |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "     |          or a number of columns) must match the number of levels\n",
      "     |      right_index : boolean, default False\n",
      "     |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      "     |          left_index\n",
      "     |      sort : boolean, default False\n",
      "     |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "     |          the order of the join keys depends on the join type (how keyword)\n",
      "     |      suffixes : 2-length sequence (tuple, list, ...)\n",
      "     |          Suffix to apply to overlapping column names in the left and right\n",
      "     |          side, respectively\n",
      "     |      copy : boolean, default True\n",
      "     |          If False, do not copy data unnecessarily\n",
      "     |      indicator : boolean or string, default False\n",
      "     |          If True, adds a column to output DataFrame called \"_merge\" with\n",
      "     |          information on the source of each row.\n",
      "     |          If string, column with information on source of each row will be added to\n",
      "     |          output DataFrame, and column will be named value of string.\n",
      "     |          Information column is Categorical-type and takes on a value of \"left_only\"\n",
      "     |          for observations whose merge key only appears in 'left' DataFrame,\n",
      "     |          \"right_only\" for observations whose merge key only appears in 'right'\n",
      "     |          DataFrame, and \"both\" if the observation's merge key is found in both.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      validate : string, default None\n",
      "     |          If specified, checks if merge is of specified type.\n",
      "     |      \n",
      "     |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "     |            left and right datasets.\n",
      "     |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "     |            dataset.\n",
      "     |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "     |            dataset.\n",
      "     |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> A              >>> B\n",
      "     |          lkey value         rkey value\n",
      "     |      0   foo  1         0   foo  5\n",
      "     |      1   bar  2         1   bar  6\n",
      "     |      2   baz  3         2   qux  7\n",
      "     |      3   foo  4         3   bar  8\n",
      "     |      \n",
      "     |      >>> A.merge(B, left_on='lkey', right_on='rkey', how='outer')\n",
      "     |         lkey  value_x  rkey  value_y\n",
      "     |      0  foo   1        foo   5\n",
      "     |      1  foo   4        foo   5\n",
      "     |      2  bar   2        bar   6\n",
      "     |      3  bar   2        bar   8\n",
      "     |      4  baz   3        NaN   NaN\n",
      "     |      5  NaN   NaN      qux   7\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      merged : DataFrame\n",
      "     |          The output type will the be same as 'left', if it is a subclass\n",
      "     |          of DataFrame.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      merge_ordered\n",
      "     |      merge_asof\n",
      "     |  \n",
      "     |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the minimum of the values in the object.\n",
      "     |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      min : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  mode(self, axis=0, numeric_only=False)\n",
      "     |      Gets the mode(s) of each element along the axis selected. Adds a row\n",
      "     |      for each mode per label, fills in gaps with nan.\n",
      "     |      \n",
      "     |      Note that there could be multiple values returned for the selected\n",
      "     |      axis (when more than one item share the maximum frequency), which is\n",
      "     |      the reason why a dataframe is returned. If you want to impute missing\n",
      "     |      values with the mode in a dataframe ``df``, you can just do this:\n",
      "     |      ``df.fillna(df.mode().iloc[0])``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          * 0 or 'index' : get mode of each column\n",
      "     |          * 1 or 'columns' : get mode of each row\n",
      "     |      numeric_only : boolean, default False\n",
      "     |          if True, only apply to numeric columns\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      modes : DataFrame (sorted)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 1, 2, 1, 2, 3]})\n",
      "     |      >>> df.mode()\n",
      "     |         A\n",
      "     |      0  1\n",
      "     |      1  2\n",
      "     |  \n",
      "     |  nlargest(self, n, columns, keep='first')\n",
      "     |      Get the rows of a DataFrame sorted by the `n` largest\n",
      "     |      values of `columns`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Number of items to retrieve\n",
      "     |      columns : list or str\n",
      "     |          Column name or names to order by\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = DataFrame({'a': [1, 10, 8, 11, -1],\n",
      "     |      ...                 'b': list('abdce'),\n",
      "     |      ...                 'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      "     |      >>> df.nlargest(3, 'a')\n",
      "     |          a  b   c\n",
      "     |      3  11  c   3\n",
      "     |      1  10  b   2\n",
      "     |      2   8  d NaN\n",
      "     |  \n",
      "     |  nsmallest(self, n, columns, keep='first')\n",
      "     |      Get the rows of a DataFrame sorted by the `n` smallest\n",
      "     |      values of `columns`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Number of items to retrieve\n",
      "     |      columns : list or str\n",
      "     |          Column name or names to order by\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = DataFrame({'a': [1, 10, 8, 11, -1],\n",
      "     |      ...                 'b': list('abdce'),\n",
      "     |      ...                 'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      "     |      >>> df.nsmallest(3, 'a')\n",
      "     |         a  b   c\n",
      "     |      4 -1  e   4\n",
      "     |      0  1  a   1\n",
      "     |      2  8  d NaN\n",
      "     |  \n",
      "     |  nunique(self, axis=0, dropna=True)\n",
      "     |      Return Series with number of distinct observations over requested\n",
      "     |      axis.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include NaN in the counts.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nunique : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n",
      "     |      >>> df.nunique()\n",
      "     |      A    3\n",
      "     |      B    1\n",
      "     |      \n",
      "     |      >>> df.nunique(axis=1)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    2\n",
      "     |  \n",
      "     |  pivot(self, index=None, columns=None, values=None)\n",
      "     |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      "     |      unique values from index / columns to form axes of the resulting\n",
      "     |      DataFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : string or object, optional\n",
      "     |          Column name to use to make new frame's index. If None, uses\n",
      "     |          existing index.\n",
      "     |      columns : string or object\n",
      "     |          Column name to use to make new frame's columns\n",
      "     |      values : string or object, optional\n",
      "     |          Column name to use for populating new frame's values. If not\n",
      "     |          specified, all remaining columns will be used and the result will\n",
      "     |          have hierarchically indexed columns\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pivoted : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pivot_table : generalization of pivot that can handle\n",
      "     |          duplicate values for one index/column pair\n",
      "     |      DataFrame.unstack : pivot based on the index values instead of a\n",
      "     |          column\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For finer-tuned control, see hierarchical indexing documentation along\n",
      "     |      with the related stack/unstack methods\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
      "     |                             'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      "     |                             'baz': [1, 2, 3, 4, 5, 6]})\n",
      "     |      >>> df\n",
      "     |          foo   bar  baz\n",
      "     |      0   one   A    1\n",
      "     |      1   one   B    2\n",
      "     |      2   one   C    3\n",
      "     |      3   two   A    4\n",
      "     |      4   two   B    5\n",
      "     |      5   two   C    6\n",
      "     |      \n",
      "     |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      "     |           A   B   C\n",
      "     |      one  1   2   3\n",
      "     |      two  4   5   6\n",
      "     |      \n",
      "     |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      "     |           A   B   C\n",
      "     |      one  1   2   3\n",
      "     |      two  4   5   6\n",
      "     |  \n",
      "     |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')\n",
      "     |      Create a spreadsheet-style pivot table as a DataFrame. The levels in\n",
      "     |      the pivot table will be stored in MultiIndex objects (hierarchical\n",
      "     |      indexes) on the index and columns of the result DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : column to aggregate, optional\n",
      "     |      index : column, Grouper, array, or list of the previous\n",
      "     |          If an array is passed, it must be the same length as the data. The\n",
      "     |          list can contain any of the other types (except list).\n",
      "     |          Keys to group by on the pivot table index.  If an array is passed,\n",
      "     |          it is being used as the same manner as column values.\n",
      "     |      columns : column, Grouper, array, or list of the previous\n",
      "     |          If an array is passed, it must be the same length as the data. The\n",
      "     |          list can contain any of the other types (except list).\n",
      "     |          Keys to group by on the pivot table column.  If an array is passed,\n",
      "     |          it is being used as the same manner as column values.\n",
      "     |      aggfunc : function or list of functions, default numpy.mean\n",
      "     |          If list of functions passed, the resulting pivot table will have\n",
      "     |          hierarchical columns whose top level are the function names\n",
      "     |          (inferred from the function objects themselves)\n",
      "     |      fill_value : scalar, default None\n",
      "     |          Value to replace missing values with\n",
      "     |      margins : boolean, default False\n",
      "     |          Add all row / columns (e.g. for subtotal / grand totals)\n",
      "     |      dropna : boolean, default True\n",
      "     |          Do not include columns whose entries are all NaN\n",
      "     |      margins_name : string, default 'All'\n",
      "     |          Name of the row / column that will contain the totals\n",
      "     |          when margins is True.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "     |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "     |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "     |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      "     |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "     |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      "     |      ...                          \"large\"],\n",
      "     |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7]})\n",
      "     |      >>> df\n",
      "     |           A    B      C  D\n",
      "     |      0  foo  one  small  1\n",
      "     |      1  foo  one  large  2\n",
      "     |      2  foo  one  large  2\n",
      "     |      3  foo  two  small  3\n",
      "     |      4  foo  two  small  3\n",
      "     |      5  bar  one  large  4\n",
      "     |      6  bar  one  small  5\n",
      "     |      7  bar  two  small  6\n",
      "     |      8  bar  two  large  7\n",
      "     |      \n",
      "     |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      "     |      ...                     columns=['C'], aggfunc=np.sum)\n",
      "     |      >>> table\n",
      "     |      ... # doctest: +NORMALIZE_WHITESPACE\n",
      "     |      C        large  small\n",
      "     |      A   B\n",
      "     |      bar one    4.0    5.0\n",
      "     |          two    7.0    6.0\n",
      "     |      foo one    4.0    1.0\n",
      "     |          two    NaN    6.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      table : DataFrame\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pivot : pivot without aggregation that can handle\n",
      "     |          non-numeric data\n",
      "     |  \n",
      "     |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : Series or DataFrame (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : Series or DataFrame (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')\n",
      "     |      Return values at the given quantile over requested axis, a la\n",
      "     |      numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          0 <= q <= 1, the quantile(s) to compute\n",
      "     |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      "     |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |          This optional parameter specifies the interpolation method to use,\n",
      "     |          when the desired quantile lies between two data points `i` and `j`:\n",
      "     |      \n",
      "     |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      "     |            fractional part of the index surrounded by `i` and `j`.\n",
      "     |          * lower: `i`.\n",
      "     |          * higher: `j`.\n",
      "     |          * nearest: `i` or `j` whichever is nearest.\n",
      "     |          * midpoint: (`i` + `j`) / 2.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      quantiles : Series or DataFrame\n",
      "     |      \n",
      "     |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      "     |            index is ``q``, the columns are the columns of self, and the\n",
      "     |            values are the quantiles.\n",
      "     |          - If ``q`` is a float, a Series will be returned where the\n",
      "     |            index is the columns of self and the values are the quantiles.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      "     |                         columns=['a', 'b'])\n",
      "     |      >>> df.quantile(.1)\n",
      "     |      a    1.3\n",
      "     |      b    3.7\n",
      "     |      dtype: float64\n",
      "     |      >>> df.quantile([.1, .5])\n",
      "     |             a     b\n",
      "     |      0.1  1.3   3.7\n",
      "     |      0.5  2.5  55.0\n",
      "     |  \n",
      "     |  query(self, expr, inplace=False, **kwargs)\n",
      "     |      Query the columns of a frame with a boolean expression.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      expr : string\n",
      "     |          The query string to evaluate.  You can refer to variables\n",
      "     |          in the environment by prefixing them with an '@' character like\n",
      "     |          ``@a + b``.\n",
      "     |      inplace : bool\n",
      "     |          Whether the query should modify the data in place or return\n",
      "     |          a modified copy\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      kwargs : dict\n",
      "     |          See the documentation for :func:`pandas.eval` for complete details\n",
      "     |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      q : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The result of the evaluation of this expression is first passed to\n",
      "     |      :attr:`DataFrame.loc` and if that fails because of a\n",
      "     |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      "     |      to :meth:`DataFrame.__getitem__`.\n",
      "     |      \n",
      "     |      This method uses the top-level :func:`pandas.eval` function to\n",
      "     |      evaluate the passed query.\n",
      "     |      \n",
      "     |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      "     |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      "     |      (bitwise) operators have the precedence of their boolean cousins,\n",
      "     |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      "     |      however the semantics are different.\n",
      "     |      \n",
      "     |      You can change the semantics of the expression by passing the keyword\n",
      "     |      argument ``parser='python'``. This enforces the same semantics as\n",
      "     |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      "     |      to evaluate an expression using Python itself as a backend. This is not\n",
      "     |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      "     |      engine.\n",
      "     |      \n",
      "     |      The :attr:`DataFrame.index` and\n",
      "     |      :attr:`DataFrame.columns` attributes of the\n",
      "     |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      "     |      by default, which allows you to treat both the index and columns of the\n",
      "     |      frame as a column in the frame.\n",
      "     |      The identifier ``index`` is used for the frame index; you can also\n",
      "     |      use the name of the index to identify it in a query.\n",
      "     |      \n",
      "     |      For further details and examples see the ``query`` documentation in\n",
      "     |      :ref:`indexing <indexing.query>`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.eval\n",
      "     |      DataFrame.eval\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from numpy.random import randn\n",
      "     |      >>> from pandas import DataFrame\n",
      "     |      >>> df = DataFrame(randn(10, 2), columns=list('ab'))\n",
      "     |      >>> df.query('a > b')\n",
      "     |      >>> df[df.a > df.b]  # same result as the previous expression\n",
      "     |  \n",
      "     |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      "     |      Conform DataFrame to new index with optional filling logic, placing\n",
      "     |      NA/NaN in locations having no value in the previous index. A new object\n",
      "     |      is produced unless the new index is equivalent to the current one and\n",
      "     |      copy=False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : array-like, optional\n",
      "     |          New labels / index to conform the axis specified by 'axis' to.\n",
      "     |      index, columns : array-like, optional (should be specified using keywords)\n",
      "     |          New labels / index to conform to. Preferably an Index object to\n",
      "     |          avoid duplicating data\n",
      "     |      axis : int or str, optional\n",
      "     |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      "     |          or number (0, 1).\n",
      "     |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "     |          method to use for filling holes in reindexed DataFrame.\n",
      "     |          Please note: this is only  applicable to DataFrames/Series with a\n",
      "     |          monotonically increasing/decreasing index.\n",
      "     |      \n",
      "     |          * default: don't fill gaps\n",
      "     |          * pad / ffill: propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * backfill / bfill: use next valid observation to fill gap\n",
      "     |          * nearest: use nearest valid observations to fill gap\n",
      "     |      \n",
      "     |      copy : boolean, default True\n",
      "     |          Return a new object, even if the passed indexes are the same\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive elements to forward or backward fill\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between original and new labels for inexact\n",
      "     |          matches. The values of the index at the matching locations most\n",
      "     |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "     |      \n",
      "     |          Tolerance may be a scalar value, which applies the same tolerance\n",
      "     |          to all values, or list-like, which applies variable tolerance per\n",
      "     |          element. List-like includes list, tuple, array, Series, and must be\n",
      "     |          the same size as the index and its dtype must exactly match the\n",
      "     |          index's type.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      ``DataFrame.reindex`` supports two calling conventions\n",
      "     |      \n",
      "     |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      "     |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      "     |      \n",
      "     |      We *highly* recommend using keyword arguments to clarify your\n",
      "     |      intent.\n",
      "     |      \n",
      "     |      Create a dataframe with some fictional data.\n",
      "     |      \n",
      "     |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...      'http_status': [200,200,404,404,301],\n",
      "     |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "     |      ...       index=index)\n",
      "     |      >>> df\n",
      "     |                 http_status  response_time\n",
      "     |      Firefox            200           0.04\n",
      "     |      Chrome             200           0.02\n",
      "     |      Safari             404           0.07\n",
      "     |      IE10               404           0.08\n",
      "     |      Konqueror          301           1.00\n",
      "     |      \n",
      "     |      Create a new index and reindex the dataframe. By default\n",
      "     |      values in the new index that do not have corresponding\n",
      "     |      records in the dataframe are assigned ``NaN``.\n",
      "     |      \n",
      "     |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "     |      ...             'Chrome']\n",
      "     |      >>> df.reindex(new_index)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari               404.0           0.07\n",
      "     |      Iceweasel              NaN            NaN\n",
      "     |      Comodo Dragon          NaN            NaN\n",
      "     |      IE10                 404.0           0.08\n",
      "     |      Chrome               200.0           0.02\n",
      "     |      \n",
      "     |      We can fill in the missing values by passing a value to\n",
      "     |      the keyword ``fill_value``. Because the index is not monotonically\n",
      "     |      increasing or decreasing, we cannot use arguments to the keyword\n",
      "     |      ``method`` to fill the ``NaN`` values.\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value=0)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari                 404           0.07\n",
      "     |      Iceweasel                0           0.00\n",
      "     |      Comodo Dragon            0           0.00\n",
      "     |      IE10                   404           0.08\n",
      "     |      Chrome                 200           0.02\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value='missing')\n",
      "     |                    http_status response_time\n",
      "     |      Safari                404          0.07\n",
      "     |      Iceweasel         missing       missing\n",
      "     |      Comodo Dragon     missing       missing\n",
      "     |      IE10                  404          0.08\n",
      "     |      Chrome                200          0.02\n",
      "     |      \n",
      "     |      We can also reindex the columns.\n",
      "     |      \n",
      "     |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      Or we can use \"axis-style\" keyword arguments\n",
      "     |      \n",
      "     |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      To further illustrate the filling functionality in\n",
      "     |      ``reindex``, we will create a dataframe with a\n",
      "     |      monotonically increasing index (for example, a sequence\n",
      "     |      of dates).\n",
      "     |      \n",
      "     |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "     |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "     |      ...                    index=date_index)\n",
      "     |      >>> df2\n",
      "     |                  prices\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      \n",
      "     |      Suppose we decide to expand the dataframe to cover a wider\n",
      "     |      date range.\n",
      "     |      \n",
      "     |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "     |      >>> df2.reindex(date_index2)\n",
      "     |                  prices\n",
      "     |      2009-12-29     NaN\n",
      "     |      2009-12-30     NaN\n",
      "     |      2009-12-31     NaN\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      The index entries that did not have a value in the original data frame\n",
      "     |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "     |      If desired, we can fill in the missing values using one of several\n",
      "     |      options.\n",
      "     |      \n",
      "     |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "     |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "     |      \n",
      "     |      >>> df2.reindex(date_index2, method='bfill')\n",
      "     |                  prices\n",
      "     |      2009-12-29     100\n",
      "     |      2009-12-30     100\n",
      "     |      2009-12-31     100\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      Please note that the ``NaN`` value present in the original dataframe\n",
      "     |      (at index value 2010-01-03) will not be filled by any of the\n",
      "     |      value propagation schemes. This is because filling while reindexing\n",
      "     |      does not look at dataframe values, but only compares the original and\n",
      "     |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "     |      in the original dataframe, use the ``fillna()`` method.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : DataFrame\n",
      "     |  \n",
      "     |  reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)\n",
      "     |      Conform input object to new index with optional\n",
      "     |      filling logic, placing NA/NaN in locations having no value in the\n",
      "     |      previous index. A new object is produced unless the new index is\n",
      "     |      equivalent to the current one and copy=False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : array-like\n",
      "     |          New labels / index to conform to. Preferably an Index object to\n",
      "     |          avoid duplicating data\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "     |          Method to use for filling holes in reindexed DataFrame:\n",
      "     |      \n",
      "     |          * default: don't fill gaps\n",
      "     |          * pad / ffill: propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * backfill / bfill: use next valid observation to fill gap\n",
      "     |          * nearest: use nearest valid observations to fill gap\n",
      "     |      \n",
      "     |      copy : boolean, default True\n",
      "     |          Return a new object, even if the passed indexes are the same\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive elements to forward or backward fill\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between original and new labels for inexact\n",
      "     |          matches. The values of the index at the matching locations most\n",
      "     |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "     |      \n",
      "     |          Tolerance may be a scalar value, which applies the same tolerance\n",
      "     |          to all values, or list-like, which applies variable tolerance per\n",
      "     |          element. List-like includes list, tuple, array, Series, and must be\n",
      "     |          the same size as the index and its dtype must exactly match the\n",
      "     |          index's type.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df.reindex_axis(['A', 'B', 'C'], axis=1)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, reindex_like\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : DataFrame\n",
      "     |  \n",
      "     |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None)\n",
      "     |      Alter axes labels.\n",
      "     |      \n",
      "     |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "     |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.rename>` for more.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper, index, columns : dict-like or function, optional\n",
      "     |          dict-like or functions transformations to apply to\n",
      "     |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      "     |          specify the axis to target with ``mapper``, or ``index`` and\n",
      "     |          ``columns``.\n",
      "     |      axis : int or str, optional\n",
      "     |          Axis to target with ``mapper``. Can be either the axis name\n",
      "     |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to return a new %(klass)s. If True then value of copy is\n",
      "     |          ignored.\n",
      "     |      level : int or level name, default None\n",
      "     |          In case of a MultiIndex, only rename labels in the specified\n",
      "     |          level.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.rename_axis\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      ``DataFrame.rename`` supports two calling conventions\n",
      "     |      \n",
      "     |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      "     |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      "     |      \n",
      "     |      We *highly* recommend using keyword arguments to clarify your\n",
      "     |      intent.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
      "     |         a  c\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      >>> df.rename(index=str, columns={\"A\": \"a\", \"C\": \"c\"})\n",
      "     |         a  B\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      Using axis-style parameters\n",
      "     |      \n",
      "     |      >>> df.rename(str.lower, axis='columns')\n",
      "     |         a  b\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      "     |         A  B\n",
      "     |      0  1  4\n",
      "     |      2  2  5\n",
      "     |      4  3  6\n",
      "     |  \n",
      "     |  reorder_levels(self, order, axis=0)\n",
      "     |      Rearrange index levels using input order.\n",
      "     |      May not drop or duplicate levels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : list of int or list of str\n",
      "     |          List representing new level order. Reference level by number\n",
      "     |          (position) or by key (label).\n",
      "     |      axis : int\n",
      "     |          Where to reorder levels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      type of caller (new object)\n",
      "     |  \n",
      "     |  reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
      "     |      For DataFrame with multi-level index, return new DataFrame with\n",
      "     |      labeling information in the columns under the index names, defaulting\n",
      "     |      to 'level_0', 'level_1', etc. if any are None. For a standard index,\n",
      "     |      the index name will be used (if set), otherwise a default 'index' or\n",
      "     |      'level_0' (if 'index' is already taken) will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, str, tuple, or list, default None\n",
      "     |          Only remove the given levels from the index. Removes all levels by\n",
      "     |          default\n",
      "     |      drop : boolean, default False\n",
      "     |          Do not try to insert index into dataframe columns. This resets\n",
      "     |          the index to the default integer index.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Modify the DataFrame in place (do not create a new object)\n",
      "     |      col_level : int or str, default 0\n",
      "     |          If the columns have multiple levels, determines which level the\n",
      "     |          labels are inserted into. By default it is inserted into the first\n",
      "     |          level.\n",
      "     |      col_fill : object, default ''\n",
      "     |          If the columns have multiple levels, determines how the other\n",
      "     |          levels are named. If None then the index name is repeated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      resetted : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('bird',    389.0),\n",
      "     |      ...                    ('bird',     24.0),\n",
      "     |      ...                    ('mammal',   80.5),\n",
      "     |      ...                    ('mammal', np.nan)],\n",
      "     |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      "     |      ...                   columns=('class', 'max_speed'))\n",
      "     |      >>> df\n",
      "     |               class  max_speed\n",
      "     |      falcon    bird      389.0\n",
      "     |      parrot    bird       24.0\n",
      "     |      lion    mammal       80.5\n",
      "     |      monkey  mammal        NaN\n",
      "     |      \n",
      "     |      When we reset the index, the old index is added as a column, and a\n",
      "     |      new sequential index is used:\n",
      "     |      \n",
      "     |      >>> df.reset_index()\n",
      "     |          index   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  parrot    bird       24.0\n",
      "     |      2    lion  mammal       80.5\n",
      "     |      3  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      We can use the `drop` parameter to avoid the old index being added as\n",
      "     |      a column:\n",
      "     |      \n",
      "     |      >>> df.reset_index(drop=True)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      1    bird       24.0\n",
      "     |      2  mammal       80.5\n",
      "     |      3  mammal        NaN\n",
      "     |      \n",
      "     |      You can also use `reset_index` with `MultiIndex`.\n",
      "     |      \n",
      "     |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      "     |      ...                                    ('bird', 'parrot'),\n",
      "     |      ...                                    ('mammal', 'lion'),\n",
      "     |      ...                                    ('mammal', 'monkey')],\n",
      "     |      ...                                   names=['class', 'name'])\n",
      "     |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      "     |      ...                                      ('species', 'type')])\n",
      "     |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      "     |      ...                    ( 24.0, 'fly'),\n",
      "     |      ...                    ( 80.5, 'run'),\n",
      "     |      ...                    (np.nan, 'jump')],\n",
      "     |      ...                   index=index,\n",
      "     |      ...                   columns=columns)\n",
      "     |      >>> df\n",
      "     |                     speed species\n",
      "     |                       max    type\n",
      "     |      class  name\n",
      "     |      bird   falcon  389.0     fly\n",
      "     |             parrot   24.0     fly\n",
      "     |      mammal lion     80.5     run\n",
      "     |             monkey    NaN    jump\n",
      "     |      \n",
      "     |      If the index has multiple levels, we can reset a subset of them:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class')\n",
      "     |               class  speed species\n",
      "     |                        max    type\n",
      "     |      name\n",
      "     |      falcon    bird  389.0     fly\n",
      "     |      parrot    bird   24.0     fly\n",
      "     |      lion    mammal   80.5     run\n",
      "     |      monkey  mammal    NaN    jump\n",
      "     |      \n",
      "     |      If we are not dropping the index, by default, it is placed in the top\n",
      "     |      level. We can place it in another level:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class', col_level=1)\n",
      "     |                      speed species\n",
      "     |               class    max    type\n",
      "     |      name\n",
      "     |      falcon    bird  389.0     fly\n",
      "     |      parrot    bird   24.0     fly\n",
      "     |      lion    mammal   80.5     run\n",
      "     |      monkey  mammal    NaN    jump\n",
      "     |      \n",
      "     |      When the index is inserted under another level, we can specify under\n",
      "     |      which one with the parameter `col_fill`:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      "     |                    species  speed species\n",
      "     |                      class    max    type\n",
      "     |      name\n",
      "     |      falcon           bird  389.0     fly\n",
      "     |      parrot           bird   24.0     fly\n",
      "     |      lion           mammal   80.5     run\n",
      "     |      monkey         mammal    NaN    jump\n",
      "     |      \n",
      "     |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      "     |      \n",
      "     |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      "     |                      genus  speed species\n",
      "     |                      class    max    type\n",
      "     |      name\n",
      "     |      falcon           bird  389.0     fly\n",
      "     |      parrot           bird   24.0     fly\n",
      "     |      lion           mammal   80.5     run\n",
      "     |      monkey         mammal    NaN    jump\n",
      "     |  \n",
      "     |  rolling(self, window, min_periods=None, freq=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      "     |      Provides rolling window calculations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      window : int, or offset\n",
      "     |          Size of the moving window. This is the number of observations used for\n",
      "     |          calculating the statistic. Each window will be a fixed size.\n",
      "     |      \n",
      "     |          If its an offset then this will be the time period of each window. Each\n",
      "     |          window will be a variable sized based on the observations included in\n",
      "     |          the time-period. This is only valid for datetimelike indexes. This is\n",
      "     |          new in 0.19.0\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA). For a window that is specified by an offset,\n",
      "     |          this will default to 1.\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      win_type : string, default None\n",
      "     |          Provide a window type. See the notes below.\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column on which to calculate\n",
      "     |          the rolling window, rather than the index\n",
      "     |      closed : string, default None\n",
      "     |          Make the interval closed on the 'right', 'left', 'both' or\n",
      "     |          'neither' endpoints.\n",
      "     |          For offset-based windows, it defaults to 'right'.\n",
      "     |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      "     |          for fixed windows.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window or Rolling sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |      >>> df\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, using the 'triang'\n",
      "     |      window type.\n",
      "     |      \n",
      "     |      >>> df.rolling(2, win_type='triang').sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  2.5\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, min_periods defaults\n",
      "     |      to the window length.\n",
      "     |      \n",
      "     |      >>> df.rolling(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Same as above, but explicity set the min_periods\n",
      "     |      \n",
      "     |      >>> df.rolling(2, min_periods=1).sum()\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  2.0\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      "     |      ....:                 index = [pd.Timestamp('20130101 09:00:00'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:02'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:03'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:05'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:06')])\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  2.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      \n",
      "     |      Contrasting to an integer rolling window, this will roll a variable\n",
      "     |      length window corresponding to the time period.\n",
      "     |      The default for min_periods is 1.\n",
      "     |      \n",
      "     |      >>> df.rolling('2s').sum()\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  3.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      To learn more about the offsets & frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      The recognized win_types are:\n",
      "     |      \n",
      "     |      * ``boxcar``\n",
      "     |      * ``triang``\n",
      "     |      * ``blackman``\n",
      "     |      * ``hamming``\n",
      "     |      * ``bartlett``\n",
      "     |      * ``parzen``\n",
      "     |      * ``bohman``\n",
      "     |      * ``blackmanharris``\n",
      "     |      * ``nuttall``\n",
      "     |      * ``barthann``\n",
      "     |      * ``kaiser`` (needs beta)\n",
      "     |      * ``gaussian`` (needs std)\n",
      "     |      * ``general_gaussian`` (needs power, width)\n",
      "     |      * ``slepian`` (needs width).\n",
      "     |      \n",
      "     |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      "     |      different window types see `scipy.signal window functions\n",
      "     |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      "     |  \n",
      "     |  round(self, decimals=0, *args, **kwargs)\n",
      "     |      Round a DataFrame to a variable number of decimal places.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      decimals : int, dict, Series\n",
      "     |          Number of decimal places to round each column to. If an int is\n",
      "     |          given, round each column to the same number of places.\n",
      "     |          Otherwise dict and Series round to variable numbers of places.\n",
      "     |          Column names should be in the keys if `decimals` is a\n",
      "     |          dict-like, or in the index if `decimals` is a Series. Any\n",
      "     |          columns not included in `decimals` will be left as is. Elements\n",
      "     |          of `decimals` which are not columns of the input will be\n",
      "     |          ignored.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.random.random([3, 3]),\n",
      "     |      ...     columns=['A', 'B', 'C'], index=['first', 'second', 'third'])\n",
      "     |      >>> df\n",
      "     |                     A         B         C\n",
      "     |      first   0.028208  0.992815  0.173891\n",
      "     |      second  0.038683  0.645646  0.577595\n",
      "     |      third   0.877076  0.149370  0.491027\n",
      "     |      >>> df.round(2)\n",
      "     |                 A     B     C\n",
      "     |      first   0.03  0.99  0.17\n",
      "     |      second  0.04  0.65  0.58\n",
      "     |      third   0.88  0.15  0.49\n",
      "     |      >>> df.round({'A': 1, 'C': 2})\n",
      "     |                A         B     C\n",
      "     |      first   0.0  0.992815  0.17\n",
      "     |      second  0.0  0.645646  0.58\n",
      "     |      third   0.9  0.149370  0.49\n",
      "     |      >>> decimals = pd.Series([1, 0, 2], index=['A', 'B', 'C'])\n",
      "     |      >>> df.round(decimals)\n",
      "     |                A  B     C\n",
      "     |      first   0.0  1  0.17\n",
      "     |      second  0.0  1  0.58\n",
      "     |      third   0.9  0  0.49\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around\n",
      "     |      Series.round\n",
      "     |  \n",
      "     |  select_dtypes(self, include=None, exclude=None)\n",
      "     |      Return a subset of a DataFrame including/excluding columns based on\n",
      "     |      their ``dtype``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      include, exclude : scalar or list-like\n",
      "     |          A selection of dtypes or strings to be included/excluded. At least\n",
      "     |          one of these parameters must be supplied.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If both of ``include`` and ``exclude`` are empty\n",
      "     |          * If ``include`` and ``exclude`` have overlapping elements\n",
      "     |          * If any kind of string dtype is passed in.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : DataFrame\n",
      "     |          The subset of the frame including the dtypes in ``include`` and\n",
      "     |          excluding the dtypes in ``exclude``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * To select all *numeric* types use the numpy dtype ``numpy.number``\n",
      "     |      * To select strings you must use the ``object`` dtype, but note that\n",
      "     |        this will return *all* object dtype columns\n",
      "     |      * See the `numpy dtype hierarchy\n",
      "     |        <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n",
      "     |      * To select datetimes, use np.datetime64, 'datetime' or 'datetime64'\n",
      "     |      * To select timedeltas, use np.timedelta64, 'timedelta' or\n",
      "     |        'timedelta64'\n",
      "     |      * To select Pandas categorical dtypes, use 'category'\n",
      "     |      * To select Pandas datetimetz dtypes, use 'datetimetz' (new in 0.20.0),\n",
      "     |        or a 'datetime64[ns, tz]' string\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'a': np.random.randn(6).astype('f4'),\n",
      "     |      ...                    'b': [True, False] * 3,\n",
      "     |      ...                    'c': [1.0, 2.0] * 3})\n",
      "     |      >>> df\n",
      "     |              a      b  c\n",
      "     |      0  0.3962   True  1\n",
      "     |      1  0.1459  False  2\n",
      "     |      2  0.2623   True  1\n",
      "     |      3  0.0764  False  2\n",
      "     |      4 -0.9703   True  1\n",
      "     |      5 -1.2094  False  2\n",
      "     |      >>> df.select_dtypes(include='bool')\n",
      "     |         c\n",
      "     |      0  True\n",
      "     |      1  False\n",
      "     |      2  True\n",
      "     |      3  False\n",
      "     |      4  True\n",
      "     |      5  False\n",
      "     |      >>> df.select_dtypes(include=['float64'])\n",
      "     |         c\n",
      "     |      0  1\n",
      "     |      1  2\n",
      "     |      2  1\n",
      "     |      3  2\n",
      "     |      4  1\n",
      "     |      5  2\n",
      "     |      >>> df.select_dtypes(exclude=['floating'])\n",
      "     |             b\n",
      "     |      0   True\n",
      "     |      1  False\n",
      "     |      2   True\n",
      "     |      3  False\n",
      "     |      4   True\n",
      "     |      5  False\n",
      "     |  \n",
      "     |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased standard error of the mean over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sem : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
      "     |      Set the DataFrame index (row labels) using one or more existing\n",
      "     |      columns. By default yields a new object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keys : column label or list of column labels / arrays\n",
      "     |      drop : boolean, default True\n",
      "     |          Delete columns to be used as the new index\n",
      "     |      append : boolean, default False\n",
      "     |          Whether to append columns to existing index\n",
      "     |      inplace : boolean, default False\n",
      "     |          Modify the DataFrame in place (do not create a new object)\n",
      "     |      verify_integrity : boolean, default False\n",
      "     |          Check the new index for duplicates. Otherwise defer the check until\n",
      "     |          necessary. Setting to False will improve the performance of this\n",
      "     |          method\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      "     |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      "     |      ...                    'sale':[55, 40, 84, 31]})\n",
      "     |         month  sale  year\n",
      "     |      0  1      55    2012\n",
      "     |      1  4      40    2014\n",
      "     |      2  7      84    2013\n",
      "     |      3  10     31    2014\n",
      "     |      \n",
      "     |      Set the index to become the 'month' column:\n",
      "     |      \n",
      "     |      >>> df.set_index('month')\n",
      "     |             sale  year\n",
      "     |      month\n",
      "     |      1      55    2012\n",
      "     |      4      40    2014\n",
      "     |      7      84    2013\n",
      "     |      10     31    2014\n",
      "     |      \n",
      "     |      Create a multi-index using columns 'year' and 'month':\n",
      "     |      \n",
      "     |      >>> df.set_index(['year', 'month'])\n",
      "     |                  sale\n",
      "     |      year  month\n",
      "     |      2012  1     55\n",
      "     |      2014  4     40\n",
      "     |      2013  7     84\n",
      "     |      2014  10    31\n",
      "     |      \n",
      "     |      Create a multi-index using a set of values and a column:\n",
      "     |      \n",
      "     |      >>> df.set_index([[1, 2, 3, 4], 'year'])\n",
      "     |               month  sale\n",
      "     |         year\n",
      "     |      1  2012  1      55\n",
      "     |      2  2014  4      40\n",
      "     |      3  2013  7      84\n",
      "     |      4  2014  10     31\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dataframe : DataFrame\n",
      "     |  \n",
      "     |  shift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift index by desired number of periods with an optional time freq\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, optional\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      "     |          See Notes.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is specified then the index values are shifted but the data\n",
      "     |      is not realigned. That is, use freq if you would like to extend the\n",
      "     |      index when shifting and preserve the original data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : DataFrame\n",
      "     |  \n",
      "     |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased skew over requested axis\n",
      "     |      Normalized by N-1\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      skew : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)\n",
      "     |      Sort object by labels (along an axis)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : index, columns to direct sorting\n",
      "     |      level : int or level name or list of ints or list of level names\n",
      "     |          if not None, sort on values in specified index level(s)\n",
      "     |      ascending : boolean, default True\n",
      "     |          Sort ascending vs. descending\n",
      "     |      inplace : bool, default False\n",
      "     |          if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      "     |           Not implemented for MultiIndex.\n",
      "     |      sort_remaining : bool, default True\n",
      "     |          if true and sorting by level and index is multilevel, sort by other\n",
      "     |          levels too (in order) after sorting by specified level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : DataFrame\n",
      "     |  \n",
      "     |  sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      "     |      Sort by the values along either axis\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : str or list of str\n",
      "     |          Name or list of names which refer to the axis items.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Axis to direct sorting\n",
      "     |      ascending : bool or list of bool, default True\n",
      "     |           Sort ascending vs. descending. Specify list for multiple sort\n",
      "     |           orders.  If this is a list of bools, must match the length of\n",
      "     |           the by.\n",
      "     |      inplace : bool, default False\n",
      "     |           if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...     'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "     |      ...     'col2' : [2, 1, 9, 8, 7, 4],\n",
      "     |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "     |      ... })\n",
      "     |      >>> df\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      \n",
      "     |      Sort by col1\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1'])\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort by multiple columns\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1', 'col2'])\n",
      "     |          col1 col2 col3\n",
      "     |      1   A    1    1\n",
      "     |      0   A    2    0\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort Descending\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False)\n",
      "     |          col1 col2 col3\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Putting NAs first\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "     |          col1 col2 col3\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |  \n",
      "     |  sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)\n",
      "     |      DEPRECATED: use :meth:`DataFrame.sort_index`\n",
      "     |      \n",
      "     |      Sort multilevel index by chosen axis and primary level. Data will be\n",
      "     |      lexicographically sorted by the chosen level followed by the other\n",
      "     |      levels (in order)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |      ascending : boolean, default True\n",
      "     |      inplace : boolean, default False\n",
      "     |          Sort the DataFrame without creating a new instance\n",
      "     |      sort_remaining : boolean, default True\n",
      "     |          Sort by the other levels too.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted : DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.sort_index(level=...)\n",
      "     |  \n",
      "     |  stack(self, level=-1, dropna=True)\n",
      "     |      Pivot a level of the (possibly hierarchical) column labels, returning a\n",
      "     |      DataFrame (or Series in the case of an object with a single level of\n",
      "     |      column labels) having a hierarchical index with a new inner-most level\n",
      "     |      of row labels.\n",
      "     |      The level involved will automatically get sorted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, string, or list of these, default last level\n",
      "     |          Level(s) to stack, can pass level name\n",
      "     |      dropna : boolean, default True\n",
      "     |          Whether to drop rows in the resulting Frame/Series with no valid\n",
      "     |          values\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      >>> s\n",
      "     |           a   b\n",
      "     |      one  1.  2.\n",
      "     |      two  3.  4.\n",
      "     |      \n",
      "     |      >>> s.stack()\n",
      "     |      one a    1\n",
      "     |          b    2\n",
      "     |      two a    3\n",
      "     |          b    4\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stacked : DataFrame or Series\n",
      "     |  \n",
      "     |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return sample standard deviation over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the sum of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sum : Series or DataFrame (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      "     |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum()\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  swaplevel(self, i=-2, j=-1, axis=0)\n",
      "     |      Swap levels i and j in a MultiIndex on a particular axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      i, j : int, string (can be mixed)\n",
      "     |          Level of index to be swapped. Can pass level name as string.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      swapped : type of caller (new object)\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.18.1\n",
      "     |      \n",
      "     |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      "     |         the two innermost levels of the index.\n",
      "     |  \n",
      "     |  to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
      "     |      Write DataFrame to a comma-separated values (csv) file\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : string or file handle, default None\n",
      "     |          File path or object, if None is provided the result is returned as\n",
      "     |          a string.\n",
      "     |      sep : character, default ','\n",
      "     |          Field delimiter for the output file.\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      columns : sequence, optional\n",
      "     |          Columns to write\n",
      "     |      header : boolean or list of string, default True\n",
      "     |          Write out the column names. If a list of strings is given it is\n",
      "     |          assumed to be aliases for the column names\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, or False, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.  If\n",
      "     |          False do not print fields for index names. Use index_label=False\n",
      "     |          for easier importing in R\n",
      "     |      mode : str\n",
      "     |          Python write mode, default 'w'\n",
      "     |      encoding : string, optional\n",
      "     |          A string representing the encoding to use in the output file,\n",
      "     |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "     |      compression : string, optional\n",
      "     |          a string representing the compression to use in the output file,\n",
      "     |          allowed values are 'gzip', 'bz2', 'xz',\n",
      "     |          only used when the first argument is a filename\n",
      "     |      line_terminator : string, default ``'\\n'``\n",
      "     |          The newline character or character sequence to use in the output\n",
      "     |          file\n",
      "     |      quoting : optional constant from csv module\n",
      "     |          defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "     |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "     |          will treat them as non-numeric\n",
      "     |      quotechar : string (length 1), default '\\\"'\n",
      "     |          character used to quote fields\n",
      "     |      doublequote : boolean, default True\n",
      "     |          Control quoting of `quotechar` inside a field\n",
      "     |      escapechar : string (length 1), default None\n",
      "     |          character used to escape `sep` and `quotechar` when appropriate\n",
      "     |      chunksize : int or None\n",
      "     |          rows to write at a time\n",
      "     |      tupleize_cols : boolean, default False\n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |             This argument will be removed and will always write each row\n",
      "     |             of the multi-index as a separate row in the CSV file.\n",
      "     |      \n",
      "     |          Write MultiIndex columns as a list of tuples (if True) or in\n",
      "     |          the new, expanded format, where each MultiIndex column is a row\n",
      "     |          in the CSV (if False).\n",
      "     |      date_format : string, default None\n",
      "     |          Format string for datetime objects\n",
      "     |      decimal: string, default '.'\n",
      "     |          Character recognized as decimal separator. E.g. use ',' for\n",
      "     |          European data\n",
      "     |  \n",
      "     |  to_dict(self, orient='dict', into=<class 'dict'>)\n",
      "     |      Convert DataFrame to dictionary.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      "     |          Determines the type of the values of the dictionary.\n",
      "     |      \n",
      "     |          - dict (default) : dict like {column -> {index -> value}}\n",
      "     |          - list : dict like {column -> [values]}\n",
      "     |          - series : dict like {column -> Series(values)}\n",
      "     |          - split : dict like\n",
      "     |            {index -> [index], columns -> [columns], data -> [values]}\n",
      "     |          - records : list like\n",
      "     |            [{column -> value}, ... , {column -> value}]\n",
      "     |          - index : dict like {index -> {column -> value}}\n",
      "     |      \n",
      "     |            .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      "     |          indicates `split`.\n",
      "     |      \n",
      "     |      into : class, default dict\n",
      "     |          The collections.Mapping subclass used for all Mappings\n",
      "     |          in the return value.  Can be the actual class or an empty\n",
      "     |          instance of the mapping type you want.  If you want a\n",
      "     |          collections.defaultdict, you must pass it initialized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : collections.Mapping like {column -> {index -> value}}\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(\n",
      "     |              {'col1': [1, 2], 'col2': [0.5, 0.75]}, index=['a', 'b'])\n",
      "     |      >>> df\n",
      "     |         col1  col2\n",
      "     |      a     1   0.1\n",
      "     |      b     2   0.2\n",
      "     |      >>> df.to_dict()\n",
      "     |      {'col1': {'a': 1, 'b': 2}, 'col2': {'a': 0.5, 'b': 0.75}}\n",
      "     |      \n",
      "     |      You can specify the return orientation.\n",
      "     |      \n",
      "     |      >>> df.to_dict('series')\n",
      "     |      {'col1': a    1\n",
      "     |      b    2\n",
      "     |      Name: col1, dtype: int64, 'col2': a    0.50\n",
      "     |      b    0.75\n",
      "     |      Name: col2, dtype: float64}\n",
      "     |      >>> df.to_dict('split')\n",
      "     |      {'columns': ['col1', 'col2'],\n",
      "     |      'data': [[1.0, 0.5], [2.0, 0.75]],\n",
      "     |      'index': ['a', 'b']}\n",
      "     |      >>> df.to_dict('records')\n",
      "     |      [{'col1': 1.0, 'col2': 0.5}, {'col1': 2.0, 'col2': 0.75}]\n",
      "     |      >>> df.to_dict('index')\n",
      "     |      {'a': {'col1': 1.0, 'col2': 0.5}, 'b': {'col1': 2.0, 'col2': 0.75}}\n",
      "     |      \n",
      "     |      You can also specify the mapping type.\n",
      "     |      \n",
      "     |      >>> from collections import OrderedDict, defaultdict\n",
      "     |      >>> df.to_dict(into=OrderedDict)\n",
      "     |      OrderedDict([('col1', OrderedDict([('a', 1), ('b', 2)])),\n",
      "     |                 ('col2', OrderedDict([('a', 0.5), ('b', 0.75)]))])\n",
      "     |      \n",
      "     |      If you want a `defaultdict`, you need to initialize it:\n",
      "     |      \n",
      "     |      >>> dd = defaultdict(list)\n",
      "     |      >>> df.to_dict('records', into=dd)\n",
      "     |      [defaultdict(<type 'list'>, {'col2': 0.5, 'col1': 1.0}),\n",
      "     |      defaultdict(<type 'list'>, {'col2': 0.75, 'col1': 2.0})]\n",
      "     |  \n",
      "     |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)\n",
      "     |      Write DataFrame to an excel sheet\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel_writer : string or ExcelWriter object\n",
      "     |          File path or existing ExcelWriter\n",
      "     |      sheet_name : string, default 'Sheet1'\n",
      "     |          Name of sheet which will contain DataFrame\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      columns : sequence, optional\n",
      "     |          Columns to write\n",
      "     |      header : boolean or list of string, default True\n",
      "     |          Write out the column names. If a list of strings is given it is\n",
      "     |          assumed to be aliases for the column names\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      startrow :\n",
      "     |          upper left cell row to dump data frame\n",
      "     |      startcol :\n",
      "     |          upper left cell column to dump data frame\n",
      "     |      engine : string, default None\n",
      "     |          write engine to use - you can also set this via the options\n",
      "     |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      "     |          ``io.excel.xlsm.writer``.\n",
      "     |      merge_cells : boolean, default True\n",
      "     |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      "     |      encoding: string, default None\n",
      "     |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      "     |          other writers support unicode natively.\n",
      "     |      inf_rep : string, default 'inf'\n",
      "     |          Representation for infinity (there is no native representation for\n",
      "     |          infinity in Excel)\n",
      "     |      freeze_panes : tuple of integer (length 2), default None\n",
      "     |          Specifies the one-based bottommost row and rightmost column that\n",
      "     |          is to be frozen\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      "     |      to the existing workbook.  This can be used to save different\n",
      "     |      DataFrames to one workbook:\n",
      "     |      \n",
      "     |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      "     |      >>> df1.to_excel(writer,'Sheet1')\n",
      "     |      >>> df2.to_excel(writer,'Sheet2')\n",
      "     |      >>> writer.save()\n",
      "     |      \n",
      "     |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      "     |      strings before writing.\n",
      "     |  \n",
      "     |  to_feather(self, fname)\n",
      "     |      write out the binary feather-format for DataFrames\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : str\n",
      "     |          string file path\n",
      "     |  \n",
      "     |  to_gbq(self, destination_table, project_id, chunksize=10000, verbose=True, reauth=False, if_exists='fail', private_key=None)\n",
      "     |      Write a DataFrame to a Google BigQuery table.\n",
      "     |      \n",
      "     |      The main method a user calls to export pandas DataFrame contents to\n",
      "     |      Google BigQuery table.\n",
      "     |      \n",
      "     |      Google BigQuery API Client Library v2 for Python is used.\n",
      "     |      Documentation is available `here\n",
      "     |      <https://developers.google.com/api-client-library/python/apis/bigquery/v2>`__\n",
      "     |      \n",
      "     |      Authentication to the Google BigQuery service is via OAuth 2.0.\n",
      "     |      \n",
      "     |      - If \"private_key\" is not provided:\n",
      "     |      \n",
      "     |        By default \"application default credentials\" are used.\n",
      "     |      \n",
      "     |        If default application credentials are not found or are restrictive,\n",
      "     |        user account credentials are used. In this case, you will be asked to\n",
      "     |        grant permissions for product name 'pandas GBQ'.\n",
      "     |      \n",
      "     |      - If \"private_key\" is provided:\n",
      "     |      \n",
      "     |        Service account credentials will be used to authenticate.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataframe : DataFrame\n",
      "     |          DataFrame to be written\n",
      "     |      destination_table : string\n",
      "     |          Name of table to be written, in the form 'dataset.tablename'\n",
      "     |      project_id : str\n",
      "     |          Google BigQuery Account project ID.\n",
      "     |      chunksize : int (default 10000)\n",
      "     |          Number of rows to be inserted in each chunk from the dataframe.\n",
      "     |      verbose : boolean (default True)\n",
      "     |          Show percentage complete\n",
      "     |      reauth : boolean (default False)\n",
      "     |          Force Google BigQuery to reauthenticate the user. This is useful\n",
      "     |          if multiple accounts are used.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          'fail': If table exists, do nothing.\n",
      "     |          'replace': If table exists, drop it, recreate it, and insert data.\n",
      "     |          'append': If table exists, insert data. Create if does not exist.\n",
      "     |      private_key : str (optional)\n",
      "     |          Service account private key in JSON format. Can be file path\n",
      "     |          or string contents. This is useful for remote server\n",
      "     |          authentication (eg. jupyter iPython notebook on remote host)\n",
      "     |  \n",
      "     |  to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None, escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False, decimal='.', border=None)\n",
      "     |      Render a DataFrame as an HTML table.\n",
      "     |      \n",
      "     |      `to_html`-specific options:\n",
      "     |      \n",
      "     |      bold_rows : boolean, default True\n",
      "     |          Make the row labels bold in the output\n",
      "     |      classes : str or list or tuple, default None\n",
      "     |          CSS class(es) to apply to the resulting html table\n",
      "     |      escape : boolean, default True\n",
      "     |          Convert the characters <, >, and & to HTML-safe sequences.=\n",
      "     |      max_rows : int, optional\n",
      "     |          Maximum number of rows to show before truncating. If None, show\n",
      "     |          all.\n",
      "     |      max_cols : int, optional\n",
      "     |          Maximum number of columns to show before truncating. If None, show\n",
      "     |          all.\n",
      "     |      decimal : string, default '.'\n",
      "     |          Character recognized as decimal separator, e.g. ',' in Europe\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      border : int\n",
      "     |          A ``border=border`` attribute is included in the opening\n",
      "     |          `<table>` tag. Default ``pd.options.html.border``.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      buf : StringIO-like, optional\n",
      "     |          buffer to write to\n",
      "     |      columns : sequence, optional\n",
      "     |          the subset of columns to write; default None writes all columns\n",
      "     |      col_space : int, optional\n",
      "     |          the minimum width of each column\n",
      "     |      header : bool, optional\n",
      "     |          whether to print column labels, default True\n",
      "     |      index : bool, optional\n",
      "     |          whether to print index (row) labels, default True\n",
      "     |      na_rep : string, optional\n",
      "     |          string representation of NAN to use, default 'NaN'\n",
      "     |      formatters : list or dict of one-parameter functions, optional\n",
      "     |          formatter functions to apply to columns' elements by position or name,\n",
      "     |          default None. The result of each function must be a unicode string.\n",
      "     |          List must be of length equal to the number of columns.\n",
      "     |      float_format : one-parameter function, optional\n",
      "     |          formatter function to apply to columns' elements if they are floats,\n",
      "     |          default None. The result of this function must be a unicode string.\n",
      "     |      sparsify : bool, optional\n",
      "     |          Set to False for a DataFrame with a hierarchical index to print every\n",
      "     |          multiindex key at each row, default True\n",
      "     |      index_names : bool, optional\n",
      "     |          Prints the names of the indexes, default True\n",
      "     |      line_width : int, optional\n",
      "     |          Width to wrap a line in characters, default no wrap\n",
      "     |      justify : {'left', 'right', 'center', 'justify',\n",
      "     |                 'justify-all', 'start', 'end', 'inherit',\n",
      "     |                 'match-parent', 'initial', 'unset'}, default None\n",
      "     |          How to justify the column labels. If None uses the option from\n",
      "     |          the print configuration (controlled by set_option), 'right' out\n",
      "     |          of the box.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      formatted : string (or unicode, depending on data and options)\n",
      "     |  \n",
      "     |  to_panel(self)\n",
      "     |      Transform long (stacked) format (DataFrame) into wide (3D, Panel)\n",
      "     |      format.\n",
      "     |      \n",
      "     |      Currently the index of the DataFrame must be a 2-level MultiIndex. This\n",
      "     |      may be generalized later\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      panel : Panel\n",
      "     |  \n",
      "     |  to_parquet(self, fname, engine='auto', compression='snappy', **kwargs)\n",
      "     |      Write a DataFrame to the binary parquet format.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : str\n",
      "     |          string file path\n",
      "     |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      "     |          Parquet reader library to use. If 'auto', then the option\n",
      "     |          'io.parquet.engine' is used. If 'auto', then the first\n",
      "     |          library to be installed is used.\n",
      "     |      compression : str, optional, default 'snappy'\n",
      "     |          compression method, includes {'gzip', 'snappy', 'brotli'}\n",
      "     |      kwargs\n",
      "     |          Additional keyword arguments passed to the engine\n",
      "     |  \n",
      "     |  to_period(self, freq=None, axis=0, copy=True)\n",
      "     |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      "     |      frequency (inferred from index if not passed)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to convert (the index by default)\n",
      "     |      copy : boolean, default True\n",
      "     |          If False then underlying input data is not copied\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ts : TimeSeries with PeriodIndex\n",
      "     |  \n",
      "     |  to_records(self, index=True, convert_datetime64=True)\n",
      "     |      Convert DataFrame to record array. Index will be put in the\n",
      "     |      'index' field of the record array if requested\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : boolean, default True\n",
      "     |          Include index in resulting record array, stored in 'index' field\n",
      "     |      convert_datetime64 : boolean, default True\n",
      "     |          Whether to convert the index to datetime.datetime if it is a\n",
      "     |          DatetimeIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : recarray\n",
      "     |  \n",
      "     |  to_sparse(self, fill_value=None, kind='block')\n",
      "     |      Convert to SparseDataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fill_value : float, default NaN\n",
      "     |      kind : {'block', 'integer'}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : SparseDataFrame\n",
      "     |  \n",
      "     |  to_stata(self, fname, convert_dates=None, write_index=True, encoding='latin-1', byteorder=None, time_stamp=None, data_label=None, variable_labels=None)\n",
      "     |      A class for writing Stata binary dta files from array-like objects\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : str or buffer\n",
      "     |          String path of file-like object\n",
      "     |      convert_dates : dict\n",
      "     |          Dictionary mapping columns containing datetime types to stata\n",
      "     |          internal format to use when wirting the dates. Options are 'tc',\n",
      "     |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      "     |          or a name. Datetime columns that do not have a conversion type\n",
      "     |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      "     |          a datetime column has timezone information\n",
      "     |      write_index : bool\n",
      "     |          Write the index to Stata dataset.\n",
      "     |      encoding : str\n",
      "     |          Default is latin-1. Unicode is not supported\n",
      "     |      byteorder : str\n",
      "     |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`\n",
      "     |      time_stamp : datetime\n",
      "     |          A datetime to use as file creation date.  Default is the current\n",
      "     |          time.\n",
      "     |      dataset_label : str\n",
      "     |          A label for the data set.  Must be 80 characters or smaller.\n",
      "     |      variable_labels : dict\n",
      "     |          Dictionary containing columns as keys and variable labels as\n",
      "     |          values. Each label must be 80 characters or smaller.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      NotImplementedError\n",
      "     |          * If datetimes contain timezone information\n",
      "     |          * Column dtype is not representable in Stata\n",
      "     |      ValueError\n",
      "     |          * Columns listed in convert_dates are noth either datetime64[ns]\n",
      "     |            or datetime.datetime\n",
      "     |          * Column listed in convert_dates is not in DataFrame\n",
      "     |          * Categorical label contains more than 32,000 characters\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> writer = StataWriter('./data_file.dta', data)\n",
      "     |      >>> writer.write_file()\n",
      "     |      \n",
      "     |      Or with dates\n",
      "     |      \n",
      "     |      >>> writer = StataWriter('./date_data_file.dta', data, {2 : 'tw'})\n",
      "     |      >>> writer.write_file()\n",
      "     |  \n",
      "     |  to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None, show_dimensions=False)\n",
      "     |      Render a DataFrame to a console-friendly tabular output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      buf : StringIO-like, optional\n",
      "     |          buffer to write to\n",
      "     |      columns : sequence, optional\n",
      "     |          the subset of columns to write; default None writes all columns\n",
      "     |      col_space : int, optional\n",
      "     |          the minimum width of each column\n",
      "     |      header : bool, optional\n",
      "     |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names\n",
      "     |      index : bool, optional\n",
      "     |          whether to print index (row) labels, default True\n",
      "     |      na_rep : string, optional\n",
      "     |          string representation of NAN to use, default 'NaN'\n",
      "     |      formatters : list or dict of one-parameter functions, optional\n",
      "     |          formatter functions to apply to columns' elements by position or name,\n",
      "     |          default None. The result of each function must be a unicode string.\n",
      "     |          List must be of length equal to the number of columns.\n",
      "     |      float_format : one-parameter function, optional\n",
      "     |          formatter function to apply to columns' elements if they are floats,\n",
      "     |          default None. The result of this function must be a unicode string.\n",
      "     |      sparsify : bool, optional\n",
      "     |          Set to False for a DataFrame with a hierarchical index to print every\n",
      "     |          multiindex key at each row, default True\n",
      "     |      index_names : bool, optional\n",
      "     |          Prints the names of the indexes, default True\n",
      "     |      line_width : int, optional\n",
      "     |          Width to wrap a line in characters, default no wrap\n",
      "     |      justify : {'left', 'right', 'center', 'justify',\n",
      "     |                 'justify-all', 'start', 'end', 'inherit',\n",
      "     |                 'match-parent', 'initial', 'unset'}, default None\n",
      "     |          How to justify the column labels. If None uses the option from\n",
      "     |          the print configuration (controlled by set_option), 'right' out\n",
      "     |          of the box.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      formatted : string (or unicode, depending on data and options)\n",
      "     |  \n",
      "     |  to_timestamp(self, freq=None, how='start', axis=0, copy=True)\n",
      "     |      Cast to DatetimeIndex of timestamps, at *beginning* of period\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default frequency of PeriodIndex\n",
      "     |          Desired frequency\n",
      "     |      how : {'s', 'e', 'start', 'end'}\n",
      "     |          Convention for converting period to timestamp; start of period\n",
      "     |          vs. end\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to convert (the index by default)\n",
      "     |      copy : boolean, default True\n",
      "     |          If false then underlying input data is not copied\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame with DatetimeIndex\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |      Call function producing a like-indexed NDFrame\n",
      "     |      and return a NDFrame with the transformed values\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          To apply to column\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      transformed : NDFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      "     |                         A         B         C\n",
      "     |      2000-01-01  0.579457  1.236184  0.123424\n",
      "     |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      "     |      2000-01-03  1.455756 -0.277446  0.288967\n",
      "     |      2000-01-04       NaN       NaN       NaN\n",
      "     |      2000-01-05       NaN       NaN       NaN\n",
      "     |      2000-01-06       NaN       NaN       NaN\n",
      "     |      2000-01-07       NaN       NaN       NaN\n",
      "     |      2000-01-08 -0.498658  1.274522  1.642524\n",
      "     |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      "     |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.aggregate\n",
      "     |      pandas.NDFrame.apply\n",
      "     |  \n",
      "     |  unstack(self, level=-1, fill_value=None)\n",
      "     |      Pivot a level of the (necessarily hierarchical) index labels, returning\n",
      "     |      a DataFrame having a new level of column labels whose inner-most level\n",
      "     |      consists of the pivoted index labels. If the index is not a MultiIndex,\n",
      "     |      the output will be a Series (the analogue of stack when the columns are\n",
      "     |      not a MultiIndex).\n",
      "     |      The level involved will automatically get sorted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, string, or list of these, default -1 (last level)\n",
      "     |          Level(s) of index to unstack, can pass level name\n",
      "     |      fill_value : replace NaN with this value if the unstack produces\n",
      "     |          missing values\n",
      "     |      \n",
      "     |          .. versionadded: 0.18.0\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      DataFrame.pivot : Pivot a table based on column values.\n",
      "     |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      "     |          from `unstack`).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      "     |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      "     |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      "     |      >>> s\n",
      "     |      one  a   1.0\n",
      "     |           b   2.0\n",
      "     |      two  a   3.0\n",
      "     |           b   4.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> s.unstack(level=-1)\n",
      "     |           a   b\n",
      "     |      one  1.0  2.0\n",
      "     |      two  3.0  4.0\n",
      "     |      \n",
      "     |      >>> s.unstack(level=0)\n",
      "     |         one  two\n",
      "     |      a  1.0   3.0\n",
      "     |      b  2.0   4.0\n",
      "     |      \n",
      "     |      >>> df = s.unstack(level=0)\n",
      "     |      >>> df.unstack()\n",
      "     |      one  a  1.0\n",
      "     |           b  2.0\n",
      "     |      two  a  3.0\n",
      "     |           b  4.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unstacked : DataFrame or Series\n",
      "     |  \n",
      "     |  update(self, other, join='left', overwrite=True, filter_func=None, raise_conflict=False)\n",
      "     |      Modify DataFrame in place using non-NA values from passed\n",
      "     |      DataFrame. Aligns on indices\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame, or object coercible into a DataFrame\n",
      "     |      join : {'left'}, default 'left'\n",
      "     |      overwrite : boolean, default True\n",
      "     |          If True then overwrite values for common keys in the calling frame\n",
      "     |      filter_func : callable(1d-array) -> 1d-array<boolean>, default None\n",
      "     |          Can choose to replace values other than NA. Return True for values\n",
      "     |          that should be updated\n",
      "     |      raise_conflict : boolean\n",
      "     |          If True, will raise an error if the DataFrame and other both\n",
      "     |          contain data in the same place.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      "     |      ...                    'B': [400, 500, 600]})\n",
      "     |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      "     |      ...                        'C': [7, 8, 9]})\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  1  4\n",
      "     |      1  2  5\n",
      "     |      2  3  6\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      "     |      ...                    'B': ['x', 'y', 'z']})\n",
      "     |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  d\n",
      "     |      1  b  e\n",
      "     |      2  c  f\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      "     |      ...                    'B': ['x', 'y', 'z']})\n",
      "     |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      "     |      >>> df.update(new_column)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  d\n",
      "     |      1  b  y\n",
      "     |      2  c  e\n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      "     |      ...                    'B': ['x', 'y', 'z']})\n",
      "     |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  x\n",
      "     |      1  b  d\n",
      "     |      2  c  e\n",
      "     |      \n",
      "     |      If ``other`` contains NaNs the corresponding values are not updated\n",
      "     |      in the original dataframe.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      "     |      ...                    'B': [400, 500, 600]})\n",
      "     |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      "     |      >>> df.update(new_df)\n",
      "     |      >>> df\n",
      "     |         A      B\n",
      "     |      0  1    4.0\n",
      "     |      1  2  500.0\n",
      "     |      2  3    6.0\n",
      "     |  \n",
      "     |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased variance over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  from_csv(path, header=0, sep=',', index_col=0, parse_dates=True, encoding=None, tupleize_cols=None, infer_datetime_format=False) from builtins.type\n",
      "     |      Read CSV file (DEPRECATED, please use :func:`pandas.read_csv`\n",
      "     |      instead).\n",
      "     |      \n",
      "     |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      "     |      for most general purposes, but ``from_csv`` makes for an easy\n",
      "     |      roundtrip to and from a file (the exact counterpart of\n",
      "     |      ``to_csv``), especially with a DataFrame of time series data.\n",
      "     |      \n",
      "     |      This method only differs from the preferred :func:`pandas.read_csv`\n",
      "     |      in some defaults:\n",
      "     |      \n",
      "     |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      "     |        by default)\n",
      "     |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      "     |        as datetime by default)\n",
      "     |      \n",
      "     |      So a ``pd.DataFrame.from_csv(path)`` can be replaced by\n",
      "     |      ``pd.read_csv(path, index_col=0, parse_dates=True)``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string file path or file handle / StringIO\n",
      "     |      header : int, default 0\n",
      "     |          Row to use as header (skip prior rows)\n",
      "     |      sep : string, default ','\n",
      "     |          Field delimiter\n",
      "     |      index_col : int or sequence, default 0\n",
      "     |          Column to use for index. If a sequence is given, a MultiIndex\n",
      "     |          is used. Different default from read_table\n",
      "     |      parse_dates : boolean, default True\n",
      "     |          Parse dates. Different default from read_table\n",
      "     |      tupleize_cols : boolean, default False\n",
      "     |          write multi_index columns as a list of tuples (if True)\n",
      "     |          or new (expanded format) if False)\n",
      "     |      infer_datetime_format: boolean, default False\n",
      "     |          If True and `parse_dates` is True for a column, try to infer the\n",
      "     |          datetime format based on the first datetime string. If the format\n",
      "     |          can be inferred, there often will be a large parsing speed-up.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.read_csv\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : DataFrame\n",
      "     |  \n",
      "     |  from_dict(data, orient='columns', dtype=None) from builtins.type\n",
      "     |      Construct DataFrame from dict of array-like or dicts\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : dict\n",
      "     |          {field : array-like} or {field : dict}\n",
      "     |      orient : {'columns', 'index'}, default 'columns'\n",
      "     |          The \"orientation\" of the data. If the keys of the passed dict\n",
      "     |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      "     |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      "     |      dtype : dtype, default None\n",
      "     |          Data type to force, otherwise infer\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |  \n",
      "     |  from_items(items, columns=None, orient='columns') from builtins.type\n",
      "     |      Convert (key, value) pairs to DataFrame. The keys will be the axis\n",
      "     |      index (usually the columns, but depends on the specified\n",
      "     |      orientation). The values should be arrays or Series.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      items : sequence of (key, value) pairs\n",
      "     |          Values should be arrays or Series.\n",
      "     |      columns : sequence of column labels, optional\n",
      "     |          Must be passed if orient='index'.\n",
      "     |      orient : {'columns', 'index'}, default 'columns'\n",
      "     |          The \"orientation\" of the data. If the keys of the\n",
      "     |          input correspond to column labels, pass 'columns'\n",
      "     |          (default). Otherwise if the keys correspond to the index,\n",
      "     |          pass 'index'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      frame : DataFrame\n",
      "     |  \n",
      "     |  from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from builtins.type\n",
      "     |      Convert structured or record ndarray to DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n",
      "     |      index : string, list of fields, array-like\n",
      "     |          Field of array to use as the index, alternately a specific set of\n",
      "     |          input labels to use\n",
      "     |      exclude : sequence, default None\n",
      "     |          Columns or fields to exclude\n",
      "     |      columns : sequence, default None\n",
      "     |          Column names to use. If the passed data do not have names\n",
      "     |          associated with them, this argument provides names for the\n",
      "     |          columns. Otherwise this argument indicates the order of the columns\n",
      "     |          in the result (any names not found in the data will become all-NA\n",
      "     |          columns)\n",
      "     |      coerce_float : boolean, default False\n",
      "     |          Attempt to convert values of non-string, non-numeric objects (like\n",
      "     |          decimal.Decimal) to floating point, useful for SQL result sets\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      df : DataFrame\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  axes\n",
      "     |      Return a list with the row axis labels and column axis labels as the\n",
      "     |      only members. They are returned in that order.\n",
      "     |  \n",
      "     |  columns\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Return a tuple representing the dimensionality of the DataFrame.\n",
      "     |  \n",
      "     |  style\n",
      "     |      Property returning a Styler object containing methods for\n",
      "     |      building a styled HTML representation fo the DataFrame.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.io.formats.style.Styler\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.frame.DataFrame:\n",
      "     |  \n",
      "     |  plot = <class 'pandas.plotting._core.FramePlotMethods'>\n",
      "     |      DataFrame plotting accessor and method\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df.plot.line()\n",
      "     |      >>> df.plot.scatter('x', 'y')\n",
      "     |      >>> df.plot.hexbin()\n",
      "     |      \n",
      "     |      These plotting methods can also be accessed by calling the accessor as a\n",
      "     |      method with the ``kind`` argument:\n",
      "     |      ``df.plot(kind='line')`` is equivalent to ``df.plot.line()``\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  __abs__(self)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __bool__ = __nonzero__(self)\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      True if the key is in the info axis\n",
      "     |  \n",
      "     |  __copy__(self, deep=True)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete item\n",
      "     |  \n",
      "     |  __finalize__(self, other, method=None, **kwargs)\n",
      "     |      Propagate metadata from other to self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : the object from which to get the attributes that we are going\n",
      "     |          to propagate\n",
      "     |      method : optional, a passed method name ; possibly to take different\n",
      "     |          types of propagation actions based on this\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |      After regular attribute access, try looking up the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__(self)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate over infor axis\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |  \n",
      "     |  __round__(self, decimals=0)\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      After regular attribute access, try setting the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |      Return an object with absolute value taken--only applicable to objects\n",
      "     |      that are all numeric.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      abs: type of caller\n",
      "     |  \n",
      "     |  add_prefix(self, prefix)\n",
      "     |      Concatenate prefix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      prefix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_prefix : type of caller\n",
      "     |  \n",
      "     |  add_suffix(self, suffix)\n",
      "     |      Concatenate suffix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      suffix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_suffix : type of caller\n",
      "     |  \n",
      "     |  as_blocks(self, copy=True)\n",
      "     |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      "     |      a homogeneous dtype.\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      "     |            as_matrix)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : a dict of dtype -> Constructor Types\n",
      "     |  \n",
      "     |  as_matrix(self, columns=None)\n",
      "     |      Convert the frame to its Numpy-array representation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns: list, optional, default:None\n",
      "     |          If None, return all columns, otherwise, returns specified columns.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : ndarray\n",
      "     |          If the caller is heterogeneous and contains booleans or objects,\n",
      "     |          the result will be of dtype=object. See Notes.\n",
      "     |      \n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      "     |      \n",
      "     |      The dtype will be a lower-common-denominator dtype (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen. Use this\n",
      "     |      with care if you are not dealing with the blocks.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      "     |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      "     |      will result in a flot64 dtype.\n",
      "     |      \n",
      "     |      This method is provided for backwards compatibility. Generally,\n",
      "     |      it is recommended to use '.values'.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.values\n",
      "     |  \n",
      "     |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      "     |      Convert TimeSeries to specified frequency.\n",
      "     |      \n",
      "     |      Optionally provide filling method to pad/backfill missing values.\n",
      "     |      \n",
      "     |      Returns the original data conformed to a new index with the specified\n",
      "     |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      "     |      summarization, is necessary to represent the data at the new frequency.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : DateOffset object, or string\n",
      "     |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      "     |          Method to use for filling holes in reindexed Series (note this\n",
      "     |          does not fill NaNs that already were present):\n",
      "     |      \n",
      "     |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      "     |      how : {'start', 'end'}, default end\n",
      "     |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      "     |      normalize : bool, default False\n",
      "     |          Whether to reset output index to midnight\n",
      "     |      fill_value: scalar, optional\n",
      "     |          Value to use for missing values, applied during upsampling (note\n",
      "     |          this does not fill NaNs that already were present).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 4 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      "     |      >>> df = pd.DataFrame({'s':series})\n",
      "     |      >>> df\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    NaN\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``fill value``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    9.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    9.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    9.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``method``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', method='bfill')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    2.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    3.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |  \n",
      "     |  asof(self, where, subset=None)\n",
      "     |      The last row without any NaN is taken (or the last row without\n",
      "     |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0 For DataFrame\n",
      "     |      \n",
      "     |      If there is no good value, NaN is returned for a Series\n",
      "     |      a Series of NaN values for a DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      where : date or array of dates\n",
      "     |      subset : string or list of strings, default None\n",
      "     |         if not None use these columns for NaN propagation\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Dates are assumed to be sorted\n",
      "     |      Raises if this is not the case\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      where is scalar\n",
      "     |      \n",
      "     |        - value or NaN if input is Series\n",
      "     |        - Series if input is DataFrame\n",
      "     |      \n",
      "     |      where is Index: same shape object as input\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      merge_asof\n",
      "     |  \n",
      "     |  at_time(self, time, asof=False)\n",
      "     |      Select values at particular time of day (e.g. 9:30AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      time : datetime.time or string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_at_time : type of caller\n",
      "     |  \n",
      "     |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      "     |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_time : datetime.time or string\n",
      "     |      end_time : datetime.time or string\n",
      "     |      include_start : boolean, default True\n",
      "     |      include_end : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_between_time : type of caller\n",
      "     |  \n",
      "     |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Return the bool of a single element PandasObject.\n",
      "     |      \n",
      "     |      This must be a boolean scalar value, either True or False.  Raise a\n",
      "     |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      "     |      element is not boolean\n",
      "     |  \n",
      "     |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      "     |      Trim values at input threshold(s).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lower : float or array_like, default None\n",
      "     |      upper : float or array_like, default None\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with lower and upper along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.256177\n",
      "     |      1 -1.367855  0.746646\n",
      "     |      2  0.027753 -1.176076\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  1.261967  0.570967\n",
      "     |      \n",
      "     |      >>> df.clip(-1.0, 0.5)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.000000\n",
      "     |      1 -1.000000  0.500000\n",
      "     |      2  0.027753 -1.000000\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  0.500000  0.500000\n",
      "     |      \n",
      "     |      >>> t\n",
      "     |      0   -0.3\n",
      "     |      1   -0.2\n",
      "     |      2   -0.1\n",
      "     |      3    0.0\n",
      "     |      4    0.1\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> df.clip(t, t + 1, axis=0)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -0.300000\n",
      "     |      1 -0.200000  0.746646\n",
      "     |      2  0.027753 -0.100000\n",
      "     |      3  0.230930  0.000000\n",
      "     |      4  1.100000  0.570967\n",
      "     |  \n",
      "     |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of the input with values below given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of input with values above given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  consolidate(self, inplace=False)\n",
      "     |      DEPRECATED: consolidate will be an internal implementation only.\n",
      "     |  \n",
      "     |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      "     |      Deprecated.\n",
      "     |      Attempt to infer better dtype for object columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      convert_dates : boolean, default True\n",
      "     |          If True, convert to date where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      convert_numeric : boolean, default False\n",
      "     |          If True, attempt to coerce to numbers (including strings), with\n",
      "     |          unconvertible values becoming NaN.\n",
      "     |      convert_timedeltas : boolean, default True\n",
      "     |          If True, convert to timedelta where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      copy : boolean, default True\n",
      "     |          If True, return a copy even if no copy is necessary (e.g. no\n",
      "     |          conversion was done). Note: This is meant for internal use, and\n",
      "     |          should not be confused with inplace.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      "     |          with day as the default.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same as input object\n",
      "     |  \n",
      "     |  describe(self, percentiles=None, include=None, exclude=None)\n",
      "     |      Generates descriptive statistics that summarize the central tendency,\n",
      "     |      dispersion and shape of a dataset's distribution, excluding\n",
      "     |      ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      summary:  Series/DataFrame of summary statistics\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      "     |      ...                     'numeric': [1, 2, 3],\n",
      "     |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |              categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count\n",
      "     |      DataFrame.max\n",
      "     |      DataFrame.min\n",
      "     |      DataFrame.mean\n",
      "     |      DataFrame.std\n",
      "     |      DataFrame.select_dtypes\n",
      "     |  \n",
      "     |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      "     |      Return new object with labels in requested axis removed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : single label or list-like\n",
      "     |          Index or column labels to drop.\n",
      "     |      axis : int or axis name\n",
      "     |          Whether to drop labels from the index (0 / 'index') or\n",
      "     |          columns (1 / 'columns').\n",
      "     |      index, columns : single label or list-like\n",
      "     |          Alternative to specifying `axis` (``labels, axis=1`` is\n",
      "     |          equivalent to ``columns=labels``).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      level : int or level name, default None\n",
      "     |          For MultiIndex\n",
      "     |      inplace : bool, default False\n",
      "     |          If True, do operation inplace and return None.\n",
      "     |      errors : {'ignore', 'raise'}, default 'raise'\n",
      "     |          If 'ignore', suppress error and existing labels are dropped.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dropped : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      "     |                            columns=['A', 'B', 'C', 'D'])\n",
      "     |      >>> df\n",
      "     |         A  B   C   D\n",
      "     |      0  0  1   2   3\n",
      "     |      1  4  5   6   7\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Drop columns\n",
      "     |      \n",
      "     |      >>> df.drop(['B', 'C'], axis=1)\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      >>> df.drop(columns=['B', 'C'])\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      Drop a row by index\n",
      "     |      \n",
      "     |      >>> df.drop([0, 1])\n",
      "     |         A  B   C   D\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Specifying both `labels` and `index` or `columns` will raise a\n",
      "     |      ValueError.\n",
      "     |  \n",
      "     |  equals(self, other)\n",
      "     |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      "     |      the same location are considered equal.\n",
      "     |  \n",
      "     |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      "     |      Subset rows or columns of dataframe according to labels in\n",
      "     |      the specified index.\n",
      "     |      \n",
      "     |      Note that this routine does not filter a dataframe on its\n",
      "     |      contents. The filter is applied to the labels of the index.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      items : list-like\n",
      "     |          List of info axis to restrict to (must not all be present)\n",
      "     |      like : string\n",
      "     |          Keep info axis where \"arg in col == True\"\n",
      "     |      regex : string (regular expression)\n",
      "     |          Keep info axis with re.search(regex, col) == True\n",
      "     |      axis : int or string axis name\n",
      "     |          The axis to filter on.  By default this is the info axis,\n",
      "     |          'index' for Series, 'columns' for DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |      one  two  three\n",
      "     |      mouse     1    2      3\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      >>> # select columns by name\n",
      "     |      >>> df.filter(items=['one', 'three'])\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select columns by regular expression\n",
      "     |      >>> df.filter(regex='e$', axis=1)\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select rows containing 'bbi'\n",
      "     |      >>> df.filter(like='bbi', axis=0)\n",
      "     |      one  two  three\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.loc\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The ``items``, ``like``, and ``regex`` parameters are\n",
      "     |      enforced to be mutually exclusive.\n",
      "     |      \n",
      "     |      ``axis`` defaults to the info axis that is used when indexing\n",
      "     |      with ``[]``.\n",
      "     |  \n",
      "     |  first(self, offset)\n",
      "     |      Convenience method for subsetting initial periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.first('10D') -> First 10 days\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Get item from object for given key (DataFrame column, Panel slice,\n",
      "     |      etc.). Returns default value if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : object\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : type of items contained in object\n",
      "     |  \n",
      "     |  get_dtype_counts(self)\n",
      "     |      Return the counts of dtypes in this object.\n",
      "     |  \n",
      "     |  get_ftype_counts(self)\n",
      "     |      Return the counts of ftypes in this object.\n",
      "     |  \n",
      "     |  get_values(self)\n",
      "     |      same as values (but handles sparseness conversions)\n",
      "     |  \n",
      "     |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      "     |      Group series using mapper (dict or key function, apply given function\n",
      "     |      to group, return result as series) or by a series of columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : mapping, function, str, or iterable\n",
      "     |          Used to determine the groups for the groupby.\n",
      "     |          If ``by`` is a function, it's called on each value of the object's\n",
      "     |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      "     |          will be used to determine the groups (the Series' values are first\n",
      "     |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      "     |          values are used as-is determine the groups. A str or list of strs\n",
      "     |          may be passed to group by the columns in ``self``\n",
      "     |      axis : int, default 0\n",
      "     |      level : int, level name, or sequence of such, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      "     |          level or levels\n",
      "     |      as_index : boolean, default True\n",
      "     |          For aggregated output, return object with group labels as the\n",
      "     |          index. Only relevant for DataFrame input. as_index=False is\n",
      "     |          effectively \"SQL-style\" grouped output\n",
      "     |      sort : boolean, default True\n",
      "     |          Sort group keys. Get better performance by turning this off.\n",
      "     |          Note this does not influence the order of observations within each\n",
      "     |          group.  groupby preserves the order of rows within each group.\n",
      "     |      group_keys : boolean, default True\n",
      "     |          When calling apply, add group keys to index to identify pieces\n",
      "     |      squeeze : boolean, default False\n",
      "     |          reduce the dimensionality of the return type if possible,\n",
      "     |          otherwise return a consistent type\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      DataFrame results\n",
      "     |      \n",
      "     |      >>> data.groupby(func, axis=0).mean()\n",
      "     |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      "     |      \n",
      "     |      DataFrame with hierarchical index\n",
      "     |      \n",
      "     |      >>> data.groupby(['col1', 'col2']).mean()\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GroupBy object\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return the first n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_head : type of caller\n",
      "     |          The first n rows of the caller object.\n",
      "     |  \n",
      "     |  infer_objects(self)\n",
      "     |      Attempt to infer better dtypes for object columns.\n",
      "     |      \n",
      "     |      Attempts soft conversion of object-dtyped\n",
      "     |      columns, leaving non-object and unconvertible\n",
      "     |      columns unchanged. The inference rules are the\n",
      "     |      same as during normal Series/DataFrame construction.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to numeric typeR\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      "     |      >>> df = df.iloc[1:]\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      \n",
      "     |      >>> df.dtypes\n",
      "     |      A    object\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> df.infer_objects().dtypes\n",
      "     |      A    int64\n",
      "     |      dtype: object\n",
      "     |  \n",
      "     |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      "     |      Interpolate values according to different methods.\n",
      "     |      \n",
      "     |      Please note that only ``method='linear'`` is supported for\n",
      "     |      DataFrames/Series with a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      "     |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      "     |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      "     |                'from_derivatives', 'pchip', 'akima'}\n",
      "     |      \n",
      "     |          * 'linear': ignore the index and treat the values as equally\n",
      "     |            spaced. This is the only method supported on MultiIndexes.\n",
      "     |            default\n",
      "     |          * 'time': interpolation works on daily and higher resolution\n",
      "     |            data to interpolate given length of interval\n",
      "     |          * 'index', 'values': use the actual numerical values of the index\n",
      "     |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      "     |            'barycentric', 'polynomial' is passed to\n",
      "     |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      "     |            require that you also specify an `order` (int),\n",
      "     |            e.g. df.interpolate(method='polynomial', order=4).\n",
      "     |            These use the actual numerical values of the index.\n",
      "     |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      "     |            are all wrappers around the scipy interpolation methods of\n",
      "     |            similar names. These use the actual numerical values of the\n",
      "     |            index. For more information on their behavior, see the\n",
      "     |            `scipy documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      "     |            and `tutorial documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      "     |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      "     |            replaces 'piecewise_polynomial' interpolation method in\n",
      "     |            scipy 0.18\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |      \n",
      "     |             Added support for the 'akima' method\n",
      "     |             Added interpolate method 'from_derivatives' which replaces\n",
      "     |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      "     |             scipy < 0.18\n",
      "     |      \n",
      "     |      axis : {0, 1}, default 0\n",
      "     |          * 0: fill column-by-column\n",
      "     |          * 1: fill row-by-row\n",
      "     |      limit : int, default None.\n",
      "     |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      "     |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      "     |          If limit is specified, consecutive NaNs will be filled in this\n",
      "     |          direction.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      inplace : bool, default False\n",
      "     |          Update the NDFrame in place if possible.\n",
      "     |      downcast : optional, 'infer' or None, defaults to None\n",
      "     |          Downcast dtypes if possible.\n",
      "     |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame of same shape interpolated at the NaNs\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, replace, fillna\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Filling in NaNs\n",
      "     |      \n",
      "     |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      "     |      >>> s.interpolate()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    3\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      Get the 'info axis' (see Indexing for more)\n",
      "     |      \n",
      "     |      This is index for Series, columns for DataFrame and major_axis for\n",
      "     |      Panel.\n",
      "     |  \n",
      "     |  last(self, offset)\n",
      "     |      Convenience method for subsetting final periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.last('5M') -> Last 5 months\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is False and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is False, keep the original value. Where\n",
      "     |          True, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is True are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The mask method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``mask`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.where`\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      "     |      Percent change over given number of periods.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming percent change\n",
      "     |      fill_method : str, default 'pad'\n",
      "     |          How to handle NAs before computing percent changes\n",
      "     |      limit : int, default None\n",
      "     |          The number of consecutive NAs to fill before stopping\n",
      "     |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      "     |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chg : NDFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      By default, the percentage change is calculated along the stat\n",
      "     |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      "     |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          function to apply to the NDFrame.\n",
      "     |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      "     |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      "     |          ``data_keyword`` is a string indicating the keyword of\n",
      "     |          ``callable`` that expects the NDFrame.\n",
      "     |      args : iterable, optional\n",
      "     |          positional arguments passed into ``func``.\n",
      "     |      kwargs : mapping, optional\n",
      "     |          a dictionary of keyword arguments passed into ``func``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of ``func``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Use ``.pipe`` when chaining together functions that expect\n",
      "     |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      "     |      \n",
      "     |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(f, arg2=b, arg3=c)\n",
      "     |      ... )\n",
      "     |      \n",
      "     |      If you have a function that takes the data as (say) the second\n",
      "     |      argument, pass a tuple indicating which keyword expects the\n",
      "     |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      "     |      ...  )\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.applymap\n",
      "     |      pandas.Series.map\n",
      "     |  \n",
      "     |  pop(self, item)\n",
      "     |      Return item and drop from frame. Raise KeyError if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      item : str\n",
      "     |          Column label to be popped\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      popped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |      ...                    ('parrot', 'bird',     24.0),\n",
      "     |      ...                    ('lion',   'mammal',   80.5),\n",
      "     |      ...                    ('monkey', 'mammal', np.nan)],\n",
      "     |      ...                   columns=('name', 'class', 'max_speed'))\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  parrot    bird       24.0\n",
      "     |      2    lion  mammal       80.5\n",
      "     |      3  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      >>> df.pop('class')\n",
      "     |      0      bird\n",
      "     |      1      bird\n",
      "     |      2    mammal\n",
      "     |      3    mammal\n",
      "     |      Name: class, dtype: object\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |           name  max_speed\n",
      "     |      0  falcon      389.0\n",
      "     |      1  parrot       24.0\n",
      "     |      2    lion       80.5\n",
      "     |      3  monkey        NaN\n",
      "     |  \n",
      "     |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      "     |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      "     |      assigned a rank that is the average of the ranks of those values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          index to direct ranking\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      "     |          * average: average rank of group\n",
      "     |          * min: lowest rank in group\n",
      "     |          * max: highest rank in group\n",
      "     |          * first: ranks assigned in order they appear in the array\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      "     |          Panel objects\n",
      "     |      na_option : {'keep', 'top', 'bottom'}\n",
      "     |          * keep: leave NA values where they are\n",
      "     |          * top: smallest rank if ascending\n",
      "     |          * bottom: smallest rank if descending\n",
      "     |      ascending : boolean, default True\n",
      "     |          False for ranks by high (1) to low (N)\n",
      "     |      pct : boolean, default False\n",
      "     |          Computes percentage rank of data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ranks : same type as caller\n",
      "     |  \n",
      "     |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      "     |      Return an object with matching indices to myself.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Object\n",
      "     |      method : string or None\n",
      "     |      copy : boolean, default True\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive labels to fill for inexact matches.\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between labels of the other object and this\n",
      "     |          object for inexact matches. Can be list-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      "     |                             method=...)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : same as input\n",
      "     |  \n",
      "     |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      "     |      Alter the name of the index or columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper : scalar, list-like, optional\n",
      "     |          Value to set the axis name attribute.\n",
      "     |      axis : int or string, default 0\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : type of caller or None if inplace=True\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      "     |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      "     |      deprecated and will be removed in a future version. Use ``rename``\n",
      "     |      instead.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.rename, pandas.DataFrame.rename\n",
      "     |      pandas.Index.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.rename_axis(\"foo\")\n",
      "     |           A  B\n",
      "     |      foo\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |      \n",
      "     |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      "     |      bar  A  B\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |  \n",
      "     |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      "     |      Replace values given in 'to_replace' with 'value'.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      "     |      \n",
      "     |          * str or regex:\n",
      "     |      \n",
      "     |              - str: string exactly matching `to_replace` will be replaced\n",
      "     |                with `value`\n",
      "     |              - regex: regexs matching `to_replace` will be replaced with\n",
      "     |                `value`\n",
      "     |      \n",
      "     |          * list of str, regex, or numeric:\n",
      "     |      \n",
      "     |              - First, if `to_replace` and `value` are both lists, they\n",
      "     |                **must** be the same length.\n",
      "     |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      "     |                lists will be interpreted as regexs otherwise they will match\n",
      "     |                directly. This doesn't matter much for `value` since there\n",
      "     |                are only a few possible substitution regexes you can use.\n",
      "     |              - str and regex rules apply as above.\n",
      "     |      \n",
      "     |          * dict:\n",
      "     |      \n",
      "     |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      "     |                follows: look in column 'a' for the value 'b' and replace it\n",
      "     |                with nan. You can nest regular expressions as well. Note that\n",
      "     |                column names (the top-level dictionary keys in a nested\n",
      "     |                dictionary) **cannot** be regular expressions.\n",
      "     |              - Keys map to column names and values map to substitution\n",
      "     |                values. You can treat this as a special case of passing two\n",
      "     |                lists except that you are specifying the column to search in.\n",
      "     |      \n",
      "     |          * None:\n",
      "     |      \n",
      "     |              - This means that the ``regex`` argument must be a string,\n",
      "     |                compiled regular expression, or list, dict, ndarray or Series\n",
      "     |                of such elements. If `value` is also ``None`` then this\n",
      "     |                **must** be a nested dictionary or ``Series``.\n",
      "     |      \n",
      "     |          See the examples section for examples of each of these.\n",
      "     |      value : scalar, dict, list, str, regex, default None\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      "     |          specifying which value to use for each column (columns not in the\n",
      "     |          dict will not be filled). Regular expressions, strings and lists or\n",
      "     |          dicts of such objects are also allowed.\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, in place. Note: this will modify any\n",
      "     |          other views on this object (e.g. a column from a DataFrame).\n",
      "     |          Returns the caller if this is True.\n",
      "     |      limit : int, default None\n",
      "     |          Maximum size gap to forward or backward fill\n",
      "     |      regex : bool or same types as `to_replace`, default False\n",
      "     |          Whether to interpret `to_replace` and/or `value` as regular\n",
      "     |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      "     |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      "     |          parameter will be interpreted as a regular expression or a list,\n",
      "     |          dict, or array of regular expressions.\n",
      "     |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      "     |          The method to use when for replacement, when ``to_replace`` is a\n",
      "     |          ``list``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      NDFrame.reindex\n",
      "     |      NDFrame.asfreq\n",
      "     |      NDFrame.fillna\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : NDFrame\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      AssertionError\n",
      "     |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      "     |      TypeError\n",
      "     |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      "     |            ``dict``, ``ndarray``, or ``Series``\n",
      "     |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      "     |            regular expression or is a list, dict, ndarray, or Series.\n",
      "     |      ValueError\n",
      "     |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      "     |            they are not the same length.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      "     |        rules for substitution for ``re.sub`` are the same.\n",
      "     |      * Regular expressions will only substitute on strings, meaning you\n",
      "     |        cannot provide, for example, a regular expression matching floating\n",
      "     |        point numbers and expect the columns in your frame that have a\n",
      "     |        numeric dtype to be matched. However, if those floating point numbers\n",
      "     |        *are* strings, then you can do this.\n",
      "     |      * This method has *a lot* of options. You are encouraged to experiment\n",
      "     |        and play with this method to gain intuition about how it works.\n",
      "     |  \n",
      "     |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      "     |      Convenience method for frequency conversion and resampling of time\n",
      "     |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      "     |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      "     |      to the on or level keyword.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : string\n",
      "     |          the offset string or object representing target conversion\n",
      "     |      axis : int, optional, default 0\n",
      "     |      closed : {'right', 'left'}\n",
      "     |          Which side of bin interval is closed. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      label : {'right', 'left'}\n",
      "     |          Which bin edge label to label bucket with. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      convention : {'start', 'end', 's', 'e'}\n",
      "     |          For PeriodIndex only, controls whether to use the start or end of\n",
      "     |          `rule`\n",
      "     |      loffset : timedelta\n",
      "     |          Adjust the resampled time labels\n",
      "     |      base : int, default 0\n",
      "     |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      "     |          aggregated intervals. For example, for '5min' frequency, base could\n",
      "     |          range from 0 through 4. Defaults to 0\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column to use instead of index for resampling.\n",
      "     |          Column must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      level : string or int, optional\n",
      "     |          For a MultiIndex, level (name or number) to use for\n",
      "     |          resampling.  Level must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the offset strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 9 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> series = pd.Series(range(9), index=index)\n",
      "     |      >>> series\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      2000-01-01 00:03:00    3\n",
      "     |      2000-01-01 00:04:00    4\n",
      "     |      2000-01-01 00:05:00    5\n",
      "     |      2000-01-01 00:06:00    6\n",
      "     |      2000-01-01 00:07:00    7\n",
      "     |      2000-01-01 00:08:00    8\n",
      "     |      Freq: T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and sum the values\n",
      "     |      of the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> series.resample('3T').sum()\n",
      "     |      2000-01-01 00:00:00     3\n",
      "     |      2000-01-01 00:03:00    12\n",
      "     |      2000-01-01 00:06:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but label each\n",
      "     |      bin using the right edge instead of the left. Please note that the\n",
      "     |      value in the bucket used as the label is not included in the bucket,\n",
      "     |      which it labels. For example, in the original series the\n",
      "     |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      "     |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      "     |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      "     |      To include this value close the right side of the bin interval as\n",
      "     |      illustrated in the example below this one.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right').sum()\n",
      "     |      2000-01-01 00:03:00     3\n",
      "     |      2000-01-01 00:06:00    12\n",
      "     |      2000-01-01 00:09:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      "     |      2000-01-01 00:00:00     0\n",
      "     |      2000-01-01 00:03:00     6\n",
      "     |      2000-01-01 00:06:00    15\n",
      "     |      2000-01-01 00:09:00    15\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      "     |      2000-01-01 00:00:00   0.0\n",
      "     |      2000-01-01 00:00:30   NaN\n",
      "     |      2000-01-01 00:01:00   1.0\n",
      "     |      2000-01-01 00:01:30   NaN\n",
      "     |      2000-01-01 00:02:00   2.0\n",
      "     |      Freq: 30S, dtype: float64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      "     |      values using the ``pad`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').pad()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the\n",
      "     |      ``NaN`` values using the ``bfill`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').bfill()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    1\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    2\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Pass a custom function via ``apply``\n",
      "     |      \n",
      "     |      >>> def custom_resampler(array_like):\n",
      "     |      ...     return np.sum(array_like)+5\n",
      "     |      \n",
      "     |      >>> series.resample('3T').apply(custom_resampler)\n",
      "     |      2000-01-01 00:00:00     8\n",
      "     |      2000-01-01 00:03:00    17\n",
      "     |      2000-01-01 00:06:00    26\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      "     |      used to control whether to use the start or end of `rule`.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      "     |                                                      freq='A',\n",
      "     |                                                      periods=2))\n",
      "     |      >>> s\n",
      "     |      2012    1\n",
      "     |      2013    2\n",
      "     |      Freq: A-DEC, dtype: int64\n",
      "     |      \n",
      "     |      Resample by month using 'start' `convention`. Values are assigned to\n",
      "     |      the first month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='start').asfreq().head()\n",
      "     |      2012-01    1.0\n",
      "     |      2012-02    NaN\n",
      "     |      2012-03    NaN\n",
      "     |      2012-04    NaN\n",
      "     |      2012-05    NaN\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      Resample by month using 'end' `convention`. Values are assigned to\n",
      "     |      the last month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='end').asfreq()\n",
      "     |      2012-12    1.0\n",
      "     |      2013-01    NaN\n",
      "     |      2013-02    NaN\n",
      "     |      2013-03    NaN\n",
      "     |      2013-04    NaN\n",
      "     |      2013-05    NaN\n",
      "     |      2013-06    NaN\n",
      "     |      2013-07    NaN\n",
      "     |      2013-08    NaN\n",
      "     |      2013-09    NaN\n",
      "     |      2013-10    NaN\n",
      "     |      2013-11    NaN\n",
      "     |      2013-12    2.0\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      "     |      column instead of the index for resampling.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      "     |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> df.resample('3T', on='time').sum()\n",
      "     |                           a  b  c  d\n",
      "     |      time\n",
      "     |      2000-01-01 00:00:00  0  3  6  9\n",
      "     |      2000-01-01 00:03:00  0  3  6  9\n",
      "     |      2000-01-01 00:06:00  0  3  6  9\n",
      "     |      \n",
      "     |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      "     |      specify on level the resampling needs to take place.\n",
      "     |      \n",
      "     |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      "     |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      "     |                             columns=['a', 'b', 'c', 'd'],\n",
      "     |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      "     |                             )\n",
      "     |      >>> df2.resample('3T', level=0).sum()\n",
      "     |                           a  b   c   d\n",
      "     |      2000-01-01 00:00:00  0  6  12  18\n",
      "     |      2000-01-01 00:03:00  0  4   8  12\n",
      "     |  \n",
      "     |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      "     |      Returns a random sample of items from an axis of object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, optional\n",
      "     |          Number of items from axis to return. Cannot be used with `frac`.\n",
      "     |          Default = 1 if `frac` = None.\n",
      "     |      frac : float, optional\n",
      "     |          Fraction of axis items to return. Cannot be used with `n`.\n",
      "     |      replace : boolean, optional\n",
      "     |          Sample with or without replacement. Default = False.\n",
      "     |      weights : str or ndarray-like, optional\n",
      "     |          Default 'None' results in equal probability weighting.\n",
      "     |          If passed a Series, will align with target object on index. Index\n",
      "     |          values in weights not found in sampled object will be ignored and\n",
      "     |          index values in sampled object not in weights will be assigned\n",
      "     |          weights of zero.\n",
      "     |          If called on a DataFrame, will accept the name of a column\n",
      "     |          when axis = 0.\n",
      "     |          Unless weights are a Series, weights must be same length as axis\n",
      "     |          being sampled.\n",
      "     |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      "     |          Missing values in the weights column will be treated as zero.\n",
      "     |          inf and -inf values not allowed.\n",
      "     |      random_state : int or numpy.random.RandomState, optional\n",
      "     |          Seed for the random number generator (if int), or numpy RandomState\n",
      "     |          object.\n",
      "     |      axis : int or string, optional\n",
      "     |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      "     |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A new object of same type as caller.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Generate an example ``Series`` and ``DataFrame``:\n",
      "     |      \n",
      "     |      >>> s = pd.Series(np.random.randn(50))\n",
      "     |      >>> s.head()\n",
      "     |      0   -0.038497\n",
      "     |      1    1.820773\n",
      "     |      2   -0.972766\n",
      "     |      3   -1.598270\n",
      "     |      4   -1.095526\n",
      "     |      dtype: float64\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      "     |      >>> df.head()\n",
      "     |                A         B         C         D\n",
      "     |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      "     |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      "     |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      "     |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      "     |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      "     |      \n",
      "     |      Next extract a random sample from both of these objects...\n",
      "     |      \n",
      "     |      3 random elements from the ``Series``:\n",
      "     |      \n",
      "     |      >>> s.sample(n=3)\n",
      "     |      27   -0.994689\n",
      "     |      55   -1.049016\n",
      "     |      67   -0.224565\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      And a random 10% of the ``DataFrame`` with replacement:\n",
      "     |      \n",
      "     |      >>> df.sample(frac=0.1, replace=True)\n",
      "     |                 A         B         C         D\n",
      "     |      35  1.981780  0.142106  1.817165 -0.290805\n",
      "     |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      "     |      40  0.823173 -0.078816  1.009536  1.015108\n",
      "     |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      "     |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      "     |  \n",
      "     |  select(self, crit, axis=0)\n",
      "     |      Return data corresponding to axis labels matching criteria\n",
      "     |      \n",
      "     |      DEPRECATED: use df.loc[df.index.map(crit)] to select via labels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      crit : function\n",
      "     |          To be called on each index (label). Should return True or False\n",
      "     |      axis : int\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      selection : type of caller\n",
      "     |  \n",
      "     |  set_axis(self, labels, axis=0, inplace=None)\n",
      "     |      Assign desired index to given axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels: list-like or Index\n",
      "     |          The values for the new index\n",
      "     |      axis : int or string, default 0\n",
      "     |      inplace : boolean, default None\n",
      "     |          Whether to return a new NDFrame instance.\n",
      "     |      \n",
      "     |          WARNING: inplace=None currently falls back to to True, but\n",
      "     |          in a future version, will default to False.  Use inplace=True\n",
      "     |          explicitly rather than relying on the default.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |          The signature is make consistent to the rest of the API.\n",
      "     |          Previously, the \"axis\" and \"labels\" arguments were respectively\n",
      "     |          the first and second positional arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : NDFrame or None\n",
      "     |          An object of same type as caller if inplace=False, None otherwise.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |      a    1\n",
      "     |      b    2\n",
      "     |      c    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |         A  B\n",
      "     |      a  1  4\n",
      "     |      b  2  5\n",
      "     |      c  3  6\n",
      "     |      >>> df.set_axis(['I', 'II'], axis=1, inplace=False)\n",
      "     |         I  II\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |      >>> df.set_axis(['i', 'ii'], axis=1, inplace=True)\n",
      "     |      >>> df\n",
      "     |         i  ii\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |  \n",
      "     |  slice_shift(self, periods=1, axis=0)\n",
      "     |      Equivalent to `shift` without copying data. The shifted data will\n",
      "     |      not include the dropped periods and the shifted axis will be smaller\n",
      "     |      than the original.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      "     |      later during alignment.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : same type as caller\n",
      "     |  \n",
      "     |  squeeze(self, axis=None)\n",
      "     |      Squeeze length 1 dimensions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : None, integer or string axis name, optional\n",
      "     |          The axis to squeeze if 1-sized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar if 1-sized, else original object\n",
      "     |  \n",
      "     |  swapaxes(self, axis1, axis2, copy=True)\n",
      "     |      Interchange axes and swap values axes appropriately\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : same as input\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return the last n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_tail : type of caller\n",
      "     |          The last n rows of the caller object.\n",
      "     |  \n",
      "     |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      "     |      Return the elements in the given *positional* indices along an axis.\n",
      "     |      \n",
      "     |      This means that we are not indexing according to actual values in\n",
      "     |      the index attribute of the object. We are indexing according to the\n",
      "     |      actual position of the element in the object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      indices : array-like\n",
      "     |          An array of ints indicating which positions to take.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis on which to select elements. \"0\" means that we are\n",
      "     |          selecting rows, \"1\" means that we are selecting columns, etc.\n",
      "     |      convert : bool, default True\n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |             In the future, negative indices will always be converted.\n",
      "     |      \n",
      "     |          Whether to convert negative indices into positive ones.\n",
      "     |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      "     |          The conversions are similar to the behavior of indexing a\n",
      "     |          regular Python list.\n",
      "     |      is_copy : bool, default True\n",
      "     |          Whether to return a copy of the original object or not.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |                             ('parrot', 'bird',     24.0),\n",
      "     |                             ('lion',   'mammal',   80.5),\n",
      "     |                             ('monkey', 'mammal', np.nan)],\n",
      "     |                            columns=('name', 'class', 'max_speed'),\n",
      "     |                            index=[0, 2, 3, 1])\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      2  parrot    bird       24.0\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      "     |      \n",
      "     |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      "     |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      "     |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      "     |      \n",
      "     |      >>> df.take([0, 3])\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      "     |      \n",
      "     |      >>> df.take([1, 2], axis=1)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      2    bird       24.0\n",
      "     |      3  mammal       80.5\n",
      "     |      1  mammal        NaN\n",
      "     |      \n",
      "     |      We may take elements using negative integers for positive indices,\n",
      "     |      starting from the end of the object, just like with Python lists.\n",
      "     |      \n",
      "     |      >>> df.take([-1, -2])\n",
      "     |           name   class  max_speed\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      taken : type of caller\n",
      "     |          An array-like containing the elements taken from the object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.take\n",
      "     |      numpy.take\n",
      "     |  \n",
      "     |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      "     |      Attempt to write text representation of object to the system clipboard\n",
      "     |      This can be pasted into Excel, for example.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel : boolean, defaults to True\n",
      "     |              if True, use the provided separator, writing in a csv\n",
      "     |              format for allowing easy pasting into excel.\n",
      "     |              if False, write a string representation of the object\n",
      "     |              to the clipboard\n",
      "     |      sep : optional, defaults to tab\n",
      "     |      other keywords are passed to to_csv\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Requirements for your platform\n",
      "     |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      "     |        - Windows: none\n",
      "     |        - OS X: none\n",
      "     |  \n",
      "     |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      "     |      Write the contained data to an HDF5 file using HDFStore.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path (string) or HDFStore object\n",
      "     |      key : string\n",
      "     |          identifier for the group in the store\n",
      "     |      mode : optional, {'a', 'w', 'r+'}, default 'a'\n",
      "     |      \n",
      "     |        ``'w'``\n",
      "     |            Write; a new file is created (an existing file with the same\n",
      "     |            name would be deleted).\n",
      "     |        ``'a'``\n",
      "     |            Append; an existing file is opened for reading and writing,\n",
      "     |            and if the file does not exist it is created.\n",
      "     |        ``'r+'``\n",
      "     |            It is similar to ``'a'``, but the file must already exist.\n",
      "     |      format : 'fixed(f)|table(t)', default is 'fixed'\n",
      "     |          fixed(f) : Fixed format\n",
      "     |                     Fast writing/reading. Not-appendable, nor searchable\n",
      "     |          table(t) : Table format\n",
      "     |                     Write as a PyTables Table structure which may perform\n",
      "     |                     worse but allow more flexible operations like searching\n",
      "     |                     / selecting subsets of the data\n",
      "     |      append : boolean, default False\n",
      "     |          For Table formats, append the input data to the existing\n",
      "     |      data_columns :  list of columns, or True, default None\n",
      "     |          List of columns to create as indexed data columns for on-disk\n",
      "     |          queries, or True to use all columns. By default only the axes\n",
      "     |          of the object are indexed. See `here\n",
      "     |          <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
      "     |      \n",
      "     |          Applicable only to format='table'.\n",
      "     |      complevel : int, 0-9, default None\n",
      "     |          Specifies a compression level for data.\n",
      "     |          A value of 0 disables compression.\n",
      "     |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      "     |          Specifies the compression library to be used.\n",
      "     |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      "     |          (default if no compressor specified: 'blosc:blosclz'):\n",
      "     |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      "     |          'blosc:zlib', 'blosc:zstd'}.\n",
      "     |          Specifying a compression library which is not available issues\n",
      "     |          a ValueError.\n",
      "     |      fletcher32 : bool, default False\n",
      "     |          If applying compression use the fletcher32 checksum\n",
      "     |      dropna : boolean, default False.\n",
      "     |          If true, ALL nan rows will not be written to store.\n",
      "     |  \n",
      "     |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None)\n",
      "     |      Convert the object to a JSON string.\n",
      "     |      \n",
      "     |      Note NaN's and None will be converted to null and datetime objects\n",
      "     |      will be converted to UNIX timestamps.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path or buffer to write the result string\n",
      "     |          if this is None, return the converted string\n",
      "     |      orient : string\n",
      "     |      \n",
      "     |          * Series\n",
      "     |      \n",
      "     |            - default is 'index'\n",
      "     |            - allowed values are: {'split','records','index'}\n",
      "     |      \n",
      "     |          * DataFrame\n",
      "     |      \n",
      "     |            - default is 'columns'\n",
      "     |            - allowed values are:\n",
      "     |              {'split','records','index','columns','values'}\n",
      "     |      \n",
      "     |          * The format of the JSON string\n",
      "     |      \n",
      "     |            - split : dict like\n",
      "     |              {index -> [index], columns -> [columns], data -> [values]}\n",
      "     |            - records : list like\n",
      "     |              [{column -> value}, ... , {column -> value}]\n",
      "     |            - index : dict like {index -> {column -> value}}\n",
      "     |            - columns : dict like {column -> {index -> value}}\n",
      "     |            - values : just the values array\n",
      "     |            - table : dict like {'schema': {schema}, 'data': {data}}\n",
      "     |              describing the data, and the data component is\n",
      "     |              like ``orient='records'``.\n",
      "     |      \n",
      "     |              .. versionchanged:: 0.20.0\n",
      "     |      \n",
      "     |      date_format : {None, 'epoch', 'iso'}\n",
      "     |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      "     |          `iso` = ISO8601. The default depends on the `orient`. For\n",
      "     |          `orient='table'`, the default is `'iso'`. For all other orients,\n",
      "     |          the default is `'epoch'`.\n",
      "     |      double_precision : The number of decimal places to use when encoding\n",
      "     |          floating point values, default 10.\n",
      "     |      force_ascii : force encoded string to be ASCII, default True.\n",
      "     |      date_unit : string, default 'ms' (milliseconds)\n",
      "     |          The time unit to encode to, governs timestamp and ISO8601\n",
      "     |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "     |          microsecond, and nanosecond respectively.\n",
      "     |      default_handler : callable, default None\n",
      "     |          Handler to call if object cannot otherwise be converted to a\n",
      "     |          suitable format for JSON. Should receive a single argument which is\n",
      "     |          the object to convert and return a serialisable object.\n",
      "     |      lines : boolean, default False\n",
      "     |          If 'orient' is 'records' write out line delimited json format. Will\n",
      "     |          throw ValueError if incorrect 'orient' since others are not list\n",
      "     |          like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      compression : {None, 'gzip', 'bz2', 'xz'}\n",
      "     |          A string representing the compression to use in the output file,\n",
      "     |          only used when the first argument is a filename\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object with filtered info axis\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pd.read_json\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "     |      ...                   index=['row 1', 'row 2'],\n",
      "     |      ...                   columns=['col 1', 'col 2'])\n",
      "     |      >>> df.to_json(orient='split')\n",
      "     |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      "     |        \"index\":[\"row 1\",\"row 2\"],\n",
      "     |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='index')\n",
      "     |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "     |      Note that index labels are not preserved with this encoding.\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='records')\n",
      "     |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      "     |      \n",
      "     |      Encoding with Table Schema\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='table')\n",
      "     |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      "     |                   \"primaryKey\": \"index\",\n",
      "     |                   \"pandas_version\": \"0.20.0\"},\n",
      "     |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      "     |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      "     |  \n",
      "     |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      "     |      Render an object to a tabular environment table. You can splice\n",
      "     |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.20.2\n",
      "     |         Added to Series\n",
      "     |      \n",
      "     |      `to_latex`-specific options:\n",
      "     |      \n",
      "     |      bold_rows : boolean, default False\n",
      "     |          Make the row labels bold in the output\n",
      "     |      column_format : str, default None\n",
      "     |          The columns format as specified in `LaTeX table format\n",
      "     |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      "     |          columns\n",
      "     |      longtable : boolean, default will be read from the pandas config module\n",
      "     |          Default: False.\n",
      "     |          Use a longtable environment instead of tabular. Requires adding\n",
      "     |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      "     |      escape : boolean, default will be read from the pandas config module\n",
      "     |          Default: True.\n",
      "     |          When set to False prevents from escaping latex special\n",
      "     |          characters in column names.\n",
      "     |      encoding : str, default None\n",
      "     |          A string representing the encoding to use in the output file,\n",
      "     |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "     |      decimal : string, default '.'\n",
      "     |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      multicolumn : boolean, default True\n",
      "     |          Use \\multicolumn to enhance MultiIndex columns.\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multicolumn_format : str, default 'l'\n",
      "     |          The alignment for multicolumns, similar to `column_format`\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multirow : boolean, default False\n",
      "     |          Use \\multirow to enhance MultiIndex rows.\n",
      "     |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      "     |          Will print centered labels (instead of top-aligned)\n",
      "     |          across the contained rows, separating groups via clines.\n",
      "     |          The default will be read from the pandas config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |  \n",
      "     |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      "     |      msgpack (serialize) object to input file path\n",
      "     |      \n",
      "     |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      "     |      may not be stable until a future release.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string File path, buffer-like, or None\n",
      "     |          if None, return generated string\n",
      "     |      append : boolean whether to append to an existing msgpack\n",
      "     |          (default is False)\n",
      "     |      compress : type of compressor (zlib or blosc), default to None (no\n",
      "     |          compression)\n",
      "     |  \n",
      "     |  to_pickle(self, path, compression='infer', protocol=4)\n",
      "     |      Pickle (serialize) object to input file path.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string\n",
      "     |          File path\n",
      "     |      compression : {'infer', 'gzip', 'bz2', 'xz', None}, default 'infer'\n",
      "     |          a string representing the compression to use in the output file\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      protocol : int\n",
      "     |          Int which indicates which protocol should be used by the pickler,\n",
      "     |          default HIGHEST_PROTOCOL (see [1], paragraph 12.1.2). The possible\n",
      "     |          values for this parameter depend on the version of Python. For\n",
      "     |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      "     |          valid value. For Python >= 3.4, 4 is a valid value.A negative value\n",
      "     |          for the protocol parameter is equivalent to setting its value to\n",
      "     |          HIGHEST_PROTOCOL.\n",
      "     |      \n",
      "     |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |  \n",
      "     |  to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : string\n",
      "     |          Name of SQL table\n",
      "     |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      "     |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "     |          library. If a DBAPI2 object, only sqlite3 is supported.\n",
      "     |      flavor : 'sqlite', default None\n",
      "     |          .. deprecated:: 0.19.0\n",
      "     |             'sqlite' is the only supported option if SQLAlchemy is not\n",
      "     |             used.\n",
      "     |      schema : string, default None\n",
      "     |          Specify the schema (if database flavor supports this). If None, use\n",
      "     |          default schema.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          - fail: If table exists, do nothing.\n",
      "     |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          - append: If table exists, insert data. Create if does not exist.\n",
      "     |      index : boolean, default True\n",
      "     |          Write DataFrame index as a column.\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s). If None is given (default) and\n",
      "     |          `index` is True, then the index names are used.\n",
      "     |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      chunksize : int, default None\n",
      "     |          If not None, then rows will be written in batches of this size at a\n",
      "     |          time.  If None, all rows will be written at once.\n",
      "     |      dtype : dict of column name to SQL type, default None\n",
      "     |          Optional specifying the datatype for columns. The SQL type should\n",
      "     |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      "     |  \n",
      "     |  to_xarray(self)\n",
      "     |      Return an xarray object from the pandas object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a DataArray for a Series\n",
      "     |      a Dataset for a DataFrame\n",
      "     |      a DataArray for higher dims\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)})\n",
      "     |      >>> df\n",
      "     |         A    B    C\n",
      "     |      0  1  foo  4.0\n",
      "     |      1  1  bar  5.0\n",
      "     |      2  2  foo  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (index: 3)\n",
      "     |      Coordinates:\n",
      "     |        * index    (index) int64 0 1 2\n",
      "     |      Data variables:\n",
      "     |          A        (index) int64 1 1 2\n",
      "     |          B        (index) object 'foo' 'bar' 'foo'\n",
      "     |          C        (index) float64 4.0 5.0 6.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)}\n",
      "     |                           ).set_index(['B','A'])\n",
      "     |      >>> df\n",
      "     |               C\n",
      "     |      B   A\n",
      "     |      foo 1  4.0\n",
      "     |      bar 1  5.0\n",
      "     |      foo 2  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (A: 2, B: 2)\n",
      "     |      Coordinates:\n",
      "     |        * B        (B) object 'bar' 'foo'\n",
      "     |        * A        (A) int64 1 2\n",
      "     |      Data variables:\n",
      "     |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      "     |      \n",
      "     |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      "     |                       items=list('ABCD'),\n",
      "     |                       major_axis=pd.date_range('20130101', periods=3),\n",
      "     |                       minor_axis=['first', 'second'])\n",
      "     |      >>> p\n",
      "     |      <class 'pandas.core.panel.Panel'>\n",
      "     |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      "     |      Items axis: A to D\n",
      "     |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      "     |      Minor_axis axis: first to second\n",
      "     |      \n",
      "     |      >>> p.to_xarray()\n",
      "     |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      "     |      array([[[ 0,  1],\n",
      "     |              [ 2,  3],\n",
      "     |              [ 4,  5]],\n",
      "     |             [[ 6,  7],\n",
      "     |              [ 8,  9],\n",
      "     |              [10, 11]],\n",
      "     |             [[12, 13],\n",
      "     |              [14, 15],\n",
      "     |              [16, 17]],\n",
      "     |             [[18, 19],\n",
      "     |              [20, 21],\n",
      "     |              [22, 23]]])\n",
      "     |      Coordinates:\n",
      "     |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      "     |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      "     |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      "     |  \n",
      "     |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      "     |      Truncates a sorted DataFrame/Series before and/or after some\n",
      "     |      particular index value. If the axis contains only datetime values,\n",
      "     |      before/after parameters are converted to datetime values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      before : date, string, int\n",
      "     |          Truncate all rows before this index value\n",
      "     |      after : date, string, int\n",
      "     |          Truncate all rows after this index value\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      \n",
      "     |          * 0 or 'index': apply truncation to rows\n",
      "     |          * 1 or 'columns': apply truncation to columns\n",
      "     |          Default is stat axis for given data type (0 for Series and\n",
      "     |          DataFrames, 1 for Panels)\n",
      "     |      copy : boolean, default is True,\n",
      "     |          return a copy of the truncated section\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      truncated : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      "     |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      "     |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      "     |      ...                    index=[1, 2, 3, 4, 5])\n",
      "     |      >>> df.truncate(before=2, after=4)\n",
      "     |         A  B  C\n",
      "     |      2  b  g  l\n",
      "     |      3  c  h  m\n",
      "     |      4  d  i  n\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
      "     |      ...                    'B': [6, 7, 8, 9, 10],\n",
      "     |      ...                    'C': [11, 12, 13, 14, 15]},\n",
      "     |      ...                    index=['a', 'b', 'c', 'd', 'e'])\n",
      "     |      >>> df.truncate(before='b', after='d')\n",
      "     |         A  B   C\n",
      "     |      b  2  7  12\n",
      "     |      c  3  8  13\n",
      "     |      d  4  9  14\n",
      "     |      \n",
      "     |      The index values in ``truncate`` can be datetimes or string\n",
      "     |      dates. Note that ``truncate`` assumes a 0 value for any unspecified\n",
      "     |      date component in a ``DatetimeIndex`` in contrast to slicing which\n",
      "     |      returns any partially matching dates.\n",
      "     |      \n",
      "     |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      "     |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      "     |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      "     |                           A\n",
      "     |      2016-01-09 23:59:56  1\n",
      "     |      2016-01-09 23:59:57  1\n",
      "     |      2016-01-09 23:59:58  1\n",
      "     |      2016-01-09 23:59:59  1\n",
      "     |      2016-01-10 00:00:00  1\n",
      "     |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      "     |                           A\n",
      "     |      2016-01-10 23:59:55  1\n",
      "     |      2016-01-10 23:59:56  1\n",
      "     |      2016-01-10 23:59:57  1\n",
      "     |      2016-01-10 23:59:58  1\n",
      "     |      2016-01-10 23:59:59  1\n",
      "     |  \n",
      "     |  tshift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift the time index, using the index's frequency if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, default None\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      "     |      axis : int or basestring\n",
      "     |          Corresponds to the axis that contains the Index\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is not specified then tries to use the freq or inferred_freq\n",
      "     |      attributes of the index. If neither of those attributes exist, a\n",
      "     |      ValueError is thrown\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : NDFrame\n",
      "     |  \n",
      "     |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      "     |      Convert tz-aware axis to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to convert\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the axis is tz-naive.\n",
      "     |  \n",
      "     |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      "     |      Localize tz-naive TimeSeries to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to localize\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      "     |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      "     |            order\n",
      "     |          - bool-ndarray where True signifies a DST time, False designates\n",
      "     |            a non-DST time (note that this flag is only applicable for\n",
      "     |            ambiguous times)\n",
      "     |          - 'NaT' will return NaT where there are ambiguous times\n",
      "     |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      "     |            times\n",
      "     |      infer_dst : boolean, default False\n",
      "     |          .. deprecated:: 0.15.0\n",
      "     |             Attempt to infer fall dst-transition hours based on order\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the TimeSeries is tz-aware and tz is not None.\n",
      "     |  \n",
      "     |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is True and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is True, keep the original value. Where\n",
      "     |          False, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is False are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The where method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``where`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.mask`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  at\n",
      "     |      Fast label-based scalar accessor\n",
      "     |      \n",
      "     |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  blocks\n",
      "     |      Internal property, property synonym for as_blocks()\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      Return the dtypes in this object.\n",
      "     |  \n",
      "     |  empty\n",
      "     |      True if NDFrame is entirely empty [no items], meaning any of the\n",
      "     |      axes are of length 0.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If NDFrame contains only NaNs, it is still not considered empty. See\n",
      "     |      the example below.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      "     |      \n",
      "     |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      "     |      >>> df_empty\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A]\n",
      "     |      Index: []\n",
      "     |      >>> df_empty.empty\n",
      "     |      True\n",
      "     |      \n",
      "     |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      "     |      will need to drop the NaNs to make the DataFrame empty:\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      "     |      >>> df\n",
      "     |          A\n",
      "     |      0 NaN\n",
      "     |      >>> df.empty\n",
      "     |      False\n",
      "     |      >>> df.dropna().empty\n",
      "     |      True\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.Series.dropna\n",
      "     |      pandas.DataFrame.dropna\n",
      "     |  \n",
      "     |  ftypes\n",
      "     |      Return the ftypes (indication of sparse/dense and dtype)\n",
      "     |      in this object.\n",
      "     |  \n",
      "     |  iat\n",
      "     |      Fast integer location scalar accessor.\n",
      "     |      \n",
      "     |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  iloc\n",
      "     |      Purely integer-location based indexing for selection by position.\n",
      "     |      \n",
      "     |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      "     |      ``length-1`` of the axis), but may also be used with a boolean\n",
      "     |      array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - An integer, e.g. ``5``.\n",
      "     |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      "     |      - A slice object with ints, e.g. ``1:7``.\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      "     |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      "     |      indexing (this conforms with python/numpy *slice* semantics).\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      "     |  \n",
      "     |  ix\n",
      "     |      A primarily label-location based indexer, with integer position\n",
      "     |      fallback.\n",
      "     |      \n",
      "     |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      "     |      primarily label based, but will fall back to integer positional\n",
      "     |      access unless the corresponding axis is of integer type.\n",
      "     |      \n",
      "     |      ``.ix`` is the most general indexer and will support any of the\n",
      "     |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      "     |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      "     |      with mixed positional and label based hierachical indexes.\n",
      "     |      \n",
      "     |      However, when an axis is integer based, ONLY label based access\n",
      "     |      and not positional access is supported. Thus, in such cases, it's\n",
      "     |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      "     |      \n",
      "     |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      "     |  \n",
      "     |  loc\n",
      "     |      Purely label-location based indexer for selection by label.\n",
      "     |      \n",
      "     |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      "     |      boolean array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      "     |        interpreted as a *label* of the index, and **never** as an\n",
      "     |        integer position along the index).\n",
      "     |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      "     |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      "     |        to usual python slices, **both** the start and the stop are included!).\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Label <indexing.label>`\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Number of axes / array dimensions\n",
      "     |  \n",
      "     |  size\n",
      "     |      number of elements in the NDFrame\n",
      "     |  \n",
      "     |  values\n",
      "     |      Numpy representation of NDFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The dtype will be a lower-common-denominator dtype (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen. Use this\n",
      "     |      with care if you are not dealing with the blocks.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      "     |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      "     |      will result in a flot64 dtype.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  is_copy = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for a object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __bytes__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Invoked by bytes(obj) in py3 only.\n",
      "     |      Yields a bytestring in both py2/py3.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return a string representation for a particular Object\n",
      "     |      \n",
      "     |      Invoked by str(df) in both py2/py3.\n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion\n",
      "     |      Only provide 'public' methods\n",
      "    \n",
      "    class SubclassedSparseSeries(pandas.core.sparse.series.SparseSeries)\n",
      "     |  Data structure for labeled, sparse floating point data\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : {array-like, Series, SparseSeries, dict}\n",
      "     |  kind : {'block', 'integer'}\n",
      "     |  fill_value : float\n",
      "     |      Code for missing value. Defaults depends on dtype.\n",
      "     |      0 for int dtype, False for bool dtype, and NaN for other dtypes\n",
      "     |  sparse_index : {BlockIndex, IntIndex}, optional\n",
      "     |      Only if you have one. Mainly used internally\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  SparseSeries objects are immutable via the typical Python means. If you\n",
      "     |  must change values, convert to dense, make your changes, then convert back\n",
      "     |  to sparse\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SubclassedSparseSeries\n",
      "     |      pandas.core.sparse.series.SparseSeries\n",
      "     |      pandas.core.series.Series\n",
      "     |      pandas.core.base.IndexOpsMixin\n",
      "     |      pandas.core.generic.NDFrame\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.base.StringMixin\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from pandas.core.sparse.series.SparseSeries:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __and__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __array__(self, result=None)\n",
      "     |      the array interface, return my values\n",
      "     |  \n",
      "     |  __array_finalize__(self, obj)\n",
      "     |      Gets called after any ufunc or other array operations, necessary\n",
      "     |      to pass on the index.\n",
      "     |  \n",
      "     |  __array_wrap__(self, result, context=None)\n",
      "     |      Gets called prior to a ufunc (and after)\n",
      "     |      \n",
      "     |      See SparseArray.__array_wrap__ for detail.\n",
      "     |  \n",
      "     |  __div__ = __truediv__(self, other)\n",
      "     |  \n",
      "     |  __divmod__ = wrapper(left, right, name='__divmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x0000021EEB354F28>)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |  \n",
      "     |  __iadd__ = f(self, other)\n",
      "     |  \n",
      "     |  __iand__ = f(self, other)\n",
      "     |  \n",
      "     |  __ifloordiv__ = f(self, other)\n",
      "     |  \n",
      "     |  __imod__ = f(self, other)\n",
      "     |  \n",
      "     |  __imul__ = f(self, other)\n",
      "     |  \n",
      "     |  __init__(self, data=None, index=None, sparse_index=None, kind='block', fill_value=None, name=None, dtype=None, copy=False, fastpath=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __ior__ = f(self, other)\n",
      "     |  \n",
      "     |  __ipow__ = f(self, other)\n",
      "     |  \n",
      "     |  __isub__ = f(self, other)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      forward to the array\n",
      "     |  \n",
      "     |  __itruediv__ = f(self, other)\n",
      "     |  \n",
      "     |  __ixor__ = f(self, other)\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      return the length of the Series\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |  \n",
      "     |  __mod__(self, other)\n",
      "     |  \n",
      "     |  __mul__(self, other)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |  \n",
      "     |  __or__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __pow__(self, other)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __rand__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __rdiv__ = __rtruediv__(self, other)\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmod__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(self, other)\n",
      "     |  \n",
      "     |  __ror__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__(self, other)\n",
      "     |  \n",
      "     |  __rxor__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |  \n",
      "     |  __truediv__(self, other)\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Return a string representation for a particular DataFrame\n",
      "     |      \n",
      "     |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      "     |      py2/py3.\n",
      "     |  \n",
      "     |  __xor__ = wrapper(self, other)\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |      Return an object with absolute value taken. Only applicable to objects\n",
      "     |      that are all numeric\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      abs: type of caller\n",
      "     |  \n",
      "     |  add(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Addition of series and other, element-wise (binary operator `add`).\n",
      "     |      \n",
      "     |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.radd\n",
      "     |  \n",
      "     |  as_sparse_array(self, kind=None, fill_value=None, copy=False)\n",
      "     |      return my self as a sparse array, do not copy by default\n",
      "     |  \n",
      "     |  combine_first(self, other)\n",
      "     |      Combine Series values, choosing the calling Series's values\n",
      "     |      first. Result index will be the union of the two indexes\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series\n",
      "     |  \n",
      "     |  copy(self, deep=True)\n",
      "     |      Make a copy of the SparseSeries. Only the actual sparse values need to\n",
      "     |      be copied\n",
      "     |  \n",
      "     |  cumsum(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative sum of non-NA/null values.\n",
      "     |      \n",
      "     |      When performing the cumulative summation, any non-NA/null values will\n",
      "     |      be skipped. The resulting SparseSeries will preserve the locations of\n",
      "     |      NaN values, but the fill value will be `np.nan` regardless.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumsum : SparseSeries\n",
      "     |  \n",
      "     |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rtruediv\n",
      "     |  \n",
      "     |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rtruediv\n",
      "     |  \n",
      "     |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      "     |      Analogous to Series.dropna. If fill_value=NaN, returns a dense Series\n",
      "     |  \n",
      "     |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      "     |      \n",
      "     |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rfloordiv\n",
      "     |  \n",
      "     |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      "     |      \n",
      "     |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  get(self, label, default=None)\n",
      "     |      Returns value occupying requested label, default to specified\n",
      "     |      missing value if not present. Analogous to dict.get\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label : object\n",
      "     |          Label value looking for\n",
      "     |      default : object, optional\n",
      "     |          Value to return if label not in index\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : scalar\n",
      "     |  \n",
      "     |  get_value(self, label, takeable=False)\n",
      "     |      Retrieve single value at passed index label\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : label\n",
      "     |      takeable : interpret the index as indexers, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar value\n",
      "     |  \n",
      "     |  get_values(self)\n",
      "     |      same as values\n",
      "     |  \n",
      "     |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      "     |      \n",
      "     |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  isna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.notna : boolean inverse of isna\n",
      "     |      %(klass)s.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  isnull = isna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.notna : boolean inverse of isna\n",
      "     |      %(klass)s.isnull : alias of isna\n",
      "     |      isna : top-level isna\n",
      "     |  \n",
      "     |  le(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      "     |      \n",
      "     |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Less than of series and other, element-wise (binary operator `lt`).\n",
      "     |      \n",
      "     |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      "     |      \n",
      "     |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rmod\n",
      "     |  \n",
      "     |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rmul\n",
      "     |  \n",
      "     |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      "     |      \n",
      "     |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rmul\n",
      "     |  \n",
      "     |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      "     |      \n",
      "     |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.None\n",
      "     |  \n",
      "     |  notna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.isna : boolean inverse of notna\n",
      "     |      %(klass)s.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  notnull = notna(self)\n",
      "     |      Return a boolean same-sized object indicating if the values are\n",
      "     |      not NA.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      %(klass)s.isna : boolean inverse of notna\n",
      "     |      %(klass)s.notnull : alias of notna\n",
      "     |      notna : top-level notna\n",
      "     |  \n",
      "     |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      "     |      \n",
      "     |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rpow\n",
      "     |  \n",
      "     |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Addition of series and other, element-wise (binary operator `radd`).\n",
      "     |      \n",
      "     |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.add\n",
      "     |  \n",
      "     |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.truediv\n",
      "     |  \n",
      "     |  reindex(self, index=None, method=None, copy=True, limit=None, **kwargs)\n",
      "     |      Conform SparseSeries to new index with optional filling logic, placing\n",
      "     |      NA/NaN in locations having no value in the previous index. A new object\n",
      "     |      is produced unless the new index is equivalent to the current one and\n",
      "     |      copy=False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      index : array-like, optional (should be specified using keywords)\n",
      "     |          New labels / index to conform to. Preferably an Index object to\n",
      "     |          avoid duplicating data\n",
      "     |      \n",
      "     |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "     |          method to use for filling holes in reindexed DataFrame.\n",
      "     |          Please note: this is only  applicable to DataFrames/Series with a\n",
      "     |          monotonically increasing/decreasing index.\n",
      "     |      \n",
      "     |          * default: don't fill gaps\n",
      "     |          * pad / ffill: propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * backfill / bfill: use next valid observation to fill gap\n",
      "     |          * nearest: use nearest valid observations to fill gap\n",
      "     |      \n",
      "     |      copy : boolean, default True\n",
      "     |          Return a new object, even if the passed indexes are the same\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive elements to forward or backward fill\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between original and new labels for inexact\n",
      "     |          matches. The values of the index at the matching locations most\n",
      "     |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "     |      \n",
      "     |          Tolerance may be a scalar value, which applies the same tolerance\n",
      "     |          to all values, or list-like, which applies variable tolerance per\n",
      "     |          element. List-like includes list, tuple, array, Series, and must be\n",
      "     |          the same size as the index and its dtype must exactly match the\n",
      "     |          index's type.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      ``DataFrame.reindex`` supports two calling conventions\n",
      "     |      \n",
      "     |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      "     |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      "     |      \n",
      "     |      We *highly* recommend using keyword arguments to clarify your\n",
      "     |      intent.\n",
      "     |      \n",
      "     |      Create a dataframe with some fictional data.\n",
      "     |      \n",
      "     |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...      'http_status': [200,200,404,404,301],\n",
      "     |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "     |      ...       index=index)\n",
      "     |      >>> df\n",
      "     |                 http_status  response_time\n",
      "     |      Firefox            200           0.04\n",
      "     |      Chrome             200           0.02\n",
      "     |      Safari             404           0.07\n",
      "     |      IE10               404           0.08\n",
      "     |      Konqueror          301           1.00\n",
      "     |      \n",
      "     |      Create a new index and reindex the dataframe. By default\n",
      "     |      values in the new index that do not have corresponding\n",
      "     |      records in the dataframe are assigned ``NaN``.\n",
      "     |      \n",
      "     |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "     |      ...             'Chrome']\n",
      "     |      >>> df.reindex(new_index)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari               404.0           0.07\n",
      "     |      Iceweasel              NaN            NaN\n",
      "     |      Comodo Dragon          NaN            NaN\n",
      "     |      IE10                 404.0           0.08\n",
      "     |      Chrome               200.0           0.02\n",
      "     |      \n",
      "     |      We can fill in the missing values by passing a value to\n",
      "     |      the keyword ``fill_value``. Because the index is not monotonically\n",
      "     |      increasing or decreasing, we cannot use arguments to the keyword\n",
      "     |      ``method`` to fill the ``NaN`` values.\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value=0)\n",
      "     |                     http_status  response_time\n",
      "     |      Safari                 404           0.07\n",
      "     |      Iceweasel                0           0.00\n",
      "     |      Comodo Dragon            0           0.00\n",
      "     |      IE10                   404           0.08\n",
      "     |      Chrome                 200           0.02\n",
      "     |      \n",
      "     |      >>> df.reindex(new_index, fill_value='missing')\n",
      "     |                    http_status response_time\n",
      "     |      Safari                404          0.07\n",
      "     |      Iceweasel         missing       missing\n",
      "     |      Comodo Dragon     missing       missing\n",
      "     |      IE10                  404          0.08\n",
      "     |      Chrome                200          0.02\n",
      "     |      \n",
      "     |      We can also reindex the columns.\n",
      "     |      \n",
      "     |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      Or we can use \"axis-style\" keyword arguments\n",
      "     |      \n",
      "     |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      "     |                 http_status  user_agent\n",
      "     |      Firefox            200         NaN\n",
      "     |      Chrome             200         NaN\n",
      "     |      Safari             404         NaN\n",
      "     |      IE10               404         NaN\n",
      "     |      Konqueror          301         NaN\n",
      "     |      \n",
      "     |      To further illustrate the filling functionality in\n",
      "     |      ``reindex``, we will create a dataframe with a\n",
      "     |      monotonically increasing index (for example, a sequence\n",
      "     |      of dates).\n",
      "     |      \n",
      "     |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "     |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "     |      ...                    index=date_index)\n",
      "     |      >>> df2\n",
      "     |                  prices\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      \n",
      "     |      Suppose we decide to expand the dataframe to cover a wider\n",
      "     |      date range.\n",
      "     |      \n",
      "     |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "     |      >>> df2.reindex(date_index2)\n",
      "     |                  prices\n",
      "     |      2009-12-29     NaN\n",
      "     |      2009-12-30     NaN\n",
      "     |      2009-12-31     NaN\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      The index entries that did not have a value in the original data frame\n",
      "     |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "     |      If desired, we can fill in the missing values using one of several\n",
      "     |      options.\n",
      "     |      \n",
      "     |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "     |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "     |      \n",
      "     |      >>> df2.reindex(date_index2, method='bfill')\n",
      "     |                  prices\n",
      "     |      2009-12-29     100\n",
      "     |      2009-12-30     100\n",
      "     |      2009-12-31     100\n",
      "     |      2010-01-01     100\n",
      "     |      2010-01-02     101\n",
      "     |      2010-01-03     NaN\n",
      "     |      2010-01-04     100\n",
      "     |      2010-01-05      89\n",
      "     |      2010-01-06      88\n",
      "     |      2010-01-07     NaN\n",
      "     |      \n",
      "     |      Please note that the ``NaN`` value present in the original dataframe\n",
      "     |      (at index value 2010-01-03) will not be filled by any of the\n",
      "     |      value propagation schemes. This is because filling while reindexing\n",
      "     |      does not look at dataframe values, but only compares the original and\n",
      "     |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "     |      in the original dataframe, use the ``fillna()`` method.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : SparseSeries\n",
      "     |  \n",
      "     |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.floordiv\n",
      "     |  \n",
      "     |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      "     |      \n",
      "     |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.mod\n",
      "     |  \n",
      "     |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      "     |      \n",
      "     |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.mul\n",
      "     |  \n",
      "     |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      "     |      \n",
      "     |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.pow\n",
      "     |  \n",
      "     |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      "     |      \n",
      "     |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.sub\n",
      "     |  \n",
      "     |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.truediv\n",
      "     |  \n",
      "     |  set_value(self, label, value, takeable=False)\n",
      "     |      Quickly set single value at passed label. If label is not contained, a\n",
      "     |      new object is created with the label placed at the end of the result\n",
      "     |      index\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Please use .at[] or .iat[] accessors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label : object\n",
      "     |          Partial indexing with MultiIndex not allowed\n",
      "     |      value : object\n",
      "     |          Scalar value\n",
      "     |      takeable : interpret the index as indexers, default False\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method *always* returns a new object. It is not particularly\n",
      "     |      efficient but is provided for API compatibility with Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      series : SparseSeries\n",
      "     |  \n",
      "     |  shift(self, periods, freq=None, axis=0)\n",
      "     |      Shift index by desired number of periods with an optional time freq\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, optional\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      "     |          See Notes.\n",
      "     |      axis : {0, 'index'}\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is specified then the index values are shifted but the data\n",
      "     |      is not realigned. That is, use freq if you would like to extend the\n",
      "     |      index when shifting and preserve the original data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : SparseSeries\n",
      "     |  \n",
      "     |  sparse_reindex(self, new_index)\n",
      "     |      Conform sparse values to new SparseIndex\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_index : {BlockIndex, IntIndex}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : SparseSeries\n",
      "     |  \n",
      "     |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rsub\n",
      "     |  \n",
      "     |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      "     |      \n",
      "     |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rsub\n",
      "     |  \n",
      "     |  take(self, indices, axis=0, convert=None, *args, **kwargs)\n",
      "     |      Return the elements in the given *positional* indices along an axis.\n",
      "     |      \n",
      "     |      This means that we are not indexing according to actual values in\n",
      "     |      the index attribute of the object. We are indexing according to the\n",
      "     |      actual position of the element in the object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      indices : array-like\n",
      "     |          An array of ints indicating which positions to take.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis on which to select elements. \"0\" means that we are\n",
      "     |          selecting rows, \"1\" means that we are selecting columns, etc.\n",
      "     |      convert : bool, default True\n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |             In the future, negative indices will always be converted.\n",
      "     |      \n",
      "     |          Whether to convert negative indices into positive ones.\n",
      "     |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      "     |          The conversions are similar to the behavior of indexing a\n",
      "     |          regular Python list.\n",
      "     |      is_copy : bool, default True\n",
      "     |          Whether to return a copy of the original object or not.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |                             ('parrot', 'bird',     24.0),\n",
      "     |                             ('lion',   'mammal',   80.5),\n",
      "     |                             ('monkey', 'mammal', np.nan)],\n",
      "     |                            columns=('name', 'class', 'max_speed'),\n",
      "     |                            index=[0, 2, 3, 1])\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      2  parrot    bird       24.0\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      "     |      \n",
      "     |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      "     |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      "     |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      "     |      \n",
      "     |      >>> df.take([0, 3])\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      "     |      \n",
      "     |      >>> df.take([1, 2], axis=1)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      2    bird       24.0\n",
      "     |      3  mammal       80.5\n",
      "     |      1  mammal        NaN\n",
      "     |      \n",
      "     |      We may take elements using negative integers for positive indices,\n",
      "     |      starting from the end of the object, just like with Python lists.\n",
      "     |      \n",
      "     |      >>> df.take([-1, -2])\n",
      "     |           name   class  max_speed\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      taken : type of caller\n",
      "     |          An array-like containing the elements taken from the object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.take\n",
      "     |      numpy.take\n",
      "     |  \n",
      "     |  to_coo(self, row_levels=(0,), column_levels=(1,), sort_labels=False)\n",
      "     |      Create a scipy.sparse.coo_matrix from a SparseSeries with MultiIndex.\n",
      "     |      \n",
      "     |      Use row_levels and column_levels to determine the row and column\n",
      "     |      coordinates respectively. row_levels and column_levels are the names\n",
      "     |      (labels) or numbers of the levels. {row_levels, column_levels} must be\n",
      "     |      a partition of the MultiIndex level names (or numbers).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      row_levels : tuple/list\n",
      "     |      column_levels : tuple/list\n",
      "     |      sort_labels : bool, default False\n",
      "     |          Sort the row and column labels before forming the sparse matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : scipy.sparse.coo_matrix\n",
      "     |      rows : list (row labels)\n",
      "     |      columns : list (column labels)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from numpy import nan\n",
      "     |      >>> s = Series([3.0, nan, 1.0, 3.0, nan, nan])\n",
      "     |      >>> s.index = MultiIndex.from_tuples([(1, 2, 'a', 0),\n",
      "     |                                            (1, 2, 'a', 1),\n",
      "     |                                            (1, 1, 'b', 0),\n",
      "     |                                            (1, 1, 'b', 1),\n",
      "     |                                            (2, 1, 'b', 0),\n",
      "     |                                            (2, 1, 'b', 1)],\n",
      "     |                                            names=['A', 'B', 'C', 'D'])\n",
      "     |      >>> ss = s.to_sparse()\n",
      "     |      >>> A, rows, columns = ss.to_coo(row_levels=['A', 'B'],\n",
      "     |                                       column_levels=['C', 'D'],\n",
      "     |                                       sort_labels=True)\n",
      "     |      >>> A\n",
      "     |      <3x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "     |              with 3 stored elements in COOrdinate format>\n",
      "     |      >>> A.todense()\n",
      "     |      matrix([[ 0.,  0.,  1.,  3.],\n",
      "     |      [ 3.,  0.,  0.,  0.],\n",
      "     |      [ 0.,  0.,  0.,  0.]])\n",
      "     |      >>> rows\n",
      "     |      [(1, 1), (1, 2), (2, 1)]\n",
      "     |      >>> columns\n",
      "     |      [('a', 0), ('a', 1), ('b', 0), ('b', 1)]\n",
      "     |  \n",
      "     |  to_dense(self, sparse_only=False)\n",
      "     |      Convert SparseSeries to a Series.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sparse_only: bool, default False\n",
      "     |          DEPRECATED: this argument will be removed in a future version.\n",
      "     |      \n",
      "     |          If True, return just the non-sparse values, or the dense version\n",
      "     |          of `self.values` if False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : Series\n",
      "     |  \n",
      "     |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      "     |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      "     |      \n",
      "     |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      "     |      missing data in one of the inputs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      fill_value : None or float value, default None (NaN)\n",
      "     |          Fill missing (NaN) values with this value. If both Series are\n",
      "     |          missing, the result will be missing\n",
      "     |      level : int or name\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.rtruediv\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pandas.core.sparse.series.SparseSeries:\n",
      "     |  \n",
      "     |  from_array(arr, index=None, name=None, copy=False, fill_value=None, fastpath=False) from builtins.type\n",
      "     |      Simplified alternate constructor\n",
      "     |  \n",
      "     |  from_coo(A, dense_index=False) from builtins.type\n",
      "     |      Create a SparseSeries from a scipy.sparse.coo_matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      A : scipy.sparse.coo_matrix\n",
      "     |      dense_index : bool, default False\n",
      "     |          If False (default), the SparseSeries index consists of only the\n",
      "     |          coords of the non-null entries of the original coo_matrix.\n",
      "     |          If True, the SparseSeries index consists of the full sorted\n",
      "     |          (row, col) coordinates of the coo_matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : SparseSeries\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ---------\n",
      "     |      >>> from scipy import sparse\n",
      "     |      >>> A = sparse.coo_matrix(([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])),\n",
      "     |                             shape=(3, 4))\n",
      "     |      >>> A\n",
      "     |      <3x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "     |              with 3 stored elements in COOrdinate format>\n",
      "     |      >>> A.todense()\n",
      "     |      matrix([[ 0.,  0.,  1.,  2.],\n",
      "     |              [ 3.,  0.,  0.,  0.],\n",
      "     |              [ 0.,  0.,  0.,  0.]])\n",
      "     |      >>> ss = SparseSeries.from_coo(A)\n",
      "     |      >>> ss\n",
      "     |      0  2    1\n",
      "     |         3    2\n",
      "     |      1  0    3\n",
      "     |      dtype: float64\n",
      "     |      BlockIndex\n",
      "     |      Block locations: array([0], dtype=int32)\n",
      "     |      Block lengths: array([3], dtype=int32)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.sparse.series.SparseSeries:\n",
      "     |  \n",
      "     |  block\n",
      "     |  \n",
      "     |  density\n",
      "     |  \n",
      "     |  fill_value\n",
      "     |  \n",
      "     |  kind\n",
      "     |  \n",
      "     |  npoints\n",
      "     |  \n",
      "     |  shape\n",
      "     |      return a tuple of the shape of the underlying data\n",
      "     |  \n",
      "     |  sp_index\n",
      "     |  \n",
      "     |  sp_values\n",
      "     |  \n",
      "     |  values\n",
      "     |      return the array\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  __array_prepare__(self, result, context=None)\n",
      "     |      Gets called prior to a ufunc\n",
      "     |  \n",
      "     |  __float__ = wrapper(self)\n",
      "     |  \n",
      "     |  __int__ = wrapper(self)\n",
      "     |  \n",
      "     |  __long__ = wrapper(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a Series or when passed to Series.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = Series(np.random.randn(10))\n",
      "     |      \n",
      "     |      >>> s.agg('min')\n",
      "     |      -1.3018049988556679\n",
      "     |      \n",
      "     |      >>> s.agg(['min', 'max'])\n",
      "     |      min   -1.301805\n",
      "     |      max    1.127688\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.Series.apply\n",
      "     |      pandas.Series.transform\n",
      "     |  \n",
      "     |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      "     |      Aggregate using callable, string, dict, or list of string/callables\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a Series or when passed to Series.apply. For\n",
      "     |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      "     |      default behavior is applying the function along axis=0\n",
      "     |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      "     |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      "     |      \n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aggregated : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = Series(np.random.randn(10))\n",
      "     |      \n",
      "     |      >>> s.agg('min')\n",
      "     |      -1.3018049988556679\n",
      "     |      \n",
      "     |      >>> s.agg(['min', 'max'])\n",
      "     |      min   -1.301805\n",
      "     |      max    1.127688\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.Series.apply\n",
      "     |      pandas.Series.transform\n",
      "     |  \n",
      "     |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      "     |      Align two objects on their axes with the\n",
      "     |      specified join method for each axis Index\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame or Series\n",
      "     |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      "     |      axis : allowed axis of the other object, default None\n",
      "     |          Align on index (0), columns (1), or both (None)\n",
      "     |      level : int or level name, default None\n",
      "     |          Broadcast across a level, matching Index values on the\n",
      "     |          passed MultiIndex level\n",
      "     |      copy : boolean, default True\n",
      "     |          Always returns new objects. If copy=False and no reindexing is\n",
      "     |          required then original objects are returned.\n",
      "     |      fill_value : scalar, default np.NaN\n",
      "     |          Value to use for missing values. Defaults to NaN, but can be any\n",
      "     |          \"compatible\" value\n",
      "     |      method : str, default None\n",
      "     |      limit : int, default None\n",
      "     |      fill_axis : {0, 'index'}, default 0\n",
      "     |          Filling axis, method and limit\n",
      "     |      broadcast_axis : {0, 'index'}, default None\n",
      "     |          Broadcast values along this axis, if aligning two objects of\n",
      "     |          different dimensions\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      (left, right) : (Series, type of other)\n",
      "     |          Aligned objects\n",
      "     |  \n",
      "     |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether all elements are True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      all : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      "     |      Return whether any element is True over requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      bool_only : boolean, default None\n",
      "     |          Include only boolean columns. If None, will attempt to use everything,\n",
      "     |          then use only boolean data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      any : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      "     |      Concatenate two or more Series.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      to_append : Series or list/tuple of Series\n",
      "     |      ignore_index : boolean, default False\n",
      "     |          If True, do not use the index labels.\n",
      "     |      \n",
      "     |          .. versionadded: 0.19.0\n",
      "     |      \n",
      "     |      verify_integrity : boolean, default False\n",
      "     |          If True, raise Exception on creating index with duplicates\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Iteratively appending to a Series can be more computationally intensive\n",
      "     |      than a single concatenate. A better solution is to append values to a\n",
      "     |      list and then concatenate the list with the original Series all at\n",
      "     |      once.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.concat : General function to concatenate DataFrame, Series\n",
      "     |          or Panel objects\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      appended : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s1 = pd.Series([1, 2, 3])\n",
      "     |      >>> s2 = pd.Series([4, 5, 6])\n",
      "     |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      "     |      >>> s1.append(s2)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      0    4\n",
      "     |      1    5\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s1.append(s3)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      3    4\n",
      "     |      4    5\n",
      "     |      5    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      With `ignore_index` set to True:\n",
      "     |      \n",
      "     |      >>> s1.append(s2, ignore_index=True)\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      3    4\n",
      "     |      4    5\n",
      "     |      5    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      With `verify_integrity` set to True:\n",
      "     |      \n",
      "     |      >>> s1.append(s2, verify_integrity=True)\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      "     |  \n",
      "     |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      "     |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      "     |      that applies to the entire Series) or a Python function that only works\n",
      "     |      on single values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |      convert_dtype : boolean, default True\n",
      "     |          Try to find better dtype for elementwise function results. If\n",
      "     |          False, leave as dtype=object\n",
      "     |      args : tuple\n",
      "     |          Positional arguments to pass to function in addition to the value\n",
      "     |      Additional keyword arguments will be passed as keywords to the function\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series or DataFrame if func returns a Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      Series.map: For element-wise operations\n",
      "     |      Series.agg: only perform aggregating type operations\n",
      "     |      Series.transform: only perform transformating type operations\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Create a series with typical summer temperatures for each city.\n",
      "     |      \n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      "     |      ... 'New York','Helsinki'])\n",
      "     |      >>> series\n",
      "     |      London      20\n",
      "     |      New York    21\n",
      "     |      Helsinki    12\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Square the values by defining a function and passing it as an\n",
      "     |      argument to ``apply()``.\n",
      "     |      \n",
      "     |      >>> def square(x):\n",
      "     |      ...     return x**2\n",
      "     |      >>> series.apply(square)\n",
      "     |      London      400\n",
      "     |      New York    441\n",
      "     |      Helsinki    144\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Square the values by passing an anonymous function as an\n",
      "     |      argument to ``apply()``.\n",
      "     |      \n",
      "     |      >>> series.apply(lambda x: x**2)\n",
      "     |      London      400\n",
      "     |      New York    441\n",
      "     |      Helsinki    144\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Define a custom function that needs additional positional\n",
      "     |      arguments and pass these additional arguments using the\n",
      "     |      ``args`` keyword.\n",
      "     |      \n",
      "     |      >>> def subtract_custom_value(x, custom_value):\n",
      "     |      ...     return x-custom_value\n",
      "     |      \n",
      "     |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      "     |      London      15\n",
      "     |      New York    16\n",
      "     |      Helsinki     7\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Define a custom function that takes keyword arguments\n",
      "     |      and pass these arguments to ``apply``.\n",
      "     |      \n",
      "     |      >>> def add_custom_values(x, **kwargs):\n",
      "     |      ...     for month in kwargs:\n",
      "     |      ...         x+=kwargs[month]\n",
      "     |      ...         return x\n",
      "     |      \n",
      "     |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      "     |      London      95\n",
      "     |      New York    96\n",
      "     |      Helsinki    87\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Use a function from the Numpy library.\n",
      "     |      \n",
      "     |      >>> series.apply(np.log)\n",
      "     |      London      2.995732\n",
      "     |      New York    3.044522\n",
      "     |      Helsinki    2.484907\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  argmax = wrapper(*args, **kwargs)\n",
      "     |  \n",
      "     |  argmin = wrapper(*args, **kwargs)\n",
      "     |  \n",
      "     |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      "     |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      "     |      and places the result in the same locations as the non-NA values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int (can only be zero)\n",
      "     |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      "     |          Choice of sorting algorithm. See np.sort for more\n",
      "     |          information. 'mergesort' is the only stable algorithm\n",
      "     |      order : ignored\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      argsorted : Series, with -1 indicated where nan values are present\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.argsort\n",
      "     |  \n",
      "     |  autocorr(self, lag=1)\n",
      "     |      Lag-N autocorrelation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lag : int, default 1\n",
      "     |          Number of lags to apply before performing autocorrelation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      autocorr : float\n",
      "     |  \n",
      "     |  between(self, left, right, inclusive=True)\n",
      "     |      Return boolean Series equivalent to left <= series <= right. NA values\n",
      "     |      will be treated as False\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      left : scalar\n",
      "     |          Left boundary\n",
      "     |      right : scalar\n",
      "     |          Right boundary\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_between : Series\n",
      "     |  \n",
      "     |  combine(self, other, func, fill_value=nan)\n",
      "     |      Perform elementwise binary operation on two Series using given function\n",
      "     |      with optional fill value when an index is missing from one Series or\n",
      "     |      the other\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or scalar value\n",
      "     |      func : function\n",
      "     |          Function that takes two scalars as inputs and return a scalar\n",
      "     |      fill_value : scalar value\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s1 = Series([1, 2])\n",
      "     |      >>> s2 = Series([0, 3])\n",
      "     |      >>> s1.combine(s2, lambda x1, x2: x1 if x1 < x2 else x2)\n",
      "     |      0    0\n",
      "     |      1    2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.combine_first : Combine Series values, choosing the calling\n",
      "     |          Series's values first\n",
      "     |  \n",
      "     |  compound(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the compound percentage of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      compounded : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  compress(self, condition, *args, **kwargs)\n",
      "     |      Return selected slices of an array along given axis as a Series\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.compress\n",
      "     |  \n",
      "     |  corr(self, other, method='pearson', min_periods=None)\n",
      "     |      Compute correlation with `other` Series, excluding missing values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      method : {'pearson', 'kendall', 'spearman'}\n",
      "     |          * pearson : standard correlation coefficient\n",
      "     |          * kendall : Kendall Tau correlation coefficient\n",
      "     |          * spearman : Spearman rank correlation\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations needed to have a valid result\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      correlation : float\n",
      "     |  \n",
      "     |  count(self, level=None)\n",
      "     |      Return number of non-NA/null observations in the Series\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a smaller Series\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nobs : int or Series (if level specified)\n",
      "     |  \n",
      "     |  cov(self, other, min_periods=None)\n",
      "     |      Compute covariance with Series, excluding missing values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations needed to have a valid result\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      covariance : float\n",
      "     |      \n",
      "     |      Normalized by N-1 (unbiased estimator).\n",
      "     |  \n",
      "     |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative max over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummax : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.max : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative minimum over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cummin : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.min : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Return cumulative product over requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cumprod : scalar\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.core.window.Expanding.prod : Similar functionality\n",
      "     |          but ignores ``NaN`` values.\n",
      "     |  \n",
      "     |  diff(self, periods=1)\n",
      "     |      1st discrete difference of object\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming difference\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      diffed : Series\n",
      "     |  \n",
      "     |  dot(self, other)\n",
      "     |      Matrix multiplication with DataFrame or inner-product with Series\n",
      "     |      objects\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series or DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dot_product : scalar or Series\n",
      "     |  \n",
      "     |  drop_duplicates(self, keep='first', inplace=False)\n",
      "     |      Return Series with duplicate values removed\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      "     |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      "     |          - False : Drop all duplicates.\n",
      "     |      inplace : boolean, default False\n",
      "     |      If True, performs operation inplace and returns None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      deduplicated : Series\n",
      "     |  \n",
      "     |  duplicated(self, keep='first')\n",
      "     |      Return boolean Series denoting duplicate values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keep : {'first', 'last', False}, default 'first'\n",
      "     |          - ``first`` : Mark duplicates as ``True`` except for the first\n",
      "     |            occurrence.\n",
      "     |          - ``last`` : Mark duplicates as ``True`` except for the last\n",
      "     |            occurrence.\n",
      "     |          - False : Mark all duplicates as ``True``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      duplicated : Series\n",
      "     |  \n",
      "     |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, freq=None, adjust=True, ignore_na=False, axis=0)\n",
      "     |      Provides exponential weighted functions\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      com : float, optional\n",
      "     |          Specify decay in terms of center of mass,\n",
      "     |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      "     |      span : float, optional\n",
      "     |          Specify decay in terms of span,\n",
      "     |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      "     |      halflife : float, optional\n",
      "     |          Specify decay in terms of half-life,\n",
      "     |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      "     |      alpha : float, optional\n",
      "     |          Specify smoothing factor :math:`\\alpha` directly,\n",
      "     |          :math:`0 < \\alpha \\leq 1`\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      min_periods : int, default 0\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : None or string alias / date offset object, default=None\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform to before computing statistic\n",
      "     |      adjust : boolean, default True\n",
      "     |          Divide by decaying adjustment factor in beginning periods to account\n",
      "     |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      "     |      ignore_na : boolean, default False\n",
      "     |          Ignore missing values when calculating weights;\n",
      "     |          specify True to reproduce pre-0.15.0 behavior\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.ewm(com=0.5).mean()\n",
      "     |                B\n",
      "     |      0  0.000000\n",
      "     |      1  0.750000\n",
      "     |      2  1.615385\n",
      "     |      3  1.615385\n",
      "     |      4  3.670213\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      "     |      Allowed values and relationship between the parameters are specified in the\n",
      "     |      parameter descriptions above; see the link at the end of this section for\n",
      "     |      a detailed explanation.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      When adjust is True (default), weighted averages are calculated using\n",
      "     |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      "     |      \n",
      "     |      When adjust is False, weighted averages are calculated recursively as:\n",
      "     |         weighted_average[0] = arg[0];\n",
      "     |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      "     |      \n",
      "     |      When ignore_na is False (default), weights are based on absolute positions.\n",
      "     |      For example, the weights of x and y used in calculating the final weighted\n",
      "     |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      "     |      (1-alpha)**2 and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      "     |      on relative positions. For example, the weights of x and y used in\n",
      "     |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      "     |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      "     |      \n",
      "     |      More details can be found at\n",
      "     |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      "     |  \n",
      "     |  expanding(self, min_periods=1, freq=None, center=False, axis=0)\n",
      "     |      Provides expanding transformations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA).\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      >>> df.expanding(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  3.0\n",
      "     |      4  7.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |  \n",
      "     |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      "     |      Fill NA/NaN values using the specified method\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar, dict, Series, or DataFrame\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a\n",
      "     |          dict/Series/DataFrame of values specifying which value to use for\n",
      "     |          each index (for a Series) or column (for a DataFrame). (values not\n",
      "     |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      "     |          be a list.\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use NEXT valid observation to fill gap\n",
      "     |      axis : {0, 'index'}\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, fill in place. Note: this will modify any\n",
      "     |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      "     |          DataFrame).\n",
      "     |      limit : int, default None\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled. Must be greater than 0 if not None.\n",
      "     |      downcast : dict, default is None\n",
      "     |          a dict of item->dtype of what to downcast if possible,\n",
      "     |          or the string 'infer' which will try to downcast to an appropriate\n",
      "     |          equal type (e.g. float64 to int64 if possible)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, asfreq\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "     |      ...                    [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      "     |      ...                    [np.nan, 3, np.nan, 4]],\n",
      "     |      ...                    columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      3  NaN  3.0 NaN  4\n",
      "     |      \n",
      "     |      Replace all NaN elements with 0s.\n",
      "     |      \n",
      "     |      >>> df.fillna(0)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 0.0 0\n",
      "     |      1   3.0 4.0 0.0 1\n",
      "     |      2   0.0 0.0 0.0 5\n",
      "     |      3   0.0 3.0 0.0 4\n",
      "     |      \n",
      "     |      We can also propagate non-null values forward or backward.\n",
      "     |      \n",
      "     |      >>> df.fillna(method='ffill')\n",
      "     |          A   B   C   D\n",
      "     |      0   NaN 2.0 NaN 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   3.0 4.0 NaN 5\n",
      "     |      3   3.0 3.0 NaN 4\n",
      "     |      \n",
      "     |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "     |      2, and 3 respectively.\n",
      "     |      \n",
      "     |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "     |      >>> df.fillna(value=values)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 2.0 1\n",
      "     |      2   0.0 1.0 2.0 5\n",
      "     |      3   0.0 3.0 2.0 4\n",
      "     |      \n",
      "     |      Only replace the first NaN element.\n",
      "     |      \n",
      "     |      >>> df.fillna(value=values, limit=1)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   NaN 1.0 NaN 5\n",
      "     |      3   NaN 3.0 NaN 4\n",
      "     |  \n",
      "     |  first_valid_index(self)\n",
      "     |      Return index for first non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      "     |      Draw histogram of the input series using matplotlib\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : object, optional\n",
      "     |          If passed, then used to form histograms for separate groups\n",
      "     |      ax : matplotlib axis object\n",
      "     |          If not passed, uses gca()\n",
      "     |      grid : boolean, default True\n",
      "     |          Whether to show axis grid lines\n",
      "     |      xlabelsize : int, default None\n",
      "     |          If specified changes the x-axis label size\n",
      "     |      xrot : float, default None\n",
      "     |          rotation of x axis labels\n",
      "     |      ylabelsize : int, default None\n",
      "     |          If specified changes the y-axis label size\n",
      "     |      yrot : float, default None\n",
      "     |          rotation of y axis labels\n",
      "     |      figsize : tuple, default None\n",
      "     |          figure size in inches by default\n",
      "     |      bins: integer, default 10\n",
      "     |          Number of histogram bins to be used\n",
      "     |      kwds : keywords\n",
      "     |          To be passed to the actual plotting function\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See matplotlib documentation online for more on this\n",
      "     |  \n",
      "     |  idxmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Index *label* of the first occurrence of maximum of values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If the entire Series is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the Series is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmax : Index of maximum of values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the Series version of ``ndarray.argmax``. This method\n",
      "     |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      "     |      the position. To get the position, use ``series.values.argmax()``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.idxmax\n",
      "     |      numpy.ndarray.argmax\n",
      "     |  \n",
      "     |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      "     |      Index *label* of the first occurrence of minimum of values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If the entire Series is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the Series is empty\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      idxmin : Index of minimum of values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the Series version of ``ndarray.argmin``. This method\n",
      "     |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      "     |      the position. To get the position, use ``series.values.argmin()``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.idxmin\n",
      "     |      numpy.ndarray.argmin\n",
      "     |  \n",
      "     |  isin(self, values)\n",
      "     |      Return a boolean :class:`~pandas.Series` showing whether each element\n",
      "     |      in the :class:`~pandas.Series` is exactly contained in the passed\n",
      "     |      sequence of ``values``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : set or list-like\n",
      "     |          The sequence of values to test. Passing in a single string will\n",
      "     |          raise a ``TypeError``. Instead, turn a single string into a\n",
      "     |          ``list`` of one element.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |      \n",
      "     |          Support for values as a set\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      isin : Series (bool dtype)\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |        * If ``values`` is a string\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.isin\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = pd.Series(list('abc'))\n",
      "     |      >>> s.isin(['a', 'c', 'e'])\n",
      "     |      0     True\n",
      "     |      1    False\n",
      "     |      2     True\n",
      "     |      dtype: bool\n",
      "     |      \n",
      "     |      Passing a single string as ``s.isin('a')`` will raise an error. Use\n",
      "     |      a list of one element instead:\n",
      "     |      \n",
      "     |      >>> s.isin(['a'])\n",
      "     |      0     True\n",
      "     |      1    False\n",
      "     |      2    False\n",
      "     |      dtype: bool\n",
      "     |  \n",
      "     |  items = iteritems(self)\n",
      "     |      Lazily iterate over (index, value) tuples\n",
      "     |  \n",
      "     |  iteritems(self)\n",
      "     |      Lazily iterate over (index, value) tuples\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      Alias for index\n",
      "     |  \n",
      "     |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      "     |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      kurt : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  last_valid_index(self)\n",
      "     |      Return index for last non-NA/null value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      --------\n",
      "     |      If all elements are non-NA/null, returns None.\n",
      "     |      Also returns None for empty Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      scalar : type of index\n",
      "     |  \n",
      "     |  mad(self, axis=None, skipna=None, level=None)\n",
      "     |      Return the mean absolute deviation of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mad : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  map(self, arg, na_action=None)\n",
      "     |      Map values of Series using input correspondence (which can be\n",
      "     |      a dict, Series, or function)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg : function, dict, or Series\n",
      "     |      na_action : {None, 'ignore'}\n",
      "     |          If 'ignore', propagate NA values, without passing them to the\n",
      "     |          mapping function\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series\n",
      "     |          same index as caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Map inputs to outputs (both of type `Series`)\n",
      "     |      \n",
      "     |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      "     |      >>> x\n",
      "     |      one      1\n",
      "     |      two      2\n",
      "     |      three    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      "     |      >>> y\n",
      "     |      1    foo\n",
      "     |      2    bar\n",
      "     |      3    baz\n",
      "     |      \n",
      "     |      >>> x.map(y)\n",
      "     |      one   foo\n",
      "     |      two   bar\n",
      "     |      three baz\n",
      "     |      \n",
      "     |      If `arg` is a dictionary, return a new Series with values converted\n",
      "     |      according to the dictionary's mapping:\n",
      "     |      \n",
      "     |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      "     |      \n",
      "     |      >>> x.map(z)\n",
      "     |      one   A\n",
      "     |      two   B\n",
      "     |      three C\n",
      "     |      \n",
      "     |      Use na_action to control whether NA values are affected by the mapping\n",
      "     |      function.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      "     |      \n",
      "     |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      "     |      0    this is a string 1.0\n",
      "     |      1    this is a string 2.0\n",
      "     |      2    this is a string 3.0\n",
      "     |      3    this is a string nan\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      "     |      0    this is a string 1.0\n",
      "     |      1    this is a string 2.0\n",
      "     |      2    this is a string 3.0\n",
      "     |      3                     NaN\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.apply: For applying more complex functions on a Series\n",
      "     |      DataFrame.apply: Apply a function row-/column-wise\n",
      "     |      DataFrame.applymap: Apply a function elementwise on a whole DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When `arg` is a dictionary, values in Series that are not in the\n",
      "     |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      "     |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      "     |      provides a method for default values), then this default is used\n",
      "     |      rather than ``NaN``:\n",
      "     |      \n",
      "     |      >>> from collections import Counter\n",
      "     |      >>> counter = Counter()\n",
      "     |      >>> counter['bar'] += 1\n",
      "     |      >>> y.map(counter)\n",
      "     |      1    0\n",
      "     |      2    1\n",
      "     |      3    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the maximum of the values in the object.\n",
      "     |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      max : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the mean of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return the median of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  memory_usage(self, index=True, deep=False)\n",
      "     |      Memory usage of the Series\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : bool\n",
      "     |          Specifies whether to include memory usage of Series index\n",
      "     |      deep : bool\n",
      "     |          Introspect the data deeply, interrogate\n",
      "     |          `object` dtypes for system-level memory consumption\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar bytes of memory consumed\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Memory usage does not include memory consumed by elements that\n",
      "     |      are not components of the array if deep=False\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.nbytes\n",
      "     |  \n",
      "     |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      This method returns the minimum of the values in the object.\n",
      "     |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      "     |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      min : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  mode(self)\n",
      "     |      Return the mode(s) of the dataset.\n",
      "     |      \n",
      "     |      Always returns Series even if only one value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      modes : Series (sorted)\n",
      "     |  \n",
      "     |  nlargest(self, n=5, keep='first')\n",
      "     |      Return the largest `n` elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Return this many descending sorted values\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      top_n : Series\n",
      "     |          The n largest values in the Series, in sorted order\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      "     |      relative to the size of the ``Series`` object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.nsmallest\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> s = pd.Series(np.random.randn(10**6))\n",
      "     |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      "     |      219921    4.644710\n",
      "     |      82124     4.608745\n",
      "     |      421689    4.564644\n",
      "     |      425277    4.447014\n",
      "     |      718691    4.414137\n",
      "     |      43154     4.403520\n",
      "     |      283187    4.313922\n",
      "     |      595519    4.273635\n",
      "     |      503969    4.250236\n",
      "     |      121637    4.240952\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  nonzero(self)\n",
      "     |      Return the indices of the elements that are non-zero\n",
      "     |      \n",
      "     |      This method is equivalent to calling `numpy.nonzero` on the\n",
      "     |      series data. For compatability with NumPy, the return value is\n",
      "     |      the same (a tuple with an array of indices for each dimension),\n",
      "     |      but it will always be a one-item tuple because series only have\n",
      "     |      one dimension.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([0, 3, 0, 4])\n",
      "     |      >>> s.nonzero()\n",
      "     |      (array([1, 3]),)\n",
      "     |      >>> s.iloc[s.nonzero()[0]]\n",
      "     |      1    3\n",
      "     |      3    4\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.nonzero\n",
      "     |  \n",
      "     |  nsmallest(self, n=5, keep='first')\n",
      "     |      Return the smallest `n` elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Return this many ascending sorted values\n",
      "     |      keep : {'first', 'last'}, default 'first'\n",
      "     |          Where there are duplicate values:\n",
      "     |          - ``first`` : take the first occurrence.\n",
      "     |          - ``last`` : take the last occurrence.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bottom_n : Series\n",
      "     |          The n smallest values in the Series, in sorted order\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      "     |      the size of the ``Series`` object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.nlargest\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import pandas as pd\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> s = pd.Series(np.random.randn(10**6))\n",
      "     |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      "     |      288532   -4.954580\n",
      "     |      732345   -4.835960\n",
      "     |      64803    -4.812550\n",
      "     |      446457   -4.609998\n",
      "     |      501225   -4.483945\n",
      "     |      669476   -4.472935\n",
      "     |      973615   -4.401699\n",
      "     |      621279   -4.355126\n",
      "     |      773916   -4.347355\n",
      "     |      359919   -4.331927\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : scalar or Series (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the product of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prod : scalar or Series (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the product of an empty or all-NA Series is ``1``\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter\n",
      "     |      \n",
      "     |      >>> pd.Series([]).prod(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).prod()\n",
      "     |      1.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Returns the difference between the maximum value and the\n",
      "     |                  minimum value in the object. This is the equivalent of the\n",
      "     |                  ``numpy.ndarray`` method ``ptp``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ptp : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  put(self, *args, **kwargs)\n",
      "     |      Applies the `put` method to its `values` attribute\n",
      "     |      if it has one.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.put\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, interpolation='linear')\n",
      "     |      Return value at the given quantile, a la numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          0 <= q <= 1, the quantile(s) to compute\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |          This optional parameter specifies the interpolation method to use,\n",
      "     |          when the desired quantile lies between two data points `i` and `j`:\n",
      "     |      \n",
      "     |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      "     |                fractional part of the index surrounded by `i` and `j`.\n",
      "     |              * lower: `i`.\n",
      "     |              * higher: `j`.\n",
      "     |              * nearest: `i` or `j` whichever is nearest.\n",
      "     |              * midpoint: (`i` + `j`) / 2.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      quantile : float or Series\n",
      "     |          if ``q`` is an array, a Series will be returned where the\n",
      "     |          index is ``q`` and the values are the quantiles.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = Series([1, 2, 3, 4])\n",
      "     |      >>> s.quantile(.5)\n",
      "     |      2.5\n",
      "     |      >>> s.quantile([.25, .5, .75])\n",
      "     |      0.25    1.75\n",
      "     |      0.50    2.50\n",
      "     |      0.75    3.25\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  ravel(self, order='C')\n",
      "     |      Return the flattened underlying data as an ndarray\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.ravel\n",
      "     |  \n",
      "     |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      "     |      for compatibility with higher dims\n",
      "     |  \n",
      "     |  rename(self, index=None, **kwargs)\n",
      "     |      Alter Series index labels or name\n",
      "     |      \n",
      "     |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "     |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      Alternatively, change ``Series.name`` with a scalar value.\n",
      "     |      \n",
      "     |      See the :ref:`user guide <basics.rename>` for more.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : scalar, hashable sequence, dict-like or function, optional\n",
      "     |          dict-like or functions are transformations to apply to\n",
      "     |          the index.\n",
      "     |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      "     |          attribute.\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to return a new %(klass)s. If True then value of copy is\n",
      "     |          ignored.\n",
      "     |      level : int or level name, default None\n",
      "     |          In case of a MultiIndex, only rename labels in the specified\n",
      "     |          level.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : Series (new object)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.rename_axis\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      Name: my_name, dtype: int64\n",
      "     |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      4    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      "     |      0    1\n",
      "     |      3    2\n",
      "     |      5    3\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  reorder_levels(self, order)\n",
      "     |      Rearrange index levels using input order. May not drop or duplicate\n",
      "     |      levels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : list of int representing new level order.\n",
      "     |             (reference level by number or key)\n",
      "     |      axis : where to reorder levels\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      type of caller (new object)\n",
      "     |  \n",
      "     |  repeat(self, repeats, *args, **kwargs)\n",
      "     |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      "     |      for more information about the `repeats` argument.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.repeat\n",
      "     |  \n",
      "     |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      "     |      Analogous to the :meth:`pandas.DataFrame.reset_index` function, see\n",
      "     |      docstring there.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, str, tuple, or list, default None\n",
      "     |          Only remove the given levels from the index. Removes all levels by\n",
      "     |          default\n",
      "     |      drop : boolean, default False\n",
      "     |          Do not try to insert index into dataframe columns\n",
      "     |      name : object, default None\n",
      "     |          The name of the column corresponding to the Series values\n",
      "     |      inplace : boolean, default False\n",
      "     |          Modify the Series in place (do not create a new object)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      ----------\n",
      "     |      resetted : DataFrame, or Series if drop == True\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4], index=pd.Index(['a', 'b', 'c', 'd'],\n",
      "     |      ...                                            name = 'idx'))\n",
      "     |      >>> s.reset_index()\n",
      "     |         index  0\n",
      "     |      0      0  1\n",
      "     |      1      1  2\n",
      "     |      2      2  3\n",
      "     |      3      3  4\n",
      "     |      \n",
      "     |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo',\n",
      "     |      ...                     'foo', 'qux', 'qux']),\n",
      "     |      ...           np.array(['one', 'two', 'one', 'two', 'one', 'two',\n",
      "     |      ...                     'one', 'two'])]\n",
      "     |      >>> s2 = pd.Series(\n",
      "     |      ...     np.random.randn(8),\n",
      "     |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      "     |      ...                                     names=['a', 'b']))\n",
      "     |      >>> s2.reset_index(level='a')\n",
      "     |             a         0\n",
      "     |      b\n",
      "     |      one  bar -0.286320\n",
      "     |      two  bar -0.587934\n",
      "     |      one  baz  0.710491\n",
      "     |      two  baz -1.429006\n",
      "     |      one  foo  0.790700\n",
      "     |      two  foo  0.824863\n",
      "     |      one  qux -0.718963\n",
      "     |      two  qux -0.055028\n",
      "     |  \n",
      "     |  reshape(self, *args, **kwargs)\n",
      "     |      .. deprecated:: 0.19.0\n",
      "     |         Calling this method will raise an error. Please call\n",
      "     |         ``.values.reshape(...)`` instead.\n",
      "     |      \n",
      "     |      return an ndarray with the values shape\n",
      "     |      if the specified shape matches exactly the current shape, then\n",
      "     |      return self (for compat)\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.reshape\n",
      "     |  \n",
      "     |  rolling(self, window, min_periods=None, freq=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      "     |      Provides rolling window calculations.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      window : int, or offset\n",
      "     |          Size of the moving window. This is the number of observations used for\n",
      "     |          calculating the statistic. Each window will be a fixed size.\n",
      "     |      \n",
      "     |          If its an offset then this will be the time period of each window. Each\n",
      "     |          window will be a variable sized based on the observations included in\n",
      "     |          the time-period. This is only valid for datetimelike indexes. This is\n",
      "     |          new in 0.19.0\n",
      "     |      min_periods : int, default None\n",
      "     |          Minimum number of observations in window required to have a value\n",
      "     |          (otherwise result is NA). For a window that is specified by an offset,\n",
      "     |          this will default to 1.\n",
      "     |      freq : string or DateOffset object, optional (default None)\n",
      "     |          .. deprecated:: 0.18.0\n",
      "     |             Frequency to conform the data to before computing the statistic.\n",
      "     |             Specified as a frequency string or DateOffset object.\n",
      "     |      center : boolean, default False\n",
      "     |          Set the labels at the center of the window.\n",
      "     |      win_type : string, default None\n",
      "     |          Provide a window type. See the notes below.\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column on which to calculate\n",
      "     |          the rolling window, rather than the index\n",
      "     |      closed : string, default None\n",
      "     |          Make the interval closed on the 'right', 'left', 'both' or\n",
      "     |          'neither' endpoints.\n",
      "     |          For offset-based windows, it defaults to 'right'.\n",
      "     |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      "     |          for fixed windows.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      axis : int or string, default 0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a Window or Rolling sub-classed for the particular operation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      "     |      >>> df\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  2.0\n",
      "     |      3  NaN\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, using the 'triang'\n",
      "     |      window type.\n",
      "     |      \n",
      "     |      >>> df.rolling(2, win_type='triang').sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  2.5\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Rolling sum with a window length of 2, min_periods defaults\n",
      "     |      to the window length.\n",
      "     |      \n",
      "     |      >>> df.rolling(2).sum()\n",
      "     |           B\n",
      "     |      0  NaN\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  NaN\n",
      "     |      4  NaN\n",
      "     |      \n",
      "     |      Same as above, but explicity set the min_periods\n",
      "     |      \n",
      "     |      >>> df.rolling(2, min_periods=1).sum()\n",
      "     |           B\n",
      "     |      0  0.0\n",
      "     |      1  1.0\n",
      "     |      2  3.0\n",
      "     |      3  2.0\n",
      "     |      4  4.0\n",
      "     |      \n",
      "     |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      "     |      ....:                 index = [pd.Timestamp('20130101 09:00:00'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:02'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:03'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:05'),\n",
      "     |      ....:                          pd.Timestamp('20130101 09:00:06')])\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  2.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      \n",
      "     |      Contrasting to an integer rolling window, this will roll a variable\n",
      "     |      length window corresponding to the time period.\n",
      "     |      The default for min_periods is 1.\n",
      "     |      \n",
      "     |      >>> df.rolling('2s').sum()\n",
      "     |                             B\n",
      "     |      2013-01-01 09:00:00  0.0\n",
      "     |      2013-01-01 09:00:02  1.0\n",
      "     |      2013-01-01 09:00:03  3.0\n",
      "     |      2013-01-01 09:00:05  NaN\n",
      "     |      2013-01-01 09:00:06  4.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      By default, the result is set to the right edge of the window. This can be\n",
      "     |      changed to the center of the window by setting ``center=True``.\n",
      "     |      \n",
      "     |      The `freq` keyword is used to conform time series data to a specified\n",
      "     |      frequency by resampling the data. This is done with the default parameters\n",
      "     |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "     |      \n",
      "     |      To learn more about the offsets & frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      The recognized win_types are:\n",
      "     |      \n",
      "     |      * ``boxcar``\n",
      "     |      * ``triang``\n",
      "     |      * ``blackman``\n",
      "     |      * ``hamming``\n",
      "     |      * ``bartlett``\n",
      "     |      * ``parzen``\n",
      "     |      * ``bohman``\n",
      "     |      * ``blackmanharris``\n",
      "     |      * ``nuttall``\n",
      "     |      * ``barthann``\n",
      "     |      * ``kaiser`` (needs beta)\n",
      "     |      * ``gaussian`` (needs std)\n",
      "     |      * ``general_gaussian`` (needs power, width)\n",
      "     |      * ``slepian`` (needs width).\n",
      "     |      \n",
      "     |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      "     |      different window types see `scipy.signal window functions\n",
      "     |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      "     |  \n",
      "     |  round(self, decimals=0, *args, **kwargs)\n",
      "     |      Round each value in a Series to the given number of decimals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      decimals : int\n",
      "     |          Number of decimal places to round to (default: 0).\n",
      "     |          If decimals is negative, it specifies the number of\n",
      "     |          positions to the left of the decimal point.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around\n",
      "     |      DataFrame.round\n",
      "     |  \n",
      "     |  searchsorted(self, value, side='left', sorter=None)\n",
      "     |      Find indices where elements should be inserted to maintain order.\n",
      "     |      \n",
      "     |      Find the indices into a sorted Series `self` such that, if the\n",
      "     |      corresponding elements in `value` were inserted before the indices,\n",
      "     |      the order of `self` would be preserved.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : array_like\n",
      "     |          Values to insert into `self`.\n",
      "     |      side : {'left', 'right'}, optional\n",
      "     |          If 'left', the index of the first suitable location found is given.\n",
      "     |          If 'right', return the last such index.  If there is no suitable\n",
      "     |          index, return either 0 or N (where N is the length of `self`).\n",
      "     |      sorter : 1-D array_like, optional\n",
      "     |          Optional array of integer indices that sort `self` into ascending\n",
      "     |          order. They are typically the result of ``np.argsort``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      indices : array of ints\n",
      "     |          Array of insertion points with the same shape as `value`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Binary search is used to find the required insertion points.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> x = pd.Series([1, 2, 3])\n",
      "     |      >>> x\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> x.searchsorted(4)\n",
      "     |      array([3])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([0, 4])\n",
      "     |      array([0, 3])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([1, 3], side='left')\n",
      "     |      array([0, 2])\n",
      "     |      \n",
      "     |      >>> x.searchsorted([1, 3], side='right')\n",
      "     |      array([1, 3])\n",
      "     |      \n",
      "     |      >>> x = pd.Categorical(['apple', 'bread', 'bread', 'cheese', 'milk' ])\n",
      "     |      [apple, bread, bread, cheese, milk]\n",
      "     |      Categories (4, object): [apple < bread < cheese < milk]\n",
      "     |      \n",
      "     |      >>> x.searchsorted('bread')\n",
      "     |      array([1])     # Note: an array, not a scalar\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread'])\n",
      "     |      array([1])\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread', 'eggs'])\n",
      "     |      array([1, 4])\n",
      "     |      \n",
      "     |      >>> x.searchsorted(['bread', 'eggs'], side='right')\n",
      "     |      array([3, 4])    # eggs before milk\n",
      "     |  \n",
      "     |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased standard error of the mean over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sem : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased skew over requested axis\n",
      "     |      Normalized by N-1\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      skew : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      "     |      Sort object by labels (along an axis)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : index to direct sorting\n",
      "     |      level : int or level name or list of ints or list of level names\n",
      "     |          if not None, sort on values in specified index level(s)\n",
      "     |      ascending : boolean, default True\n",
      "     |          Sort ascending vs. descending\n",
      "     |      inplace : bool, default False\n",
      "     |          if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      "     |           Not implemented for MultiIndex.\n",
      "     |      sort_remaining : bool, default True\n",
      "     |          if true and sorting by level and index is multilevel, sort by other\n",
      "     |          levels too (in order) after sorting by specified level\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : Series\n",
      "     |  \n",
      "     |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      "     |      Sort by the values along either axis\n",
      "     |      \n",
      "     |      .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0, 'index'}, default 0\n",
      "     |          Axis to direct sorting\n",
      "     |      ascending : bool or list of bool, default True\n",
      "     |           Sort ascending vs. descending. Specify list for multiple sort\n",
      "     |           orders.  If this is a list of bools, must match the length of\n",
      "     |           the by.\n",
      "     |      inplace : bool, default False\n",
      "     |           if True, perform operation in-place\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "     |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "     |           information.  `mergesort` is the only stable algorithm. For\n",
      "     |           DataFrames, this option is only applied when sorting on a single\n",
      "     |           column or label.\n",
      "     |      na_position : {'first', 'last'}, default 'last'\n",
      "     |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted_obj : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\n",
      "     |      ...     'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "     |      ...     'col2' : [2, 1, 9, 8, 7, 4],\n",
      "     |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "     |      ... })\n",
      "     |      >>> df\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      \n",
      "     |      Sort by col1\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1'])\n",
      "     |          col1 col2 col3\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort by multiple columns\n",
      "     |      \n",
      "     |      >>> df.sort_values(by=['col1', 'col2'])\n",
      "     |          col1 col2 col3\n",
      "     |      1   A    1    1\n",
      "     |      0   A    2    0\n",
      "     |      2   B    9    9\n",
      "     |      5   C    4    3\n",
      "     |      4   D    7    2\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Sort Descending\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False)\n",
      "     |          col1 col2 col3\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |      3   NaN  8    4\n",
      "     |      \n",
      "     |      Putting NAs first\n",
      "     |      \n",
      "     |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "     |          col1 col2 col3\n",
      "     |      3   NaN  8    4\n",
      "     |      4   D    7    2\n",
      "     |      5   C    4    3\n",
      "     |      2   B    9    9\n",
      "     |      0   A    2    0\n",
      "     |      1   A    1    1\n",
      "     |  \n",
      "     |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      "     |      DEPRECATED: use :meth:`Series.sort_index`\n",
      "     |      \n",
      "     |      Sort Series with MultiIndex by chosen level. Data will be\n",
      "     |      lexicographically sorted by the chosen level followed by the other\n",
      "     |      levels (in order)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int or level name, default None\n",
      "     |      ascending : bool, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sorted : Series\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.sort_index(level=...)\n",
      "     |  \n",
      "     |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return sample standard deviation over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      "     |      Return the sum of the values for the requested axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      min_count : int, default 0\n",
      "     |          The required number of valid values to perform the operation. If fewer than\n",
      "     |          ``min_count`` non-NA values are present the result will be NA.\n",
      "     |      \n",
      "     |          .. versionadded :: 0.22.0\n",
      "     |      \n",
      "     |             Added with the default being 1. This means the sum or product\n",
      "     |             of an all-NA or empty series is ``NaN``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sum : scalar or Series (if level specified)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      "     |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      "     |      \n",
      "     |      >>> pd.Series([]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |      \n",
      "     |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      "     |      empty series identically.\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum()\n",
      "     |      0.0\n",
      "     |      \n",
      "     |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      "     |      Swap levels i and j in a MultiIndex\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      i, j : int, string (can be mixed)\n",
      "     |          Level of index to be swapped. Can pass level name as string.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      swapped : Series\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.18.1\n",
      "     |      \n",
      "     |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      "     |         the two innermost levels of the index.\n",
      "     |  \n",
      "     |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, date_format=None, decimal='.')\n",
      "     |      Write Series to a comma-separated values (csv) file\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string or file handle, default None\n",
      "     |          File path or object, if None is provided the result is returned as\n",
      "     |          a string.\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      header : boolean, default False\n",
      "     |          Write out series name\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      mode : Python write mode, default 'w'\n",
      "     |      sep : character, default \",\"\n",
      "     |          Field delimiter for the output file.\n",
      "     |      encoding : string, optional\n",
      "     |          a string representing the encoding to use if the contents are\n",
      "     |          non-ascii, for python versions prior to 3\n",
      "     |      date_format: string, default None\n",
      "     |          Format string for datetime objects.\n",
      "     |      decimal: string, default '.'\n",
      "     |          Character recognized as decimal separator. E.g. use ',' for\n",
      "     |          European data\n",
      "     |  \n",
      "     |  to_dict(self, into=<class 'dict'>)\n",
      "     |      Convert Series to {label -> value} dict or dict-like object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      into : class, default dict\n",
      "     |          The collections.Mapping subclass to use as the return\n",
      "     |          object. Can be the actual class or an empty\n",
      "     |          instance of the mapping type you want.  If you want a\n",
      "     |          collections.defaultdict, you must pass it initialized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value_dict : collections.Mapping\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4])\n",
      "     |      >>> s.to_dict()\n",
      "     |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      "     |      >>> from collections import OrderedDict, defaultdict\n",
      "     |      >>> s.to_dict(OrderedDict)\n",
      "     |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      "     |      >>> dd = defaultdict(list)\n",
      "     |      >>> s.to_dict(dd)\n",
      "     |      defaultdict(<type 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      "     |  \n",
      "     |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      "     |      Write Series to an excel sheet\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel_writer : string or ExcelWriter object\n",
      "     |          File path or existing ExcelWriter\n",
      "     |      sheet_name : string, default 'Sheet1'\n",
      "     |          Name of sheet which will contain DataFrame\n",
      "     |      na_rep : string, default ''\n",
      "     |          Missing data representation\n",
      "     |      float_format : string, default None\n",
      "     |          Format string for floating point numbers\n",
      "     |      columns : sequence, optional\n",
      "     |          Columns to write\n",
      "     |      header : boolean or list of string, default True\n",
      "     |          Write out the column names. If a list of strings is given it is\n",
      "     |          assumed to be aliases for the column names\n",
      "     |      index : boolean, default True\n",
      "     |          Write row names (index)\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s) if desired. If None is given, and\n",
      "     |          `header` and `index` are True, then the index names are used. A\n",
      "     |          sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      startrow :\n",
      "     |          upper left cell row to dump data frame\n",
      "     |      startcol :\n",
      "     |          upper left cell column to dump data frame\n",
      "     |      engine : string, default None\n",
      "     |          write engine to use - you can also set this via the options\n",
      "     |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      "     |          ``io.excel.xlsm.writer``.\n",
      "     |      merge_cells : boolean, default True\n",
      "     |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      "     |      encoding: string, default None\n",
      "     |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      "     |          other writers support unicode natively.\n",
      "     |      inf_rep : string, default 'inf'\n",
      "     |          Representation for infinity (there is no native representation for\n",
      "     |          infinity in Excel)\n",
      "     |      freeze_panes : tuple of integer (length 2), default None\n",
      "     |          Specifies the one-based bottommost row and rightmost column that\n",
      "     |          is to be frozen\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      "     |      to the existing workbook.  This can be used to save different\n",
      "     |      DataFrames to one workbook:\n",
      "     |      \n",
      "     |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      "     |      >>> df1.to_excel(writer,'Sheet1')\n",
      "     |      >>> df2.to_excel(writer,'Sheet2')\n",
      "     |      >>> writer.save()\n",
      "     |      \n",
      "     |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      "     |      strings before writing.\n",
      "     |  \n",
      "     |  to_frame(self, name=None)\n",
      "     |      Convert Series to DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : object, default None\n",
      "     |          The passed name should substitute for the series name (if it has\n",
      "     |          one).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data_frame : DataFrame\n",
      "     |  \n",
      "     |  to_period(self, freq=None, copy=True)\n",
      "     |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      "     |      frequency (inferred from index if not passed)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ts : Series with PeriodIndex\n",
      "     |  \n",
      "     |  to_sparse(self, kind='block', fill_value=None)\n",
      "     |      Convert Series to SparseSeries\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kind : {'block', 'integer'}\n",
      "     |      fill_value : float, defaults to NaN (missing)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sp : SparseSeries\n",
      "     |  \n",
      "     |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      "     |      Render a string representation of the Series\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      buf : StringIO-like, optional\n",
      "     |          buffer to write to\n",
      "     |      na_rep : string, optional\n",
      "     |          string representation of NAN to use, default 'NaN'\n",
      "     |      float_format : one-parameter function, optional\n",
      "     |          formatter function to apply to columns' elements if they are floats\n",
      "     |          default None\n",
      "     |      header: boolean, default True\n",
      "     |          Add the Series header (index name)\n",
      "     |      index : bool, optional\n",
      "     |          Add index (row) labels, default True\n",
      "     |      length : boolean, default False\n",
      "     |          Add the Series length\n",
      "     |      dtype : boolean, default False\n",
      "     |          Add the Series dtype\n",
      "     |      name : boolean, default False\n",
      "     |          Add the Series name if not None\n",
      "     |      max_rows : int, optional\n",
      "     |          Maximum number of rows to show before truncating. If None, show\n",
      "     |          all.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      formatted : string (if not buffer passed)\n",
      "     |  \n",
      "     |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      "     |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : string, default frequency of PeriodIndex\n",
      "     |          Desired frequency\n",
      "     |      how : {'s', 'e', 'start', 'end'}\n",
      "     |          Convention for converting period to timestamp; start of period\n",
      "     |          vs. end\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ts : Series with DatetimeIndex\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |      Call function producing a like-indexed NDFrame\n",
      "     |      and return a NDFrame with the transformed values\n",
      "     |      \n",
      "     |      .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, string, dictionary, or list of string/callables\n",
      "     |          To apply to column\n",
      "     |      \n",
      "     |          Accepted Combinations are:\n",
      "     |      \n",
      "     |          - string function name\n",
      "     |          - function\n",
      "     |          - list of functions\n",
      "     |          - dict of column names -> functions (or list of functions)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      transformed : NDFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      "     |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      "     |      df.iloc[3:7] = np.nan\n",
      "     |      \n",
      "     |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      "     |                         A         B         C\n",
      "     |      2000-01-01  0.579457  1.236184  0.123424\n",
      "     |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      "     |      2000-01-03  1.455756 -0.277446  0.288967\n",
      "     |      2000-01-04       NaN       NaN       NaN\n",
      "     |      2000-01-05       NaN       NaN       NaN\n",
      "     |      2000-01-06       NaN       NaN       NaN\n",
      "     |      2000-01-07       NaN       NaN       NaN\n",
      "     |      2000-01-08 -0.498658  1.274522  1.642524\n",
      "     |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      "     |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.aggregate\n",
      "     |      pandas.NDFrame.apply\n",
      "     |  \n",
      "     |  unique(self)\n",
      "     |      Return unique values in the object. Uniques are returned in order\n",
      "     |      of appearance, this does NOT sort. Hash table-based unique.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : 1d array-like\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unique values.\n",
      "     |        - If the input is an Index, the return is an Index\n",
      "     |        - If the input is a Categorical dtype, the return is a Categorical\n",
      "     |        - If the input is a Series/ndarray, the return will be an ndarray\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      unique\n",
      "     |      Index.unique\n",
      "     |      Series.unique\n",
      "     |  \n",
      "     |  unstack(self, level=-1, fill_value=None)\n",
      "     |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      "     |      The level involved will automatically get sorted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : int, string, or list of these, default last level\n",
      "     |          Level(s) to unstack, can pass level name\n",
      "     |      fill_value : replace NaN with this value if the unstack produces\n",
      "     |          missing values\n",
      "     |      \n",
      "     |          .. versionadded: 0.18.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4],\n",
      "     |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      "     |      >>> s\n",
      "     |      one  a    1\n",
      "     |           b    2\n",
      "     |      two  a    3\n",
      "     |           b    4\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s.unstack(level=-1)\n",
      "     |           a  b\n",
      "     |      one  1  2\n",
      "     |      two  3  4\n",
      "     |      \n",
      "     |      >>> s.unstack(level=0)\n",
      "     |         one  two\n",
      "     |      a    1    3\n",
      "     |      b    2    4\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unstacked : DataFrame\n",
      "     |  \n",
      "     |  update(self, other)\n",
      "     |      Modify Series in place using non-NA values from passed\n",
      "     |      Series. Aligns on index\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.update(pd.Series([4, 5, 6]))\n",
      "     |      >>> s\n",
      "     |      0    4\n",
      "     |      1    5\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      "     |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      "     |      >>> s\n",
      "     |      0    d\n",
      "     |      1    b\n",
      "     |      2    e\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      "     |      >>> s\n",
      "     |      0    4\n",
      "     |      1    5\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      If ``other`` contains NaNs the corresponding values are not updated\n",
      "     |      in the original Series.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      "     |      >>> s\n",
      "     |      0    4\n",
      "     |      1    2\n",
      "     |      2    6\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  valid lambda self, inplace=False, **kwargs\n",
      "     |  \n",
      "     |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "     |      Return unbiased variance over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |      skipna : boolean, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar\n",
      "     |      ddof : int, default 1\n",
      "     |          degrees of freedom\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  view(self, dtype=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      "     |      Read CSV file (DEPRECATED, please use :func:`pandas.read_csv`\n",
      "     |      instead).\n",
      "     |      \n",
      "     |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      "     |      for most general purposes, but ``from_csv`` makes for an easy\n",
      "     |      roundtrip to and from a file (the exact counterpart of\n",
      "     |      ``to_csv``), especially with a time Series.\n",
      "     |      \n",
      "     |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      "     |      \n",
      "     |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      "     |        by default)\n",
      "     |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      "     |        the column names)\n",
      "     |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      "     |        as datetime by default)\n",
      "     |      \n",
      "     |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      "     |      to return a Series like ``from_csv``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string file path or file handle / StringIO\n",
      "     |      sep : string, default ','\n",
      "     |          Field delimiter\n",
      "     |      parse_dates : boolean, default True\n",
      "     |          Parse dates. Different default from read_table\n",
      "     |      header : int, default None\n",
      "     |          Row to use as header (skip prior rows)\n",
      "     |      index_col : int or sequence, default 0\n",
      "     |          Column to use for index. If a sequence is given, a MultiIndex\n",
      "     |          is used. Different default from read_table\n",
      "     |      encoding : string, optional\n",
      "     |          a string representing the encoding to use if the contents are\n",
      "     |          non-ascii, for python versions prior to 3\n",
      "     |      infer_datetime_format: boolean, default False\n",
      "     |          If True and `parse_dates` is True for a column, try to infer the\n",
      "     |          datetime format based on the first datetime string. If the format\n",
      "     |          can be inferred, there often will be a large parsing speed-up.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.read_csv\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : Series\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  asobject\n",
      "     |      return object Series which contains boxed values\n",
      "     |      \n",
      "     |      *this is an internal non-public method*\n",
      "     |  \n",
      "     |  axes\n",
      "     |      Return a list of the row axis labels\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      return the dtype object of the underlying data\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      return the dtype object of the underlying data\n",
      "     |  \n",
      "     |  ftype\n",
      "     |      return if the data is sparse|dense\n",
      "     |  \n",
      "     |  ftypes\n",
      "     |      return if the data is sparse|dense\n",
      "     |  \n",
      "     |  imag\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  real\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.series.Series:\n",
      "     |  \n",
      "     |  cat = <class 'pandas.core.categorical.CategoricalAccessor'>\n",
      "     |      Accessor object for categorical properties of the Series values.\n",
      "     |      \n",
      "     |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      "     |      methods return new categorical data per default (but can be called with\n",
      "     |      `inplace=True`).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.cat.categories\n",
      "     |      >>> s.cat.categories = list('abc')\n",
      "     |      >>> s.cat.rename_categories(list('cab'))\n",
      "     |      >>> s.cat.reorder_categories(list('cab'))\n",
      "     |      >>> s.cat.add_categories(['d','e'])\n",
      "     |      >>> s.cat.remove_categories(['d'])\n",
      "     |      >>> s.cat.remove_unused_categories()\n",
      "     |      >>> s.cat.set_categories(list('abcde'))\n",
      "     |      >>> s.cat.as_ordered()\n",
      "     |      >>> s.cat.as_unordered()\n",
      "     |  \n",
      "     |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      "     |      Accessor object for datetimelike properties of the Series values.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.dt.hour\n",
      "     |      >>> s.dt.second\n",
      "     |      >>> s.dt.quarter\n",
      "     |      \n",
      "     |      Returns a Series indexed like the original Series.\n",
      "     |      Raises TypeError if the Series does not contain datetimelike values.\n",
      "     |  \n",
      "     |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      "     |      Series plotting accessor and method\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.plot.line()\n",
      "     |      >>> s.plot.bar()\n",
      "     |      >>> s.plot.hist()\n",
      "     |      \n",
      "     |      Plotting methods can also be accessed by calling the accessor as a method\n",
      "     |      with the ``kind`` argument:\n",
      "     |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      "     |  \n",
      "     |  str = <class 'pandas.core.strings.StringMethods'>\n",
      "     |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      "     |      handled otherwise by a particular method. Patterned after Python's string\n",
      "     |      methods, with some inspiration from R's stringr package.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s.str.split('_')\n",
      "     |      >>> s.str.replace('_', '')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      "     |  \n",
      "     |  factorize(self, sort=False, na_sentinel=-1)\n",
      "     |      Encode the object as an enumerated type or categorical variable\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sort : boolean, default False\n",
      "     |          Sort by values\n",
      "     |      na_sentinel: int, default -1\n",
      "     |          Value to mark \"not found\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      labels : the indexer to the original array\n",
      "     |      uniques : the unique Index\n",
      "     |  \n",
      "     |  item(self)\n",
      "     |      return the first element of the underlying data as a python\n",
      "     |      scalar\n",
      "     |  \n",
      "     |  nunique(self, dropna=True)\n",
      "     |      Return number of unique elements in the object.\n",
      "     |      \n",
      "     |      Excludes NA values by default.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include NaN in the count.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nunique : int\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Return a list of the values.\n",
      "     |      \n",
      "     |      These are each a scalar type, which is a Python scalar\n",
      "     |      (for str, int, float) or a pandas scalar\n",
      "     |      (for Timestamp/Timedelta/Interval/Period)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ndarray.tolist\n",
      "     |  \n",
      "     |  transpose(self, *args, **kwargs)\n",
      "     |      return the transpose, which is by definition self\n",
      "     |  \n",
      "     |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      "     |      Returns object containing counts of unique values.\n",
      "     |      \n",
      "     |      The resulting object will be in descending order so that the\n",
      "     |      first element is the most frequently-occurring element.\n",
      "     |      Excludes NA values by default.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      normalize : boolean, default False\n",
      "     |          If True then the object returned will contain the relative\n",
      "     |          frequencies of the unique values.\n",
      "     |      sort : boolean, default True\n",
      "     |          Sort by values\n",
      "     |      ascending : boolean, default False\n",
      "     |          Sort in ascending order\n",
      "     |      bins : integer, optional\n",
      "     |          Rather than count values, group them into half-open bins,\n",
      "     |          a convenience for pd.cut, only works with numeric data\n",
      "     |      dropna : boolean, default True\n",
      "     |          Don't include counts of NaN.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      counts : Series\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      "     |  \n",
      "     |  T\n",
      "     |      return the transpose, which is by definition self\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  base\n",
      "     |      return the base object if the memory of the underlying data is\n",
      "     |      shared\n",
      "     |  \n",
      "     |  data\n",
      "     |      return the data pointer of the underlying data\n",
      "     |  \n",
      "     |  empty\n",
      "     |  \n",
      "     |  flags\n",
      "     |      return the ndarray.flags for the underlying data\n",
      "     |  \n",
      "     |  hasnans\n",
      "     |  \n",
      "     |  is_monotonic\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_increasing\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_monotonic : boolean\n",
      "     |  \n",
      "     |  is_monotonic_decreasing\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_decreasing\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_monotonic_decreasing : boolean\n",
      "     |  \n",
      "     |  is_monotonic_increasing\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_increasing\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_monotonic : boolean\n",
      "     |  \n",
      "     |  is_unique\n",
      "     |      Return boolean if values in the object are unique\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_unique : boolean\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |      return the size of the dtype of the item of the underlying data\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |      return the number of bytes in the underlying data\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      return the number of dimensions of the underlying data,\n",
      "     |      by definition 1\n",
      "     |  \n",
      "     |  size\n",
      "     |      return the number of elements in the underlying data\n",
      "     |  \n",
      "     |  strides\n",
      "     |      return the strides of the underlying data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  __abs__(self)\n",
      "     |  \n",
      "     |  __bool__ = __nonzero__(self)\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      True if the key is in the info axis\n",
      "     |  \n",
      "     |  __copy__(self, deep=True)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete item\n",
      "     |  \n",
      "     |  __finalize__(self, other, method=None, **kwargs)\n",
      "     |      Propagate metadata from other to self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : the object from which to get the attributes that we are going\n",
      "     |          to propagate\n",
      "     |      method : optional, a passed method name ; possibly to take different\n",
      "     |          types of propagation actions based on this\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |      After regular attribute access, try looking up the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__(self)\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |  \n",
      "     |  __round__(self, decimals=0)\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      After regular attribute access, try setting the name\n",
      "     |      This allows simpler access to columns for interactive use.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  add_prefix(self, prefix)\n",
      "     |      Concatenate prefix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      prefix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_prefix : type of caller\n",
      "     |  \n",
      "     |  add_suffix(self, suffix)\n",
      "     |      Concatenate suffix string with panel items names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      suffix : string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      with_suffix : type of caller\n",
      "     |  \n",
      "     |  as_blocks(self, copy=True)\n",
      "     |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      "     |      a homogeneous dtype.\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      "     |            as_matrix)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : a dict of dtype -> Constructor Types\n",
      "     |  \n",
      "     |  as_matrix(self, columns=None)\n",
      "     |      Convert the frame to its Numpy-array representation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns: list, optional, default:None\n",
      "     |          If None, return all columns, otherwise, returns specified columns.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : ndarray\n",
      "     |          If the caller is heterogeneous and contains booleans or objects,\n",
      "     |          the result will be of dtype=object. See Notes.\n",
      "     |      \n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      "     |      \n",
      "     |      The dtype will be a lower-common-denominator dtype (implicit\n",
      "     |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      "     |      are mixed, the one that accommodates all will be chosen. Use this\n",
      "     |      with care if you are not dealing with the blocks.\n",
      "     |      \n",
      "     |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      "     |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      "     |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      "     |      will result in a flot64 dtype.\n",
      "     |      \n",
      "     |      This method is provided for backwards compatibility. Generally,\n",
      "     |      it is recommended to use '.values'.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.values\n",
      "     |  \n",
      "     |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      "     |      Convert TimeSeries to specified frequency.\n",
      "     |      \n",
      "     |      Optionally provide filling method to pad/backfill missing values.\n",
      "     |      \n",
      "     |      Returns the original data conformed to a new index with the specified\n",
      "     |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      "     |      summarization, is necessary to represent the data at the new frequency.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      freq : DateOffset object, or string\n",
      "     |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      "     |          Method to use for filling holes in reindexed Series (note this\n",
      "     |          does not fill NaNs that already were present):\n",
      "     |      \n",
      "     |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      "     |            valid\n",
      "     |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      "     |      how : {'start', 'end'}, default end\n",
      "     |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      "     |      normalize : bool, default False\n",
      "     |          Whether to reset output index to midnight\n",
      "     |      fill_value: scalar, optional\n",
      "     |          Value to use for missing values, applied during upsampling (note\n",
      "     |          this does not fill NaNs that already were present).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 4 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      "     |      >>> df = pd.DataFrame({'s':series})\n",
      "     |      >>> df\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    NaN\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    NaN\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``fill value``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    9.0\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    9.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    9.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      Upsample again, providing a ``method``.\n",
      "     |      \n",
      "     |      >>> df.asfreq(freq='30S', method='bfill')\n",
      "     |                             s\n",
      "     |      2000-01-01 00:00:00    0.0\n",
      "     |      2000-01-01 00:00:30    NaN\n",
      "     |      2000-01-01 00:01:00    NaN\n",
      "     |      2000-01-01 00:01:30    2.0\n",
      "     |      2000-01-01 00:02:00    2.0\n",
      "     |      2000-01-01 00:02:30    3.0\n",
      "     |      2000-01-01 00:03:00    3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the frequency strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |  \n",
      "     |  asof(self, where, subset=None)\n",
      "     |      The last row without any NaN is taken (or the last row without\n",
      "     |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      "     |      \n",
      "     |      .. versionadded:: 0.19.0 For DataFrame\n",
      "     |      \n",
      "     |      If there is no good value, NaN is returned for a Series\n",
      "     |      a Series of NaN values for a DataFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      where : date or array of dates\n",
      "     |      subset : string or list of strings, default None\n",
      "     |         if not None use these columns for NaN propagation\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Dates are assumed to be sorted\n",
      "     |      Raises if this is not the case\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      where is scalar\n",
      "     |      \n",
      "     |        - value or NaN if input is Series\n",
      "     |        - Series if input is DataFrame\n",
      "     |      \n",
      "     |      where is Index: same shape object as input\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      merge_asof\n",
      "     |  \n",
      "     |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      "     |      Cast a pandas object to a specified dtype ``dtype``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data type, or dict of column name -> data type\n",
      "     |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      "     |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      "     |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      "     |          or more of the DataFrame's columns to column-specific types.\n",
      "     |      copy : bool, default True.\n",
      "     |          Return a copy when ``copy=True`` (be very careful setting\n",
      "     |          ``copy=False`` as changes to values then may propagate to other\n",
      "     |          pandas objects).\n",
      "     |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      "     |          Control raising of exceptions on invalid data for provided dtype.\n",
      "     |      \n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      raise_on_error : raise on invalid input\n",
      "     |          .. deprecated:: 0.20.0\n",
      "     |             Use ``errors`` instead\n",
      "     |      kwargs : keyword arguments to pass on to the constructor\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      casted : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      "     |      >>> ser\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int32\n",
      "     |      >>> ser.astype('int64')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      Convert to categorical type:\n",
      "     |      \n",
      "     |      >>> ser.astype('category')\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [1, 2]\n",
      "     |      \n",
      "     |      Convert to ordered categorical type with custom ordering:\n",
      "     |      \n",
      "     |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      dtype: category\n",
      "     |      Categories (2, int64): [2 < 1]\n",
      "     |      \n",
      "     |      Note that using ``copy=False`` and changing data on a new\n",
      "     |      pandas object may propagate changes:\n",
      "     |      \n",
      "     |      >>> s1 = pd.Series([1,2])\n",
      "     |      >>> s2 = s1.astype('int', copy=False)\n",
      "     |      >>> s2[0] = 10\n",
      "     |      >>> s1  # note that s1[0] has changed too\n",
      "     |      0    10\n",
      "     |      1     2\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to a numeric type.\n",
      "     |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      "     |  \n",
      "     |  at_time(self, time, asof=False)\n",
      "     |      Select values at particular time of day (e.g. 9:30AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      time : datetime.time or string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_at_time : type of caller\n",
      "     |  \n",
      "     |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      "     |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_time : datetime.time or string\n",
      "     |      end_time : datetime.time or string\n",
      "     |      include_start : boolean, default True\n",
      "     |      include_end : boolean, default True\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values_between_time : type of caller\n",
      "     |  \n",
      "     |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Return the bool of a single element PandasObject.\n",
      "     |      \n",
      "     |      This must be a boolean scalar value, either True or False.  Raise a\n",
      "     |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      "     |      element is not boolean\n",
      "     |  \n",
      "     |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      "     |      Trim values at input threshold(s).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lower : float or array_like, default None\n",
      "     |      upper : float or array_like, default None\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with lower and upper along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.256177\n",
      "     |      1 -1.367855  0.746646\n",
      "     |      2  0.027753 -1.176076\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  1.261967  0.570967\n",
      "     |      \n",
      "     |      >>> df.clip(-1.0, 0.5)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -1.000000\n",
      "     |      1 -1.000000  0.500000\n",
      "     |      2  0.027753 -1.000000\n",
      "     |      3  0.230930 -0.679613\n",
      "     |      4  0.500000  0.500000\n",
      "     |      \n",
      "     |      >>> t\n",
      "     |      0   -0.3\n",
      "     |      1   -0.2\n",
      "     |      2   -0.1\n",
      "     |      3    0.0\n",
      "     |      4    0.1\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> df.clip(t, t + 1, axis=0)\n",
      "     |                0         1\n",
      "     |      0  0.335232 -0.300000\n",
      "     |      1 -0.200000  0.746646\n",
      "     |      2  0.027753 -0.100000\n",
      "     |      3  0.230930  0.000000\n",
      "     |      4  1.100000  0.570967\n",
      "     |  \n",
      "     |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of the input with values below given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      "     |      Return copy of input with values above given value(s) truncated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : float or array_like\n",
      "     |      axis : int or string axis name, optional\n",
      "     |          Align object with threshold along the given axis.\n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |              .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      clip\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      clipped : same type as input\n",
      "     |  \n",
      "     |  consolidate(self, inplace=False)\n",
      "     |      DEPRECATED: consolidate will be an internal implementation only.\n",
      "     |  \n",
      "     |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      "     |      Deprecated.\n",
      "     |      Attempt to infer better dtype for object columns\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      convert_dates : boolean, default True\n",
      "     |          If True, convert to date where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      convert_numeric : boolean, default False\n",
      "     |          If True, attempt to coerce to numbers (including strings), with\n",
      "     |          unconvertible values becoming NaN.\n",
      "     |      convert_timedeltas : boolean, default True\n",
      "     |          If True, convert to timedelta where possible. If 'coerce', force\n",
      "     |          conversion, with unconvertible values becoming NaT.\n",
      "     |      copy : boolean, default True\n",
      "     |          If True, return a copy even if no copy is necessary (e.g. no\n",
      "     |          conversion was done). Note: This is meant for internal use, and\n",
      "     |          should not be confused with inplace.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      "     |          with day as the default.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same as input object\n",
      "     |  \n",
      "     |  describe(self, percentiles=None, include=None, exclude=None)\n",
      "     |      Generates descriptive statistics that summarize the central tendency,\n",
      "     |      dispersion and shape of a dataset's distribution, excluding\n",
      "     |      ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      summary:  Series/DataFrame of summary statistics\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      "     |      ...                     'numeric': [1, 2, 3],\n",
      "     |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |              categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count\n",
      "     |      DataFrame.max\n",
      "     |      DataFrame.min\n",
      "     |      DataFrame.mean\n",
      "     |      DataFrame.std\n",
      "     |      DataFrame.select_dtypes\n",
      "     |  \n",
      "     |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      "     |      Return new object with labels in requested axis removed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels : single label or list-like\n",
      "     |          Index or column labels to drop.\n",
      "     |      axis : int or axis name\n",
      "     |          Whether to drop labels from the index (0 / 'index') or\n",
      "     |          columns (1 / 'columns').\n",
      "     |      index, columns : single label or list-like\n",
      "     |          Alternative to specifying `axis` (``labels, axis=1`` is\n",
      "     |          equivalent to ``columns=labels``).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      level : int or level name, default None\n",
      "     |          For MultiIndex\n",
      "     |      inplace : bool, default False\n",
      "     |          If True, do operation inplace and return None.\n",
      "     |      errors : {'ignore', 'raise'}, default 'raise'\n",
      "     |          If 'ignore', suppress error and existing labels are dropped.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dropped : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      "     |                            columns=['A', 'B', 'C', 'D'])\n",
      "     |      >>> df\n",
      "     |         A  B   C   D\n",
      "     |      0  0  1   2   3\n",
      "     |      1  4  5   6   7\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Drop columns\n",
      "     |      \n",
      "     |      >>> df.drop(['B', 'C'], axis=1)\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      >>> df.drop(columns=['B', 'C'])\n",
      "     |         A   D\n",
      "     |      0  0   3\n",
      "     |      1  4   7\n",
      "     |      2  8  11\n",
      "     |      \n",
      "     |      Drop a row by index\n",
      "     |      \n",
      "     |      >>> df.drop([0, 1])\n",
      "     |         A  B   C   D\n",
      "     |      2  8  9  10  11\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Specifying both `labels` and `index` or `columns` will raise a\n",
      "     |      ValueError.\n",
      "     |  \n",
      "     |  equals(self, other)\n",
      "     |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      "     |      the same location are considered equal.\n",
      "     |  \n",
      "     |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      "     |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      "     |  \n",
      "     |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      "     |      Subset rows or columns of dataframe according to labels in\n",
      "     |      the specified index.\n",
      "     |      \n",
      "     |      Note that this routine does not filter a dataframe on its\n",
      "     |      contents. The filter is applied to the labels of the index.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      items : list-like\n",
      "     |          List of info axis to restrict to (must not all be present)\n",
      "     |      like : string\n",
      "     |          Keep info axis where \"arg in col == True\"\n",
      "     |      regex : string (regular expression)\n",
      "     |          Keep info axis with re.search(regex, col) == True\n",
      "     |      axis : int or string axis name\n",
      "     |          The axis to filter on.  By default this is the info axis,\n",
      "     |          'index' for Series, 'columns' for DataFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |      one  two  three\n",
      "     |      mouse     1    2      3\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      >>> # select columns by name\n",
      "     |      >>> df.filter(items=['one', 'three'])\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select columns by regular expression\n",
      "     |      >>> df.filter(regex='e$', axis=1)\n",
      "     |      one  three\n",
      "     |      mouse     1      3\n",
      "     |      rabbit    4      6\n",
      "     |      \n",
      "     |      >>> # select rows containing 'bbi'\n",
      "     |      >>> df.filter(like='bbi', axis=0)\n",
      "     |      one  two  three\n",
      "     |      rabbit    4    5      6\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.loc\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The ``items``, ``like``, and ``regex`` parameters are\n",
      "     |      enforced to be mutually exclusive.\n",
      "     |      \n",
      "     |      ``axis`` defaults to the info axis that is used when indexing\n",
      "     |      with ``[]``.\n",
      "     |  \n",
      "     |  first(self, offset)\n",
      "     |      Convenience method for subsetting initial periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.first('10D') -> First 10 days\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  get_dtype_counts(self)\n",
      "     |      Return the counts of dtypes in this object.\n",
      "     |  \n",
      "     |  get_ftype_counts(self)\n",
      "     |      Return the counts of ftypes in this object.\n",
      "     |  \n",
      "     |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      "     |      Group series using mapper (dict or key function, apply given function\n",
      "     |      to group, return result as series) or by a series of columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : mapping, function, str, or iterable\n",
      "     |          Used to determine the groups for the groupby.\n",
      "     |          If ``by`` is a function, it's called on each value of the object's\n",
      "     |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      "     |          will be used to determine the groups (the Series' values are first\n",
      "     |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      "     |          values are used as-is determine the groups. A str or list of strs\n",
      "     |          may be passed to group by the columns in ``self``\n",
      "     |      axis : int, default 0\n",
      "     |      level : int, level name, or sequence of such, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      "     |          level or levels\n",
      "     |      as_index : boolean, default True\n",
      "     |          For aggregated output, return object with group labels as the\n",
      "     |          index. Only relevant for DataFrame input. as_index=False is\n",
      "     |          effectively \"SQL-style\" grouped output\n",
      "     |      sort : boolean, default True\n",
      "     |          Sort group keys. Get better performance by turning this off.\n",
      "     |          Note this does not influence the order of observations within each\n",
      "     |          group.  groupby preserves the order of rows within each group.\n",
      "     |      group_keys : boolean, default True\n",
      "     |          When calling apply, add group keys to index to identify pieces\n",
      "     |      squeeze : boolean, default False\n",
      "     |          reduce the dimensionality of the return type if possible,\n",
      "     |          otherwise return a consistent type\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      DataFrame results\n",
      "     |      \n",
      "     |      >>> data.groupby(func, axis=0).mean()\n",
      "     |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      "     |      \n",
      "     |      DataFrame with hierarchical index\n",
      "     |      \n",
      "     |      >>> data.groupby(['col1', 'col2']).mean()\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GroupBy object\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return the first n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_head : type of caller\n",
      "     |          The first n rows of the caller object.\n",
      "     |  \n",
      "     |  infer_objects(self)\n",
      "     |      Attempt to infer better dtypes for object columns.\n",
      "     |      \n",
      "     |      Attempts soft conversion of object-dtyped\n",
      "     |      columns, leaving non-object and unconvertible\n",
      "     |      columns unchanged. The inference rules are the\n",
      "     |      same as during normal Series/DataFrame construction.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.to_datetime : Convert argument to datetime.\n",
      "     |      pandas.to_timedelta : Convert argument to timedelta.\n",
      "     |      pandas.to_numeric : Convert argument to numeric typeR\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      converted : same type as input object\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      "     |      >>> df = df.iloc[1:]\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      1  1\n",
      "     |      2  2\n",
      "     |      3  3\n",
      "     |      \n",
      "     |      >>> df.dtypes\n",
      "     |      A    object\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      >>> df.infer_objects().dtypes\n",
      "     |      A    int64\n",
      "     |      dtype: object\n",
      "     |  \n",
      "     |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      "     |      Interpolate values according to different methods.\n",
      "     |      \n",
      "     |      Please note that only ``method='linear'`` is supported for\n",
      "     |      DataFrames/Series with a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      "     |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      "     |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      "     |                'from_derivatives', 'pchip', 'akima'}\n",
      "     |      \n",
      "     |          * 'linear': ignore the index and treat the values as equally\n",
      "     |            spaced. This is the only method supported on MultiIndexes.\n",
      "     |            default\n",
      "     |          * 'time': interpolation works on daily and higher resolution\n",
      "     |            data to interpolate given length of interval\n",
      "     |          * 'index', 'values': use the actual numerical values of the index\n",
      "     |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      "     |            'barycentric', 'polynomial' is passed to\n",
      "     |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      "     |            require that you also specify an `order` (int),\n",
      "     |            e.g. df.interpolate(method='polynomial', order=4).\n",
      "     |            These use the actual numerical values of the index.\n",
      "     |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      "     |            are all wrappers around the scipy interpolation methods of\n",
      "     |            similar names. These use the actual numerical values of the\n",
      "     |            index. For more information on their behavior, see the\n",
      "     |            `scipy documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      "     |            and `tutorial documentation\n",
      "     |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      "     |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      "     |            replaces 'piecewise_polynomial' interpolation method in\n",
      "     |            scipy 0.18\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |      \n",
      "     |             Added support for the 'akima' method\n",
      "     |             Added interpolate method 'from_derivatives' which replaces\n",
      "     |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      "     |             scipy < 0.18\n",
      "     |      \n",
      "     |      axis : {0, 1}, default 0\n",
      "     |          * 0: fill column-by-column\n",
      "     |          * 1: fill row-by-row\n",
      "     |      limit : int, default None.\n",
      "     |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      "     |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      "     |          If limit is specified, consecutive NaNs will be filled in this\n",
      "     |          direction.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |      \n",
      "     |      inplace : bool, default False\n",
      "     |          Update the NDFrame in place if possible.\n",
      "     |      downcast : optional, 'infer' or None, defaults to None\n",
      "     |          Downcast dtypes if possible.\n",
      "     |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame of same shape interpolated at the NaNs\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      reindex, replace, fillna\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Filling in NaNs\n",
      "     |      \n",
      "     |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      "     |      >>> s.interpolate()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    3\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  last(self, offset)\n",
      "     |      Convenience method for subsetting final periods of time series data\n",
      "     |      based on a date offset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      offset : string, DateOffset, dateutil.relativedelta\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      ts.last('5M') -> Last 5 months\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : type of caller\n",
      "     |  \n",
      "     |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is False and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is False, keep the original value. Where\n",
      "     |          True, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is True are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The mask method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``mask`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.where`\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      "     |      Percent change over given number of periods.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for forming percent change\n",
      "     |      fill_method : str, default 'pad'\n",
      "     |          How to handle NAs before computing percent changes\n",
      "     |      limit : int, default None\n",
      "     |          The number of consecutive NAs to fill before stopping\n",
      "     |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      "     |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chg : NDFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      By default, the percentage change is calculated along the stat\n",
      "     |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      "     |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          function to apply to the NDFrame.\n",
      "     |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      "     |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      "     |          ``data_keyword`` is a string indicating the keyword of\n",
      "     |          ``callable`` that expects the NDFrame.\n",
      "     |      args : iterable, optional\n",
      "     |          positional arguments passed into ``func``.\n",
      "     |      kwargs : mapping, optional\n",
      "     |          a dictionary of keyword arguments passed into ``func``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of ``func``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Use ``.pipe`` when chaining together functions that expect\n",
      "     |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      "     |      \n",
      "     |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(f, arg2=b, arg3=c)\n",
      "     |      ... )\n",
      "     |      \n",
      "     |      If you have a function that takes the data as (say) the second\n",
      "     |      argument, pass a tuple indicating which keyword expects the\n",
      "     |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      "     |      \n",
      "     |      >>> (df.pipe(h)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      "     |      ...  )\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.apply\n",
      "     |      pandas.DataFrame.applymap\n",
      "     |      pandas.Series.map\n",
      "     |  \n",
      "     |  pop(self, item)\n",
      "     |      Return item and drop from frame. Raise KeyError if not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      item : str\n",
      "     |          Column label to be popped\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      popped : Series\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      "     |      ...                    ('parrot', 'bird',     24.0),\n",
      "     |      ...                    ('lion',   'mammal',   80.5),\n",
      "     |      ...                    ('monkey', 'mammal', np.nan)],\n",
      "     |      ...                   columns=('name', 'class', 'max_speed'))\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  parrot    bird       24.0\n",
      "     |      2    lion  mammal       80.5\n",
      "     |      3  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      >>> df.pop('class')\n",
      "     |      0      bird\n",
      "     |      1      bird\n",
      "     |      2    mammal\n",
      "     |      3    mammal\n",
      "     |      Name: class, dtype: object\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |           name  max_speed\n",
      "     |      0  falcon      389.0\n",
      "     |      1  parrot       24.0\n",
      "     |      2    lion       80.5\n",
      "     |      3  monkey        NaN\n",
      "     |  \n",
      "     |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      "     |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      "     |      assigned a rank that is the average of the ranks of those values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          index to direct ranking\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      "     |          * average: average rank of group\n",
      "     |          * min: lowest rank in group\n",
      "     |          * max: highest rank in group\n",
      "     |          * first: ranks assigned in order they appear in the array\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups\n",
      "     |      numeric_only : boolean, default None\n",
      "     |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      "     |          Panel objects\n",
      "     |      na_option : {'keep', 'top', 'bottom'}\n",
      "     |          * keep: leave NA values where they are\n",
      "     |          * top: smallest rank if ascending\n",
      "     |          * bottom: smallest rank if descending\n",
      "     |      ascending : boolean, default True\n",
      "     |          False for ranks by high (1) to low (N)\n",
      "     |      pct : boolean, default False\n",
      "     |          Computes percentage rank of data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ranks : same type as caller\n",
      "     |  \n",
      "     |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      "     |      Return an object with matching indices to myself.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Object\n",
      "     |      method : string or None\n",
      "     |      copy : boolean, default True\n",
      "     |      limit : int, default None\n",
      "     |          Maximum number of consecutive labels to fill for inexact matches.\n",
      "     |      tolerance : optional\n",
      "     |          Maximum distance between labels of the other object and this\n",
      "     |          object for inexact matches. Can be list-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17.0\n",
      "     |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      "     |                             method=...)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      reindexed : same as input\n",
      "     |  \n",
      "     |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      "     |      Alter the name of the index or columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mapper : scalar, list-like, optional\n",
      "     |          Value to set the axis name attribute.\n",
      "     |      axis : int or string, default 0\n",
      "     |      copy : boolean, default True\n",
      "     |          Also copy underlying data\n",
      "     |      inplace : boolean, default False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : type of caller or None if inplace=True\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      "     |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      "     |      deprecated and will be removed in a future version. Use ``rename``\n",
      "     |      instead.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.rename, pandas.DataFrame.rename\n",
      "     |      pandas.Index.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.rename_axis(\"foo\")\n",
      "     |           A  B\n",
      "     |      foo\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |      \n",
      "     |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      "     |      bar  A  B\n",
      "     |      0    1  4\n",
      "     |      1    2  5\n",
      "     |      2    3  6\n",
      "     |  \n",
      "     |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      "     |      Replace values given in 'to_replace' with 'value'.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      "     |      \n",
      "     |          * str or regex:\n",
      "     |      \n",
      "     |              - str: string exactly matching `to_replace` will be replaced\n",
      "     |                with `value`\n",
      "     |              - regex: regexs matching `to_replace` will be replaced with\n",
      "     |                `value`\n",
      "     |      \n",
      "     |          * list of str, regex, or numeric:\n",
      "     |      \n",
      "     |              - First, if `to_replace` and `value` are both lists, they\n",
      "     |                **must** be the same length.\n",
      "     |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      "     |                lists will be interpreted as regexs otherwise they will match\n",
      "     |                directly. This doesn't matter much for `value` since there\n",
      "     |                are only a few possible substitution regexes you can use.\n",
      "     |              - str and regex rules apply as above.\n",
      "     |      \n",
      "     |          * dict:\n",
      "     |      \n",
      "     |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      "     |                follows: look in column 'a' for the value 'b' and replace it\n",
      "     |                with nan. You can nest regular expressions as well. Note that\n",
      "     |                column names (the top-level dictionary keys in a nested\n",
      "     |                dictionary) **cannot** be regular expressions.\n",
      "     |              - Keys map to column names and values map to substitution\n",
      "     |                values. You can treat this as a special case of passing two\n",
      "     |                lists except that you are specifying the column to search in.\n",
      "     |      \n",
      "     |          * None:\n",
      "     |      \n",
      "     |              - This means that the ``regex`` argument must be a string,\n",
      "     |                compiled regular expression, or list, dict, ndarray or Series\n",
      "     |                of such elements. If `value` is also ``None`` then this\n",
      "     |                **must** be a nested dictionary or ``Series``.\n",
      "     |      \n",
      "     |          See the examples section for examples of each of these.\n",
      "     |      value : scalar, dict, list, str, regex, default None\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      "     |          specifying which value to use for each column (columns not in the\n",
      "     |          dict will not be filled). Regular expressions, strings and lists or\n",
      "     |          dicts of such objects are also allowed.\n",
      "     |      inplace : boolean, default False\n",
      "     |          If True, in place. Note: this will modify any\n",
      "     |          other views on this object (e.g. a column from a DataFrame).\n",
      "     |          Returns the caller if this is True.\n",
      "     |      limit : int, default None\n",
      "     |          Maximum size gap to forward or backward fill\n",
      "     |      regex : bool or same types as `to_replace`, default False\n",
      "     |          Whether to interpret `to_replace` and/or `value` as regular\n",
      "     |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      "     |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      "     |          parameter will be interpreted as a regular expression or a list,\n",
      "     |          dict, or array of regular expressions.\n",
      "     |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      "     |          The method to use when for replacement, when ``to_replace`` is a\n",
      "     |          ``list``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      NDFrame.reindex\n",
      "     |      NDFrame.asfreq\n",
      "     |      NDFrame.fillna\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filled : NDFrame\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      AssertionError\n",
      "     |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      "     |      TypeError\n",
      "     |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      "     |            ``dict``, ``ndarray``, or ``Series``\n",
      "     |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      "     |            regular expression or is a list, dict, ndarray, or Series.\n",
      "     |      ValueError\n",
      "     |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      "     |            they are not the same length.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      "     |        rules for substitution for ``re.sub`` are the same.\n",
      "     |      * Regular expressions will only substitute on strings, meaning you\n",
      "     |        cannot provide, for example, a regular expression matching floating\n",
      "     |        point numbers and expect the columns in your frame that have a\n",
      "     |        numeric dtype to be matched. However, if those floating point numbers\n",
      "     |        *are* strings, then you can do this.\n",
      "     |      * This method has *a lot* of options. You are encouraged to experiment\n",
      "     |        and play with this method to gain intuition about how it works.\n",
      "     |  \n",
      "     |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      "     |      Convenience method for frequency conversion and resampling of time\n",
      "     |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      "     |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      "     |      to the on or level keyword.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : string\n",
      "     |          the offset string or object representing target conversion\n",
      "     |      axis : int, optional, default 0\n",
      "     |      closed : {'right', 'left'}\n",
      "     |          Which side of bin interval is closed. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      label : {'right', 'left'}\n",
      "     |          Which bin edge label to label bucket with. The default is 'left'\n",
      "     |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "     |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "     |      convention : {'start', 'end', 's', 'e'}\n",
      "     |          For PeriodIndex only, controls whether to use the start or end of\n",
      "     |          `rule`\n",
      "     |      loffset : timedelta\n",
      "     |          Adjust the resampled time labels\n",
      "     |      base : int, default 0\n",
      "     |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      "     |          aggregated intervals. For example, for '5min' frequency, base could\n",
      "     |          range from 0 through 4. Defaults to 0\n",
      "     |      on : string, optional\n",
      "     |          For a DataFrame, column to use instead of index for resampling.\n",
      "     |          Column must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      level : string or int, optional\n",
      "     |          For a MultiIndex, level (name or number) to use for\n",
      "     |          resampling.  Level must be datetime-like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To learn more about the offset strings, please see `this link\n",
      "     |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Start by creating a series with 9 one minute timestamps.\n",
      "     |      \n",
      "     |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> series = pd.Series(range(9), index=index)\n",
      "     |      >>> series\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      2000-01-01 00:03:00    3\n",
      "     |      2000-01-01 00:04:00    4\n",
      "     |      2000-01-01 00:05:00    5\n",
      "     |      2000-01-01 00:06:00    6\n",
      "     |      2000-01-01 00:07:00    7\n",
      "     |      2000-01-01 00:08:00    8\n",
      "     |      Freq: T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and sum the values\n",
      "     |      of the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> series.resample('3T').sum()\n",
      "     |      2000-01-01 00:00:00     3\n",
      "     |      2000-01-01 00:03:00    12\n",
      "     |      2000-01-01 00:06:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but label each\n",
      "     |      bin using the right edge instead of the left. Please note that the\n",
      "     |      value in the bucket used as the label is not included in the bucket,\n",
      "     |      which it labels. For example, in the original series the\n",
      "     |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      "     |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      "     |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      "     |      To include this value close the right side of the bin interval as\n",
      "     |      illustrated in the example below this one.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right').sum()\n",
      "     |      2000-01-01 00:03:00     3\n",
      "     |      2000-01-01 00:06:00    12\n",
      "     |      2000-01-01 00:09:00    21\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      "     |      2000-01-01 00:00:00     0\n",
      "     |      2000-01-01 00:03:00     6\n",
      "     |      2000-01-01 00:06:00    15\n",
      "     |      2000-01-01 00:09:00    15\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      "     |      2000-01-01 00:00:00   0.0\n",
      "     |      2000-01-01 00:00:30   NaN\n",
      "     |      2000-01-01 00:01:00   1.0\n",
      "     |      2000-01-01 00:01:30   NaN\n",
      "     |      2000-01-01 00:02:00   2.0\n",
      "     |      Freq: 30S, dtype: float64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      "     |      values using the ``pad`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').pad()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    0\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    1\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins and fill the\n",
      "     |      ``NaN`` values using the ``bfill`` method.\n",
      "     |      \n",
      "     |      >>> series.resample('30S').bfill()[0:5]\n",
      "     |      2000-01-01 00:00:00    0\n",
      "     |      2000-01-01 00:00:30    1\n",
      "     |      2000-01-01 00:01:00    1\n",
      "     |      2000-01-01 00:01:30    2\n",
      "     |      2000-01-01 00:02:00    2\n",
      "     |      Freq: 30S, dtype: int64\n",
      "     |      \n",
      "     |      Pass a custom function via ``apply``\n",
      "     |      \n",
      "     |      >>> def custom_resampler(array_like):\n",
      "     |      ...     return np.sum(array_like)+5\n",
      "     |      \n",
      "     |      >>> series.resample('3T').apply(custom_resampler)\n",
      "     |      2000-01-01 00:00:00     8\n",
      "     |      2000-01-01 00:03:00    17\n",
      "     |      2000-01-01 00:06:00    26\n",
      "     |      Freq: 3T, dtype: int64\n",
      "     |      \n",
      "     |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      "     |      used to control whether to use the start or end of `rule`.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      "     |                                                      freq='A',\n",
      "     |                                                      periods=2))\n",
      "     |      >>> s\n",
      "     |      2012    1\n",
      "     |      2013    2\n",
      "     |      Freq: A-DEC, dtype: int64\n",
      "     |      \n",
      "     |      Resample by month using 'start' `convention`. Values are assigned to\n",
      "     |      the first month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='start').asfreq().head()\n",
      "     |      2012-01    1.0\n",
      "     |      2012-02    NaN\n",
      "     |      2012-03    NaN\n",
      "     |      2012-04    NaN\n",
      "     |      2012-05    NaN\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      Resample by month using 'end' `convention`. Values are assigned to\n",
      "     |      the last month of the period.\n",
      "     |      \n",
      "     |      >>> s.resample('M', convention='end').asfreq()\n",
      "     |      2012-12    1.0\n",
      "     |      2013-01    NaN\n",
      "     |      2013-02    NaN\n",
      "     |      2013-03    NaN\n",
      "     |      2013-04    NaN\n",
      "     |      2013-05    NaN\n",
      "     |      2013-06    NaN\n",
      "     |      2013-07    NaN\n",
      "     |      2013-08    NaN\n",
      "     |      2013-09    NaN\n",
      "     |      2013-10    NaN\n",
      "     |      2013-11    NaN\n",
      "     |      2013-12    2.0\n",
      "     |      Freq: M, dtype: float64\n",
      "     |      \n",
      "     |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      "     |      column instead of the index for resampling.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      "     |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "     |      >>> df.resample('3T', on='time').sum()\n",
      "     |                           a  b  c  d\n",
      "     |      time\n",
      "     |      2000-01-01 00:00:00  0  3  6  9\n",
      "     |      2000-01-01 00:03:00  0  3  6  9\n",
      "     |      2000-01-01 00:06:00  0  3  6  9\n",
      "     |      \n",
      "     |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      "     |      specify on level the resampling needs to take place.\n",
      "     |      \n",
      "     |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      "     |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      "     |                             columns=['a', 'b', 'c', 'd'],\n",
      "     |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      "     |                             )\n",
      "     |      >>> df2.resample('3T', level=0).sum()\n",
      "     |                           a  b   c   d\n",
      "     |      2000-01-01 00:00:00  0  6  12  18\n",
      "     |      2000-01-01 00:03:00  0  4   8  12\n",
      "     |  \n",
      "     |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      "     |      Returns a random sample of items from an axis of object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, optional\n",
      "     |          Number of items from axis to return. Cannot be used with `frac`.\n",
      "     |          Default = 1 if `frac` = None.\n",
      "     |      frac : float, optional\n",
      "     |          Fraction of axis items to return. Cannot be used with `n`.\n",
      "     |      replace : boolean, optional\n",
      "     |          Sample with or without replacement. Default = False.\n",
      "     |      weights : str or ndarray-like, optional\n",
      "     |          Default 'None' results in equal probability weighting.\n",
      "     |          If passed a Series, will align with target object on index. Index\n",
      "     |          values in weights not found in sampled object will be ignored and\n",
      "     |          index values in sampled object not in weights will be assigned\n",
      "     |          weights of zero.\n",
      "     |          If called on a DataFrame, will accept the name of a column\n",
      "     |          when axis = 0.\n",
      "     |          Unless weights are a Series, weights must be same length as axis\n",
      "     |          being sampled.\n",
      "     |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      "     |          Missing values in the weights column will be treated as zero.\n",
      "     |          inf and -inf values not allowed.\n",
      "     |      random_state : int or numpy.random.RandomState, optional\n",
      "     |          Seed for the random number generator (if int), or numpy RandomState\n",
      "     |          object.\n",
      "     |      axis : int or string, optional\n",
      "     |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      "     |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A new object of same type as caller.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Generate an example ``Series`` and ``DataFrame``:\n",
      "     |      \n",
      "     |      >>> s = pd.Series(np.random.randn(50))\n",
      "     |      >>> s.head()\n",
      "     |      0   -0.038497\n",
      "     |      1    1.820773\n",
      "     |      2   -0.972766\n",
      "     |      3   -1.598270\n",
      "     |      4   -1.095526\n",
      "     |      dtype: float64\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      "     |      >>> df.head()\n",
      "     |                A         B         C         D\n",
      "     |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      "     |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      "     |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      "     |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      "     |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      "     |      \n",
      "     |      Next extract a random sample from both of these objects...\n",
      "     |      \n",
      "     |      3 random elements from the ``Series``:\n",
      "     |      \n",
      "     |      >>> s.sample(n=3)\n",
      "     |      27   -0.994689\n",
      "     |      55   -1.049016\n",
      "     |      67   -0.224565\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      And a random 10% of the ``DataFrame`` with replacement:\n",
      "     |      \n",
      "     |      >>> df.sample(frac=0.1, replace=True)\n",
      "     |                 A         B         C         D\n",
      "     |      35  1.981780  0.142106  1.817165 -0.290805\n",
      "     |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      "     |      40  0.823173 -0.078816  1.009536  1.015108\n",
      "     |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      "     |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      "     |  \n",
      "     |  select(self, crit, axis=0)\n",
      "     |      Return data corresponding to axis labels matching criteria\n",
      "     |      \n",
      "     |      DEPRECATED: use df.loc[df.index.map(crit)] to select via labels\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      crit : function\n",
      "     |          To be called on each index (label). Should return True or False\n",
      "     |      axis : int\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      selection : type of caller\n",
      "     |  \n",
      "     |  set_axis(self, labels, axis=0, inplace=None)\n",
      "     |      Assign desired index to given axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      labels: list-like or Index\n",
      "     |          The values for the new index\n",
      "     |      axis : int or string, default 0\n",
      "     |      inplace : boolean, default None\n",
      "     |          Whether to return a new NDFrame instance.\n",
      "     |      \n",
      "     |          WARNING: inplace=None currently falls back to to True, but\n",
      "     |          in a future version, will default to False.  Use inplace=True\n",
      "     |          explicitly rather than relying on the default.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |          The signature is make consistent to the rest of the API.\n",
      "     |          Previously, the \"axis\" and \"labels\" arguments were respectively\n",
      "     |          the first and second positional arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      renamed : NDFrame or None\n",
      "     |          An object of same type as caller if inplace=False, None otherwise.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.NDFrame.rename\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |      a    1\n",
      "     |      b    2\n",
      "     |      c    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "     |      >>> df.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      "     |         A  B\n",
      "     |      a  1  4\n",
      "     |      b  2  5\n",
      "     |      c  3  6\n",
      "     |      >>> df.set_axis(['I', 'II'], axis=1, inplace=False)\n",
      "     |         I  II\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |      >>> df.set_axis(['i', 'ii'], axis=1, inplace=True)\n",
      "     |      >>> df\n",
      "     |         i  ii\n",
      "     |      0  1   4\n",
      "     |      1  2   5\n",
      "     |      2  3   6\n",
      "     |  \n",
      "     |  slice_shift(self, periods=1, axis=0)\n",
      "     |      Equivalent to `shift` without copying data. The shifted data will\n",
      "     |      not include the dropped periods and the shifted axis will be smaller\n",
      "     |      than the original.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      "     |      later during alignment.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : same type as caller\n",
      "     |  \n",
      "     |  squeeze(self, axis=None)\n",
      "     |      Squeeze length 1 dimensions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : None, integer or string axis name, optional\n",
      "     |          The axis to squeeze if 1-sized.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar if 1-sized, else original object\n",
      "     |  \n",
      "     |  swapaxes(self, axis1, axis2, copy=True)\n",
      "     |      Interchange axes and swap values axes appropriately\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : same as input\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return the last n rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Number of rows to select.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      obj_tail : type of caller\n",
      "     |          The last n rows of the caller object.\n",
      "     |  \n",
      "     |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      "     |      Attempt to write text representation of object to the system clipboard\n",
      "     |      This can be pasted into Excel, for example.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      excel : boolean, defaults to True\n",
      "     |              if True, use the provided separator, writing in a csv\n",
      "     |              format for allowing easy pasting into excel.\n",
      "     |              if False, write a string representation of the object\n",
      "     |              to the clipboard\n",
      "     |      sep : optional, defaults to tab\n",
      "     |      other keywords are passed to to_csv\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Requirements for your platform\n",
      "     |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      "     |        - Windows: none\n",
      "     |        - OS X: none\n",
      "     |  \n",
      "     |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      "     |      Write the contained data to an HDF5 file using HDFStore.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path (string) or HDFStore object\n",
      "     |      key : string\n",
      "     |          identifier for the group in the store\n",
      "     |      mode : optional, {'a', 'w', 'r+'}, default 'a'\n",
      "     |      \n",
      "     |        ``'w'``\n",
      "     |            Write; a new file is created (an existing file with the same\n",
      "     |            name would be deleted).\n",
      "     |        ``'a'``\n",
      "     |            Append; an existing file is opened for reading and writing,\n",
      "     |            and if the file does not exist it is created.\n",
      "     |        ``'r+'``\n",
      "     |            It is similar to ``'a'``, but the file must already exist.\n",
      "     |      format : 'fixed(f)|table(t)', default is 'fixed'\n",
      "     |          fixed(f) : Fixed format\n",
      "     |                     Fast writing/reading. Not-appendable, nor searchable\n",
      "     |          table(t) : Table format\n",
      "     |                     Write as a PyTables Table structure which may perform\n",
      "     |                     worse but allow more flexible operations like searching\n",
      "     |                     / selecting subsets of the data\n",
      "     |      append : boolean, default False\n",
      "     |          For Table formats, append the input data to the existing\n",
      "     |      data_columns :  list of columns, or True, default None\n",
      "     |          List of columns to create as indexed data columns for on-disk\n",
      "     |          queries, or True to use all columns. By default only the axes\n",
      "     |          of the object are indexed. See `here\n",
      "     |          <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
      "     |      \n",
      "     |          Applicable only to format='table'.\n",
      "     |      complevel : int, 0-9, default None\n",
      "     |          Specifies a compression level for data.\n",
      "     |          A value of 0 disables compression.\n",
      "     |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      "     |          Specifies the compression library to be used.\n",
      "     |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      "     |          (default if no compressor specified: 'blosc:blosclz'):\n",
      "     |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      "     |          'blosc:zlib', 'blosc:zstd'}.\n",
      "     |          Specifying a compression library which is not available issues\n",
      "     |          a ValueError.\n",
      "     |      fletcher32 : bool, default False\n",
      "     |          If applying compression use the fletcher32 checksum\n",
      "     |      dropna : boolean, default False.\n",
      "     |          If true, ALL nan rows will not be written to store.\n",
      "     |  \n",
      "     |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None)\n",
      "     |      Convert the object to a JSON string.\n",
      "     |      \n",
      "     |      Note NaN's and None will be converted to null and datetime objects\n",
      "     |      will be converted to UNIX timestamps.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path_or_buf : the path or buffer to write the result string\n",
      "     |          if this is None, return the converted string\n",
      "     |      orient : string\n",
      "     |      \n",
      "     |          * Series\n",
      "     |      \n",
      "     |            - default is 'index'\n",
      "     |            - allowed values are: {'split','records','index'}\n",
      "     |      \n",
      "     |          * DataFrame\n",
      "     |      \n",
      "     |            - default is 'columns'\n",
      "     |            - allowed values are:\n",
      "     |              {'split','records','index','columns','values'}\n",
      "     |      \n",
      "     |          * The format of the JSON string\n",
      "     |      \n",
      "     |            - split : dict like\n",
      "     |              {index -> [index], columns -> [columns], data -> [values]}\n",
      "     |            - records : list like\n",
      "     |              [{column -> value}, ... , {column -> value}]\n",
      "     |            - index : dict like {index -> {column -> value}}\n",
      "     |            - columns : dict like {column -> {index -> value}}\n",
      "     |            - values : just the values array\n",
      "     |            - table : dict like {'schema': {schema}, 'data': {data}}\n",
      "     |              describing the data, and the data component is\n",
      "     |              like ``orient='records'``.\n",
      "     |      \n",
      "     |              .. versionchanged:: 0.20.0\n",
      "     |      \n",
      "     |      date_format : {None, 'epoch', 'iso'}\n",
      "     |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      "     |          `iso` = ISO8601. The default depends on the `orient`. For\n",
      "     |          `orient='table'`, the default is `'iso'`. For all other orients,\n",
      "     |          the default is `'epoch'`.\n",
      "     |      double_precision : The number of decimal places to use when encoding\n",
      "     |          floating point values, default 10.\n",
      "     |      force_ascii : force encoded string to be ASCII, default True.\n",
      "     |      date_unit : string, default 'ms' (milliseconds)\n",
      "     |          The time unit to encode to, governs timestamp and ISO8601\n",
      "     |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "     |          microsecond, and nanosecond respectively.\n",
      "     |      default_handler : callable, default None\n",
      "     |          Handler to call if object cannot otherwise be converted to a\n",
      "     |          suitable format for JSON. Should receive a single argument which is\n",
      "     |          the object to convert and return a serialisable object.\n",
      "     |      lines : boolean, default False\n",
      "     |          If 'orient' is 'records' write out line delimited json format. Will\n",
      "     |          throw ValueError if incorrect 'orient' since others are not list\n",
      "     |          like.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.19.0\n",
      "     |      \n",
      "     |      compression : {None, 'gzip', 'bz2', 'xz'}\n",
      "     |          A string representing the compression to use in the output file,\n",
      "     |          only used when the first argument is a filename\n",
      "     |      \n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      same type as input object with filtered info axis\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pd.read_json\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "     |      ...                   index=['row 1', 'row 2'],\n",
      "     |      ...                   columns=['col 1', 'col 2'])\n",
      "     |      >>> df.to_json(orient='split')\n",
      "     |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      "     |        \"index\":[\"row 1\",\"row 2\"],\n",
      "     |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='index')\n",
      "     |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      "     |      \n",
      "     |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "     |      Note that index labels are not preserved with this encoding.\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='records')\n",
      "     |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      "     |      \n",
      "     |      Encoding with Table Schema\n",
      "     |      \n",
      "     |      >>> df.to_json(orient='table')\n",
      "     |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      "     |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      "     |                   \"primaryKey\": \"index\",\n",
      "     |                   \"pandas_version\": \"0.20.0\"},\n",
      "     |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      "     |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      "     |  \n",
      "     |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      "     |      Render an object to a tabular environment table. You can splice\n",
      "     |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      "     |      \n",
      "     |      .. versionchanged:: 0.20.2\n",
      "     |         Added to Series\n",
      "     |      \n",
      "     |      `to_latex`-specific options:\n",
      "     |      \n",
      "     |      bold_rows : boolean, default False\n",
      "     |          Make the row labels bold in the output\n",
      "     |      column_format : str, default None\n",
      "     |          The columns format as specified in `LaTeX table format\n",
      "     |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      "     |          columns\n",
      "     |      longtable : boolean, default will be read from the pandas config module\n",
      "     |          Default: False.\n",
      "     |          Use a longtable environment instead of tabular. Requires adding\n",
      "     |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      "     |      escape : boolean, default will be read from the pandas config module\n",
      "     |          Default: True.\n",
      "     |          When set to False prevents from escaping latex special\n",
      "     |          characters in column names.\n",
      "     |      encoding : str, default None\n",
      "     |          A string representing the encoding to use in the output file,\n",
      "     |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "     |      decimal : string, default '.'\n",
      "     |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.0\n",
      "     |      \n",
      "     |      multicolumn : boolean, default True\n",
      "     |          Use \\multicolumn to enhance MultiIndex columns.\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multicolumn_format : str, default 'l'\n",
      "     |          The alignment for multicolumns, similar to `column_format`\n",
      "     |          The default will be read from the config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      \n",
      "     |      multirow : boolean, default False\n",
      "     |          Use \\multirow to enhance MultiIndex rows.\n",
      "     |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      "     |          Will print centered labels (instead of top-aligned)\n",
      "     |          across the contained rows, separating groups via clines.\n",
      "     |          The default will be read from the pandas config module.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |  \n",
      "     |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      "     |      msgpack (serialize) object to input file path\n",
      "     |      \n",
      "     |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      "     |      may not be stable until a future release.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string File path, buffer-like, or None\n",
      "     |          if None, return generated string\n",
      "     |      append : boolean whether to append to an existing msgpack\n",
      "     |          (default is False)\n",
      "     |      compress : type of compressor (zlib or blosc), default to None (no\n",
      "     |          compression)\n",
      "     |  \n",
      "     |  to_pickle(self, path, compression='infer', protocol=4)\n",
      "     |      Pickle (serialize) object to input file path.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : string\n",
      "     |          File path\n",
      "     |      compression : {'infer', 'gzip', 'bz2', 'xz', None}, default 'infer'\n",
      "     |          a string representing the compression to use in the output file\n",
      "     |      \n",
      "     |          .. versionadded:: 0.20.0\n",
      "     |      protocol : int\n",
      "     |          Int which indicates which protocol should be used by the pickler,\n",
      "     |          default HIGHEST_PROTOCOL (see [1], paragraph 12.1.2). The possible\n",
      "     |          values for this parameter depend on the version of Python. For\n",
      "     |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      "     |          valid value. For Python >= 3.4, 4 is a valid value.A negative value\n",
      "     |          for the protocol parameter is equivalent to setting its value to\n",
      "     |          HIGHEST_PROTOCOL.\n",
      "     |      \n",
      "     |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      "     |          .. versionadded:: 0.21.0\n",
      "     |  \n",
      "     |  to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : string\n",
      "     |          Name of SQL table\n",
      "     |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      "     |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "     |          library. If a DBAPI2 object, only sqlite3 is supported.\n",
      "     |      flavor : 'sqlite', default None\n",
      "     |          .. deprecated:: 0.19.0\n",
      "     |             'sqlite' is the only supported option if SQLAlchemy is not\n",
      "     |             used.\n",
      "     |      schema : string, default None\n",
      "     |          Specify the schema (if database flavor supports this). If None, use\n",
      "     |          default schema.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          - fail: If table exists, do nothing.\n",
      "     |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          - append: If table exists, insert data. Create if does not exist.\n",
      "     |      index : boolean, default True\n",
      "     |          Write DataFrame index as a column.\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s). If None is given (default) and\n",
      "     |          `index` is True, then the index names are used.\n",
      "     |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      chunksize : int, default None\n",
      "     |          If not None, then rows will be written in batches of this size at a\n",
      "     |          time.  If None, all rows will be written at once.\n",
      "     |      dtype : dict of column name to SQL type, default None\n",
      "     |          Optional specifying the datatype for columns. The SQL type should\n",
      "     |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      "     |  \n",
      "     |  to_xarray(self)\n",
      "     |      Return an xarray object from the pandas object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a DataArray for a Series\n",
      "     |      a Dataset for a DataFrame\n",
      "     |      a DataArray for higher dims\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)})\n",
      "     |      >>> df\n",
      "     |         A    B    C\n",
      "     |      0  1  foo  4.0\n",
      "     |      1  1  bar  5.0\n",
      "     |      2  2  foo  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (index: 3)\n",
      "     |      Coordinates:\n",
      "     |        * index    (index) int64 0 1 2\n",
      "     |      Data variables:\n",
      "     |          A        (index) int64 1 1 2\n",
      "     |          B        (index) object 'foo' 'bar' 'foo'\n",
      "     |          C        (index) float64 4.0 5.0 6.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      "     |                             'B' : ['foo', 'bar', 'foo'],\n",
      "     |                             'C' : np.arange(4.,7)}\n",
      "     |                           ).set_index(['B','A'])\n",
      "     |      >>> df\n",
      "     |               C\n",
      "     |      B   A\n",
      "     |      foo 1  4.0\n",
      "     |      bar 1  5.0\n",
      "     |      foo 2  6.0\n",
      "     |      \n",
      "     |      >>> df.to_xarray()\n",
      "     |      <xarray.Dataset>\n",
      "     |      Dimensions:  (A: 2, B: 2)\n",
      "     |      Coordinates:\n",
      "     |        * B        (B) object 'bar' 'foo'\n",
      "     |        * A        (A) int64 1 2\n",
      "     |      Data variables:\n",
      "     |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      "     |      \n",
      "     |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      "     |                       items=list('ABCD'),\n",
      "     |                       major_axis=pd.date_range('20130101', periods=3),\n",
      "     |                       minor_axis=['first', 'second'])\n",
      "     |      >>> p\n",
      "     |      <class 'pandas.core.panel.Panel'>\n",
      "     |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      "     |      Items axis: A to D\n",
      "     |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      "     |      Minor_axis axis: first to second\n",
      "     |      \n",
      "     |      >>> p.to_xarray()\n",
      "     |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      "     |      array([[[ 0,  1],\n",
      "     |              [ 2,  3],\n",
      "     |              [ 4,  5]],\n",
      "     |             [[ 6,  7],\n",
      "     |              [ 8,  9],\n",
      "     |              [10, 11]],\n",
      "     |             [[12, 13],\n",
      "     |              [14, 15],\n",
      "     |              [16, 17]],\n",
      "     |             [[18, 19],\n",
      "     |              [20, 21],\n",
      "     |              [22, 23]]])\n",
      "     |      Coordinates:\n",
      "     |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      "     |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      "     |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      "     |  \n",
      "     |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      "     |      Truncates a sorted DataFrame/Series before and/or after some\n",
      "     |      particular index value. If the axis contains only datetime values,\n",
      "     |      before/after parameters are converted to datetime values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      before : date, string, int\n",
      "     |          Truncate all rows before this index value\n",
      "     |      after : date, string, int\n",
      "     |          Truncate all rows after this index value\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |      \n",
      "     |          * 0 or 'index': apply truncation to rows\n",
      "     |          * 1 or 'columns': apply truncation to columns\n",
      "     |          Default is stat axis for given data type (0 for Series and\n",
      "     |          DataFrames, 1 for Panels)\n",
      "     |      copy : boolean, default is True,\n",
      "     |          return a copy of the truncated section\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      truncated : type of caller\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      "     |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      "     |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      "     |      ...                    index=[1, 2, 3, 4, 5])\n",
      "     |      >>> df.truncate(before=2, after=4)\n",
      "     |         A  B  C\n",
      "     |      2  b  g  l\n",
      "     |      3  c  h  m\n",
      "     |      4  d  i  n\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
      "     |      ...                    'B': [6, 7, 8, 9, 10],\n",
      "     |      ...                    'C': [11, 12, 13, 14, 15]},\n",
      "     |      ...                    index=['a', 'b', 'c', 'd', 'e'])\n",
      "     |      >>> df.truncate(before='b', after='d')\n",
      "     |         A  B   C\n",
      "     |      b  2  7  12\n",
      "     |      c  3  8  13\n",
      "     |      d  4  9  14\n",
      "     |      \n",
      "     |      The index values in ``truncate`` can be datetimes or string\n",
      "     |      dates. Note that ``truncate`` assumes a 0 value for any unspecified\n",
      "     |      date component in a ``DatetimeIndex`` in contrast to slicing which\n",
      "     |      returns any partially matching dates.\n",
      "     |      \n",
      "     |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      "     |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      "     |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      "     |                           A\n",
      "     |      2016-01-09 23:59:56  1\n",
      "     |      2016-01-09 23:59:57  1\n",
      "     |      2016-01-09 23:59:58  1\n",
      "     |      2016-01-09 23:59:59  1\n",
      "     |      2016-01-10 00:00:00  1\n",
      "     |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      "     |                           A\n",
      "     |      2016-01-10 23:59:55  1\n",
      "     |      2016-01-10 23:59:56  1\n",
      "     |      2016-01-10 23:59:57  1\n",
      "     |      2016-01-10 23:59:58  1\n",
      "     |      2016-01-10 23:59:59  1\n",
      "     |  \n",
      "     |  tshift(self, periods=1, freq=None, axis=0)\n",
      "     |      Shift the time index, using the index's frequency if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative\n",
      "     |      freq : DateOffset, timedelta, or time rule string, default None\n",
      "     |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      "     |      axis : int or basestring\n",
      "     |          Corresponds to the axis that contains the Index\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is not specified then tries to use the freq or inferred_freq\n",
      "     |      attributes of the index. If neither of those attributes exist, a\n",
      "     |      ValueError is thrown\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : NDFrame\n",
      "     |  \n",
      "     |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      "     |      Convert tz-aware axis to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to convert\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the axis is tz-naive.\n",
      "     |  \n",
      "     |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      "     |      Localize tz-naive TimeSeries to target time zone.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tz : string or pytz.timezone object\n",
      "     |      axis : the axis to localize\n",
      "     |      level : int, str, default None\n",
      "     |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      "     |          must be None\n",
      "     |      copy : boolean, default True\n",
      "     |          Also make a copy of the underlying data\n",
      "     |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      "     |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      "     |            order\n",
      "     |          - bool-ndarray where True signifies a DST time, False designates\n",
      "     |            a non-DST time (note that this flag is only applicable for\n",
      "     |            ambiguous times)\n",
      "     |          - 'NaT' will return NaT where there are ambiguous times\n",
      "     |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      "     |            times\n",
      "     |      infer_dst : boolean, default False\n",
      "     |          .. deprecated:: 0.15.0\n",
      "     |             Attempt to infer fall dst-transition hours based on order\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      TypeError\n",
      "     |          If the TimeSeries is tz-aware and tz is not None.\n",
      "     |  \n",
      "     |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      "     |      Return an object of same shape as self and whose corresponding\n",
      "     |      entries are from self where `cond` is True and otherwise are from\n",
      "     |      `other`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cond : boolean NDFrame, array-like, or callable\n",
      "     |          Where `cond` is True, keep the original value. Where\n",
      "     |          False, replace with corresponding value from `other`.\n",
      "     |          If `cond` is callable, it is computed on the NDFrame and\n",
      "     |          should return boolean NDFrame or array. The callable must\n",
      "     |          not change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as cond.\n",
      "     |      \n",
      "     |      other : scalar, NDFrame, or callable\n",
      "     |          Entries where `cond` is False are replaced with\n",
      "     |          corresponding value from `other`.\n",
      "     |          If other is callable, it is computed on the NDFrame and\n",
      "     |          should return scalar or NDFrame. The callable must not\n",
      "     |          change input NDFrame (though pandas doesn't check it).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.18.1\n",
      "     |              A callable can be used as other.\n",
      "     |      \n",
      "     |      inplace : boolean, default False\n",
      "     |          Whether to perform the operation in place on the data\n",
      "     |      axis : alignment axis if needed, default None\n",
      "     |      level : alignment level if needed, default None\n",
      "     |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      "     |          - ``raise`` : allow exceptions to be raised\n",
      "     |          - ``ignore`` : suppress exceptions. On error return original object\n",
      "     |      \n",
      "     |          Note that currently this parameter won't affect\n",
      "     |          the results and will always coerce to a suitable dtype.\n",
      "     |      \n",
      "     |      try_cast : boolean, default False\n",
      "     |          try to cast the result back to the input type (if possible),\n",
      "     |      raise_on_error : boolean, default True\n",
      "     |          Whether to raise on invalid data types (e.g. trying to where on\n",
      "     |          strings)\n",
      "     |      \n",
      "     |          .. deprecated:: 0.21.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      wh : same type as caller\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The where method is an application of the if-then idiom. For each\n",
      "     |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      "     |      element is used; otherwise the corresponding element from the DataFrame\n",
      "     |      ``other`` is used.\n",
      "     |      \n",
      "     |      The signature for :func:`DataFrame.where` differs from\n",
      "     |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      "     |      ``np.where(m, df1, df2)``.\n",
      "     |      \n",
      "     |      For further details and examples see the ``where`` documentation in\n",
      "     |      :ref:`indexing <indexing.where_mask>`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(range(5))\n",
      "     |      >>> s.where(s > 0)\n",
      "     |      0    NaN\n",
      "     |      1    1.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> s.mask(s > 0)\n",
      "     |      0    0.0\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    NaN\n",
      "     |      4    NaN\n",
      "     |      \n",
      "     |      >>> s.where(s > 1, 10)\n",
      "     |      0    10.0\n",
      "     |      1    10.0\n",
      "     |      2    2.0\n",
      "     |      3    3.0\n",
      "     |      4    4.0\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      "     |      >>> m = df % 3 == 0\n",
      "     |      >>> df.where(m, -df)\n",
      "     |         A  B\n",
      "     |      0  0 -1\n",
      "     |      1 -2  3\n",
      "     |      2 -4 -5\n",
      "     |      3  6 -7\n",
      "     |      4 -8  9\n",
      "     |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      "     |            A     B\n",
      "     |      0  True  True\n",
      "     |      1  True  True\n",
      "     |      2  True  True\n",
      "     |      3  True  True\n",
      "     |      4  True  True\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      :func:`DataFrame.mask`\n",
      "     |  \n",
      "     |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      "     |      Returns a cross-section (row(s) or column(s)) from the\n",
      "     |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : object\n",
      "     |          Some label contained in the index, or partially in a MultiIndex\n",
      "     |      axis : int, default 0\n",
      "     |          Axis to retrieve cross-section on\n",
      "     |      level : object, defaults to first n levels (n=1 or len(key))\n",
      "     |          In case of a key partially contained in a MultiIndex, indicate\n",
      "     |          which levels are used. Levels can be referred by label or position.\n",
      "     |      drop_level : boolean, default True\n",
      "     |          If False, returns object with same levels as self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df\n",
      "     |         A  B  C\n",
      "     |      a  4  5  2\n",
      "     |      b  4  0  9\n",
      "     |      c  9  7  3\n",
      "     |      >>> df.xs('a')\n",
      "     |      A    4\n",
      "     |      B    5\n",
      "     |      C    2\n",
      "     |      Name: a\n",
      "     |      >>> df.xs('C', axis=1)\n",
      "     |      a    2\n",
      "     |      b    9\n",
      "     |      c    3\n",
      "     |      Name: C\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |                          A  B  C  D\n",
      "     |      first second third\n",
      "     |      bar   one    1      4  1  8  9\n",
      "     |            two    1      7  5  5  0\n",
      "     |      baz   one    1      6  6  8  0\n",
      "     |            three  2      5  3  5  3\n",
      "     |      >>> df.xs(('baz', 'three'))\n",
      "     |             A  B  C  D\n",
      "     |      third\n",
      "     |      2      5  3  5  3\n",
      "     |      >>> df.xs('one', level=1)\n",
      "     |                   A  B  C  D\n",
      "     |      first third\n",
      "     |      bar   1      4  1  8  9\n",
      "     |      baz   1      6  6  8  0\n",
      "     |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      "     |              A  B  C  D\n",
      "     |      second\n",
      "     |      three   5  3  5  3\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      xs : Series or DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      xs is only for getting, not setting values.\n",
      "     |      \n",
      "     |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      "     |      levels.  It is a superset of xs functionality, see\n",
      "     |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  at\n",
      "     |      Fast label-based scalar accessor\n",
      "     |      \n",
      "     |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  blocks\n",
      "     |      Internal property, property synonym for as_blocks()\n",
      "     |      \n",
      "     |      .. deprecated:: 0.21.0\n",
      "     |  \n",
      "     |  iat\n",
      "     |      Fast integer location scalar accessor.\n",
      "     |      \n",
      "     |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      "     |      You can also set using these indexers.\n",
      "     |  \n",
      "     |  iloc\n",
      "     |      Purely integer-location based indexing for selection by position.\n",
      "     |      \n",
      "     |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      "     |      ``length-1`` of the axis), but may also be used with a boolean\n",
      "     |      array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - An integer, e.g. ``5``.\n",
      "     |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      "     |      - A slice object with ints, e.g. ``1:7``.\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      "     |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      "     |      indexing (this conforms with python/numpy *slice* semantics).\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      "     |  \n",
      "     |  ix\n",
      "     |      A primarily label-location based indexer, with integer position\n",
      "     |      fallback.\n",
      "     |      \n",
      "     |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      "     |      primarily label based, but will fall back to integer positional\n",
      "     |      access unless the corresponding axis is of integer type.\n",
      "     |      \n",
      "     |      ``.ix`` is the most general indexer and will support any of the\n",
      "     |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      "     |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      "     |      with mixed positional and label based hierachical indexes.\n",
      "     |      \n",
      "     |      However, when an axis is integer based, ONLY label based access\n",
      "     |      and not positional access is supported. Thus, in such cases, it's\n",
      "     |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      "     |      \n",
      "     |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      "     |  \n",
      "     |  loc\n",
      "     |      Purely label-location based indexer for selection by label.\n",
      "     |      \n",
      "     |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      "     |      boolean array.\n",
      "     |      \n",
      "     |      Allowed inputs are:\n",
      "     |      \n",
      "     |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      "     |        interpreted as a *label* of the index, and **never** as an\n",
      "     |        integer position along the index).\n",
      "     |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      "     |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      "     |        to usual python slices, **both** the start and the stop are included!).\n",
      "     |      - A boolean array.\n",
      "     |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      "     |        or Panel) and that returns valid output for indexing (one of the above)\n",
      "     |      \n",
      "     |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      "     |      \n",
      "     |      See more at :ref:`Selection by Label <indexing.label>`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      "     |  \n",
      "     |  is_copy = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for a object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.StringMixin:\n",
      "     |  \n",
      "     |  __bytes__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Invoked by bytes(obj) in py3 only.\n",
      "     |      Yields a bytestring in both py2/py3.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for a particular object.\n",
      "     |      \n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return a string representation for a particular Object\n",
      "     |      \n",
      "     |      Invoked by str(df) in both py2/py3.\n",
      "     |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion\n",
      "     |      Only provide 'public' methods\n",
      "    \n",
      "    class TestSubDict(builtins.dict)\n",
      "     |  dict() -> new empty dictionary\n",
      "     |  dict(mapping) -> new dictionary initialized from a mapping object's\n",
      "     |      (key, value) pairs\n",
      "     |  dict(iterable) -> new dictionary initialized as if via:\n",
      "     |      d = {}\n",
      "     |      for k, v in iterable:\n",
      "     |          d[k] = v\n",
      "     |  dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      "     |      in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TestSubDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if D has a key k, else False.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      x.__getitem__(y) <==> x[y]\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |  \n",
      "     |  fromkeys(iterable, value=None, /) from builtins.type\n",
      "     |      Returns a new dict with keys from iterable and values equal to value.\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      "     |  \n",
      "     |  popitem(...)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
      "     |      2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(...)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "\n",
      "FUNCTIONS\n",
      "    add_nans(panel)\n",
      "    \n",
      "    add_nans_panel4d(panel4d)\n",
      "    \n",
      "    all_index_generator(k=10)\n",
      "        Generator which can be iterated over to get instances of all the various\n",
      "        index classes.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        k: length of each of the index instances\n",
      "    \n",
      "    all_timeseries_index_generator(k=10)\n",
      "        Generator which can be iterated over to get instances of all the classes\n",
      "        which represent time-seires.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        k: length of each of the index instances\n",
      "    \n",
      "    assert_almost_equal(left, right, check_exact=False, check_dtype='equiv', check_less_precise=False, **kwargs)\n",
      "        Check that the left and right objects are approximately equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : object\n",
      "        right : object\n",
      "        check_exact : bool, default False\n",
      "            Whether to compare number exactly.\n",
      "        check_dtype: bool, default True\n",
      "            check dtype if both a and b are the same type\n",
      "        check_less_precise : bool or int, default False\n",
      "            Specify comparison precision. Only used when check_exact is False.\n",
      "            5 digits (False) or 3 digits (True) after decimal points are compared.\n",
      "            If int, then specify the digits to compare\n",
      "    \n",
      "    assert_attr_equal(attr, left, right, obj='Attributes')\n",
      "        checks attributes are equal. Both objects must have attribute.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        attr : str\n",
      "            Attribute name being compared.\n",
      "        left : object\n",
      "        right : object\n",
      "        obj : str, default 'Attributes'\n",
      "            Specify object name being compared, internally used to show appropriate\n",
      "            assertion message\n",
      "    \n",
      "    assert_categorical_equal(left, right, check_dtype=True, obj='Categorical', check_category_order=True)\n",
      "        Test that Categoricals are equivalent.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left, right : Categorical\n",
      "            Categoricals to compare\n",
      "        check_dtype : bool, default True\n",
      "            Check that integer dtype of the codes are the same\n",
      "        obj : str, default 'Categorical'\n",
      "            Specify object name being compared, internally used to show appropriate\n",
      "            assertion message\n",
      "        check_category_order : bool, default True\n",
      "            Whether the order of the categories should be compared, which\n",
      "            implies identical integer codes.  If False, only the resulting\n",
      "            values are compared.  The ordered attribute is\n",
      "            checked regardless.\n",
      "    \n",
      "    assert_class_equal(left, right, exact=True, obj='Input')\n",
      "        checks classes are equal.\n",
      "    \n",
      "    assert_contains_all(iterable, dic)\n",
      "    \n",
      "    assert_copy(iter1, iter2, **eql_kwargs)\n",
      "        iter1, iter2: iterables that produce elements\n",
      "        comparable with assert_almost_equal\n",
      "        \n",
      "        Checks that the elements are equal, but not\n",
      "        the same object. (Does not check that items\n",
      "        in sequences are also not the same object)\n",
      "    \n",
      "    assert_dict_equal(left, right, compare_keys=True)\n",
      "    \n",
      "    assert_frame_equal(left, right, check_dtype=True, check_index_type='equiv', check_column_type='equiv', check_frame_type=True, check_less_precise=False, check_names=True, by_blocks=False, check_exact=False, check_datetimelike_compat=False, check_categorical=True, check_like=False, obj='DataFrame')\n",
      "        Check that left and right DataFrame are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : DataFrame\n",
      "        right : DataFrame\n",
      "        check_dtype : bool, default True\n",
      "            Whether to check the DataFrame dtype is identical.\n",
      "        check_index_type : bool / string {'equiv'}, default False\n",
      "            Whether to check the Index class, dtype and inferred_type\n",
      "            are identical.\n",
      "        check_column_type : bool / string {'equiv'}, default False\n",
      "            Whether to check the columns class, dtype and inferred_type\n",
      "            are identical.\n",
      "        check_frame_type : bool, default False\n",
      "            Whether to check the DataFrame class is identical.\n",
      "        check_less_precise : bool or int, default False\n",
      "            Specify comparison precision. Only used when check_exact is False.\n",
      "            5 digits (False) or 3 digits (True) after decimal points are compared.\n",
      "            If int, then specify the digits to compare\n",
      "        check_names : bool, default True\n",
      "            Whether to check the Index names attribute.\n",
      "        by_blocks : bool, default False\n",
      "            Specify how to compare internal data. If False, compare by columns.\n",
      "            If True, compare by blocks.\n",
      "        check_exact : bool, default False\n",
      "            Whether to compare number exactly.\n",
      "        check_datetimelike_compat : bool, default False\n",
      "            Compare datetime-like which is comparable ignoring dtype.\n",
      "        check_categorical : bool, default True\n",
      "            Whether to compare internal Categorical exactly.\n",
      "        check_like : bool, default False\n",
      "            If true, ignore the order of rows & columns\n",
      "        obj : str, default 'DataFrame'\n",
      "            Specify object name being compared, internally used to show appropriate\n",
      "            assertion message\n",
      "    \n",
      "    assert_index_equal(left, right, exact='equiv', check_names=True, check_less_precise=False, check_exact=True, check_categorical=True, obj='Index')\n",
      "        Check that left and right Index are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : Index\n",
      "        right : Index\n",
      "        exact : bool / string {'equiv'}, default False\n",
      "            Whether to check the Index class, dtype and inferred_type\n",
      "            are identical. If 'equiv', then RangeIndex can be substituted for\n",
      "            Int64Index as well.\n",
      "        check_names : bool, default True\n",
      "            Whether to check the names attribute.\n",
      "        check_less_precise : bool or int, default False\n",
      "            Specify comparison precision. Only used when check_exact is False.\n",
      "            5 digits (False) or 3 digits (True) after decimal points are compared.\n",
      "            If int, then specify the digits to compare\n",
      "        check_exact : bool, default True\n",
      "            Whether to compare number exactly.\n",
      "        check_categorical : bool, default True\n",
      "            Whether to compare internal Categorical exactly.\n",
      "        obj : str, default 'Index'\n",
      "            Specify object name being compared, internally used to show appropriate\n",
      "            assertion message\n",
      "    \n",
      "    assert_is_valid_plot_return_object(objs)\n",
      "    \n",
      "    assert_numpy_array_equal(left, right, strict_nan=False, check_dtype=True, err_msg=None, obj='numpy array', check_same=None)\n",
      "        Checks that 'np.ndarray' is equivalent\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : np.ndarray or iterable\n",
      "        right : np.ndarray or iterable\n",
      "        strict_nan : bool, default False\n",
      "            If True, consider NaN and None to be different.\n",
      "        check_dtype: bool, default True\n",
      "            check dtype if both a and b are np.ndarray\n",
      "        err_msg : str, default None\n",
      "            If provided, used as assertion message\n",
      "        obj : str, default 'numpy array'\n",
      "            Specify object name being compared, internally used to show appropriate\n",
      "            assertion message\n",
      "        check_same : None|'copy'|'same', default None\n",
      "            Ensure left and right refer/do not refer to the same memory area\n",
      "    \n",
      "    assert_panelnd_equal(left, right, check_dtype=True, check_panel_type=False, check_less_precise=False, assert_func=<function assert_frame_equal at 0x0000021EEB551D08>, check_names=False, by_blocks=False, obj='Panel')\n",
      "        Check that left and right Panels are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : Panel (or nd)\n",
      "        right : Panel (or nd)\n",
      "        check_dtype : bool, default True\n",
      "            Whether to check the Panel dtype is identical.\n",
      "        check_panel_type : bool, default False\n",
      "            Whether to check the Panel class is identical.\n",
      "        check_less_precise : bool or int, default False\n",
      "            Specify comparison precision. Only used when check_exact is False.\n",
      "            5 digits (False) or 3 digits (True) after decimal points are compared.\n",
      "            If int, then specify the digits to compare\n",
      "        assert_func : function for comparing data\n",
      "        check_names : bool, default True\n",
      "            Whether to check the Index names attribute.\n",
      "        by_blocks : bool, default False\n",
      "            Specify how to compare internal data. If False, compare by columns.\n",
      "            If True, compare by blocks.\n",
      "        obj : str, default 'Panel'\n",
      "            Specify the object name being compared, internally used to show\n",
      "            the appropriate assertion message.\n",
      "    \n",
      "    assert_produces_warning(expected_warning=<class 'Warning'>, filter_level='always', clear=None, check_stacklevel=True)\n",
      "        Context manager for running code that expects to raise (or not raise)\n",
      "        warnings.  Checks that code raises the expected warning and only the\n",
      "        expected warning. Pass ``False`` or ``None`` to check that it does *not*\n",
      "        raise a warning. Defaults to ``exception.Warning``, baseclass of all\n",
      "        Warnings. (basically a wrapper around ``warnings.catch_warnings``).\n",
      "        \n",
      "        >>> import warnings\n",
      "        >>> with assert_produces_warning():\n",
      "        ...     warnings.warn(UserWarning())\n",
      "        ...\n",
      "        >>> with assert_produces_warning(False):\n",
      "        ...     warnings.warn(RuntimeWarning())\n",
      "        ...\n",
      "        Traceback (most recent call last):\n",
      "            ...\n",
      "        AssertionError: Caused unexpected warning(s): ['RuntimeWarning'].\n",
      "        >>> with assert_produces_warning(UserWarning):\n",
      "        ...     warnings.warn(RuntimeWarning())\n",
      "        Traceback (most recent call last):\n",
      "            ...\n",
      "        AssertionError: Did not see expected warning of class 'UserWarning'.\n",
      "        \n",
      "        ..warn:: This is *not* thread-safe.\n",
      "    \n",
      "    assert_raises_regex(_exception, _regexp, _callable=None, *args, **kwargs)\n",
      "            Check that the specified Exception is raised and that the error message\n",
      "            matches a given regular expression pattern. This may be a regular\n",
      "            expression object or a string containing a regular expression suitable\n",
      "            for use by `re.search()`. This is a port of the `assertRaisesRegexp`\n",
      "            function from unittest in Python 2.7.\n",
      "        \n",
      "            Examples\n",
      "            --------\n",
      "            >>> assert_raises_regex(ValueError, 'invalid literal for.*XYZ', int, 'XYZ')\n",
      "            >>> import re\n",
      "            >>> assert_raises_regex(ValueError, re.compile('literal'), int, 'XYZ')\n",
      "        \n",
      "            If an exception of a different type is raised, it bubbles up.\n",
      "        \n",
      "            >>> assert_raises_regex(TypeError, 'literal', int, 'XYZ')\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "            ValueError: invalid literal for int() with base 10: 'XYZ'\n",
      "            >>> dct = dict()\n",
      "            >>> assert_raises_regex(KeyError, 'pear', dct.__getitem__, 'apple')\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "            AssertionError: \"pear\" does not match \"'apple'\"\n",
      "        \n",
      "            You can also use this in a with statement.\n",
      "            >>> with assert_raises_regex(TypeError, 'unsupported operand type\\(s\\)'):\n",
      "            ...     1 + {}\n",
      "            >>> with assert_raises_regex(TypeError, 'banana'):\n",
      "            ...     'apple'[0] = 'b'\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "            AssertionError: \"banana\" does not match \"'str' object does not support \\\n",
      "        item assignment\"\n",
      "    \n",
      "    assert_series_equal(left, right, check_dtype=True, check_index_type='equiv', check_series_type=True, check_less_precise=False, check_names=True, check_exact=False, check_datetimelike_compat=False, check_categorical=True, obj='Series')\n",
      "        Check that left and right Series are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : Series\n",
      "        right : Series\n",
      "        check_dtype : bool, default True\n",
      "            Whether to check the Series dtype is identical.\n",
      "        check_index_type : bool / string {'equiv'}, default 'equiv'\n",
      "            Whether to check the Index class, dtype and inferred_type\n",
      "            are identical.\n",
      "        check_series_type : bool, default True\n",
      "            Whether to check the Series class is identical.\n",
      "        check_less_precise : bool or int, default False\n",
      "            Specify comparison precision. Only used when check_exact is False.\n",
      "            5 digits (False) or 3 digits (True) after decimal points are compared.\n",
      "            If int, then specify the digits to compare\n",
      "        check_exact : bool, default False\n",
      "            Whether to compare number exactly.\n",
      "        check_names : bool, default True\n",
      "            Whether to check the Series and Index names attribute.\n",
      "        check_datetimelike_compat : bool, default False\n",
      "            Compare datetime-like which is comparable ignoring dtype.\n",
      "        check_categorical : bool, default True\n",
      "            Whether to compare internal Categorical exactly.\n",
      "        obj : str, default 'Series'\n",
      "            Specify object name being compared, internally used to show appropriate\n",
      "            assertion message\n",
      "    \n",
      "    assert_sp_array_equal(left, right, check_dtype=True)\n",
      "        Check that the left and right SparseArray are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : SparseArray\n",
      "        right : SparseArray\n",
      "        check_dtype : bool, default True\n",
      "            Whether to check the data dtype is identical.\n",
      "    \n",
      "    assert_sp_frame_equal(left, right, check_dtype=True, exact_indices=True, check_frame_type=True, obj='SparseDataFrame')\n",
      "        Check that the left and right SparseDataFrame are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : SparseDataFrame\n",
      "        right : SparseDataFrame\n",
      "        check_dtype : bool, default True\n",
      "            Whether to check the Series dtype is identical.\n",
      "        exact_indices : bool, default True\n",
      "            SparseSeries SparseIndex objects must be exactly the same,\n",
      "            otherwise just compare dense representations.\n",
      "        check_frame_type : bool, default True\n",
      "            Whether to check the SparseDataFrame class is identical.\n",
      "        obj : str, default 'SparseDataFrame'\n",
      "            Specify the object name being compared, internally used to show\n",
      "            the appropriate assertion message.\n",
      "    \n",
      "    assert_sp_list_equal(left, right)\n",
      "    \n",
      "    assert_sp_series_equal(left, right, check_dtype=True, exact_indices=True, check_series_type=True, check_names=True, obj='SparseSeries')\n",
      "        Check that the left and right SparseSeries are equal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : SparseSeries\n",
      "        right : SparseSeries\n",
      "        check_dtype : bool, default True\n",
      "            Whether to check the Series dtype is identical.\n",
      "        exact_indices : bool, default True\n",
      "        check_series_type : bool, default True\n",
      "            Whether to check the SparseSeries class is identical.\n",
      "        check_names : bool, default True\n",
      "            Whether to check the SparseSeries name attribute.\n",
      "        obj : str, default 'SparseSeries'\n",
      "            Specify the object name being compared, internally used to show\n",
      "            the appropriate assertion message.\n",
      "    \n",
      "    callable(obj, /)\n",
      "        Return whether the object is callable (i.e., some kind of function).\n",
      "        \n",
      "        Note that classes are callable, as are instances of classes with a\n",
      "        __call__() method.\n",
      "    \n",
      "    can_connect(url, error_classes=(<class 'OSError'>, <class 'http.client.HTTPException'>, <class 'TimeoutError'>))\n",
      "        Try to connect to the given url. True if succeeds, False if IOError\n",
      "        raised\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url : basestring\n",
      "            The URL to try to connect to\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        connectable : bool\n",
      "            Return True if no IOError (unable to connect) or URLError (bad url) was\n",
      "            raised\n",
      "    \n",
      "    capture_stderr(f)\n",
      "            Decorator to capture stderr in a buffer so that it can be checked\n",
      "            (or suppressed) during testing.\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "            f : callable\n",
      "                The test that is capturing stderr.\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "            f : callable\n",
      "                The decorated test ``f``, which captures stderr.\n",
      "        \n",
      "            Examples\n",
      "            --------\n",
      "        \n",
      "            >>> from pandas.util.testing import capture_stderr\n",
      "            >>>\n",
      "            >>> import sys\n",
      "            >>>\n",
      "            >>> @capture_stderr\n",
      "            ... def test_stderr_pass():\n",
      "            ...     sys.stderr.write(\"foo\")\n",
      "            ...     out = sys.stderr.getvalue()\n",
      "            ...     assert out == \"foo\n",
      "        \"\n",
      "            >>>\n",
      "            >>> @capture_stderr\n",
      "            ... def test_stderr_fail():\n",
      "            ...     sys.stderr.write(\"foo\")\n",
      "            ...     out = sys.stderr.getvalue()\n",
      "            ...     assert out == \"bar\n",
      "        \"\n",
      "            ...\n",
      "            AssertionError: assert 'foo\n",
      "        ' == 'bar\n",
      "        '\n",
      "    \n",
      "    capture_stdout(f)\n",
      "            Decorator to capture stdout in a buffer so that it can be checked\n",
      "            (or suppressed) during testing.\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "            f : callable\n",
      "                The test that is capturing stdout.\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "            f : callable\n",
      "                The decorated test ``f``, which captures stdout.\n",
      "        \n",
      "            Examples\n",
      "            --------\n",
      "        \n",
      "            >>> from pandas.util.testing import capture_stdout\n",
      "            >>>\n",
      "            >>> import sys\n",
      "            >>>\n",
      "            >>> @capture_stdout\n",
      "            ... def test_print_pass():\n",
      "            ...     print(\"foo\")\n",
      "            ...     out = sys.stdout.getvalue()\n",
      "            ...     assert out == \"foo\n",
      "        \"\n",
      "            >>>\n",
      "            >>> @capture_stdout\n",
      "            ... def test_print_fail():\n",
      "            ...     print(\"foo\")\n",
      "            ...     out = sys.stdout.getvalue()\n",
      "            ...     assert out == \"bar\n",
      "        \"\n",
      "            ...\n",
      "            AssertionError: assert 'foo\n",
      "        ' == 'bar\n",
      "        '\n",
      "    \n",
      "    check_output(*popenargs, **kwargs)\n",
      "        Run command with arguments and return its output as a byte string.\n",
      "        \n",
      "        If the exit code was non-zero it raises a CalledProcessError.  The\n",
      "        CalledProcessError object will have the return code in the returncode\n",
      "        attribute and output in the output attribute.\n",
      "        \n",
      "        The arguments are the same as for the Popen constructor.  Example:\n",
      "        \n",
      "        >>> check_output([\"ls\", \"-l\", \"/dev/null\"])\n",
      "        'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n",
      "        \n",
      "        The stdout argument is not allowed as it is used internally.\n",
      "        To capture standard error in the result, use stderr=STDOUT.\n",
      "        \n",
      "        >>> check_output([\"/bin/sh\", \"-c\",\n",
      "        ...               \"ls -l non_existent_file ; exit 0\"],\n",
      "        ...              stderr=STDOUT)\n",
      "        'ls: non_existent_file: No such file or directory\\n'\n",
      "    \n",
      "    close(fignum=None)\n",
      "    \n",
      "    debug(f, *args, **kwargs)\n",
      "    \n",
      "    ensure_clean(filename=None, return_filelike=False)\n",
      "        Gets a temporary path and agrees to remove on close.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : str (optional)\n",
      "            if None, creates a temporary file which is then removed when out of\n",
      "            scope. if passed, creates temporary file with filename as ending.\n",
      "        return_filelike : bool (default False)\n",
      "            if True, returns a file-like which is *always* cleaned. Necessary for\n",
      "            savefig and other functions which want to append extensions.\n",
      "    \n",
      "    equalContents(arr1, arr2)\n",
      "        Checks if the set of unique elements of arr1 and arr2 are equivalent.\n",
      "    \n",
      "    getArangeMat()\n",
      "    \n",
      "    getCols(k)\n",
      "    \n",
      "    getMixedTypeDict()\n",
      "    \n",
      "    getPeriodData(nper=None)\n",
      "    \n",
      "    getSeriesData()\n",
      "    \n",
      "    getTimeSeriesData(nper=None, freq='B')\n",
      "    \n",
      "    get_data_path(f='')\n",
      "        Return the path of a data file, these are relative to the current test\n",
      "        directory.\n",
      "    \n",
      "    get_locales(prefix=None, normalize=True, locale_getter=<function _default_locale_getter at 0x0000021EEB550F28>)\n",
      "        Get all the locales that are available on the system.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        prefix : str\n",
      "            If not ``None`` then return only those locales with the prefix\n",
      "            provided. For example to get all English language locales (those that\n",
      "            start with ``\"en\"``), pass ``prefix=\"en\"``.\n",
      "        normalize : bool\n",
      "            Call ``locale.normalize`` on the resulting list of available locales.\n",
      "            If ``True``, only locales that can be set without throwing an\n",
      "            ``Exception`` are returned.\n",
      "        locale_getter : callable\n",
      "            The function to use to retrieve the current locales. This should return\n",
      "            a string with each locale separated by a newline character.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        locales : list of strings\n",
      "            A list of locale strings that can be set with ``locale.setlocale()``.\n",
      "            For example::\n",
      "        \n",
      "                locale.setlocale(locale.LC_ALL, locale_string)\n",
      "        \n",
      "        On error will return None (no locale available, e.g. Windows)\n",
      "    \n",
      "    is_bool(...)\n",
      "    \n",
      "    is_sorted(seq)\n",
      "    \n",
      "    isiterable(obj)\n",
      "    \n",
      "    makeBoolIndex(k=10, name=None)\n",
      "    \n",
      "    makeCategoricalIndex(k=10, n=3, name=None)\n",
      "        make a length k index or n categories\n",
      "    \n",
      "    makeCustomDataframe(nrows, ncols, c_idx_names=True, r_idx_names=True, c_idx_nlevels=1, r_idx_nlevels=1, data_gen_f=None, c_ndupe_l=None, r_ndupe_l=None, dtype=None, c_idx_type=None, r_idx_type=None)\n",
      "        nrows,  ncols - number of data rows/cols\n",
      "        c_idx_names, idx_names  - False/True/list of strings,  yields No names ,\n",
      "             default names or  uses the provided names for the levels of the\n",
      "             corresponding  index. You can provide a single string when\n",
      "             c_idx_nlevels ==1.\n",
      "        c_idx_nlevels - number of levels in columns index. > 1 will yield MultiIndex\n",
      "        r_idx_nlevels - number of levels in rows index. > 1 will yield MultiIndex\n",
      "        data_gen_f - a function f(row,col) which return the data value\n",
      "             at that position, the default generator used yields values of the form\n",
      "             \"RxCy\" based on position.\n",
      "        c_ndupe_l, r_ndupe_l - list of integers, determines the number\n",
      "             of duplicates for each label at a given level of the corresponding\n",
      "             index. The default `None` value produces a multiplicity of 1 across\n",
      "             all levels, i.e. a unique index. Will accept a partial list of length\n",
      "             N < idx_nlevels, for just the first N levels. If ndupe doesn't divide\n",
      "             nrows/ncol, the last label might have lower multiplicity.\n",
      "        dtype - passed to the DataFrame constructor as is, in case you wish to\n",
      "             have more control in conjuncion with a custom `data_gen_f`\n",
      "        r_idx_type, c_idx_type -  \"i\"/\"f\"/\"s\"/\"u\"/\"dt\"/\"td\".\n",
      "            If idx_type is not None, `idx_nlevels` must be 1.\n",
      "            \"i\"/\"f\" creates an integer/float index,\n",
      "            \"s\"/\"u\" creates a string/unicode index\n",
      "            \"dt\" create a datetime index.\n",
      "            \"td\" create a timedelta index.\n",
      "        \n",
      "             if unspecified, string labels will be generated.\n",
      "        \n",
      "         Examples:\n",
      "        \n",
      "         # 5 row, 3 columns, default names on both, single index on both axis\n",
      "         >> makeCustomDataframe(5,3)\n",
      "        \n",
      "         # make the data a random int between 1 and 100\n",
      "         >> mkdf(5,3,data_gen_f=lambda r,c:randint(1,100))\n",
      "        \n",
      "         # 2-level multiindex on rows with each label duplicated\n",
      "         # twice on first level, default names on both axis, single\n",
      "         # index on both axis\n",
      "         >> a=makeCustomDataframe(5,3,r_idx_nlevels=2,r_ndupe_l=[2])\n",
      "        \n",
      "         # DatetimeIndex on row, index with unicode labels on columns\n",
      "         # no names on either axis\n",
      "         >> a=makeCustomDataframe(5,3,c_idx_names=False,r_idx_names=False,\n",
      "                                  r_idx_type=\"dt\",c_idx_type=\"u\")\n",
      "        \n",
      "         # 4-level multindex on rows with names provided, 2-level multindex\n",
      "         # on columns with default labels and default names.\n",
      "         >> a=makeCustomDataframe(5,3,r_idx_nlevels=4,\n",
      "                                  r_idx_names=[\"FEE\",\"FI\",\"FO\",\"FAM\"],\n",
      "                                  c_idx_nlevels=2)\n",
      "        \n",
      "         >> a=mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)\n",
      "    \n",
      "    makeCustomIndex(nentries, nlevels, prefix='#', names=False, ndupe_l=None, idx_type=None)\n",
      "        Create an index/multindex with given dimensions, levels, names, etc'\n",
      "        \n",
      "        nentries - number of entries in index\n",
      "        nlevels - number of levels (> 1 produces multindex)\n",
      "        prefix - a string prefix for labels\n",
      "        names - (Optional), bool or list of strings. if True will use default\n",
      "           names, if false will use no names, if a list is given, the name of\n",
      "           each level in the index will be taken from the list.\n",
      "        ndupe_l - (Optional), list of ints, the number of rows for which the\n",
      "           label will repeated at the corresponding level, you can specify just\n",
      "           the first few, the rest will use the default ndupe_l of 1.\n",
      "           len(ndupe_l) <= nlevels.\n",
      "        idx_type - \"i\"/\"f\"/\"s\"/\"u\"/\"dt\"/\"p\"/\"td\".\n",
      "           If idx_type is not None, `idx_nlevels` must be 1.\n",
      "           \"i\"/\"f\" creates an integer/float index,\n",
      "           \"s\"/\"u\" creates a string/unicode index\n",
      "           \"dt\" create a datetime index.\n",
      "           \"td\" create a datetime index.\n",
      "        \n",
      "            if unspecified, string labels will be generated.\n",
      "    \n",
      "    makeDataFrame()\n",
      "    \n",
      "    makeDateIndex(k=10, freq='B', name=None)\n",
      "    \n",
      "    makeFloatIndex(k=10, name=None)\n",
      "    \n",
      "    makeFloatSeries(name=None)\n",
      "        # make series\n",
      "    \n",
      "    makeIntIndex(k=10, name=None)\n",
      "    \n",
      "    makeIntervalIndex(k=10, name=None)\n",
      "        make a length k IntervalIndex\n",
      "    \n",
      "    makeMissingCustomDataframe(nrows, ncols, density=0.9, random_state=None, c_idx_names=True, r_idx_names=True, c_idx_nlevels=1, r_idx_nlevels=1, data_gen_f=None, c_ndupe_l=None, r_ndupe_l=None, dtype=None, c_idx_type=None, r_idx_type=None)\n",
      "        Parameters\n",
      "        ----------\n",
      "        Density : float, optional\n",
      "            Float in (0, 1) that gives the percentage of non-missing numbers in\n",
      "            the DataFrame.\n",
      "        random_state : {np.random.RandomState, int}, optional\n",
      "            Random number generator or random seed.\n",
      "        \n",
      "        See makeCustomDataframe for descriptions of the rest of the parameters.\n",
      "    \n",
      "    makeMissingDataframe(density=0.9, random_state=None)\n",
      "    \n",
      "    makeMixedDataFrame()\n",
      "    \n",
      "    makeObjectSeries(name=None)\n",
      "    \n",
      "    makePanel(nper=None)\n",
      "    \n",
      "    makePanel4D(nper=None)\n",
      "    \n",
      "    makePeriodFrame(nper=None)\n",
      "    \n",
      "    makePeriodIndex(k=10, name=None)\n",
      "    \n",
      "    makePeriodPanel(nper=None)\n",
      "    \n",
      "    makePeriodSeries(nper=None, name=None)\n",
      "    \n",
      "    makeRangeIndex(k=10, name=None)\n",
      "    \n",
      "    makeStringIndex(k=10, name=None)\n",
      "        # make index\n",
      "    \n",
      "    makeStringSeries(name=None)\n",
      "    \n",
      "    makeTimeDataFrame(nper=None, freq='B')\n",
      "        # make frame\n",
      "    \n",
      "    makeTimeSeries(nper=None, freq='B', name=None)\n",
      "    \n",
      "    makeTimedeltaIndex(k=10, freq='D', name=None)\n",
      "    \n",
      "    makeUIntIndex(k=10, name=None)\n",
      "    \n",
      "    makeUnicodeIndex(k=10, name=None)\n",
      "    \n",
      "    network(t, url='http://www.google.com', raise_on_error=False, check_before_test=False, error_classes=(<class 'OSError'>, <class 'http.client.HTTPException'>, <class 'TimeoutError'>), skip_errnos=(101, 111, 110, 104, 54, 60), _skip_on_messages=('timed out', 'Server Hangup', 'HTTP Error 503: Service Unavailable', '502: Proxy Error', 'HTTP Error 502: internal error', 'HTTP Error 502', 'HTTP Error 503', 'HTTP Error 403', 'HTTP Error 400', 'Temporary failure in name resolution', 'Name or service not known', 'Connection refused', 'certificate verify'))\n",
      "        Label a test as requiring network connection and, if an error is\n",
      "        encountered, only raise if it does not find a network connection.\n",
      "        \n",
      "        In comparison to ``network``, this assumes an added contract to your test:\n",
      "        you must assert that, under normal conditions, your test will ONLY fail if\n",
      "        it does not have network connectivity.\n",
      "        \n",
      "        You can call this in 3 ways: as a standard decorator, with keyword\n",
      "        arguments, or with a positional argument that is the url to check.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        t : callable\n",
      "            The test requiring network connectivity.\n",
      "        url : path\n",
      "            The url to test via ``pandas.io.common.urlopen`` to check\n",
      "            for connectivity. Defaults to 'http://www.google.com'.\n",
      "        raise_on_error : bool\n",
      "            If True, never catches errors.\n",
      "        check_before_test : bool\n",
      "            If True, checks connectivity before running the test case.\n",
      "        error_classes : tuple or Exception\n",
      "            error classes to ignore. If not in ``error_classes``, raises the error.\n",
      "            defaults to IOError. Be careful about changing the error classes here.\n",
      "        skip_errnos : iterable of int\n",
      "            Any exception that has .errno or .reason.erno set to one\n",
      "            of these values will be skipped with an appropriate\n",
      "            message.\n",
      "        _skip_on_messages: iterable of string\n",
      "            any exception e for which one of the strings is\n",
      "            a substring of str(e) will be skipped with an appropriate\n",
      "            message. Intended to supress errors where an errno isn't available.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        * ``raise_on_error`` supercedes ``check_before_test``\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        t : callable\n",
      "            The decorated test ``t``, with checks for connectivity errors.\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        Tests decorated with @network will fail if it's possible to make a network\n",
      "        connection to another URL (defaults to google.com)::\n",
      "        \n",
      "          >>> from pandas.util.testing import network\n",
      "          >>> from pandas.io.common import urlopen\n",
      "          >>> @network\n",
      "          ... def test_network():\n",
      "          ...     with urlopen(\"rabbit://bonanza.com\"):\n",
      "          ...         pass\n",
      "          Traceback\n",
      "             ...\n",
      "          URLError: <urlopen error unknown url type: rabit>\n",
      "        \n",
      "          You can specify alternative URLs::\n",
      "        \n",
      "            >>> @network(\"http://www.yahoo.com\")\n",
      "            ... def test_something_with_yahoo():\n",
      "            ...    raise IOError(\"Failure Message\")\n",
      "            >>> test_something_with_yahoo()\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "            IOError: Failure Message\n",
      "        \n",
      "        If you set check_before_test, it will check the url first and not run the\n",
      "        test on failure::\n",
      "        \n",
      "            >>> @network(\"failing://url.blaher\", check_before_test=True)\n",
      "            ... def test_something():\n",
      "            ...     print(\"I ran!\")\n",
      "            ...     raise ValueError(\"Failure\")\n",
      "            >>> test_something()\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "        \n",
      "        Errors not related to networking will always be raised.\n",
      "    \n",
      "    optional_args(decorator)\n",
      "        allows a decorator to take optional positional and keyword arguments.\n",
      "        Assumes that taking a single, callable, positional argument means that\n",
      "        it is decorating a function, i.e. something like this::\n",
      "        \n",
      "            @my_decorator\n",
      "            def function(): pass\n",
      "        \n",
      "        Calls decorator with decorator(f, *args, **kwargs)\n",
      "    \n",
      "    patch(ob, attr, value)\n",
      "        Temporarily patch an attribute of an object.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ob : any\n",
      "            The object to patch. This must support attribute assignment for `attr`.\n",
      "        attr : str\n",
      "            The name of the attribute to patch.\n",
      "        value : any\n",
      "            The temporary attribute to assign.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> class C(object):\n",
      "        ...     attribute = 'original'\n",
      "        ...\n",
      "        >>> C.attribute\n",
      "        'original'\n",
      "        >>> with patch(C, 'attribute', 'patched'):\n",
      "        ...     in_context = C.attribute\n",
      "        ...\n",
      "        >>> in_context\n",
      "        'patched'\n",
      "        >>> C.attribute  # the value is reset when the context manager exists\n",
      "        'original'\n",
      "        \n",
      "        Correctly replaces attribute when the manager exits with an exception.\n",
      "        >>> with patch(C, 'attribute', 'patched'):\n",
      "        ...     in_context = C.attribute\n",
      "        ...     raise ValueError()\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        ValueError\n",
      "        >>> in_context\n",
      "        'patched'\n",
      "        >>> C.attribute\n",
      "        'original'\n",
      "    \n",
      "    pudebug(f, *args, **kwargs)\n",
      "    \n",
      "    raise_assert_detail(obj, message, left, right, diff=None)\n",
      "    \n",
      "    rand(...) method of mtrand.RandomState instance\n",
      "        rand(d0, d1, ..., dn)\n",
      "        \n",
      "        Random values in a given shape.\n",
      "        \n",
      "        Create an array of the given shape and populate it with\n",
      "        random samples from a uniform distribution\n",
      "        over ``[0, 1)``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        d0, d1, ..., dn : int, optional\n",
      "            The dimensions of the returned array, should all be positive.\n",
      "            If no argument is given a single Python float is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray, shape ``(d0, d1, ..., dn)``\n",
      "            Random values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        random\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is a convenience function. If you want an interface that\n",
      "        takes a shape-tuple as the first argument, refer to\n",
      "        np.random.random_sample .\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.rand(3,2)\n",
      "        array([[ 0.14022471,  0.96360618],  #random\n",
      "               [ 0.37601032,  0.25528411],  #random\n",
      "               [ 0.49313049,  0.94909878]]) #random\n",
      "    \n",
      "    randbool(size=(), p=0.5)\n",
      "    \n",
      "    randn(...) method of mtrand.RandomState instance\n",
      "        randn(d0, d1, ..., dn)\n",
      "        \n",
      "        Return a sample (or samples) from the \"standard normal\" distribution.\n",
      "        \n",
      "        If positive, int_like or int-convertible arguments are provided,\n",
      "        `randn` generates an array of shape ``(d0, d1, ..., dn)``, filled\n",
      "        with random floats sampled from a univariate \"normal\" (Gaussian)\n",
      "        distribution of mean 0 and variance 1 (if any of the :math:`d_i` are\n",
      "        floats, they are first converted to integers by truncation). A single\n",
      "        float randomly sampled from the distribution is returned if no\n",
      "        argument is provided.\n",
      "        \n",
      "        This is a convenience function.  If you want an interface that takes a\n",
      "        tuple as the first argument, use `numpy.random.standard_normal` instead.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        d0, d1, ..., dn : int, optional\n",
      "            The dimensions of the returned array, should be all positive.\n",
      "            If no argument is given a single Python float is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Z : ndarray or float\n",
      "            A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\n",
      "            the standard normal distribution, or a single such float if\n",
      "            no parameters were supplied.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        random.standard_normal : Similar, but takes a tuple as its argument.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For random samples from :math:`N(\\mu, \\sigma^2)`, use:\n",
      "        \n",
      "        ``sigma * np.random.randn(...) + mu``\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.randn()\n",
      "        2.1923875335537315 #random\n",
      "        \n",
      "        Two-by-four array of samples from N(3, 6.25):\n",
      "        \n",
      "        >>> 2.5 * np.random.randn(2, 4) + 3\n",
      "        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],  #random\n",
      "               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]]) #random\n",
      "    \n",
      "    rands(nchars)\n",
      "        Generate one random byte string.\n",
      "        \n",
      "        See `rands_array` if you want to create an array of random strings.\n",
      "    \n",
      "    rands_array(nchars, size, dtype='O')\n",
      "        Generate an array of byte strings.\n",
      "    \n",
      "    randu(nchars)\n",
      "        Generate one random unicode string.\n",
      "        \n",
      "        See `randu_array` if you want to create an array of random unicode strings.\n",
      "    \n",
      "    randu_array(nchars, size, dtype='O')\n",
      "        Generate an array of unicode strings.\n",
      "    \n",
      "    reset_display_options()\n",
      "        Reset the display options for printing and representing objects.\n",
      "    \n",
      "    reset_testing_mode()\n",
      "    \n",
      "    round_trip_localpath(writer, reader, path=None)\n",
      "        Write an object to file specifed by a py.path LocalPath and read it back\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        writer : callable bound to pandas object\n",
      "            IO writing function (e.g. DataFrame.to_csv )\n",
      "        reader : callable\n",
      "            IO reading function (e.g. pd.read_csv )\n",
      "        path : str, default None\n",
      "            The path where the object is written and then read.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        round_trip_object : pandas object\n",
      "            The original object that was serialized and then re-read.\n",
      "    \n",
      "    round_trip_pathlib(writer, reader, path=None)\n",
      "        Write an object to file specifed by a pathlib.Path and read it back\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        writer : callable bound to pandas object\n",
      "            IO writing function (e.g. DataFrame.to_csv )\n",
      "        reader : callable\n",
      "            IO reading function (e.g. pd.read_csv )\n",
      "        path : str, default None\n",
      "            The path where the object is written and then read.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        round_trip_object : pandas object\n",
      "            The original object that was serialized and then re-read.\n",
      "    \n",
      "    round_trip_pickle(obj, path=None)\n",
      "        Pickle an object and then read it again.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        obj : pandas object\n",
      "            The object to pickle and then re-read.\n",
      "        path : str, default None\n",
      "            The path where the pickled object is written and then read.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        round_trip_pickled_object : pandas object\n",
      "            The original object that was pickled and then re-read.\n",
      "    \n",
      "    set_locale(new_locale, lc_var=0)\n",
      "        Context manager for temporarily setting a locale.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        new_locale : str or tuple\n",
      "            A string of the form <language_country>.<encoding>. For example to set\n",
      "            the current locale to US English with a UTF8 encoding, you would pass\n",
      "            \"en_US.UTF-8\".\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is useful when you want to run a particular block of code under a\n",
      "        particular locale, without globally setting the locale. This probably isn't\n",
      "        thread-safe.\n",
      "    \n",
      "    set_testing_mode()\n",
      "    \n",
      "    set_timezone(tz)\n",
      "        Context manager for temporarily setting a timezone.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        tz : str\n",
      "            A string representing a valid timezone.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from datetime import datetime\n",
      "        >>> from dateutil.tz import tzlocal\n",
      "        >>> tzlocal().tzname(datetime.now())\n",
      "        'IST'\n",
      "        \n",
      "        >>> with set_timezone('US/Eastern'):\n",
      "        ...     tzlocal().tzname(datetime.now())\n",
      "        ...\n",
      "        'EDT'\n",
      "    \n",
      "    set_trace()\n",
      "    \n",
      "    skip_if_no_ne(engine='numexpr')\n",
      "    \n",
      "    skip_if_no_package(pkg_name, min_version=None, max_version=None, app='pandas', checker=<class 'distutils.version.LooseVersion'>)\n",
      "        Check that the min/max version of the required package is installed.\n",
      "        \n",
      "        If the package check fails, the test is automatically skipped.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        pkg_name : string\n",
      "            Name of the required package.\n",
      "        min_version : string, optional\n",
      "            Minimal version number for required package.\n",
      "        max_version : string, optional\n",
      "            Max version number for required package.\n",
      "        app : string, optional\n",
      "            Application that is performing the check. For instance, the\n",
      "            name of the tutorial being executed that depends on specific\n",
      "            packages.\n",
      "        checker : object, optional\n",
      "            The class that will perform the version checking. Default is\n",
      "            distutils.version.LooseVersion.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        package_check('numpy', '1.3')\n",
      "    \n",
      "    stdin_encoding(encoding=None)\n",
      "        Context manager for running bits of code while emulating an arbitrary\n",
      "        stdin encoding.\n",
      "        \n",
      "        >>> import sys\n",
      "        >>> _encoding = sys.stdin.encoding\n",
      "        >>> with stdin_encoding('AES'): sys.stdin.encoding\n",
      "        'AES'\n",
      "        >>> sys.stdin.encoding==_encoding\n",
      "        True\n",
      "    \n",
      "    test_parallel(num_threads=2, kwargs_list=None)\n",
      "        Decorator to run the same function multiple times in parallel.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        num_threads : int, optional\n",
      "            The number of times the function is run in parallel.\n",
      "        kwargs_list : list of dicts, optional\n",
      "            The list of kwargs to update original\n",
      "            function kwargs on different threads.\n",
      "        Notes\n",
      "        -----\n",
      "        This decorator does not pass the return value of the decorated function.\n",
      "        \n",
      "        Original from scikit-image:\n",
      "        \n",
      "        https://github.com/scikit-image/scikit-image/pull/1519\n",
      "    \n",
      "    unichr = chr(i, /)\n",
      "        Return a Unicode string of one character with ordinal i; 0 <= i <= 0x10ffff.\n",
      "    \n",
      "    use_numexpr(use, min_elements=None)\n",
      "    \n",
      "    with_connectivity_check = network(t, url='http://www.google.com', raise_on_error=False, check_before_test=False, error_classes=(<class 'OSError'>, <class 'http.client.HTTPException'>, <class 'TimeoutError'>), skip_errnos=(101, 111, 110, 104, 54, 60), _skip_on_messages=('timed out', 'Server Hangup', 'HTTP Error 503: Service Unavailable', '502: Proxy Error', 'HTTP Error 502: internal error', 'HTTP Error 502', 'HTTP Error 503', 'HTTP Error 403', 'HTTP Error 400', 'Temporary failure in name resolution', 'Name or service not known', 'Connection refused', 'certificate verify'))\n",
      "        Label a test as requiring network connection and, if an error is\n",
      "        encountered, only raise if it does not find a network connection.\n",
      "        \n",
      "        In comparison to ``network``, this assumes an added contract to your test:\n",
      "        you must assert that, under normal conditions, your test will ONLY fail if\n",
      "        it does not have network connectivity.\n",
      "        \n",
      "        You can call this in 3 ways: as a standard decorator, with keyword\n",
      "        arguments, or with a positional argument that is the url to check.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        t : callable\n",
      "            The test requiring network connectivity.\n",
      "        url : path\n",
      "            The url to test via ``pandas.io.common.urlopen`` to check\n",
      "            for connectivity. Defaults to 'http://www.google.com'.\n",
      "        raise_on_error : bool\n",
      "            If True, never catches errors.\n",
      "        check_before_test : bool\n",
      "            If True, checks connectivity before running the test case.\n",
      "        error_classes : tuple or Exception\n",
      "            error classes to ignore. If not in ``error_classes``, raises the error.\n",
      "            defaults to IOError. Be careful about changing the error classes here.\n",
      "        skip_errnos : iterable of int\n",
      "            Any exception that has .errno or .reason.erno set to one\n",
      "            of these values will be skipped with an appropriate\n",
      "            message.\n",
      "        _skip_on_messages: iterable of string\n",
      "            any exception e for which one of the strings is\n",
      "            a substring of str(e) will be skipped with an appropriate\n",
      "            message. Intended to supress errors where an errno isn't available.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        * ``raise_on_error`` supercedes ``check_before_test``\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        t : callable\n",
      "            The decorated test ``t``, with checks for connectivity errors.\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        Tests decorated with @network will fail if it's possible to make a network\n",
      "        connection to another URL (defaults to google.com)::\n",
      "        \n",
      "          >>> from pandas.util.testing import network\n",
      "          >>> from pandas.io.common import urlopen\n",
      "          >>> @network\n",
      "          ... def test_network():\n",
      "          ...     with urlopen(\"rabbit://bonanza.com\"):\n",
      "          ...         pass\n",
      "          Traceback\n",
      "             ...\n",
      "          URLError: <urlopen error unknown url type: rabit>\n",
      "        \n",
      "          You can specify alternative URLs::\n",
      "        \n",
      "            >>> @network(\"http://www.yahoo.com\")\n",
      "            ... def test_something_with_yahoo():\n",
      "            ...    raise IOError(\"Failure Message\")\n",
      "            >>> test_something_with_yahoo()\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "            IOError: Failure Message\n",
      "        \n",
      "        If you set check_before_test, it will check the url first and not run the\n",
      "        test on failure::\n",
      "        \n",
      "            >>> @network(\"failing://url.blaher\", check_before_test=True)\n",
      "            ... def test_something():\n",
      "            ...     print(\"I ran!\")\n",
      "            ...     raise ValueError(\"Failure\")\n",
      "            >>> test_something()\n",
      "            Traceback (most recent call last):\n",
      "                ...\n",
      "        \n",
      "        Errors not related to networking will always be raised.\n",
      "\n",
      "DATA\n",
      "    K = 4\n",
      "    N = 3\n",
      "    PY3 = True\n",
      "    RANDS_CHARS = array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', '... '3',...\n",
      "    RANDU_CHARS = array(['', '', '', '', '', '', '', '', '... '3',...\n",
      "    assert_panel4d_equal = functools.partial(<function assert_panelnd_equa...\n",
      "    assert_panel_equal = functools.partial(<function assert_panelnd_equal....\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\home\\anaconda3\\lib\\site-packages\\pandas\\util\\testing.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>0.470422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>1.286901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.036826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date variable     value\n",
       "0 2000-01-03        A  0.470422\n",
       "1 2000-01-04        A  1.286901\n",
       "2 2000-01-05        A -0.036826"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['variable']=='A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>0.470422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>1.286901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.036826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>B</td>\n",
       "      <td>0.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>B</td>\n",
       "      <td>0.985982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.199990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.111952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>0.664046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>D</td>\n",
       "      <td>1.216088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date variable     value\n",
       "0 2000-01-03        A  0.470422\n",
       "1 2000-01-04        A  1.286901\n",
       "2 2000-01-05        A -0.036826\n",
       "3 2000-01-03        B  0.392200\n",
       "4 2000-01-04        B  0.985982\n",
       "5 2000-01-05        B -0.018447\n",
       "6 2000-01-03        C -0.199990\n",
       "7 2000-01-04        C  0.111952\n",
       "8 2000-01-05        C  0.664046\n",
       "9 2000-01-03        D  1.216088"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[0:10].copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0.470422</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>-0.199990</td>\n",
       "      <td>1.216088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1.286901</td>\n",
       "      <td>0.985982</td>\n",
       "      <td>0.111952</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-0.018447</td>\n",
       "      <td>0.664046</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable           A         B         C         D\n",
       "date                                              \n",
       "2000-01-03  0.470422  0.392200 -0.199990  1.216088\n",
       "2000-01-04  1.286901  0.985982  0.111952       NaN\n",
       "2000-01-05 -0.036826 -0.018447  0.664046       NaN"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.pivot(index='date', columns='variable', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>0.470422</td>\n",
       "      <td>0.940845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>1.286901</td>\n",
       "      <td>2.573801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-0.073653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>B</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>B</td>\n",
       "      <td>0.985982</td>\n",
       "      <td>1.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.018447</td>\n",
       "      <td>-0.036894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.199990</td>\n",
       "      <td>-0.399980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.111952</td>\n",
       "      <td>0.223905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>0.664046</td>\n",
       "      <td>1.328093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>D</td>\n",
       "      <td>1.216088</td>\n",
       "      <td>2.432175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date variable     value    value2\n",
       "0 2000-01-03        A  0.470422  0.940845\n",
       "1 2000-01-04        A  1.286901  2.573801\n",
       "2 2000-01-05        A -0.036826 -0.073653\n",
       "3 2000-01-03        B  0.392200  0.784400\n",
       "4 2000-01-04        B  0.985982  1.971963\n",
       "5 2000-01-05        B -0.018447 -0.036894\n",
       "6 2000-01-03        C -0.199990 -0.399980\n",
       "7 2000-01-04        C  0.111952  0.223905\n",
       "8 2000-01-05        C  0.664046  1.328093\n",
       "9 2000-01-03        D  1.216088  2.432175"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['value2'] = df1['value'] * 2\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0.940845</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>-0.399980</td>\n",
       "      <td>2.432175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>2.573801</td>\n",
       "      <td>1.971963</td>\n",
       "      <td>0.223905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.073653</td>\n",
       "      <td>-0.036894</td>\n",
       "      <td>1.328093</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable           A         B         C         D\n",
       "date                                              \n",
       "2000-01-03  0.940845  0.784400 -0.399980  2.432175\n",
       "2000-01-04  2.573801  1.971963  0.223905       NaN\n",
       "2000-01-05 -0.073653 -0.036894  1.328093       NaN"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted = df1.pivot(index='date', columns='variable')\n",
    "pivoted['value2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bar', 'one'),\n",
       " ('bar', 'two'),\n",
       " ('baz', 'one'),\n",
       " ('baz', 'two'),\n",
       " ('foo', 'one'),\n",
       " ('foo', 'two'),\n",
       " ('qux', 'one'),\n",
       " ('qux', 'two')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "   ...:                      'foo', 'foo', 'qux', 'qux'],\n",
    "   ...:                     ['one', 'two', 'one', 'two',\n",
    "   ...:                      'one', 'two', 'one', 'two']]))\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],\n",
       "           labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]],\n",
       "           names=['first', 'second'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.229533</td>\n",
       "      <td>1.180940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.360108</td>\n",
       "      <td>-0.875396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.188990</td>\n",
       "      <td>-0.959360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.893057</td>\n",
       "      <td>-1.808227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>0.928166</td>\n",
       "      <td>-0.135463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.964639</td>\n",
       "      <td>0.051308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">qux</th>\n",
       "      <th>one</th>\n",
       "      <td>0.605947</td>\n",
       "      <td>0.850131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.591137</td>\n",
       "      <td>1.308144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.229533  1.180940\n",
       "      two    -0.360108 -0.875396\n",
       "baz   one    -1.188990 -0.959360\n",
       "      two    -1.893057 -1.808227\n",
       "foo   one     0.928166 -0.135463\n",
       "      two    -1.964639  0.051308\n",
       "qux   one     0.605947  0.850131\n",
       "      two    -1.591137  1.308144"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.229533</td>\n",
       "      <td>1.180940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.360108</td>\n",
       "      <td>-0.875396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.188990</td>\n",
       "      <td>-0.959360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.893057</td>\n",
       "      <td>-1.808227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.229533  1.180940\n",
       "      two    -0.360108 -0.875396\n",
       "baz   one    -1.188990 -0.959360\n",
       "      two    -1.893057 -1.808227"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[:4].copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second   \n",
       "bar    one     A    0.229533\n",
       "               B    1.180940\n",
       "       two     A   -0.360108\n",
       "               B   -0.875396\n",
       "baz    one     A   -1.188990\n",
       "               B   -0.959360\n",
       "       two     A   -1.893057\n",
       "               B   -1.808227\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = df2.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two'], ['A', 'B']],\n",
       "           labels=[[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1]],\n",
       "           names=['first', 'second', None])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.229533</td>\n",
       "      <td>1.180940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.360108</td>\n",
       "      <td>-0.875396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.188990</td>\n",
       "      <td>-0.959360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.893057</td>\n",
       "      <td>-1.808227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.229533  1.180940\n",
       "      two    -0.360108 -0.875396\n",
       "baz   one    -1.188990 -0.959360\n",
       "      two    -1.893057 -1.808227"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>bar</th>\n",
       "      <th>baz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">one</th>\n",
       "      <th>A</th>\n",
       "      <td>0.229533</td>\n",
       "      <td>-1.188990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.180940</td>\n",
       "      <td>-0.959360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">two</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.360108</td>\n",
       "      <td>-1.893057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.875396</td>\n",
       "      <td>-1.808227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first          bar       baz\n",
       "second                      \n",
       "one    A  0.229533 -1.188990\n",
       "       B  1.180940 -0.959360\n",
       "two    A -0.360108 -1.893057\n",
       "       B -0.875396 -1.808227"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.229533</td>\n",
       "      <td>1.180940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.360108</td>\n",
       "      <td>-0.875396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.188990</td>\n",
       "      <td>-0.959360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.893057</td>\n",
       "      <td>-1.808227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.229533  1.180940\n",
       "      two    -0.360108 -0.875396\n",
       "baz   one    -1.188990 -0.959360\n",
       "      two    -1.893057 -1.808227"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second   \n",
       "bar    one     A    0.229533\n",
       "               B    1.180940\n",
       "       two     A   -0.360108\n",
       "               B   -0.875396\n",
       "baz    one     A   -1.188990\n",
       "               B   -0.959360\n",
       "       two     A   -1.893057\n",
       "               B   -1.808227\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>0.229533</td>\n",
       "      <td>1.180940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.360108</td>\n",
       "      <td>-0.875396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.188990</td>\n",
       "      <td>-0.959360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.893057</td>\n",
       "      <td>-1.808227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>0.928166</td>\n",
       "      <td>-0.135463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.964639</td>\n",
       "      <td>0.051308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">qux</th>\n",
       "      <th>one</th>\n",
       "      <td>0.605947</td>\n",
       "      <td>0.850131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.591137</td>\n",
       "      <td>1.308144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     0.229533  1.180940\n",
       "      two    -0.360108 -0.875396\n",
       "baz   one    -1.188990 -0.959360\n",
       "      two    -1.893057 -1.808227\n",
       "foo   one     0.928166 -0.135463\n",
       "      two    -1.964639  0.051308\n",
       "qux   one     0.605947  0.850131\n",
       "      two    -1.591137  1.308144"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second   \n",
       "bar    one     A    0.229533\n",
       "               B    1.180940\n",
       "       two     A   -0.360108\n",
       "               B   -0.875396\n",
       "baz    one     A   -1.188990\n",
       "               B   -0.959360\n",
       "       two     A   -1.893057\n",
       "               B   -1.808227\n",
       "foo    one     A    0.928166\n",
       "               B   -0.135463\n",
       "       two     A   -1.964639\n",
       "               B    0.051308\n",
       "qux    one     A    0.605947\n",
       "               B    0.850131\n",
       "       two     A   -1.591137\n",
       "               B    1.308144\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.955935</td>\n",
       "      <td>-1.184404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.609215</td>\n",
       "      <td>-1.240981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.018117</td>\n",
       "      <td>0.706581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>-0.371389</td>\n",
       "      <td>-0.395869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>0.125718</td>\n",
       "      <td>-0.209153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.446443</td>\n",
       "      <td>1.612916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>two</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.659526</td>\n",
       "      <td>-0.647838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.556809</td>\n",
       "      <td>0.966120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>-1.522588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.440249</td>\n",
       "      <td>-1.203995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>two</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>-1.473991</td>\n",
       "      <td>0.365113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>three</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>-0.742968</td>\n",
       "      <td>-0.073726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A  B    C         D         E\n",
       "0     one  A  foo -0.955935 -1.184404\n",
       "1     one  B  foo -0.609215 -1.240981\n",
       "2     two  C  foo -0.018117  0.706581\n",
       "3   three  A  bar -0.371389 -0.395869\n",
       "4     one  B  bar  0.125718 -0.209153\n",
       "5     one  C  bar  1.446443  1.612916\n",
       "6     two  A  foo -0.659526 -0.647838\n",
       "7   three  B  foo -0.556809  0.966120\n",
       "8     one  C  foo  0.089385 -1.522588\n",
       "9     one  A  bar  1.440249 -1.203995\n",
       "10    two  B  bar -1.473991  0.365113\n",
       "11  three  C  bar -0.742968 -0.073726"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,\n",
    "   .....:                    'B' : ['A', 'B', 'C'] * 4,\n",
    "   .....:                    'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "   .....:                    'D' : np.random.randn(12),\n",
    "   .....:                    'E' : np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">one</th>\n",
       "      <th>A</th>\n",
       "      <td>1.440249</td>\n",
       "      <td>-0.955935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.125718</td>\n",
       "      <td>-0.609215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.446443</td>\n",
       "      <td>0.089385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">three</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.371389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.556809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.742968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">two</th>\n",
       "      <th>A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.659526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-1.473991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C             bar       foo\n",
       "A     B                    \n",
       "one   A  1.440249 -0.955935\n",
       "      B  0.125718 -0.609215\n",
       "      C  1.446443  0.089385\n",
       "three A -0.371389       NaN\n",
       "      B       NaN -0.556809\n",
       "      C -0.742968       NaN\n",
       "two   A       NaN -0.659526\n",
       "      B -1.473991       NaN\n",
       "      C       NaN -0.018117"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(values='D', index=['A', 'B'], columns='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.955935</td>\n",
       "      <td>-1.184404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.609215</td>\n",
       "      <td>-1.240981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.018117</td>\n",
       "      <td>0.706581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>-0.371389</td>\n",
       "      <td>-0.395869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>0.125718</td>\n",
       "      <td>-0.209153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.446443</td>\n",
       "      <td>1.612916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>two</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.659526</td>\n",
       "      <td>-0.647838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.556809</td>\n",
       "      <td>0.966120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>-1.522588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.440249</td>\n",
       "      <td>-1.203995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>two</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>-1.473991</td>\n",
       "      <td>0.365113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>three</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>-0.742968</td>\n",
       "      <td>-0.073726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A  B    C         D         E\n",
       "0     one  A  foo -0.955935 -1.184404\n",
       "1     one  B  foo -0.609215 -1.240981\n",
       "2     two  C  foo -0.018117  0.706581\n",
       "3   three  A  bar -0.371389 -0.395869\n",
       "4     one  B  bar  0.125718 -0.209153\n",
       "5     one  C  bar  1.446443  1.612916\n",
       "6     two  A  foo -0.659526 -0.647838\n",
       "7   three  B  foo -0.556809  0.966120\n",
       "8     one  C  foo  0.089385 -1.522588\n",
       "9     one  A  bar  1.440249 -1.203995\n",
       "10    two  B  bar -1.473991  0.365113\n",
       "11  three  C  bar -0.742968 -0.073726"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      6\n",
       "three    3\n",
       "two      3\n",
       "Name: A, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
